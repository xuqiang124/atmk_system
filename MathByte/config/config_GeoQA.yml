# this config is for dataset GeoQA
cache_file_h5py: "../file_data/a7/math_data.h5"
cache_file_pickle: "../file_data/a7/vocab_label.pkl"
embeddings: "../file_data/a7/embeddings.pkl"
maxlen: 120 # 句子最大长度
emb_size: 300
epochs: 100
batch_size: 256 # 批处理尺寸, 感觉原则上越大越好,尤其是样本不均衡的时候, batch_size设置影响比较大
alpha: 4 # new model 的 loss 中的 alpha
hidden_size: 512 # lstm
num_classes_list: [49]
l_patience: 2  # patience for early stopping
b_patience: 3 # patience for basic model with a bigger patience