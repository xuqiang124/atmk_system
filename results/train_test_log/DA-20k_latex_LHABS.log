/home/dzq/anaconda3/envs/k121/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/home/dzq/anaconda3/envs/k121/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). 
 The versions of TensorFlow you are currently using is 2.7.0 and is not supported. 
Some things might work, some things might not.
If you were to encounter a bug, do not file an issue.
If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. 
You can find the compatibility matrix in TensorFlow Addon's readme:
https://github.com/tensorflow/addons
  warnings.warn(
2024-06-04 15:30:23,616 : INFO : Loading config...
2024-06-04 15:30:23,618 : INFO : {'cache_file_h5py': '../file_data/a32/math_data_latex.h5', 'cache_file_pickle': '../file_data/a32/vocab_label.pkl', 'embeddings': '../file_data/a32/embeddings.pkl', 'maxlen': 150, 'emb_size': 300, 'epochs': 150, 'batch_size': 512, 'alpha': 4, 'hidden_size': 512, 'num_classes_list': [15, 427], 'l_patience': 2, 'b_patience': 10}
2024-06-04 15:30:23,618 : INFO : Loading data...
2024-06-04 15:30:24,082 : INFO : Loading embeddings...
2024-06-04 15:30:24,153 : INFO : model name labs
TOTAL: 22498 TRAIN: [[ 126    3 1315 ...    0    0    0]
 [  44    3   17 ...    0    0    0]
 [ 216    3   11 ...    0    0    0]
 ...
 [ 130    3   78 ...    0    0    0]
 [ 238    3  134 ...    0    0    0]
 [  59    3   78 ...    0    0    0]] 16873 TEST: [[  105     3  1490 ...   930  1490   262]
 [  238     3  2235 ...     0     0     0]
 [  172     3   134 ...     0     0     0]
 ...
 [  161     3  2144 ... 82330  1152 33879]
 [  161     3  4753 ...     0     0     0]
 [  189     3    17 ...     0     0     0]] 5625
2024-06-04 15:30:24,187 : INFO : =====Start final=====
13498
3375
5625
2024-06-04 15:30:24.616879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:30:24.640192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:30:24.640298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:30:24.640527: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-04 15:30:24.642089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:30:24.642188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:30:24.642249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:30:24.974041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:30:24.974169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:30:24.974240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:30:24.974309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22102 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem (Slic  (None, 15, 300)     0           ['label_emb[0][0]']              
 ingOpLambda)                                                                                     
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem[0][0]'
                                                                 ]                                
                                                                                                  
 permute (Permute)              (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda (Lambda)                (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute[0][0]']                
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda[0][0]']                 
 Dense)                                                                                           
                                                                                                  
 lambda_1 (Lambda)              (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean (TFOpLambd  (None, 1024)        0           ['BiLSTM[0][0]']                 
 a)                                                                                               
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_1[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 tf.concat (TFOpLambda)         (None, 2048)         0           ['tf.math.reduce_mean[0][0]',    
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense (Dense)                  (None, 1024)         2098176     ['tf.concat[0][0]']              
                                                                                                  
 dense_1 (Dense)                (None, 15)           15375       ['dense[0][0]']                  
                                                                                                  
 tf.nn.softmax (TFOpLambda)     (None, 15)           0           ['dense_1[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 15, 1)        0           ['tf.nn.softmax[0][0]']          
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims[0][0]']         
 (Dense)                                                                                          
                                                                                                  
 permute_1 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_2 (Lambda)              (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_1[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 15, 150)      22650       ['lambda_2[0][0]']               
                                                                                                  
 tf.math.reduce_mean_1 (TFOpLam  (None, 150)         0           ['dense_2[0][0]']                
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_1 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_1[0][0]']  
                                                                                                  
 tf.__operators__.getitem_1 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 tf.math.multiply (TFOpLambda)  (None, 150, 1024)    0           ['BiLSTM[0][0]',                 
                                                                  'tf.expand_dims_1[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_1[0][0
                                                                 ]']                              
                                                                                                  
 permute_2 (Permute)            (None, 1024, 150)    0           ['tf.math.multiply[0][0]']       
                                                                                                  
 lambda_3 (Lambda)              (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_2[0][0]']              
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_3[0][0]']               
 Dense)                                                                                           
                                                                                                  
 lambda_4 (Lambda)              (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply[0][0]']       
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_4[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
==================================================================================================
Total params: 31,474,320
Trainable params: 6,695,820
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
2 patience
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem (Slic  (None, 15, 300)     0           ['label_emb[0][0]']              
 ingOpLambda)                                                                                     
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem[0][0]'
                                                                 ]                                
                                                                                                  
 permute (Permute)              (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda (Lambda)                (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute[0][0]']                
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda[0][0]']                 
 Dense)                                                                                           
                                                                                                  
 lambda_1 (Lambda)              (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean (TFOpLambd  (None, 1024)        0           ['BiLSTM[0][0]']                 
 a)                                                                                               
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_1[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 tf.concat (TFOpLambda)         (None, 2048)         0           ['tf.math.reduce_mean[0][0]',    
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense (Dense)                  (None, 1024)         2098176     ['tf.concat[0][0]']              
                                                                                                  
 dense_1 (Dense)                (None, 15)           15375       ['dense[0][0]']                  
                                                                                                  
 tf.nn.softmax (TFOpLambda)     (None, 15)           0           ['dense_1[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 15, 1)        0           ['tf.nn.softmax[0][0]']          
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims[0][0]']         
 (Dense)                                                                                          
                                                                                                  
 permute_1 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_2 (Lambda)              (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_1[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 15, 150)      22650       ['lambda_2[0][0]']               
                                                                                                  
 tf.math.reduce_mean_1 (TFOpLam  (None, 150)         0           ['dense_2[0][0]']                
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_1 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_1[0][0]']  
                                                                                                  
 tf.__operators__.getitem_1 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 tf.math.multiply (TFOpLambda)  (None, 150, 1024)    0           ['BiLSTM[0][0]',                 
                                                                  'tf.expand_dims_1[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_1[0][0
                                                                 ]']                              
                                                                                                  
 permute_2 (Permute)            (None, 1024, 150)    0           ['tf.math.multiply[0][0]']       
                                                                                                  
 lambda_3 (Lambda)              (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_2[0][0]']              
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_3[0][0]']               
 Dense)                                                                                           
                                                                                                  
 lambda_4 (Lambda)              (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply[0][0]']       
                                                                                                  
 tf.__operators__.getitem_2 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_4[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 label_lcm_emb (Dense)          (None, 427, 1024)    308224      ['tf.__operators__.getitem_2[0][0
                                                                 ]']                              
                                                                                                  
 dot (Dot)                      (None, 427)          0           ['label_lcm_emb[0][0]',          
                                                                  '1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 label_sim_dict (Dense)         (None, 427)          182756      ['dot[0][0]']                    
                                                                                                  
 concatenate (Concatenate)      (None, 854)          0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 31,965,300
Trainable params: 7,186,800
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
Epoch 1/150
2024-06-04 15:30:28.471003: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2024-06-04 15:30:28.504462: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8906
27/27 [==============================] - ETA: 0s - loss: 0.5350 - lcm_precision_1k: 0.0878 - lcm_precision_2k: 0.0760 - lcm_precision_3k: 0.0707 - lcm_precision_5k: 0.0615 - lcm_recall_1k: 0.0441 - lcm_recall_2k: 0.0767 - lcm_recall_3k: 0.1088 - lcm_recall_5k: 0.1597 - lcm_f1_1k: 0.0586 - lcm_f1_2k: 0.0763 - lcm_f1_3k: 0.0856 - lcm_f1_5k: 0.0887 - lcm_accuracy_1k: 0.0878 - lcm_accuracy_2k: 0.1460 - lcm_accuracy_3k: 0.1973 - lcm_accuracy_5k: 0.2657 - lcm_hamming_loss_k: 0.0064
Epoch 00001: val_loss improved from inf to 0.46285, saving model to logs/lnqtuh-labs-0604-153024/model/checkpoint_labs.h5
27/27 [==============================] - 14s 417ms/step - loss: 0.5350 - lcm_precision_1k: 0.0878 - lcm_precision_2k: 0.0760 - lcm_precision_3k: 0.0707 - lcm_precision_5k: 0.0615 - lcm_recall_1k: 0.0441 - lcm_recall_2k: 0.0767 - lcm_recall_3k: 0.1088 - lcm_recall_5k: 0.1597 - lcm_f1_1k: 0.0586 - lcm_f1_2k: 0.0763 - lcm_f1_3k: 0.0856 - lcm_f1_5k: 0.0887 - lcm_accuracy_1k: 0.0878 - lcm_accuracy_2k: 0.1460 - lcm_accuracy_3k: 0.1973 - lcm_accuracy_5k: 0.2657 - lcm_hamming_loss_k: 0.0064 - val_loss: 0.4629 - val_lcm_precision_1k: 0.1146 - val_lcm_precision_2k: 0.1185 - val_lcm_precision_3k: 0.1203 - val_lcm_precision_5k: 0.1155 - val_lcm_recall_1k: 0.0608 - val_lcm_recall_2k: 0.1293 - val_lcm_recall_3k: 0.1992 - val_lcm_recall_5k: 0.3133 - val_lcm_f1_1k: 0.0793 - val_lcm_f1_2k: 0.1236 - val_lcm_f1_3k: 0.1499 - val_lcm_f1_5k: 0.1687 - val_lcm_accuracy_1k: 0.1146 - val_lcm_accuracy_2k: 0.2171 - val_lcm_accuracy_3k: 0.3207 - val_lcm_accuracy_5k: 0.4574 - val_lcm_hamming_loss_k: 0.0062
Epoch 2/150
27/27 [==============================] - ETA: 0s - loss: 0.4073 - lcm_precision_1k: 0.3224 - lcm_precision_2k: 0.2718 - lcm_precision_3k: 0.2345 - lcm_precision_5k: 0.1871 - lcm_recall_1k: 0.1842 - lcm_recall_2k: 0.3022 - lcm_recall_3k: 0.3839 - lcm_recall_5k: 0.5025 - lcm_f1_1k: 0.2343 - lcm_f1_2k: 0.2861 - lcm_f1_3k: 0.2911 - lcm_f1_5k: 0.2727 - lcm_accuracy_1k: 0.3224 - lcm_accuracy_2k: 0.4644 - lcm_accuracy_3k: 0.5477 - lcm_accuracy_5k: 0.6546 - lcm_hamming_loss_k: 0.0053
Epoch 00002: val_loss improved from 0.46285 to 0.36953, saving model to logs/lnqtuh-labs-0604-153024/model/checkpoint_labs.h5
27/27 [==============================] - 11s 424ms/step - loss: 0.4073 - lcm_precision_1k: 0.3224 - lcm_precision_2k: 0.2718 - lcm_precision_3k: 0.2345 - lcm_precision_5k: 0.1871 - lcm_recall_1k: 0.1842 - lcm_recall_2k: 0.3022 - lcm_recall_3k: 0.3839 - lcm_recall_5k: 0.5025 - lcm_f1_1k: 0.2343 - lcm_f1_2k: 0.2861 - lcm_f1_3k: 0.2911 - lcm_f1_5k: 0.2727 - lcm_accuracy_1k: 0.3224 - lcm_accuracy_2k: 0.4644 - lcm_accuracy_3k: 0.5477 - lcm_accuracy_5k: 0.6546 - lcm_hamming_loss_k: 0.0053 - val_loss: 0.3695 - val_lcm_precision_1k: 0.3808 - val_lcm_precision_2k: 0.3132 - val_lcm_precision_3k: 0.2644 - val_lcm_precision_5k: 0.2040 - val_lcm_recall_1k: 0.2338 - val_lcm_recall_2k: 0.3666 - val_lcm_recall_3k: 0.4582 - val_lcm_recall_5k: 0.5708 - val_lcm_f1_1k: 0.2896 - val_lcm_f1_2k: 0.3377 - val_lcm_f1_3k: 0.3352 - val_lcm_f1_5k: 0.3005 - val_lcm_accuracy_1k: 0.3808 - val_lcm_accuracy_2k: 0.5380 - val_lcm_accuracy_3k: 0.6267 - val_lcm_accuracy_5k: 0.7254 - val_lcm_hamming_loss_k: 0.0050
Epoch 3/150
27/27 [==============================] - ETA: 0s - loss: 0.3457 - lcm_precision_1k: 0.4442 - lcm_precision_2k: 0.3614 - lcm_precision_3k: 0.3019 - lcm_precision_5k: 0.2277 - lcm_recall_1k: 0.2650 - lcm_recall_2k: 0.4113 - lcm_recall_3k: 0.5065 - lcm_recall_5k: 0.6222 - lcm_f1_1k: 0.3319 - lcm_f1_2k: 0.3847 - lcm_f1_3k: 0.3782 - lcm_f1_5k: 0.3334 - lcm_accuracy_1k: 0.4442 - lcm_accuracy_2k: 0.5981 - lcm_accuracy_3k: 0.6827 - lcm_accuracy_5k: 0.7723 - lcm_hamming_loss_k: 0.0048 ETA: 5s - loss: 0.3561 - lcm_precision_1k: 0.4199 - lcm_precision_2k: 0.3398 - lcm_precision_3k: 0.2882 - lcm_precision_5k: 0.2198 - lcm_recall_1k: 0.2517 - lcm_recall_2k: 0.3901 - lcm_recall_3k: 0.4867 - lcm_recall_5k: 0.6035 - lcm_f1_1k: 0.3148 - lcm_f1_2k: 0.3632 - lcm_f1_3k: 0.3620 - lcm_f1_5k: 0.3222 - lcm_accuracy_1k: 0.4199 - lcm_accuracy_2k: 0.5731 - lcm_accuracy_3k: 0.6628 - lcm_accuracy_5k: 0.7
Epoch 00003: val_loss improved from 0.36953 to 0.34085, saving model to logs/lnqtuh-labs-0604-153024/model/checkpoint_labs.h5
27/27 [==============================] - 11s 423ms/step - loss: 0.3457 - lcm_precision_1k: 0.4442 - lcm_precision_2k: 0.3614 - lcm_precision_3k: 0.3019 - lcm_precision_5k: 0.2277 - lcm_recall_1k: 0.2650 - lcm_recall_2k: 0.4113 - lcm_recall_3k: 0.5065 - lcm_recall_5k: 0.6222 - lcm_f1_1k: 0.3319 - lcm_f1_2k: 0.3847 - lcm_f1_3k: 0.3782 - lcm_f1_5k: 0.3334 - lcm_accuracy_1k: 0.4442 - lcm_accuracy_2k: 0.5981 - lcm_accuracy_3k: 0.6827 - lcm_accuracy_5k: 0.7723 - lcm_hamming_loss_k: 0.0048 - val_loss: 0.3408 - val_lcm_precision_1k: 0.4408 - val_lcm_precision_2k: 0.3658 - val_lcm_precision_3k: 0.3021 - val_lcm_precision_5k: 0.2226 - val_lcm_recall_1k: 0.2715 - val_lcm_recall_2k: 0.4293 - val_lcm_recall_3k: 0.5213 - val_lcm_recall_5k: 0.6222 - val_lcm_f1_1k: 0.3359 - val_lcm_f1_2k: 0.3949 - val_lcm_f1_3k: 0.3825 - val_lcm_f1_5k: 0.3278 - val_lcm_accuracy_1k: 0.4408 - val_lcm_accuracy_2k: 0.6076 - val_lcm_accuracy_3k: 0.6888 - val_lcm_accuracy_5k: 0.7687 - val_lcm_hamming_loss_k: 0.0047
Epoch 4/150
27/27 [==============================] - ETA: 0s - loss: 0.3215 - lcm_precision_1k: 0.4999 - lcm_precision_2k: 0.4004 - lcm_precision_3k: 0.3293 - lcm_precision_5k: 0.2436 - lcm_recall_1k: 0.3039 - lcm_recall_2k: 0.4614 - lcm_recall_3k: 0.5569 - lcm_recall_5k: 0.6682 - lcm_f1_1k: 0.3779 - lcm_f1_2k: 0.4287 - lcm_f1_3k: 0.4138 - lcm_f1_5k: 0.3569 - lcm_accuracy_1k: 0.4999 - lcm_accuracy_2k: 0.6532 - lcm_accuracy_3k: 0.7324 - lcm_accuracy_5k: 0.8127 - lcm_hamming_loss_k: 0.0045
Epoch 00004: val_loss improved from 0.34085 to 0.32260, saving model to logs/lnqtuh-labs-0604-153024/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.3215 - lcm_precision_1k: 0.4999 - lcm_precision_2k: 0.4004 - lcm_precision_3k: 0.3293 - lcm_precision_5k: 0.2436 - lcm_recall_1k: 0.3039 - lcm_recall_2k: 0.4614 - lcm_recall_3k: 0.5569 - lcm_recall_5k: 0.6682 - lcm_f1_1k: 0.3779 - lcm_f1_2k: 0.4287 - lcm_f1_3k: 0.4138 - lcm_f1_5k: 0.3569 - lcm_accuracy_1k: 0.4999 - lcm_accuracy_2k: 0.6532 - lcm_accuracy_3k: 0.7324 - lcm_accuracy_5k: 0.8127 - lcm_hamming_loss_k: 0.0045 - val_loss: 0.3226 - val_lcm_precision_1k: 0.4835 - val_lcm_precision_2k: 0.3843 - val_lcm_precision_3k: 0.3164 - val_lcm_precision_5k: 0.2364 - val_lcm_recall_1k: 0.3038 - val_lcm_recall_2k: 0.4559 - val_lcm_recall_3k: 0.5521 - val_lcm_recall_5k: 0.6639 - val_lcm_f1_1k: 0.3730 - val_lcm_f1_2k: 0.4169 - val_lcm_f1_3k: 0.4021 - val_lcm_f1_5k: 0.3485 - val_lcm_accuracy_1k: 0.4835 - val_lcm_accuracy_2k: 0.6443 - val_lcm_accuracy_3k: 0.7281 - val_lcm_accuracy_5k: 0.8152 - val_lcm_hamming_loss_k: 0.0045
Epoch 5/150
27/27 [==============================] - ETA: 0s - loss: 0.3035 - lcm_precision_1k: 0.5361 - lcm_precision_2k: 0.4233 - lcm_precision_3k: 0.3475 - lcm_precision_5k: 0.2555 - lcm_recall_1k: 0.3281 - lcm_recall_2k: 0.4911 - lcm_recall_3k: 0.5903 - lcm_recall_5k: 0.7026 - lcm_f1_1k: 0.4070 - lcm_f1_2k: 0.4546 - lcm_f1_3k: 0.4374 - lcm_f1_5k: 0.3747 - lcm_accuracy_1k: 0.5361 - lcm_accuracy_2k: 0.6877 - lcm_accuracy_3k: 0.7652 - lcm_accuracy_5k: 0.8449 - lcm_hamming_loss_k: 0.0043
Epoch 00005: val_loss improved from 0.32260 to 0.31210, saving model to logs/lnqtuh-labs-0604-153024/model/checkpoint_labs.h5
27/27 [==============================] - 11s 422ms/step - loss: 0.3035 - lcm_precision_1k: 0.5361 - lcm_precision_2k: 0.4233 - lcm_precision_3k: 0.3475 - lcm_precision_5k: 0.2555 - lcm_recall_1k: 0.3281 - lcm_recall_2k: 0.4911 - lcm_recall_3k: 0.5903 - lcm_recall_5k: 0.7026 - lcm_f1_1k: 0.4070 - lcm_f1_2k: 0.4546 - lcm_f1_3k: 0.4374 - lcm_f1_5k: 0.3747 - lcm_accuracy_1k: 0.5361 - lcm_accuracy_2k: 0.6877 - lcm_accuracy_3k: 0.7652 - lcm_accuracy_5k: 0.8449 - lcm_hamming_loss_k: 0.0043 - val_loss: 0.3121 - val_lcm_precision_1k: 0.5096 - val_lcm_precision_2k: 0.4071 - val_lcm_precision_3k: 0.3305 - val_lcm_precision_5k: 0.2421 - val_lcm_recall_1k: 0.3181 - val_lcm_recall_2k: 0.4849 - val_lcm_recall_3k: 0.5753 - val_lcm_recall_5k: 0.6811 - val_lcm_f1_1k: 0.3916 - val_lcm_f1_2k: 0.4425 - val_lcm_f1_3k: 0.4196 - val_lcm_f1_5k: 0.3572 - val_lcm_accuracy_1k: 0.5096 - val_lcm_accuracy_2k: 0.6743 - val_lcm_accuracy_3k: 0.7463 - val_lcm_accuracy_5k: 0.8249 - val_lcm_hamming_loss_k: 0.0044
Epoch 6/150
27/27 [==============================] - ETA: 0s - loss: 0.2928 - lcm_precision_1k: 0.5605 - lcm_precision_2k: 0.4458 - lcm_precision_3k: 0.3632 - lcm_precision_5k: 0.2626 - lcm_recall_1k: 0.3461 - lcm_recall_2k: 0.5200 - lcm_recall_3k: 0.6196 - lcm_recall_5k: 0.7234 - lcm_f1_1k: 0.4279 - lcm_f1_2k: 0.4800 - lcm_f1_3k: 0.4579 - lcm_f1_5k: 0.3854 - lcm_accuracy_1k: 0.5605 - lcm_accuracy_2k: 0.7173 - lcm_accuracy_3k: 0.7938 - lcm_accuracy_5k: 0.8598 - lcm_hamming_loss_k: 0.0042 ETA: 2s - loss: 0.2934 - lcm_precision_1k: 0.5591 - lcm_precision_2k: 0.4460 - lcm_precision_3k: 0.3629 - lcm_precision_5k: 0.2631 - lcm_recall_1k: 0.3445 - lcm_recall_2k: 0.5194 - lcm_recall_3k: 0.6183 - lcm_recall_5k: 0.7238 - lcm_f1_1k: 0.4262 - lcm_f1_2k: 0.4799 - lcm_f1_3k: 0.4573 - lcm_f1_5k: 0.3859 - lcm_accuracy_1k: 0.5591 - lcm_accuracy_2k: 0.7172 - lcm_accuracy_3k: 0.7929 - lcm_accuracy_5k: 0.8597 - lcm_hammin
Epoch 00006: val_loss improved from 0.31210 to 0.30431, saving model to logs/lnqtuh-labs-0604-153024/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.2928 - lcm_precision_1k: 0.5605 - lcm_precision_2k: 0.4458 - lcm_precision_3k: 0.3632 - lcm_precision_5k: 0.2626 - lcm_recall_1k: 0.3461 - lcm_recall_2k: 0.5200 - lcm_recall_3k: 0.6196 - lcm_recall_5k: 0.7234 - lcm_f1_1k: 0.4279 - lcm_f1_2k: 0.4800 - lcm_f1_3k: 0.4579 - lcm_f1_5k: 0.3854 - lcm_accuracy_1k: 0.5605 - lcm_accuracy_2k: 0.7173 - lcm_accuracy_3k: 0.7938 - lcm_accuracy_5k: 0.8598 - lcm_hamming_loss_k: 0.0042 - val_loss: 0.3043 - val_lcm_precision_1k: 0.5238 - val_lcm_precision_2k: 0.4206 - val_lcm_precision_3k: 0.3434 - val_lcm_precision_5k: 0.2481 - val_lcm_recall_1k: 0.3264 - val_lcm_recall_2k: 0.4997 - val_lcm_recall_3k: 0.5953 - val_lcm_recall_5k: 0.6993 - val_lcm_f1_1k: 0.4020 - val_lcm_f1_2k: 0.4566 - val_lcm_f1_3k: 0.4354 - val_lcm_f1_5k: 0.3661 - val_lcm_accuracy_1k: 0.5238 - val_lcm_accuracy_2k: 0.6831 - val_lcm_accuracy_3k: 0.7604 - val_lcm_accuracy_5k: 0.8397 - val_lcm_hamming_loss_k: 0.0043
Epoch 7/150
27/27 [==============================] - ETA: 0s - loss: 0.2822 - lcm_precision_1k: 0.5818 - lcm_precision_2k: 0.4598 - lcm_precision_3k: 0.3755 - lcm_precision_5k: 0.2700 - lcm_recall_1k: 0.3596 - lcm_recall_2k: 0.5364 - lcm_recall_3k: 0.6390 - lcm_recall_5k: 0.7429 - lcm_f1_1k: 0.4444 - lcm_f1_2k: 0.4951 - lcm_f1_3k: 0.4729 - lcm_f1_5k: 0.3960 - lcm_accuracy_1k: 0.5818 - lcm_accuracy_2k: 0.7387 - lcm_accuracy_3k: 0.8096 - lcm_accuracy_5k: 0.8760 - lcm_hamming_loss_k: 0.0041
Epoch 00007: val_loss improved from 0.30431 to 0.29996, saving model to logs/lnqtuh-labs-0604-153024/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.2822 - lcm_precision_1k: 0.5818 - lcm_precision_2k: 0.4598 - lcm_precision_3k: 0.3755 - lcm_precision_5k: 0.2700 - lcm_recall_1k: 0.3596 - lcm_recall_2k: 0.5364 - lcm_recall_3k: 0.6390 - lcm_recall_5k: 0.7429 - lcm_f1_1k: 0.4444 - lcm_f1_2k: 0.4951 - lcm_f1_3k: 0.4729 - lcm_f1_5k: 0.3960 - lcm_accuracy_1k: 0.5818 - lcm_accuracy_2k: 0.7387 - lcm_accuracy_3k: 0.8096 - lcm_accuracy_5k: 0.8760 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.3000 - val_lcm_precision_1k: 0.5340 - val_lcm_precision_2k: 0.4273 - val_lcm_precision_3k: 0.3486 - val_lcm_precision_5k: 0.2491 - val_lcm_recall_1k: 0.3360 - val_lcm_recall_2k: 0.5106 - val_lcm_recall_3k: 0.6045 - val_lcm_recall_5k: 0.7006 - val_lcm_f1_1k: 0.4124 - val_lcm_f1_2k: 0.4651 - val_lcm_f1_3k: 0.4421 - val_lcm_f1_5k: 0.3674 - val_lcm_accuracy_1k: 0.5340 - val_lcm_accuracy_2k: 0.7016 - val_lcm_accuracy_3k: 0.7762 - val_lcm_accuracy_5k: 0.8436 - val_lcm_hamming_loss_k: 0.0042
Epoch 8/150
27/27 [==============================] - ETA: 0s - loss: 0.2733 - lcm_precision_1k: 0.5923 - lcm_precision_2k: 0.4718 - lcm_precision_3k: 0.3836 - lcm_precision_5k: 0.2758 - lcm_recall_1k: 0.3682 - lcm_recall_2k: 0.5532 - lcm_recall_3k: 0.6546 - lcm_recall_5k: 0.7591 - lcm_f1_1k: 0.4541 - lcm_f1_2k: 0.5092 - lcm_f1_3k: 0.4837 - lcm_f1_5k: 0.4045 - lcm_accuracy_1k: 0.5923 - lcm_accuracy_2k: 0.7550 - lcm_accuracy_3k: 0.8271 - lcm_accuracy_5k: 0.8887 - lcm_hamming_loss_k: 0.0041
Epoch 00008: val_loss improved from 0.29996 to 0.29844, saving model to logs/lnqtuh-labs-0604-153024/model/checkpoint_labs.h5
27/27 [==============================] - 11s 428ms/step - loss: 0.2733 - lcm_precision_1k: 0.5923 - lcm_precision_2k: 0.4718 - lcm_precision_3k: 0.3836 - lcm_precision_5k: 0.2758 - lcm_recall_1k: 0.3682 - lcm_recall_2k: 0.5532 - lcm_recall_3k: 0.6546 - lcm_recall_5k: 0.7591 - lcm_f1_1k: 0.4541 - lcm_f1_2k: 0.5092 - lcm_f1_3k: 0.4837 - lcm_f1_5k: 0.4045 - lcm_accuracy_1k: 0.5923 - lcm_accuracy_2k: 0.7550 - lcm_accuracy_3k: 0.8271 - lcm_accuracy_5k: 0.8887 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2984 - val_lcm_precision_1k: 0.5532 - val_lcm_precision_2k: 0.4363 - val_lcm_precision_3k: 0.3547 - val_lcm_precision_5k: 0.2526 - val_lcm_recall_1k: 0.3469 - val_lcm_recall_2k: 0.5223 - val_lcm_recall_3k: 0.6192 - val_lcm_recall_5k: 0.7116 - val_lcm_f1_1k: 0.4263 - val_lcm_f1_2k: 0.4753 - val_lcm_f1_3k: 0.4509 - val_lcm_f1_5k: 0.3727 - val_lcm_accuracy_1k: 0.5532 - val_lcm_accuracy_2k: 0.7110 - val_lcm_accuracy_3k: 0.7841 - val_lcm_accuracy_5k: 0.8521 - val_lcm_hamming_loss_k: 0.0042
Epoch 9/150
27/27 [==============================] - ETA: 0s - loss: 0.2669 - lcm_precision_1k: 0.6121 - lcm_precision_2k: 0.4827 - lcm_precision_3k: 0.3916 - lcm_precision_5k: 0.2801 - lcm_recall_1k: 0.3827 - lcm_recall_2k: 0.5670 - lcm_recall_3k: 0.6695 - lcm_recall_5k: 0.7699 - lcm_f1_1k: 0.4709 - lcm_f1_2k: 0.5214 - lcm_f1_3k: 0.4941 - lcm_f1_5k: 0.4107 - lcm_accuracy_1k: 0.6121 - lcm_accuracy_2k: 0.7670 - lcm_accuracy_3k: 0.8380 - lcm_accuracy_5k: 0.8944 - lcm_hamming_loss_k: 0.0040
Epoch 00009: val_loss improved from 0.29844 to 0.28896, saving model to logs/lnqtuh-labs-0604-153024/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2669 - lcm_precision_1k: 0.6121 - lcm_precision_2k: 0.4827 - lcm_precision_3k: 0.3916 - lcm_precision_5k: 0.2801 - lcm_recall_1k: 0.3827 - lcm_recall_2k: 0.5670 - lcm_recall_3k: 0.6695 - lcm_recall_5k: 0.7699 - lcm_f1_1k: 0.4709 - lcm_f1_2k: 0.5214 - lcm_f1_3k: 0.4941 - lcm_f1_5k: 0.4107 - lcm_accuracy_1k: 0.6121 - lcm_accuracy_2k: 0.7670 - lcm_accuracy_3k: 0.8380 - lcm_accuracy_5k: 0.8944 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2890 - val_lcm_precision_1k: 0.5642 - val_lcm_precision_2k: 0.4436 - val_lcm_precision_3k: 0.3609 - val_lcm_precision_5k: 0.2578 - val_lcm_recall_1k: 0.3559 - val_lcm_recall_2k: 0.5292 - val_lcm_recall_3k: 0.6275 - val_lcm_recall_5k: 0.7258 - val_lcm_f1_1k: 0.4364 - val_lcm_f1_2k: 0.4826 - val_lcm_f1_3k: 0.4581 - val_lcm_f1_5k: 0.3804 - val_lcm_accuracy_1k: 0.5642 - val_lcm_accuracy_2k: 0.7171 - val_lcm_accuracy_3k: 0.7949 - val_lcm_accuracy_5k: 0.8586 - val_lcm_hamming_loss_k: 0.0041
Epoch 10/150
27/27 [==============================] - ETA: 0s - loss: 0.2584 - lcm_precision_1k: 0.6281 - lcm_precision_2k: 0.4936 - lcm_precision_3k: 0.3998 - lcm_precision_5k: 0.2862 - lcm_recall_1k: 0.3930 - lcm_recall_2k: 0.5791 - lcm_recall_3k: 0.6821 - lcm_recall_5k: 0.7867 - lcm_f1_1k: 0.4834 - lcm_f1_2k: 0.5328 - lcm_f1_3k: 0.5040 - lcm_f1_5k: 0.4197 - lcm_accuracy_1k: 0.6281 - lcm_accuracy_2k: 0.7819 - lcm_accuracy_3k: 0.8498 - lcm_accuracy_5k: 0.9087 - lcm_hamming_loss_k: 0.0039
Epoch 00010: val_loss improved from 0.28896 to 0.28310, saving model to logs/lnqtuh-labs-0604-153024/model/checkpoint_labs.h5
27/27 [==============================] - 11s 429ms/step - loss: 0.2584 - lcm_precision_1k: 0.6281 - lcm_precision_2k: 0.4936 - lcm_precision_3k: 0.3998 - lcm_precision_5k: 0.2862 - lcm_recall_1k: 0.3930 - lcm_recall_2k: 0.5791 - lcm_recall_3k: 0.6821 - lcm_recall_5k: 0.7867 - lcm_f1_1k: 0.4834 - lcm_f1_2k: 0.5328 - lcm_f1_3k: 0.5040 - lcm_f1_5k: 0.4197 - lcm_accuracy_1k: 0.6281 - lcm_accuracy_2k: 0.7819 - lcm_accuracy_3k: 0.8498 - lcm_accuracy_5k: 0.9087 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2831 - val_lcm_precision_1k: 0.5682 - val_lcm_precision_2k: 0.4455 - val_lcm_precision_3k: 0.3656 - val_lcm_precision_5k: 0.2594 - val_lcm_recall_1k: 0.3599 - val_lcm_recall_2k: 0.5344 - val_lcm_recall_3k: 0.6386 - val_lcm_recall_5k: 0.7323 - val_lcm_f1_1k: 0.4405 - val_lcm_f1_2k: 0.4858 - val_lcm_f1_3k: 0.4649 - val_lcm_f1_5k: 0.3830 - val_lcm_accuracy_1k: 0.5682 - val_lcm_accuracy_2k: 0.7266 - val_lcm_accuracy_3k: 0.8090 - val_lcm_accuracy_5k: 0.8696 - val_lcm_hamming_loss_k: 0.0041
Epoch 11/150
27/27 [==============================] - ETA: 0s - loss: 0.2524 - lcm_precision_1k: 0.6396 - lcm_precision_2k: 0.5025 - lcm_precision_3k: 0.4074 - lcm_precision_5k: 0.2890 - lcm_recall_1k: 0.4014 - lcm_recall_2k: 0.5927 - lcm_recall_3k: 0.6957 - lcm_recall_5k: 0.7950 - lcm_f1_1k: 0.4932 - lcm_f1_2k: 0.5438 - lcm_f1_3k: 0.5139 - lcm_f1_5k: 0.4239 - lcm_accuracy_1k: 0.6396 - lcm_accuracy_2k: 0.7947 - lcm_accuracy_3k: 0.8606 - lcm_accuracy_5k: 0.9140 - lcm_hamming_loss_k: 0.0038
Epoch 00011: val_loss did not improve from 0.28310
27/27 [==============================] - 10s 388ms/step - loss: 0.2524 - lcm_precision_1k: 0.6396 - lcm_precision_2k: 0.5025 - lcm_precision_3k: 0.4074 - lcm_precision_5k: 0.2890 - lcm_recall_1k: 0.4014 - lcm_recall_2k: 0.5927 - lcm_recall_3k: 0.6957 - lcm_recall_5k: 0.7950 - lcm_f1_1k: 0.4932 - lcm_f1_2k: 0.5438 - lcm_f1_3k: 0.5139 - lcm_f1_5k: 0.4239 - lcm_accuracy_1k: 0.6396 - lcm_accuracy_2k: 0.7947 - lcm_accuracy_3k: 0.8606 - lcm_accuracy_5k: 0.9140 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2838 - val_lcm_precision_1k: 0.5755 - val_lcm_precision_2k: 0.4516 - val_lcm_precision_3k: 0.3664 - val_lcm_precision_5k: 0.2612 - val_lcm_recall_1k: 0.3638 - val_lcm_recall_2k: 0.5395 - val_lcm_recall_3k: 0.6373 - val_lcm_recall_5k: 0.7358 - val_lcm_f1_1k: 0.4457 - val_lcm_f1_2k: 0.4916 - val_lcm_f1_3k: 0.4652 - val_lcm_f1_5k: 0.3854 - val_lcm_accuracy_1k: 0.5755 - val_lcm_accuracy_2k: 0.7318 - val_lcm_accuracy_3k: 0.8034 - val_lcm_accuracy_5k: 0.8679 - val_lcm_hamming_loss_k: 0.0040
Epoch 12/150
27/27 [==============================] - ETA: 0s - loss: 0.2468 - lcm_precision_1k: 0.6519 - lcm_precision_2k: 0.5134 - lcm_precision_3k: 0.4133 - lcm_precision_5k: 0.2925 - lcm_recall_1k: 0.4100 - lcm_recall_2k: 0.6054 - lcm_recall_3k: 0.7067 - lcm_recall_5k: 0.8045 - lcm_f1_1k: 0.5033 - lcm_f1_2k: 0.5556 - lcm_f1_3k: 0.5215 - lcm_f1_5k: 0.4289 - lcm_accuracy_1k: 0.6519 - lcm_accuracy_2k: 0.8072 - lcm_accuracy_3k: 0.8687 - lcm_accuracy_5k: 0.9202 - lcm_hamming_loss_k: 0.0038
Epoch 00012: val_loss improved from 0.28310 to 0.27750, saving model to logs/lnqtuh-labs-0604-153024/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2468 - lcm_precision_1k: 0.6519 - lcm_precision_2k: 0.5134 - lcm_precision_3k: 0.4133 - lcm_precision_5k: 0.2925 - lcm_recall_1k: 0.4100 - lcm_recall_2k: 0.6054 - lcm_recall_3k: 0.7067 - lcm_recall_5k: 0.8045 - lcm_f1_1k: 0.5033 - lcm_f1_2k: 0.5556 - lcm_f1_3k: 0.5215 - lcm_f1_5k: 0.4289 - lcm_accuracy_1k: 0.6519 - lcm_accuracy_2k: 0.8072 - lcm_accuracy_3k: 0.8687 - lcm_accuracy_5k: 0.9202 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2775 - val_lcm_precision_1k: 0.5890 - val_lcm_precision_2k: 0.4604 - val_lcm_precision_3k: 0.3732 - val_lcm_precision_5k: 0.2638 - val_lcm_recall_1k: 0.3732 - val_lcm_recall_2k: 0.5520 - val_lcm_recall_3k: 0.6514 - val_lcm_recall_5k: 0.7446 - val_lcm_f1_1k: 0.4568 - val_lcm_f1_2k: 0.5020 - val_lcm_f1_3k: 0.4744 - val_lcm_f1_5k: 0.3894 - val_lcm_accuracy_1k: 0.5890 - val_lcm_accuracy_2k: 0.7457 - val_lcm_accuracy_3k: 0.8155 - val_lcm_accuracy_5k: 0.8786 - val_lcm_hamming_loss_k: 0.0040
Epoch 13/150
27/27 [==============================] - ETA: 0s - loss: 0.2384 - lcm_precision_1k: 0.6700 - lcm_precision_2k: 0.5253 - lcm_precision_3k: 0.4229 - lcm_precision_5k: 0.2976 - lcm_recall_1k: 0.4233 - lcm_recall_2k: 0.6186 - lcm_recall_3k: 0.7212 - lcm_recall_5k: 0.8163 - lcm_f1_1k: 0.5187 - lcm_f1_2k: 0.5681 - lcm_f1_3k: 0.5331 - lcm_f1_5k: 0.4362 - lcm_accuracy_1k: 0.6700 - lcm_accuracy_2k: 0.8214 - lcm_accuracy_3k: 0.8815 - lcm_accuracy_5k: 0.9285 - lcm_hamming_loss_k: 0.0037 ETA: 1s - loss: 0.2368 - lcm_precision_1k: 0.6716 - lcm_precision_2k: 0.5257 - lcm_precision_3k: 0.4229 - lcm_precision_5k: 0.2972 - lcm_recall_1k: 0.4259 - lcm_recall_2k: 0.6215 - lcm_recall_3k: 0.7242 - lcm_recall_5k: 0.8189 - lcm_f1_1k: 0.5212 - lcm_f1_2k: 0.5695 - lcm_f1_3k: 0.5339 - lcm_f1_5k: 0.4361 - lcm_accuracy_1k: 0.6716 - lcm_accuracy_2k: 0.8221 - lcm_accuracy_3k: 0.8825 - lcm_accuracy_5k: 0.9301 - lcm_hamming_lo
Epoch 00013: val_loss improved from 0.27750 to 0.27675, saving model to logs/lnqtuh-labs-0604-153024/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.2384 - lcm_precision_1k: 0.6700 - lcm_precision_2k: 0.5253 - lcm_precision_3k: 0.4229 - lcm_precision_5k: 0.2976 - lcm_recall_1k: 0.4233 - lcm_recall_2k: 0.6186 - lcm_recall_3k: 0.7212 - lcm_recall_5k: 0.8163 - lcm_f1_1k: 0.5187 - lcm_f1_2k: 0.5681 - lcm_f1_3k: 0.5331 - lcm_f1_5k: 0.4362 - lcm_accuracy_1k: 0.6700 - lcm_accuracy_2k: 0.8214 - lcm_accuracy_3k: 0.8815 - lcm_accuracy_5k: 0.9285 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2768 - val_lcm_precision_1k: 0.5873 - val_lcm_precision_2k: 0.4679 - val_lcm_precision_3k: 0.3766 - val_lcm_precision_5k: 0.2653 - val_lcm_recall_1k: 0.3711 - val_lcm_recall_2k: 0.5594 - val_lcm_recall_3k: 0.6592 - val_lcm_recall_5k: 0.7501 - val_lcm_f1_1k: 0.4547 - val_lcm_f1_2k: 0.5095 - val_lcm_f1_3k: 0.4792 - val_lcm_f1_5k: 0.3919 - val_lcm_accuracy_1k: 0.5873 - val_lcm_accuracy_2k: 0.7521 - val_lcm_accuracy_3k: 0.8298 - val_lcm_accuracy_5k: 0.8811 - val_lcm_hamming_loss_k: 0.0040
Epoch 14/150
27/27 [==============================] - ETA: 0s - loss: 0.2323 - lcm_precision_1k: 0.6919 - lcm_precision_2k: 0.5355 - lcm_precision_3k: 0.4285 - lcm_precision_5k: 0.3033 - lcm_recall_1k: 0.4371 - lcm_recall_2k: 0.6305 - lcm_recall_3k: 0.7298 - lcm_recall_5k: 0.8311 - lcm_f1_1k: 0.5357 - lcm_f1_2k: 0.5791 - lcm_f1_3k: 0.5399 - lcm_f1_5k: 0.4443 - lcm_accuracy_1k: 0.6919 - lcm_accuracy_2k: 0.8304 - lcm_accuracy_3k: 0.8867 - lcm_accuracy_5k: 0.9378 - lcm_hamming_loss_k: 0.0036
Epoch 00014: val_loss improved from 0.27675 to 0.27596, saving model to logs/lnqtuh-labs-0604-153024/model/checkpoint_labs.h5
27/27 [==============================] - 11s 429ms/step - loss: 0.2323 - lcm_precision_1k: 0.6919 - lcm_precision_2k: 0.5355 - lcm_precision_3k: 0.4285 - lcm_precision_5k: 0.3033 - lcm_recall_1k: 0.4371 - lcm_recall_2k: 0.6305 - lcm_recall_3k: 0.7298 - lcm_recall_5k: 0.8311 - lcm_f1_1k: 0.5357 - lcm_f1_2k: 0.5791 - lcm_f1_3k: 0.5399 - lcm_f1_5k: 0.4443 - lcm_accuracy_1k: 0.6919 - lcm_accuracy_2k: 0.8304 - lcm_accuracy_3k: 0.8867 - lcm_accuracy_5k: 0.9378 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2760 - val_lcm_precision_1k: 0.5891 - val_lcm_precision_2k: 0.4629 - val_lcm_precision_3k: 0.3765 - val_lcm_precision_5k: 0.2648 - val_lcm_recall_1k: 0.3718 - val_lcm_recall_2k: 0.5522 - val_lcm_recall_3k: 0.6557 - val_lcm_recall_5k: 0.7458 - val_lcm_f1_1k: 0.4558 - val_lcm_f1_2k: 0.5035 - val_lcm_f1_3k: 0.4782 - val_lcm_f1_5k: 0.3907 - val_lcm_accuracy_1k: 0.5891 - val_lcm_accuracy_2k: 0.7423 - val_lcm_accuracy_3k: 0.8215 - val_lcm_accuracy_5k: 0.8791 - val_lcm_hamming_loss_k: 0.0040
Epoch 15/150
27/27 [==============================] - ETA: 0s - loss: 0.2282 - lcm_precision_1k: 0.6974 - lcm_precision_2k: 0.5394 - lcm_precision_3k: 0.4340 - lcm_precision_5k: 0.3059 - lcm_recall_1k: 0.4426 - lcm_recall_2k: 0.6360 - lcm_recall_3k: 0.7409 - lcm_recall_5k: 0.8388 - lcm_f1_1k: 0.5414 - lcm_f1_2k: 0.5837 - lcm_f1_3k: 0.5473 - lcm_f1_5k: 0.4483 - lcm_accuracy_1k: 0.6974 - lcm_accuracy_2k: 0.8347 - lcm_accuracy_3k: 0.8969 - lcm_accuracy_5k: 0.9438 - lcm_hamming_loss_k: 0.0036 ETA: 8s - loss: 0.2333 - lcm_precision_1k: 0.6924 - lcm_precision_2k: 0.5235 - lcm_precision_3k: 0.4238 - lcm_precision_5k: 0.3041 - lcm_recall_1k: 0.4444 - lcm_recall_2k: 0.6210 - lcm_recall_3k: 0.7271 - lcm_recall_5k: 0.8355 - lcm_f1_1k: 0.5413 - lcm_f1_2k: 0.5681 - lcm_f1_3k: 0.5355 - lcm_f1_5k: 0.4459 - lcm_accuracy_1k: 0.6924 - lcm_accuracy_2k: 0.8223 - lcm_accuracy_3k: 0.8916 - lc
Epoch 00015: val_loss improved from 0.27596 to 0.27080, saving model to logs/lnqtuh-labs-0604-153024/model/checkpoint_labs.h5
27/27 [==============================] - 11s 429ms/step - loss: 0.2282 - lcm_precision_1k: 0.6974 - lcm_precision_2k: 0.5394 - lcm_precision_3k: 0.4340 - lcm_precision_5k: 0.3059 - lcm_recall_1k: 0.4426 - lcm_recall_2k: 0.6360 - lcm_recall_3k: 0.7409 - lcm_recall_5k: 0.8388 - lcm_f1_1k: 0.5414 - lcm_f1_2k: 0.5837 - lcm_f1_3k: 0.5473 - lcm_f1_5k: 0.4483 - lcm_accuracy_1k: 0.6974 - lcm_accuracy_2k: 0.8347 - lcm_accuracy_3k: 0.8969 - lcm_accuracy_5k: 0.9438 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2708 - val_lcm_precision_1k: 0.5981 - val_lcm_precision_2k: 0.4721 - val_lcm_precision_3k: 0.3810 - val_lcm_precision_5k: 0.2673 - val_lcm_recall_1k: 0.3790 - val_lcm_recall_2k: 0.5670 - val_lcm_recall_3k: 0.6660 - val_lcm_recall_5k: 0.7533 - val_lcm_f1_1k: 0.4639 - val_lcm_f1_2k: 0.5151 - val_lcm_f1_3k: 0.4846 - val_lcm_f1_5k: 0.3945 - val_lcm_accuracy_1k: 0.5981 - val_lcm_accuracy_2k: 0.7615 - val_lcm_accuracy_3k: 0.8309 - val_lcm_accuracy_5k: 0.8854 - val_lcm_hamming_loss_k: 0.0039
Epoch 16/150
27/27 [==============================] - ETA: 0s - loss: 0.2222 - lcm_precision_1k: 0.7075 - lcm_precision_2k: 0.5506 - lcm_precision_3k: 0.4418 - lcm_precision_5k: 0.3087 - lcm_recall_1k: 0.4509 - lcm_recall_2k: 0.6498 - lcm_recall_3k: 0.7529 - lcm_recall_5k: 0.8450 - lcm_f1_1k: 0.5508 - lcm_f1_2k: 0.5960 - lcm_f1_3k: 0.5568 - lcm_f1_5k: 0.4522 - lcm_accuracy_1k: 0.7075 - lcm_accuracy_2k: 0.8475 - lcm_accuracy_3k: 0.9043 - lcm_accuracy_5k: 0.9462 - lcm_hamming_loss_k: 0.0035
Epoch 00016: val_loss did not improve from 0.27080
27/27 [==============================] - 11s 392ms/step - loss: 0.2222 - lcm_precision_1k: 0.7075 - lcm_precision_2k: 0.5506 - lcm_precision_3k: 0.4418 - lcm_precision_5k: 0.3087 - lcm_recall_1k: 0.4509 - lcm_recall_2k: 0.6498 - lcm_recall_3k: 0.7529 - lcm_recall_5k: 0.8450 - lcm_f1_1k: 0.5508 - lcm_f1_2k: 0.5960 - lcm_f1_3k: 0.5568 - lcm_f1_5k: 0.4522 - lcm_accuracy_1k: 0.7075 - lcm_accuracy_2k: 0.8475 - lcm_accuracy_3k: 0.9043 - lcm_accuracy_5k: 0.9462 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2721 - val_lcm_precision_1k: 0.5988 - val_lcm_precision_2k: 0.4771 - val_lcm_precision_3k: 0.3798 - val_lcm_precision_5k: 0.2668 - val_lcm_recall_1k: 0.3785 - val_lcm_recall_2k: 0.5711 - val_lcm_recall_3k: 0.6630 - val_lcm_recall_5k: 0.7527 - val_lcm_f1_1k: 0.4637 - val_lcm_f1_2k: 0.5198 - val_lcm_f1_3k: 0.4828 - val_lcm_f1_5k: 0.3939 - val_lcm_accuracy_1k: 0.5988 - val_lcm_accuracy_2k: 0.7618 - val_lcm_accuracy_3k: 0.8293 - val_lcm_accuracy_5k: 0.8831 - val_lcm_hamming_loss_k: 0.0039
Epoch 17/150
27/27 [==============================] - ETA: 0s - loss: 0.2173 - lcm_precision_1k: 0.7227 - lcm_precision_2k: 0.5592 - lcm_precision_3k: 0.4477 - lcm_precision_5k: 0.3122 - lcm_recall_1k: 0.4611 - lcm_recall_2k: 0.6604 - lcm_recall_3k: 0.7632 - lcm_recall_5k: 0.8557 - lcm_f1_1k: 0.5629 - lcm_f1_2k: 0.6055 - lcm_f1_3k: 0.5643 - lcm_f1_5k: 0.4574 - lcm_accuracy_1k: 0.7227 - lcm_accuracy_2k: 0.8588 - lcm_accuracy_3k: 0.9118 - lcm_accuracy_5k: 0.9544 - lcm_hamming_loss_k: 0.0034 ETA: 7s - loss: 0.2199 - lcm_precision_1k: 0.7266 - lcm_precision_2k: 0.5593 - lcm_precision_3k: 0.4491 - lcm_precision_5k: 0.3132 - lcm_recall_1k: 0.4598 - lcm_recall_2k: 0.6555 - lcm_recall_3k: 0.7605 - lcm_recall_5k: 0.8511 - lcm_f1_1k: 0.5632 - lcm_f1_2k: 0.6036 - lcm_f1_3k: 0.5647 - lcm_f1_5k: 0.4579 - lcm_accuracy_1k: 0.7266 - lcm_accuracy_2k: 0.8625 - lcm_accuracy_3k: 0.9152 - lcm_accu
Epoch 00017: val_loss improved from 0.27080 to 0.26867, saving model to logs/lnqtuh-labs-0604-153024/model/checkpoint_labs.h5
27/27 [==============================] - 11s 423ms/step - loss: 0.2173 - lcm_precision_1k: 0.7227 - lcm_precision_2k: 0.5592 - lcm_precision_3k: 0.4477 - lcm_precision_5k: 0.3122 - lcm_recall_1k: 0.4611 - lcm_recall_2k: 0.6604 - lcm_recall_3k: 0.7632 - lcm_recall_5k: 0.8557 - lcm_f1_1k: 0.5629 - lcm_f1_2k: 0.6055 - lcm_f1_3k: 0.5643 - lcm_f1_5k: 0.4574 - lcm_accuracy_1k: 0.7227 - lcm_accuracy_2k: 0.8588 - lcm_accuracy_3k: 0.9118 - lcm_accuracy_5k: 0.9544 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2687 - val_lcm_precision_1k: 0.6041 - val_lcm_precision_2k: 0.4763 - val_lcm_precision_3k: 0.3818 - val_lcm_precision_5k: 0.2682 - val_lcm_recall_1k: 0.3847 - val_lcm_recall_2k: 0.5706 - val_lcm_recall_3k: 0.6649 - val_lcm_recall_5k: 0.7541 - val_lcm_f1_1k: 0.4699 - val_lcm_f1_2k: 0.5190 - val_lcm_f1_3k: 0.4849 - val_lcm_f1_5k: 0.3955 - val_lcm_accuracy_1k: 0.6041 - val_lcm_accuracy_2k: 0.7644 - val_lcm_accuracy_3k: 0.8272 - val_lcm_accuracy_5k: 0.8834 - val_lcm_hamming_loss_k: 0.0039
Epoch 18/150
27/27 [==============================] - ETA: 0s - loss: 0.2111 - lcm_precision_1k: 0.7357 - lcm_precision_2k: 0.5690 - lcm_precision_3k: 0.4554 - lcm_precision_5k: 0.3173 - lcm_recall_1k: 0.4696 - lcm_recall_2k: 0.6709 - lcm_recall_3k: 0.7739 - lcm_recall_5k: 0.8672 - lcm_f1_1k: 0.5732 - lcm_f1_2k: 0.6157 - lcm_f1_3k: 0.5733 - lcm_f1_5k: 0.4646 - lcm_accuracy_1k: 0.7357 - lcm_accuracy_2k: 0.8679 - lcm_accuracy_3k: 0.9195 - lcm_accuracy_5k: 0.9586 - lcm_hamming_loss_k: 0.0034
Epoch 00018: val_loss did not improve from 0.26867
27/27 [==============================] - 10s 389ms/step - loss: 0.2111 - lcm_precision_1k: 0.7357 - lcm_precision_2k: 0.5690 - lcm_precision_3k: 0.4554 - lcm_precision_5k: 0.3173 - lcm_recall_1k: 0.4696 - lcm_recall_2k: 0.6709 - lcm_recall_3k: 0.7739 - lcm_recall_5k: 0.8672 - lcm_f1_1k: 0.5732 - lcm_f1_2k: 0.6157 - lcm_f1_3k: 0.5733 - lcm_f1_5k: 0.4646 - lcm_accuracy_1k: 0.7357 - lcm_accuracy_2k: 0.8679 - lcm_accuracy_3k: 0.9195 - lcm_accuracy_5k: 0.9586 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2689 - val_lcm_precision_1k: 0.6169 - val_lcm_precision_2k: 0.4782 - val_lcm_precision_3k: 0.3842 - val_lcm_precision_5k: 0.2688 - val_lcm_recall_1k: 0.3927 - val_lcm_recall_2k: 0.5753 - val_lcm_recall_3k: 0.6725 - val_lcm_recall_5k: 0.7575 - val_lcm_f1_1k: 0.4798 - val_lcm_f1_2k: 0.5221 - val_lcm_f1_3k: 0.4889 - val_lcm_f1_5k: 0.3967 - val_lcm_accuracy_1k: 0.6169 - val_lcm_accuracy_2k: 0.7656 - val_lcm_accuracy_3k: 0.8352 - val_lcm_accuracy_5k: 0.8859 - val_lcm_hamming_loss_k: 0.0039
Epoch 19/150
27/27 [==============================] - ETA: 0s - loss: 0.2057 - lcm_precision_1k: 0.7419 - lcm_precision_2k: 0.5779 - lcm_precision_3k: 0.4611 - lcm_precision_5k: 0.3209 - lcm_recall_1k: 0.4746 - lcm_recall_2k: 0.6795 - lcm_recall_3k: 0.7815 - lcm_recall_5k: 0.8745 - lcm_f1_1k: 0.5788 - lcm_f1_2k: 0.6245 - lcm_f1_3k: 0.5799 - lcm_f1_5k: 0.4695 - lcm_accuracy_1k: 0.7419 - lcm_accuracy_2k: 0.8756 - lcm_accuracy_3k: 0.9248 - lcm_accuracy_5k: 0.9631 - lcm_hamming_loss_k: 0.0034
Epoch 00019: val_loss did not improve from 0.26867
27/27 [==============================] - 10s 389ms/step - loss: 0.2057 - lcm_precision_1k: 0.7419 - lcm_precision_2k: 0.5779 - lcm_precision_3k: 0.4611 - lcm_precision_5k: 0.3209 - lcm_recall_1k: 0.4746 - lcm_recall_2k: 0.6795 - lcm_recall_3k: 0.7815 - lcm_recall_5k: 0.8745 - lcm_f1_1k: 0.5788 - lcm_f1_2k: 0.6245 - lcm_f1_3k: 0.5799 - lcm_f1_5k: 0.4695 - lcm_accuracy_1k: 0.7419 - lcm_accuracy_2k: 0.8756 - lcm_accuracy_3k: 0.9248 - lcm_accuracy_5k: 0.9631 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2710 - val_lcm_precision_1k: 0.6043 - val_lcm_precision_2k: 0.4754 - val_lcm_precision_3k: 0.3829 - val_lcm_precision_5k: 0.2674 - val_lcm_recall_1k: 0.3841 - val_lcm_recall_2k: 0.5658 - val_lcm_recall_3k: 0.6665 - val_lcm_recall_5k: 0.7529 - val_lcm_f1_1k: 0.4696 - val_lcm_f1_2k: 0.5165 - val_lcm_f1_3k: 0.4862 - val_lcm_f1_5k: 0.3946 - val_lcm_accuracy_1k: 0.6043 - val_lcm_accuracy_2k: 0.7548 - val_lcm_accuracy_3k: 0.8262 - val_lcm_accuracy_5k: 0.8814 - val_lcm_hamming_loss_k: 0.0039
Epoch 00019: early stopping
176/176 [==============================] - 8s 42ms/step - loss: 0.2351 - lcm_precision_1k: 0.6821 - lcm_precision_2k: 0.5252 - lcm_precision_3k: 0.4194 - lcm_precision_5k: 0.2949 - lcm_recall_1k: 0.4369 - lcm_recall_2k: 0.6268 - lcm_recall_3k: 0.7237 - lcm_recall_5k: 0.8177 - lcm_f1_1k: 0.5314 - lcm_f1_2k: 0.5703 - lcm_f1_3k: 0.5300 - lcm_f1_5k: 0.4327 - lcm_accuracy_1k: 0.6821 - lcm_accuracy_2k: 0.8198 - lcm_accuracy_3k: 0.8755 - lcm_accuracy_5k: 0.9236 - lcm_hamming_loss_k: 0.0036 2s - loss: 0.2346 - lcm_precision_1k: 0.6888 - lcm_precision_2k: 0.5280 - lcm_precision_3k: 0.4190 - lcm_precision_5k: 0.2937 - lcm_recall_1k: 0.4420 - lcm_recall_2k: 0.6320 - lcm_recall_3k: 0.7257 - lcm_recall_5k: 0.8168 - lcm_f1_1k: 0.5371 - lcm_f1_2k: 0.5741 - lcm_f1_3k: 0.5302 - lcm_f1_5k: 0.4313 - lcm_accuracy_1k: 0.6888 - lcm_accuracy_2k: 0.8228 - lcm_accuracy_3k: 0.8777 - 
Best model result:  [0.2351495921611786, 0.6821318864822388, 0.5252103209495544, 0.41941431164741516, 0.29490920901298523, 0.43692609667778015, 0.6267563104629517, 0.7237006425857544, 0.8177171349525452, 0.5313565731048584, 0.5702890753746033, 0.5300061702728271, 0.4327174425125122, 0.6821318864822388, 0.8198381066322327, 0.8755115270614624, 0.9235553741455078, 0.003590688342228532]
13498
3375
5625
Model: "model_2"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_3 (Sl  (None, 15, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_3[0][0
                                                                 ]']                              
                                                                                                  
 permute_3 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_5 (Lambda)              (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_3[0][0]']              
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_5[0][0]']               
 Dense)                                                                                           
                                                                                                  
 lambda_6 (Lambda)              (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_2 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_6[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_1 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_2[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_3 (Dense)                (None, 1024)         2098176     ['tf.concat_1[0][0]']            
                                                                                                  
 dense_4 (Dense)                (None, 15)           15375       ['dense_3[0][0]']                
                                                                                                  
 tf.nn.softmax_1 (TFOpLambda)   (None, 15)           0           ['dense_4[0][0]']                
                                                                                                  
 tf.expand_dims_2 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_1[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_2[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_4 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_7 (Lambda)              (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_4[0][0]']              
                                                                                                  
 dense_5 (Dense)                (None, 15, 150)      22650       ['lambda_7[0][0]']               
                                                                                                  
 tf.math.reduce_mean_3 (TFOpLam  (None, 150)         0           ['dense_5[0][0]']                
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_3 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_3[0][0]']  
                                                                                                  
 tf.__operators__.getitem_4 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 tf.math.multiply_1 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_3[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_4[0][0
                                                                 ]']                              
                                                                                                  
 permute_5 (Permute)            (None, 1024, 150)    0           ['tf.math.multiply_1[0][0]']     
                                                                                                  
 lambda_8 (Lambda)              (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_5[0][0]']              
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_8[0][0]']               
 Dense)                                                                                           
                                                                                                  
 lambda_9 (Lambda)              (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_1[0][0]']     
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_9[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
==================================================================================================
Total params: 31,474,320
Trainable params: 6,695,820
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
2 patience
Model: "model_3"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_3 (Sl  (None, 15, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_3[0][0
                                                                 ]']                              
                                                                                                  
 permute_3 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_5 (Lambda)              (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_3[0][0]']              
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_5[0][0]']               
 Dense)                                                                                           
                                                                                                  
 lambda_6 (Lambda)              (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_2 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_6[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_1 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_2[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_3 (Dense)                (None, 1024)         2098176     ['tf.concat_1[0][0]']            
                                                                                                  
 dense_4 (Dense)                (None, 15)           15375       ['dense_3[0][0]']                
                                                                                                  
 tf.nn.softmax_1 (TFOpLambda)   (None, 15)           0           ['dense_4[0][0]']                
                                                                                                  
 tf.expand_dims_2 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_1[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_2[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_4 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_7 (Lambda)              (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_4[0][0]']              
                                                                                                  
 dense_5 (Dense)                (None, 15, 150)      22650       ['lambda_7[0][0]']               
                                                                                                  
 tf.math.reduce_mean_3 (TFOpLam  (None, 150)         0           ['dense_5[0][0]']                
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_3 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_3[0][0]']  
                                                                                                  
 tf.__operators__.getitem_4 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 tf.math.multiply_1 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_3[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_4[0][0
                                                                 ]']                              
                                                                                                  
 permute_5 (Permute)            (None, 1024, 150)    0           ['tf.math.multiply_1[0][0]']     
                                                                                                  
 lambda_8 (Lambda)              (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_5[0][0]']              
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_8[0][0]']               
 Dense)                                                                                           
                                                                                                  
 lambda_9 (Lambda)              (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_1[0][0]']     
                                                                                                  
 tf.__operators__.getitem_5 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_9[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 label_lcm_emb (Dense)          (None, 427, 1024)    308224      ['tf.__operators__.getitem_5[0][0
                                                                 ]']                              
                                                                                                  
 dot_1 (Dot)                    (None, 427)          0           ['label_lcm_emb[0][0]',          
                                                                  '1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 label_sim_dict (Dense)         (None, 427)          182756      ['dot_1[0][0]']                  
                                                                                                  
 concatenate_1 (Concatenate)    (None, 854)          0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 31,965,300
Trainable params: 7,186,800
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
Epoch 1/150
27/27 [==============================] - ETA: 0s - loss: 0.5365 - lcm_precision_1k: 0.0787 - lcm_precision_2k: 0.0654 - lcm_precision_3k: 0.0594 - lcm_precision_5k: 0.0549 - lcm_recall_1k: 0.0426 - lcm_recall_2k: 0.0700 - lcm_recall_3k: 0.0950 - lcm_recall_5k: 0.1456 - lcm_f1_1k: 0.0552 - lcm_f1_2k: 0.0675 - lcm_f1_3k: 0.0730 - lcm_f1_5k: 0.0797 - lcm_accuracy_1k: 0.0787 - lcm_accuracy_2k: 0.1262 - lcm_accuracy_3k: 0.1685 - lcm_accuracy_5k: 0.2437 - lcm_hamming_loss_k: 0.0064
Epoch 00001: val_loss improved from inf to 0.47238, saving model to logs/iryqte-labs-0604-153410/model/checkpoint_labs.h5
27/27 [==============================] - 13s 416ms/step - loss: 0.5365 - lcm_precision_1k: 0.0787 - lcm_precision_2k: 0.0654 - lcm_precision_3k: 0.0594 - lcm_precision_5k: 0.0549 - lcm_recall_1k: 0.0426 - lcm_recall_2k: 0.0700 - lcm_recall_3k: 0.0950 - lcm_recall_5k: 0.1456 - lcm_f1_1k: 0.0552 - lcm_f1_2k: 0.0675 - lcm_f1_3k: 0.0730 - lcm_f1_5k: 0.0797 - lcm_accuracy_1k: 0.0787 - lcm_accuracy_2k: 0.1262 - lcm_accuracy_3k: 0.1685 - lcm_accuracy_5k: 0.2437 - lcm_hamming_loss_k: 0.0064 - val_loss: 0.4724 - val_lcm_precision_1k: 0.0667 - val_lcm_precision_2k: 0.0663 - val_lcm_precision_3k: 0.0767 - val_lcm_precision_5k: 0.0908 - val_lcm_recall_1k: 0.0321 - val_lcm_recall_2k: 0.0686 - val_lcm_recall_3k: 0.1227 - val_lcm_recall_5k: 0.2428 - val_lcm_f1_1k: 0.0433 - val_lcm_f1_2k: 0.0673 - val_lcm_f1_3k: 0.0942 - val_lcm_f1_5k: 0.1321 - val_lcm_accuracy_1k: 0.0667 - val_lcm_accuracy_2k: 0.1257 - val_lcm_accuracy_3k: 0.2131 - val_lcm_accuracy_5k: 0.3795 - val_lcm_hamming_loss_k: 0.0065
Epoch 2/150
27/27 [==============================] - ETA: 0s - loss: 0.4114 - lcm_precision_1k: 0.2974 - lcm_precision_2k: 0.2489 - lcm_precision_3k: 0.2194 - lcm_precision_5k: 0.1777 - lcm_recall_1k: 0.1707 - lcm_recall_2k: 0.2791 - lcm_recall_3k: 0.3627 - lcm_recall_5k: 0.4802 - lcm_f1_1k: 0.2168 - lcm_f1_2k: 0.2631 - lcm_f1_3k: 0.2733 - lcm_f1_5k: 0.2593 - lcm_accuracy_1k: 0.2974 - lcm_accuracy_2k: 0.4298 - lcm_accuracy_3k: 0.5213 - lcm_accuracy_5k: 0.6321 - lcm_hamming_loss_k: 0.0054 ETA: 7s - loss: 0.4576 - lcm_precision_1k: 0.0883 - lcm_precision_2k: 0.0953 - lcm_precision_3k: 0.1073 - lcm_precision_5k: 0.1131 - lcm_recall_1k: 0.0463 - lcm_recall_2k: 0.1050 - lcm_recall_3k: 0.1743 - lcm_recall_5k: 0.3076 - lcm_f1_1k: 0.0607 - lcm_f1_2k: 0.0998 - lcm_f1_3k: 0.1328 - lcm_f1_5k: 0.1653 - lcm_accuracy_1k: 0.0883 - lcm_accuracy_2k: 0.1785 - lcm_accuracy_3k: 0.2824 - lcm_accu
Epoch 00002: val_loss improved from 0.47238 to 0.37174, saving model to logs/iryqte-labs-0604-153410/model/checkpoint_labs.h5
27/27 [==============================] - 11s 424ms/step - loss: 0.4114 - lcm_precision_1k: 0.2974 - lcm_precision_2k: 0.2489 - lcm_precision_3k: 0.2194 - lcm_precision_5k: 0.1777 - lcm_recall_1k: 0.1707 - lcm_recall_2k: 0.2791 - lcm_recall_3k: 0.3627 - lcm_recall_5k: 0.4802 - lcm_f1_1k: 0.2168 - lcm_f1_2k: 0.2631 - lcm_f1_3k: 0.2733 - lcm_f1_5k: 0.2593 - lcm_accuracy_1k: 0.2974 - lcm_accuracy_2k: 0.4298 - lcm_accuracy_3k: 0.5213 - lcm_accuracy_5k: 0.6321 - lcm_hamming_loss_k: 0.0054 - val_loss: 0.3717 - val_lcm_precision_1k: 0.4108 - val_lcm_precision_2k: 0.3329 - val_lcm_precision_3k: 0.2776 - val_lcm_precision_5k: 0.2148 - val_lcm_recall_1k: 0.2398 - val_lcm_recall_2k: 0.3785 - val_lcm_recall_3k: 0.4659 - val_lcm_recall_5k: 0.5820 - val_lcm_f1_1k: 0.3026 - val_lcm_f1_2k: 0.3540 - val_lcm_f1_3k: 0.3478 - val_lcm_f1_5k: 0.3137 - val_lcm_accuracy_1k: 0.4108 - val_lcm_accuracy_2k: 0.5603 - val_lcm_accuracy_3k: 0.6450 - val_lcm_accuracy_5k: 0.7349 - val_lcm_hamming_loss_k: 0.0049
Epoch 3/150
27/27 [==============================] - ETA: 0s - loss: 0.3472 - lcm_precision_1k: 0.4402 - lcm_precision_2k: 0.3571 - lcm_precision_3k: 0.2974 - lcm_precision_5k: 0.2251 - lcm_recall_1k: 0.2643 - lcm_recall_2k: 0.4110 - lcm_recall_3k: 0.5032 - lcm_recall_5k: 0.6164 - lcm_f1_1k: 0.3303 - lcm_f1_2k: 0.3821 - lcm_f1_3k: 0.3738 - lcm_f1_5k: 0.3297 - lcm_accuracy_1k: 0.4402 - lcm_accuracy_2k: 0.5971 - lcm_accuracy_3k: 0.6800 - lcm_accuracy_5k: 0.7667 - lcm_hamming_loss_k: 0.0047
Epoch 00003: val_loss improved from 0.37174 to 0.34256, saving model to logs/iryqte-labs-0604-153410/model/checkpoint_labs.h5
27/27 [==============================] - 11s 429ms/step - loss: 0.3472 - lcm_precision_1k: 0.4402 - lcm_precision_2k: 0.3571 - lcm_precision_3k: 0.2974 - lcm_precision_5k: 0.2251 - lcm_recall_1k: 0.2643 - lcm_recall_2k: 0.4110 - lcm_recall_3k: 0.5032 - lcm_recall_5k: 0.6164 - lcm_f1_1k: 0.3303 - lcm_f1_2k: 0.3821 - lcm_f1_3k: 0.3738 - lcm_f1_5k: 0.3297 - lcm_accuracy_1k: 0.4402 - lcm_accuracy_2k: 0.5971 - lcm_accuracy_3k: 0.6800 - lcm_accuracy_5k: 0.7667 - lcm_hamming_loss_k: 0.0047 - val_loss: 0.3426 - val_lcm_precision_1k: 0.4727 - val_lcm_precision_2k: 0.3767 - val_lcm_precision_3k: 0.3107 - val_lcm_precision_5k: 0.2315 - val_lcm_recall_1k: 0.2812 - val_lcm_recall_2k: 0.4315 - val_lcm_recall_3k: 0.5246 - val_lcm_recall_5k: 0.6309 - val_lcm_f1_1k: 0.3524 - val_lcm_f1_2k: 0.4021 - val_lcm_f1_3k: 0.3901 - val_lcm_f1_5k: 0.3386 - val_lcm_accuracy_1k: 0.4727 - val_lcm_accuracy_2k: 0.6224 - val_lcm_accuracy_3k: 0.7082 - val_lcm_accuracy_5k: 0.7827 - val_lcm_hamming_loss_k: 0.0046
Epoch 4/150
27/27 [==============================] - ETA: 0s - loss: 0.3218 - lcm_precision_1k: 0.4922 - lcm_precision_2k: 0.3951 - lcm_precision_3k: 0.3279 - lcm_precision_5k: 0.2409 - lcm_recall_1k: 0.2999 - lcm_recall_2k: 0.4572 - lcm_recall_3k: 0.5569 - lcm_recall_5k: 0.6630 - lcm_f1_1k: 0.3726 - lcm_f1_2k: 0.4238 - lcm_f1_3k: 0.4127 - lcm_f1_5k: 0.3533 - lcm_accuracy_1k: 0.4922 - lcm_accuracy_2k: 0.6501 - lcm_accuracy_3k: 0.7305 - lcm_accuracy_5k: 0.8104 - lcm_hamming_loss_k: 0.0045
Epoch 00004: val_loss improved from 0.34256 to 0.32853, saving model to logs/iryqte-labs-0604-153410/model/checkpoint_labs.h5
27/27 [==============================] - 11s 424ms/step - loss: 0.3218 - lcm_precision_1k: 0.4922 - lcm_precision_2k: 0.3951 - lcm_precision_3k: 0.3279 - lcm_precision_5k: 0.2409 - lcm_recall_1k: 0.2999 - lcm_recall_2k: 0.4572 - lcm_recall_3k: 0.5569 - lcm_recall_5k: 0.6630 - lcm_f1_1k: 0.3726 - lcm_f1_2k: 0.4238 - lcm_f1_3k: 0.4127 - lcm_f1_5k: 0.3533 - lcm_accuracy_1k: 0.4922 - lcm_accuracy_2k: 0.6501 - lcm_accuracy_3k: 0.7305 - lcm_accuracy_5k: 0.8104 - lcm_hamming_loss_k: 0.0045 - val_loss: 0.3285 - val_lcm_precision_1k: 0.4947 - val_lcm_precision_2k: 0.3946 - val_lcm_precision_3k: 0.3267 - val_lcm_precision_5k: 0.2404 - val_lcm_recall_1k: 0.3003 - val_lcm_recall_2k: 0.4586 - val_lcm_recall_3k: 0.5544 - val_lcm_recall_5k: 0.6593 - val_lcm_f1_1k: 0.3735 - val_lcm_f1_2k: 0.4240 - val_lcm_f1_3k: 0.4109 - val_lcm_f1_5k: 0.3522 - val_lcm_accuracy_1k: 0.4947 - val_lcm_accuracy_2k: 0.6561 - val_lcm_accuracy_3k: 0.7385 - val_lcm_accuracy_5k: 0.8108 - val_lcm_hamming_loss_k: 0.0045
Epoch 5/150
27/27 [==============================] - ETA: 0s - loss: 0.3061 - lcm_precision_1k: 0.5291 - lcm_precision_2k: 0.4173 - lcm_precision_3k: 0.3439 - lcm_precision_5k: 0.2517 - lcm_recall_1k: 0.3262 - lcm_recall_2k: 0.4867 - lcm_recall_3k: 0.5859 - lcm_recall_5k: 0.6941 - lcm_f1_1k: 0.4035 - lcm_f1_2k: 0.4493 - lcm_f1_3k: 0.4334 - lcm_f1_5k: 0.3694 - lcm_accuracy_1k: 0.5291 - lcm_accuracy_2k: 0.6816 - lcm_accuracy_3k: 0.7590 - lcm_accuracy_5k: 0.8355 - lcm_hamming_loss_k: 0.0043
Epoch 00005: val_loss improved from 0.32853 to 0.31317, saving model to logs/iryqte-labs-0604-153410/model/checkpoint_labs.h5
27/27 [==============================] - 11s 423ms/step - loss: 0.3061 - lcm_precision_1k: 0.5291 - lcm_precision_2k: 0.4173 - lcm_precision_3k: 0.3439 - lcm_precision_5k: 0.2517 - lcm_recall_1k: 0.3262 - lcm_recall_2k: 0.4867 - lcm_recall_3k: 0.5859 - lcm_recall_5k: 0.6941 - lcm_f1_1k: 0.4035 - lcm_f1_2k: 0.4493 - lcm_f1_3k: 0.4334 - lcm_f1_5k: 0.3694 - lcm_accuracy_1k: 0.5291 - lcm_accuracy_2k: 0.6816 - lcm_accuracy_3k: 0.7590 - lcm_accuracy_5k: 0.8355 - lcm_hamming_loss_k: 0.0043 - val_loss: 0.3132 - val_lcm_precision_1k: 0.5269 - val_lcm_precision_2k: 0.4203 - val_lcm_precision_3k: 0.3414 - val_lcm_precision_5k: 0.2462 - val_lcm_recall_1k: 0.3196 - val_lcm_recall_2k: 0.4865 - val_lcm_recall_3k: 0.5794 - val_lcm_recall_5k: 0.6756 - val_lcm_f1_1k: 0.3977 - val_lcm_f1_2k: 0.4508 - val_lcm_f1_3k: 0.4295 - val_lcm_f1_5k: 0.3607 - val_lcm_accuracy_1k: 0.5269 - val_lcm_accuracy_2k: 0.6807 - val_lcm_accuracy_3k: 0.7518 - val_lcm_accuracy_5k: 0.8194 - val_lcm_hamming_loss_k: 0.0044
Epoch 6/150
27/27 [==============================] - ETA: 0s - loss: 0.2934 - lcm_precision_1k: 0.5527 - lcm_precision_2k: 0.4402 - lcm_precision_3k: 0.3591 - lcm_precision_5k: 0.2602 - lcm_recall_1k: 0.3418 - lcm_recall_2k: 0.5146 - lcm_recall_3k: 0.6130 - lcm_recall_5k: 0.7185 - lcm_f1_1k: 0.4223 - lcm_f1_2k: 0.4745 - lcm_f1_3k: 0.4529 - lcm_f1_5k: 0.3820 - lcm_accuracy_1k: 0.5527 - lcm_accuracy_2k: 0.7102 - lcm_accuracy_3k: 0.7849 - lcm_accuracy_5k: 0.8556 - lcm_hamming_loss_k: 0.0042
Epoch 00006: val_loss improved from 0.31317 to 0.30734, saving model to logs/iryqte-labs-0604-153410/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.2934 - lcm_precision_1k: 0.5527 - lcm_precision_2k: 0.4402 - lcm_precision_3k: 0.3591 - lcm_precision_5k: 0.2602 - lcm_recall_1k: 0.3418 - lcm_recall_2k: 0.5146 - lcm_recall_3k: 0.6130 - lcm_recall_5k: 0.7185 - lcm_f1_1k: 0.4223 - lcm_f1_2k: 0.4745 - lcm_f1_3k: 0.4529 - lcm_f1_5k: 0.3820 - lcm_accuracy_1k: 0.5527 - lcm_accuracy_2k: 0.7102 - lcm_accuracy_3k: 0.7849 - lcm_accuracy_5k: 0.8556 - lcm_hamming_loss_k: 0.0042 - val_loss: 0.3073 - val_lcm_precision_1k: 0.5348 - val_lcm_precision_2k: 0.4329 - val_lcm_precision_3k: 0.3532 - val_lcm_precision_5k: 0.2552 - val_lcm_recall_1k: 0.3287 - val_lcm_recall_2k: 0.5020 - val_lcm_recall_3k: 0.5989 - val_lcm_recall_5k: 0.7001 - val_lcm_f1_1k: 0.4070 - val_lcm_f1_2k: 0.4647 - val_lcm_f1_3k: 0.4442 - val_lcm_f1_5k: 0.3739 - val_lcm_accuracy_1k: 0.5348 - val_lcm_accuracy_2k: 0.6974 - val_lcm_accuracy_3k: 0.7721 - val_lcm_accuracy_5k: 0.8396 - val_lcm_hamming_loss_k: 0.0043
Epoch 7/150
27/27 [==============================] - ETA: 0s - loss: 0.2828 - lcm_precision_1k: 0.5753 - lcm_precision_2k: 0.4560 - lcm_precision_3k: 0.3716 - lcm_precision_5k: 0.2681 - lcm_recall_1k: 0.3574 - lcm_recall_2k: 0.5352 - lcm_recall_3k: 0.6352 - lcm_recall_5k: 0.7404 - lcm_f1_1k: 0.4408 - lcm_f1_2k: 0.4924 - lcm_f1_3k: 0.4688 - lcm_f1_5k: 0.3937 - lcm_accuracy_1k: 0.5753 - lcm_accuracy_2k: 0.7351 - lcm_accuracy_3k: 0.8072 - lcm_accuracy_5k: 0.8735 - lcm_hamming_loss_k: 0.0041
Epoch 00007: val_loss improved from 0.30734 to 0.29799, saving model to logs/iryqte-labs-0604-153410/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2828 - lcm_precision_1k: 0.5753 - lcm_precision_2k: 0.4560 - lcm_precision_3k: 0.3716 - lcm_precision_5k: 0.2681 - lcm_recall_1k: 0.3574 - lcm_recall_2k: 0.5352 - lcm_recall_3k: 0.6352 - lcm_recall_5k: 0.7404 - lcm_f1_1k: 0.4408 - lcm_f1_2k: 0.4924 - lcm_f1_3k: 0.4688 - lcm_f1_5k: 0.3937 - lcm_accuracy_1k: 0.5753 - lcm_accuracy_2k: 0.7351 - lcm_accuracy_3k: 0.8072 - lcm_accuracy_5k: 0.8735 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2980 - val_lcm_precision_1k: 0.5575 - val_lcm_precision_2k: 0.4421 - val_lcm_precision_3k: 0.3598 - val_lcm_precision_5k: 0.2591 - val_lcm_recall_1k: 0.3424 - val_lcm_recall_2k: 0.5156 - val_lcm_recall_3k: 0.6113 - val_lcm_recall_5k: 0.7142 - val_lcm_f1_1k: 0.4240 - val_lcm_f1_2k: 0.4758 - val_lcm_f1_3k: 0.4528 - val_lcm_f1_5k: 0.3802 - val_lcm_accuracy_1k: 0.5575 - val_lcm_accuracy_2k: 0.7124 - val_lcm_accuracy_3k: 0.7858 - val_lcm_accuracy_5k: 0.8524 - val_lcm_hamming_loss_k: 0.0042
Epoch 8/150
27/27 [==============================] - ETA: 0s - loss: 0.2735 - lcm_precision_1k: 0.5915 - lcm_precision_2k: 0.4682 - lcm_precision_3k: 0.3796 - lcm_precision_5k: 0.2740 - lcm_recall_1k: 0.3689 - lcm_recall_2k: 0.5507 - lcm_recall_3k: 0.6502 - lcm_recall_5k: 0.7594 - lcm_f1_1k: 0.4543 - lcm_f1_2k: 0.5059 - lcm_f1_3k: 0.4792 - lcm_f1_5k: 0.4026 - lcm_accuracy_1k: 0.5915 - lcm_accuracy_2k: 0.7489 - lcm_accuracy_3k: 0.8204 - lcm_accuracy_5k: 0.8877 - lcm_hamming_loss_k: 0.0040
Epoch 00008: val_loss improved from 0.29799 to 0.29253, saving model to logs/iryqte-labs-0604-153410/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.2735 - lcm_precision_1k: 0.5915 - lcm_precision_2k: 0.4682 - lcm_precision_3k: 0.3796 - lcm_precision_5k: 0.2740 - lcm_recall_1k: 0.3689 - lcm_recall_2k: 0.5507 - lcm_recall_3k: 0.6502 - lcm_recall_5k: 0.7594 - lcm_f1_1k: 0.4543 - lcm_f1_2k: 0.5059 - lcm_f1_3k: 0.4792 - lcm_f1_5k: 0.4026 - lcm_accuracy_1k: 0.5915 - lcm_accuracy_2k: 0.7489 - lcm_accuracy_3k: 0.8204 - lcm_accuracy_5k: 0.8877 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2925 - val_lcm_precision_1k: 0.5689 - val_lcm_precision_2k: 0.4487 - val_lcm_precision_3k: 0.3668 - val_lcm_precision_5k: 0.2645 - val_lcm_recall_1k: 0.3494 - val_lcm_recall_2k: 0.5248 - val_lcm_recall_3k: 0.6239 - val_lcm_recall_5k: 0.7282 - val_lcm_f1_1k: 0.4327 - val_lcm_f1_2k: 0.4836 - val_lcm_f1_3k: 0.4618 - val_lcm_f1_5k: 0.3879 - val_lcm_accuracy_1k: 0.5689 - val_lcm_accuracy_2k: 0.7223 - val_lcm_accuracy_3k: 0.7980 - val_lcm_accuracy_5k: 0.8661 - val_lcm_hamming_loss_k: 0.0042
Epoch 9/150
27/27 [==============================] - ETA: 0s - loss: 0.2655 - lcm_precision_1k: 0.6093 - lcm_precision_2k: 0.4799 - lcm_precision_3k: 0.3891 - lcm_precision_5k: 0.2790 - lcm_recall_1k: 0.3807 - lcm_recall_2k: 0.5655 - lcm_recall_3k: 0.6682 - lcm_recall_5k: 0.7712 - lcm_f1_1k: 0.4685 - lcm_f1_2k: 0.5191 - lcm_f1_3k: 0.4917 - lcm_f1_5k: 0.4097 - lcm_accuracy_1k: 0.6093 - lcm_accuracy_2k: 0.7644 - lcm_accuracy_3k: 0.8375 - lcm_accuracy_5k: 0.8970 - lcm_hamming_loss_k: 0.0040
Epoch 00009: val_loss improved from 0.29253 to 0.29099, saving model to logs/iryqte-labs-0604-153410/model/checkpoint_labs.h5
27/27 [==============================] - 11s 429ms/step - loss: 0.2655 - lcm_precision_1k: 0.6093 - lcm_precision_2k: 0.4799 - lcm_precision_3k: 0.3891 - lcm_precision_5k: 0.2790 - lcm_recall_1k: 0.3807 - lcm_recall_2k: 0.5655 - lcm_recall_3k: 0.6682 - lcm_recall_5k: 0.7712 - lcm_f1_1k: 0.4685 - lcm_f1_2k: 0.5191 - lcm_f1_3k: 0.4917 - lcm_f1_5k: 0.4097 - lcm_accuracy_1k: 0.6093 - lcm_accuracy_2k: 0.7644 - lcm_accuracy_3k: 0.8375 - lcm_accuracy_5k: 0.8970 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2910 - val_lcm_precision_1k: 0.5712 - val_lcm_precision_2k: 0.4565 - val_lcm_precision_3k: 0.3708 - val_lcm_precision_5k: 0.2666 - val_lcm_recall_1k: 0.3523 - val_lcm_recall_2k: 0.5325 - val_lcm_recall_3k: 0.6307 - val_lcm_recall_5k: 0.7358 - val_lcm_f1_1k: 0.4356 - val_lcm_f1_2k: 0.4914 - val_lcm_f1_3k: 0.4668 - val_lcm_f1_5k: 0.3912 - val_lcm_accuracy_1k: 0.5712 - val_lcm_accuracy_2k: 0.7310 - val_lcm_accuracy_3k: 0.8026 - val_lcm_accuracy_5k: 0.8729 - val_lcm_hamming_loss_k: 0.0042
Epoch 10/150
27/27 [==============================] - ETA: 0s - loss: 0.2597 - lcm_precision_1k: 0.6265 - lcm_precision_2k: 0.4893 - lcm_precision_3k: 0.3962 - lcm_precision_5k: 0.2827 - lcm_recall_1k: 0.3926 - lcm_recall_2k: 0.5771 - lcm_recall_3k: 0.6780 - lcm_recall_5k: 0.7817 - lcm_f1_1k: 0.4826 - lcm_f1_2k: 0.5295 - lcm_f1_3k: 0.5000 - lcm_f1_5k: 0.4152 - lcm_accuracy_1k: 0.6265 - lcm_accuracy_2k: 0.7790 - lcm_accuracy_3k: 0.8440 - lcm_accuracy_5k: 0.9045 - lcm_hamming_loss_k: 0.0039
Epoch 00010: val_loss improved from 0.29099 to 0.28435, saving model to logs/iryqte-labs-0604-153410/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.2597 - lcm_precision_1k: 0.6265 - lcm_precision_2k: 0.4893 - lcm_precision_3k: 0.3962 - lcm_precision_5k: 0.2827 - lcm_recall_1k: 0.3926 - lcm_recall_2k: 0.5771 - lcm_recall_3k: 0.6780 - lcm_recall_5k: 0.7817 - lcm_f1_1k: 0.4826 - lcm_f1_2k: 0.5295 - lcm_f1_3k: 0.5000 - lcm_f1_5k: 0.4152 - lcm_accuracy_1k: 0.6265 - lcm_accuracy_2k: 0.7790 - lcm_accuracy_3k: 0.8440 - lcm_accuracy_5k: 0.9045 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2844 - val_lcm_precision_1k: 0.5813 - val_lcm_precision_2k: 0.4605 - val_lcm_precision_3k: 0.3719 - val_lcm_precision_5k: 0.2684 - val_lcm_recall_1k: 0.3589 - val_lcm_recall_2k: 0.5405 - val_lcm_recall_3k: 0.6363 - val_lcm_recall_5k: 0.7398 - val_lcm_f1_1k: 0.4436 - val_lcm_f1_2k: 0.4971 - val_lcm_f1_3k: 0.4692 - val_lcm_f1_5k: 0.3938 - val_lcm_accuracy_1k: 0.5813 - val_lcm_accuracy_2k: 0.7394 - val_lcm_accuracy_3k: 0.8100 - val_lcm_accuracy_5k: 0.8759 - val_lcm_hamming_loss_k: 0.0041
Epoch 11/150
27/27 [==============================] - ETA: 0s - loss: 0.2530 - lcm_precision_1k: 0.6332 - lcm_precision_2k: 0.4987 - lcm_precision_3k: 0.4037 - lcm_precision_5k: 0.2880 - lcm_recall_1k: 0.3986 - lcm_recall_2k: 0.5879 - lcm_recall_3k: 0.6920 - lcm_recall_5k: 0.7953 - lcm_f1_1k: 0.4892 - lcm_f1_2k: 0.5396 - lcm_f1_3k: 0.5099 - lcm_f1_5k: 0.4228 - lcm_accuracy_1k: 0.6332 - lcm_accuracy_2k: 0.7882 - lcm_accuracy_3k: 0.8567 - lcm_accuracy_5k: 0.9135 - lcm_hamming_loss_k: 0.0038
Epoch 00011: val_loss improved from 0.28435 to 0.28062, saving model to logs/iryqte-labs-0604-153410/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.2530 - lcm_precision_1k: 0.6332 - lcm_precision_2k: 0.4987 - lcm_precision_3k: 0.4037 - lcm_precision_5k: 0.2880 - lcm_recall_1k: 0.3986 - lcm_recall_2k: 0.5879 - lcm_recall_3k: 0.6920 - lcm_recall_5k: 0.7953 - lcm_f1_1k: 0.4892 - lcm_f1_2k: 0.5396 - lcm_f1_3k: 0.5099 - lcm_f1_5k: 0.4228 - lcm_accuracy_1k: 0.6332 - lcm_accuracy_2k: 0.7882 - lcm_accuracy_3k: 0.8567 - lcm_accuracy_5k: 0.9135 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2806 - val_lcm_precision_1k: 0.5894 - val_lcm_precision_2k: 0.4753 - val_lcm_precision_3k: 0.3856 - val_lcm_precision_5k: 0.2725 - val_lcm_recall_1k: 0.3651 - val_lcm_recall_2k: 0.5585 - val_lcm_recall_3k: 0.6563 - val_lcm_recall_5k: 0.7510 - val_lcm_f1_1k: 0.4507 - val_lcm_f1_2k: 0.5133 - val_lcm_f1_3k: 0.4856 - val_lcm_f1_5k: 0.3997 - val_lcm_accuracy_1k: 0.5894 - val_lcm_accuracy_2k: 0.7571 - val_lcm_accuracy_3k: 0.8241 - val_lcm_accuracy_5k: 0.8831 - val_lcm_hamming_loss_k: 0.0041
Epoch 12/150
27/27 [==============================] - ETA: 0s - loss: 0.2462 - lcm_precision_1k: 0.6493 - lcm_precision_2k: 0.5116 - lcm_precision_3k: 0.4119 - lcm_precision_5k: 0.2922 - lcm_recall_1k: 0.4105 - lcm_recall_2k: 0.6052 - lcm_recall_3k: 0.7062 - lcm_recall_5k: 0.8072 - lcm_f1_1k: 0.5029 - lcm_f1_2k: 0.5544 - lcm_f1_3k: 0.5203 - lcm_f1_5k: 0.4290 - lcm_accuracy_1k: 0.6493 - lcm_accuracy_2k: 0.8059 - lcm_accuracy_3k: 0.8697 - lcm_accuracy_5k: 0.9216 - lcm_hamming_loss_k: 0.0038
Epoch 00012: val_loss improved from 0.28062 to 0.27729, saving model to logs/iryqte-labs-0604-153410/model/checkpoint_labs.h5
27/27 [==============================] - 11s 424ms/step - loss: 0.2462 - lcm_precision_1k: 0.6493 - lcm_precision_2k: 0.5116 - lcm_precision_3k: 0.4119 - lcm_precision_5k: 0.2922 - lcm_recall_1k: 0.4105 - lcm_recall_2k: 0.6052 - lcm_recall_3k: 0.7062 - lcm_recall_5k: 0.8072 - lcm_f1_1k: 0.5029 - lcm_f1_2k: 0.5544 - lcm_f1_3k: 0.5203 - lcm_f1_5k: 0.4290 - lcm_accuracy_1k: 0.6493 - lcm_accuracy_2k: 0.8059 - lcm_accuracy_3k: 0.8697 - lcm_accuracy_5k: 0.9216 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2773 - val_lcm_precision_1k: 0.5921 - val_lcm_precision_2k: 0.4693 - val_lcm_precision_3k: 0.3835 - val_lcm_precision_5k: 0.2735 - val_lcm_recall_1k: 0.3660 - val_lcm_recall_2k: 0.5481 - val_lcm_recall_3k: 0.6525 - val_lcm_recall_5k: 0.7519 - val_lcm_f1_1k: 0.4523 - val_lcm_f1_2k: 0.5054 - val_lcm_f1_3k: 0.4829 - val_lcm_f1_5k: 0.4009 - val_lcm_accuracy_1k: 0.5921 - val_lcm_accuracy_2k: 0.7433 - val_lcm_accuracy_3k: 0.8198 - val_lcm_accuracy_5k: 0.8843 - val_lcm_hamming_loss_k: 0.0041
Epoch 13/150
27/27 [==============================] - ETA: 0s - loss: 0.2403 - lcm_precision_1k: 0.6637 - lcm_precision_2k: 0.5198 - lcm_precision_3k: 0.4157 - lcm_precision_5k: 0.2946 - lcm_recall_1k: 0.4198 - lcm_recall_2k: 0.6154 - lcm_recall_3k: 0.7139 - lcm_recall_5k: 0.8149 - lcm_f1_1k: 0.5142 - lcm_f1_2k: 0.5635 - lcm_f1_3k: 0.5253 - lcm_f1_5k: 0.4327 - lcm_accuracy_1k: 0.6637 - lcm_accuracy_2k: 0.8135 - lcm_accuracy_3k: 0.8748 - lcm_accuracy_5k: 0.9269 - lcm_hamming_loss_k: 0.0037 ETA: 1s - loss: 0.2402 - lcm_precision_1k: 0.6655 - lcm_precision_2k: 0.5230 - lcm_precision_3k: 0.4180 - lcm_precision_5k: 0.2972 - lcm_recall_1k: 0.4188 - lcm_recall_2k: 0.6172 - lcm_recall_3k: 0.7149 - lcm_recall_5k: 0.8178 - lcm_f1_1k: 0.5140 - lcm_f1_2k: 0.5662 - lcm_f1_3k: 0.5275 - lcm_f1_5k: 0.4359 - lcm_accuracy_1k: 0.6655 - lcm_accuracy_2k: 0.8180 - lcm_accuracy_3k: 0.8773 - lcm_accuracy_5k: 0.9300 - lcm_hamming_loss
Epoch 00013: val_loss did not improve from 0.27729
27/27 [==============================] - 10s 389ms/step - loss: 0.2403 - lcm_precision_1k: 0.6637 - lcm_precision_2k: 0.5198 - lcm_precision_3k: 0.4157 - lcm_precision_5k: 0.2946 - lcm_recall_1k: 0.4198 - lcm_recall_2k: 0.6154 - lcm_recall_3k: 0.7139 - lcm_recall_5k: 0.8149 - lcm_f1_1k: 0.5142 - lcm_f1_2k: 0.5635 - lcm_f1_3k: 0.5253 - lcm_f1_5k: 0.4327 - lcm_accuracy_1k: 0.6637 - lcm_accuracy_2k: 0.8135 - lcm_accuracy_3k: 0.8748 - lcm_accuracy_5k: 0.9269 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2805 - val_lcm_precision_1k: 0.5994 - val_lcm_precision_2k: 0.4772 - val_lcm_precision_3k: 0.3868 - val_lcm_precision_5k: 0.2720 - val_lcm_recall_1k: 0.3727 - val_lcm_recall_2k: 0.5622 - val_lcm_recall_3k: 0.6620 - val_lcm_recall_5k: 0.7514 - val_lcm_f1_1k: 0.4594 - val_lcm_f1_2k: 0.5160 - val_lcm_f1_3k: 0.4881 - val_lcm_f1_5k: 0.3992 - val_lcm_accuracy_1k: 0.5994 - val_lcm_accuracy_2k: 0.7613 - val_lcm_accuracy_3k: 0.8320 - val_lcm_accuracy_5k: 0.8838 - val_lcm_hamming_loss_k: 0.0040
Epoch 14/150
27/27 [==============================] - ETA: 0s - loss: 0.2356 - lcm_precision_1k: 0.6784 - lcm_precision_2k: 0.5294 - lcm_precision_3k: 0.4253 - lcm_precision_5k: 0.2993 - lcm_recall_1k: 0.4308 - lcm_recall_2k: 0.6287 - lcm_recall_3k: 0.7312 - lcm_recall_5k: 0.8275 - lcm_f1_1k: 0.5269 - lcm_f1_2k: 0.5748 - lcm_f1_3k: 0.5378 - lcm_f1_5k: 0.4396 - lcm_accuracy_1k: 0.6784 - lcm_accuracy_2k: 0.8289 - lcm_accuracy_3k: 0.8894 - lcm_accuracy_5k: 0.9364 - lcm_hamming_loss_k: 0.0036
Epoch 00014: val_loss improved from 0.27729 to 0.27541, saving model to logs/iryqte-labs-0604-153410/model/checkpoint_labs.h5
27/27 [==============================] - 11s 429ms/step - loss: 0.2356 - lcm_precision_1k: 0.6784 - lcm_precision_2k: 0.5294 - lcm_precision_3k: 0.4253 - lcm_precision_5k: 0.2993 - lcm_recall_1k: 0.4308 - lcm_recall_2k: 0.6287 - lcm_recall_3k: 0.7312 - lcm_recall_5k: 0.8275 - lcm_f1_1k: 0.5269 - lcm_f1_2k: 0.5748 - lcm_f1_3k: 0.5378 - lcm_f1_5k: 0.4396 - lcm_accuracy_1k: 0.6784 - lcm_accuracy_2k: 0.8289 - lcm_accuracy_3k: 0.8894 - lcm_accuracy_5k: 0.9364 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2754 - val_lcm_precision_1k: 0.6143 - val_lcm_precision_2k: 0.4798 - val_lcm_precision_3k: 0.3875 - val_lcm_precision_5k: 0.2720 - val_lcm_recall_1k: 0.3848 - val_lcm_recall_2k: 0.5661 - val_lcm_recall_3k: 0.6634 - val_lcm_recall_5k: 0.7514 - val_lcm_f1_1k: 0.4731 - val_lcm_f1_2k: 0.5192 - val_lcm_f1_3k: 0.4891 - val_lcm_f1_5k: 0.3993 - val_lcm_accuracy_1k: 0.6143 - val_lcm_accuracy_2k: 0.7648 - val_lcm_accuracy_3k: 0.8333 - val_lcm_accuracy_5k: 0.8842 - val_lcm_hamming_loss_k: 0.0040
Epoch 15/150
27/27 [==============================] - ETA: 0s - loss: 0.2293 - lcm_precision_1k: 0.6873 - lcm_precision_2k: 0.5385 - lcm_precision_3k: 0.4313 - lcm_precision_5k: 0.3025 - lcm_recall_1k: 0.4364 - lcm_recall_2k: 0.6370 - lcm_recall_3k: 0.7386 - lcm_recall_5k: 0.8351 - lcm_f1_1k: 0.5338 - lcm_f1_2k: 0.5835 - lcm_f1_3k: 0.5445 - lcm_f1_5k: 0.4440 - lcm_accuracy_1k: 0.6873 - lcm_accuracy_2k: 0.8347 - lcm_accuracy_3k: 0.8930 - lcm_accuracy_5k: 0.9399 - lcm_hamming_loss_k: 0.0036
Epoch 00015: val_loss did not improve from 0.27541
27/27 [==============================] - 10s 390ms/step - loss: 0.2293 - lcm_precision_1k: 0.6873 - lcm_precision_2k: 0.5385 - lcm_precision_3k: 0.4313 - lcm_precision_5k: 0.3025 - lcm_recall_1k: 0.4364 - lcm_recall_2k: 0.6370 - lcm_recall_3k: 0.7386 - lcm_recall_5k: 0.8351 - lcm_f1_1k: 0.5338 - lcm_f1_2k: 0.5835 - lcm_f1_3k: 0.5445 - lcm_f1_5k: 0.4440 - lcm_accuracy_1k: 0.6873 - lcm_accuracy_2k: 0.8347 - lcm_accuracy_3k: 0.8930 - lcm_accuracy_5k: 0.9399 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2768 - val_lcm_precision_1k: 0.6098 - val_lcm_precision_2k: 0.4863 - val_lcm_precision_3k: 0.3857 - val_lcm_precision_5k: 0.2739 - val_lcm_recall_1k: 0.3799 - val_lcm_recall_2k: 0.5745 - val_lcm_recall_3k: 0.6608 - val_lcm_recall_5k: 0.7554 - val_lcm_f1_1k: 0.4679 - val_lcm_f1_2k: 0.5266 - val_lcm_f1_3k: 0.4868 - val_lcm_f1_5k: 0.4019 - val_lcm_accuracy_1k: 0.6098 - val_lcm_accuracy_2k: 0.7782 - val_lcm_accuracy_3k: 0.8318 - val_lcm_accuracy_5k: 0.8869 - val_lcm_hamming_loss_k: 0.0040
Epoch 16/150
27/27 [==============================] - ETA: 0s - loss: 0.2249 - lcm_precision_1k: 0.7022 - lcm_precision_2k: 0.5465 - lcm_precision_3k: 0.4362 - lcm_precision_5k: 0.3056 - lcm_recall_1k: 0.4484 - lcm_recall_2k: 0.6486 - lcm_recall_3k: 0.7485 - lcm_recall_5k: 0.8447 - lcm_f1_1k: 0.5473 - lcm_f1_2k: 0.5931 - lcm_f1_3k: 0.5511 - lcm_f1_5k: 0.4488 - lcm_accuracy_1k: 0.7022 - lcm_accuracy_2k: 0.8442 - lcm_accuracy_3k: 0.9003 - lcm_accuracy_5k: 0.9463 - lcm_hamming_loss_k: 0.0035
Epoch 00016: val_loss improved from 0.27541 to 0.27022, saving model to logs/iryqte-labs-0604-153410/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.2249 - lcm_precision_1k: 0.7022 - lcm_precision_2k: 0.5465 - lcm_precision_3k: 0.4362 - lcm_precision_5k: 0.3056 - lcm_recall_1k: 0.4484 - lcm_recall_2k: 0.6486 - lcm_recall_3k: 0.7485 - lcm_recall_5k: 0.8447 - lcm_f1_1k: 0.5473 - lcm_f1_2k: 0.5931 - lcm_f1_3k: 0.5511 - lcm_f1_5k: 0.4488 - lcm_accuracy_1k: 0.7022 - lcm_accuracy_2k: 0.8442 - lcm_accuracy_3k: 0.9003 - lcm_accuracy_5k: 0.9463 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2702 - val_lcm_precision_1k: 0.6273 - val_lcm_precision_2k: 0.4916 - val_lcm_precision_3k: 0.3945 - val_lcm_precision_5k: 0.2745 - val_lcm_recall_1k: 0.3946 - val_lcm_recall_2k: 0.5800 - val_lcm_recall_3k: 0.6754 - val_lcm_recall_5k: 0.7555 - val_lcm_f1_1k: 0.4842 - val_lcm_f1_2k: 0.5319 - val_lcm_f1_3k: 0.4979 - val_lcm_f1_5k: 0.4025 - val_lcm_accuracy_1k: 0.6273 - val_lcm_accuracy_2k: 0.7777 - val_lcm_accuracy_3k: 0.8422 - val_lcm_accuracy_5k: 0.8861 - val_lcm_hamming_loss_k: 0.0039
Epoch 17/150
27/27 [==============================] - ETA: 0s - loss: 0.2188 - lcm_precision_1k: 0.7188 - lcm_precision_2k: 0.5578 - lcm_precision_3k: 0.4455 - lcm_precision_5k: 0.3117 - lcm_recall_1k: 0.4606 - lcm_recall_2k: 0.6605 - lcm_recall_3k: 0.7617 - lcm_recall_5k: 0.8572 - lcm_f1_1k: 0.5613 - lcm_f1_2k: 0.6047 - lcm_f1_3k: 0.5621 - lcm_f1_5k: 0.4571 - lcm_accuracy_1k: 0.7188 - lcm_accuracy_2k: 0.8566 - lcm_accuracy_3k: 0.9114 - lcm_accuracy_5k: 0.9543 - lcm_hamming_loss_k: 0.0034
Epoch 00017: val_loss improved from 0.27022 to 0.26910, saving model to logs/iryqte-labs-0604-153410/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.2188 - lcm_precision_1k: 0.7188 - lcm_precision_2k: 0.5578 - lcm_precision_3k: 0.4455 - lcm_precision_5k: 0.3117 - lcm_recall_1k: 0.4606 - lcm_recall_2k: 0.6605 - lcm_recall_3k: 0.7617 - lcm_recall_5k: 0.8572 - lcm_f1_1k: 0.5613 - lcm_f1_2k: 0.6047 - lcm_f1_3k: 0.5621 - lcm_f1_5k: 0.4571 - lcm_accuracy_1k: 0.7188 - lcm_accuracy_2k: 0.8566 - lcm_accuracy_3k: 0.9114 - lcm_accuracy_5k: 0.9543 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2691 - val_lcm_precision_1k: 0.6318 - val_lcm_precision_2k: 0.4910 - val_lcm_precision_3k: 0.3946 - val_lcm_precision_5k: 0.2780 - val_lcm_recall_1k: 0.3974 - val_lcm_recall_2k: 0.5801 - val_lcm_recall_3k: 0.6740 - val_lcm_recall_5k: 0.7658 - val_lcm_f1_1k: 0.4878 - val_lcm_f1_2k: 0.5317 - val_lcm_f1_3k: 0.4976 - val_lcm_f1_5k: 0.4077 - val_lcm_accuracy_1k: 0.6318 - val_lcm_accuracy_2k: 0.7818 - val_lcm_accuracy_3k: 0.8385 - val_lcm_accuracy_5k: 0.8948 - val_lcm_hamming_loss_k: 0.0039
Epoch 18/150
27/27 [==============================] - ETA: 0s - loss: 0.2134 - lcm_precision_1k: 0.7307 - lcm_precision_2k: 0.5668 - lcm_precision_3k: 0.4507 - lcm_precision_5k: 0.3145 - lcm_recall_1k: 0.4683 - lcm_recall_2k: 0.6712 - lcm_recall_3k: 0.7708 - lcm_recall_5k: 0.8651 - lcm_f1_1k: 0.5707 - lcm_f1_2k: 0.6145 - lcm_f1_3k: 0.5688 - lcm_f1_5k: 0.4613 - lcm_accuracy_1k: 0.7307 - lcm_accuracy_2k: 0.8646 - lcm_accuracy_3k: 0.9164 - lcm_accuracy_5k: 0.9573 - lcm_hamming_loss_k: 0.0034
Epoch 00018: val_loss did not improve from 0.26910
27/27 [==============================] - 10s 389ms/step - loss: 0.2134 - lcm_precision_1k: 0.7307 - lcm_precision_2k: 0.5668 - lcm_precision_3k: 0.4507 - lcm_precision_5k: 0.3145 - lcm_recall_1k: 0.4683 - lcm_recall_2k: 0.6712 - lcm_recall_3k: 0.7708 - lcm_recall_5k: 0.8651 - lcm_f1_1k: 0.5707 - lcm_f1_2k: 0.6145 - lcm_f1_3k: 0.5688 - lcm_f1_5k: 0.4613 - lcm_accuracy_1k: 0.7307 - lcm_accuracy_2k: 0.8646 - lcm_accuracy_3k: 0.9164 - lcm_accuracy_5k: 0.9573 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2728 - val_lcm_precision_1k: 0.6254 - val_lcm_precision_2k: 0.4876 - val_lcm_precision_3k: 0.3890 - val_lcm_precision_5k: 0.2760 - val_lcm_recall_1k: 0.3937 - val_lcm_recall_2k: 0.5769 - val_lcm_recall_3k: 0.6673 - val_lcm_recall_5k: 0.7626 - val_lcm_f1_1k: 0.4831 - val_lcm_f1_2k: 0.5282 - val_lcm_f1_3k: 0.4912 - val_lcm_f1_5k: 0.4052 - val_lcm_accuracy_1k: 0.6254 - val_lcm_accuracy_2k: 0.7739 - val_lcm_accuracy_3k: 0.8336 - val_lcm_accuracy_5k: 0.8908 - val_lcm_hamming_loss_k: 0.0039
Epoch 19/150
27/27 [==============================] - ETA: 0s - loss: 0.2072 - lcm_precision_1k: 0.7393 - lcm_precision_2k: 0.5743 - lcm_precision_3k: 0.4564 - lcm_precision_5k: 0.3179 - lcm_recall_1k: 0.4746 - lcm_recall_2k: 0.6806 - lcm_recall_3k: 0.7800 - lcm_recall_5k: 0.8735 - lcm_f1_1k: 0.5780 - lcm_f1_2k: 0.6229 - lcm_f1_3k: 0.5758 - lcm_f1_5k: 0.4661 - lcm_accuracy_1k: 0.7393 - lcm_accuracy_2k: 0.8725 - lcm_accuracy_3k: 0.9214 - lcm_accuracy_5k: 0.9613 - lcm_hamming_loss_k: 0.0033
Epoch 00019: val_loss did not improve from 0.26910
27/27 [==============================] - 10s 389ms/step - loss: 0.2072 - lcm_precision_1k: 0.7393 - lcm_precision_2k: 0.5743 - lcm_precision_3k: 0.4564 - lcm_precision_5k: 0.3179 - lcm_recall_1k: 0.4746 - lcm_recall_2k: 0.6806 - lcm_recall_3k: 0.7800 - lcm_recall_5k: 0.8735 - lcm_f1_1k: 0.5780 - lcm_f1_2k: 0.6229 - lcm_f1_3k: 0.5758 - lcm_f1_5k: 0.4661 - lcm_accuracy_1k: 0.7393 - lcm_accuracy_2k: 0.8725 - lcm_accuracy_3k: 0.9214 - lcm_accuracy_5k: 0.9613 - lcm_hamming_loss_k: 0.0033 - val_loss: 0.2703 - val_lcm_precision_1k: 0.6229 - val_lcm_precision_2k: 0.4914 - val_lcm_precision_3k: 0.3941 - val_lcm_precision_5k: 0.2753 - val_lcm_recall_1k: 0.3906 - val_lcm_recall_2k: 0.5808 - val_lcm_recall_3k: 0.6737 - val_lcm_recall_5k: 0.7582 - val_lcm_f1_1k: 0.4799 - val_lcm_f1_2k: 0.5322 - val_lcm_f1_3k: 0.4971 - val_lcm_f1_5k: 0.4038 - val_lcm_accuracy_1k: 0.6229 - val_lcm_accuracy_2k: 0.7779 - val_lcm_accuracy_3k: 0.8412 - val_lcm_accuracy_5k: 0.8889 - val_lcm_hamming_loss_k: 0.0039
Epoch 00019: early stopping
176/176 [==============================] - 8s 43ms/step - loss: 0.2316 - lcm_precision_1k: 0.6889 - lcm_precision_2k: 0.5300 - lcm_precision_3k: 0.4264 - lcm_precision_5k: 0.2978 - lcm_recall_1k: 0.4419 - lcm_recall_2k: 0.6322 - lcm_recall_3k: 0.7341 - lcm_recall_5k: 0.8265 - lcm_f1_1k: 0.5371 - lcm_f1_2k: 0.5754 - lcm_f1_3k: 0.5383 - lcm_f1_5k: 0.4371 - lcm_accuracy_1k: 0.6889 - lcm_accuracy_2k: 0.8271 - lcm_accuracy_3k: 0.8825 - lcm_accuracy_5k: 0.9306 - lcm_hamming_loss_k: 0.0036
Best model result:  [0.2315511703491211, 0.6888749599456787, 0.5300329923629761, 0.4263506233692169, 0.2978267967700958, 0.44189146161079407, 0.6321953535079956, 0.7340865731239319, 0.8264983892440796, 0.5371054410934448, 0.5753656625747681, 0.5383042693138123, 0.43711748719215393, 0.6888749599456787, 0.8271154761314392, 0.8824829459190369, 0.9305791258811951, 0.003559085540473461]
13498
3375
5625
Model: "model_4"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_6 (Sl  (None, 15, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_6[0][0
                                                                 ]']                              
                                                                                                  
 permute_6 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_10 (Lambda)             (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_6[0][0]']              
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_10[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_11 (Lambda)             (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_4 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_11[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_2 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_4[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_6 (Dense)                (None, 1024)         2098176     ['tf.concat_2[0][0]']            
                                                                                                  
 dense_7 (Dense)                (None, 15)           15375       ['dense_6[0][0]']                
                                                                                                  
 tf.nn.softmax_2 (TFOpLambda)   (None, 15)           0           ['dense_7[0][0]']                
                                                                                                  
 tf.expand_dims_4 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_2[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_4[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_7 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_12 (Lambda)             (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_7[0][0]']              
                                                                                                  
 dense_8 (Dense)                (None, 15, 150)      22650       ['lambda_12[0][0]']              
                                                                                                  
 tf.math.reduce_mean_5 (TFOpLam  (None, 150)         0           ['dense_8[0][0]']                
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_5 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_5[0][0]']  
                                                                                                  
 tf.__operators__.getitem_7 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 tf.math.multiply_2 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_5[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_7[0][0
                                                                 ]']                              
                                                                                                  
 permute_8 (Permute)            (None, 1024, 150)    0           ['tf.math.multiply_2[0][0]']     
                                                                                                  
 lambda_13 (Lambda)             (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_8[0][0]']              
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_13[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_14 (Lambda)             (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_2[0][0]']     
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_14[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
==================================================================================================
Total params: 31,474,320
Trainable params: 6,695,820
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
2 patience
Model: "model_5"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_6 (Sl  (None, 15, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_6[0][0
                                                                 ]']                              
                                                                                                  
 permute_6 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_10 (Lambda)             (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_6[0][0]']              
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_10[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_11 (Lambda)             (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_4 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_11[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_2 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_4[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_6 (Dense)                (None, 1024)         2098176     ['tf.concat_2[0][0]']            
                                                                                                  
 dense_7 (Dense)                (None, 15)           15375       ['dense_6[0][0]']                
                                                                                                  
 tf.nn.softmax_2 (TFOpLambda)   (None, 15)           0           ['dense_7[0][0]']                
                                                                                                  
 tf.expand_dims_4 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_2[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_4[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_7 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_12 (Lambda)             (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_7[0][0]']              
                                                                                                  
 dense_8 (Dense)                (None, 15, 150)      22650       ['lambda_12[0][0]']              
                                                                                                  
 tf.math.reduce_mean_5 (TFOpLam  (None, 150)         0           ['dense_8[0][0]']                
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_5 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_5[0][0]']  
                                                                                                  
 tf.__operators__.getitem_7 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 tf.math.multiply_2 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_5[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_7[0][0
                                                                 ]']                              
                                                                                                  
 permute_8 (Permute)            (None, 1024, 150)    0           ['tf.math.multiply_2[0][0]']     
                                                                                                  
 lambda_13 (Lambda)             (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_8[0][0]']              
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_13[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_14 (Lambda)             (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_2[0][0]']     
                                                                                                  
 tf.__operators__.getitem_8 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_14[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 label_lcm_emb (Dense)          (None, 427, 1024)    308224      ['tf.__operators__.getitem_8[0][0
                                                                 ]']                              
                                                                                                  
 dot_2 (Dot)                    (None, 427)          0           ['label_lcm_emb[0][0]',          
                                                                  '1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 label_sim_dict (Dense)         (None, 427)          182756      ['dot_2[0][0]']                  
                                                                                                  
 concatenate_2 (Concatenate)    (None, 854)          0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 31,965,300
Trainable params: 7,186,800
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
Epoch 1/150
27/27 [==============================] - ETA: 0s - loss: 0.5343 - lcm_precision_1k: 0.0624 - lcm_precision_2k: 0.0687 - lcm_precision_3k: 0.0655 - lcm_precision_5k: 0.0587 - lcm_recall_1k: 0.0338 - lcm_recall_2k: 0.0743 - lcm_recall_3k: 0.1069 - lcm_recall_5k: 0.1582 - lcm_f1_1k: 0.0437 - lcm_f1_2k: 0.0714 - lcm_f1_3k: 0.0812 - lcm_f1_5k: 0.0855 - lcm_accuracy_1k: 0.0624 - lcm_accuracy_2k: 0.1351 - lcm_accuracy_3k: 0.1852 - lcm_accuracy_5k: 0.2550 - lcm_hamming_loss_k: 0.0065
Epoch 00001: val_loss improved from inf to 0.47757, saving model to logs/gdhwyc-labs-0604-153754/model/checkpoint_labs.h5
27/27 [==============================] - 13s 426ms/step - loss: 0.5343 - lcm_precision_1k: 0.0624 - lcm_precision_2k: 0.0687 - lcm_precision_3k: 0.0655 - lcm_precision_5k: 0.0587 - lcm_recall_1k: 0.0338 - lcm_recall_2k: 0.0743 - lcm_recall_3k: 0.1069 - lcm_recall_5k: 0.1582 - lcm_f1_1k: 0.0437 - lcm_f1_2k: 0.0714 - lcm_f1_3k: 0.0812 - lcm_f1_5k: 0.0855 - lcm_accuracy_1k: 0.0624 - lcm_accuracy_2k: 0.1351 - lcm_accuracy_3k: 0.1852 - lcm_accuracy_5k: 0.2550 - lcm_hamming_loss_k: 0.0065 - val_loss: 0.4776 - val_lcm_precision_1k: 0.0153 - val_lcm_precision_2k: 0.1036 - val_lcm_precision_3k: 0.1176 - val_lcm_precision_5k: 0.1121 - val_lcm_recall_1k: 0.0085 - val_lcm_recall_2k: 0.1132 - val_lcm_recall_3k: 0.1915 - val_lcm_recall_5k: 0.2999 - val_lcm_f1_1k: 0.0108 - val_lcm_f1_2k: 0.1081 - val_lcm_f1_3k: 0.1456 - val_lcm_f1_5k: 0.1631 - val_lcm_accuracy_1k: 0.0153 - val_lcm_accuracy_2k: 0.2058 - val_lcm_accuracy_3k: 0.3135 - val_lcm_accuracy_5k: 0.4441 - val_lcm_hamming_loss_k: 0.0068
Epoch 2/150
27/27 [==============================] - ETA: 0s - loss: 0.4138 - lcm_precision_1k: 0.2059 - lcm_precision_2k: 0.2266 - lcm_precision_3k: 0.2104 - lcm_precision_5k: 0.1745 - lcm_recall_1k: 0.1181 - lcm_recall_2k: 0.2555 - lcm_recall_3k: 0.3502 - lcm_recall_5k: 0.4736 - lcm_f1_1k: 0.1499 - lcm_f1_2k: 0.2401 - lcm_f1_3k: 0.2628 - lcm_f1_5k: 0.2550 - lcm_accuracy_1k: 0.2059 - lcm_accuracy_2k: 0.4066 - lcm_accuracy_3k: 0.5116 - lcm_accuracy_5k: 0.6292 - lcm_hamming_loss_k: 0.0058 ETA: 3s - loss: 0.4313 - lcm_precision_1k: 0.0991 - lcm_precision_2k: 0.1782 - lcm_precision_3k: 0.1788 - lcm_precision_5k: 0.1566 - lcm_recall_1k: 0.0550 - lcm_recall_2k: 0.2017 - lcm_recall_3k: 0.2987 - lcm_recall_5k: 0.4260 - lcm_f1_1k: 0.0706 - lcm_f1_2k: 0.1892 - lcm_f1_3k: 0.2236 - lcm_f1_5k: 0.2290 - lcm_accuracy_1k: 0.0991 - lcm_accuracy_2k: 0.3383 - lcm_accuracy_3k: 0.4541 - lcm_accuracy_5k: 0.5826 - lcm_
Epoch 00002: val_loss improved from 0.47757 to 0.37942, saving model to logs/gdhwyc-labs-0604-153754/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.4138 - lcm_precision_1k: 0.2059 - lcm_precision_2k: 0.2266 - lcm_precision_3k: 0.2104 - lcm_precision_5k: 0.1745 - lcm_recall_1k: 0.1181 - lcm_recall_2k: 0.2555 - lcm_recall_3k: 0.3502 - lcm_recall_5k: 0.4736 - lcm_f1_1k: 0.1499 - lcm_f1_2k: 0.2401 - lcm_f1_3k: 0.2628 - lcm_f1_5k: 0.2550 - lcm_accuracy_1k: 0.2059 - lcm_accuracy_2k: 0.4066 - lcm_accuracy_3k: 0.5116 - lcm_accuracy_5k: 0.6292 - lcm_hamming_loss_k: 0.0058 - val_loss: 0.3794 - val_lcm_precision_1k: 0.3960 - val_lcm_precision_2k: 0.3245 - val_lcm_precision_3k: 0.2734 - val_lcm_precision_5k: 0.2082 - val_lcm_recall_1k: 0.2314 - val_lcm_recall_2k: 0.3669 - val_lcm_recall_3k: 0.4551 - val_lcm_recall_5k: 0.5595 - val_lcm_f1_1k: 0.2920 - val_lcm_f1_2k: 0.3441 - val_lcm_f1_3k: 0.3414 - val_lcm_f1_5k: 0.3033 - val_lcm_accuracy_1k: 0.3960 - val_lcm_accuracy_2k: 0.5453 - val_lcm_accuracy_3k: 0.6325 - val_lcm_accuracy_5k: 0.7160 - val_lcm_hamming_loss_k: 0.0050
Epoch 3/150
27/27 [==============================] - ETA: 0s - loss: 0.3487 - lcm_precision_1k: 0.4346 - lcm_precision_2k: 0.3565 - lcm_precision_3k: 0.2958 - lcm_precision_5k: 0.2245 - lcm_recall_1k: 0.2609 - lcm_recall_2k: 0.4102 - lcm_recall_3k: 0.4989 - lcm_recall_5k: 0.6146 - lcm_f1_1k: 0.3260 - lcm_f1_2k: 0.3814 - lcm_f1_3k: 0.3713 - lcm_f1_5k: 0.3288 - lcm_accuracy_1k: 0.4346 - lcm_accuracy_2k: 0.5934 - lcm_accuracy_3k: 0.6745 - lcm_accuracy_5k: 0.7667 - lcm_hamming_loss_k: 0.0048 ETA: 7s - loss: 0.3565 - lcm_precision_1k: 0.4141 - lcm_precision_2k: 0.3447 - lcm_precision_3k: 0.2856 - lcm_precision_5k: 0.2169 - lcm_recall_1k: 0.2432 - lcm_recall_2k: 0.3910 - lcm_recall_3k: 0.4753 - lcm_recall_5k: 0.5906 - lcm_f1_1k: 0.3064 - lcm_f1_2k: 0.3664 - lcm_f1_3k: 0.3568 - lcm_f1_5k: 0.3173 - lcm_accuracy_1k: 0.4141 - lcm_accuracy_2k: 0.5697 - lcm_accuracy_3k: 0.6478 - lcm_
Epoch 00003: val_loss improved from 0.37942 to 0.34374, saving model to logs/gdhwyc-labs-0604-153754/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.3487 - lcm_precision_1k: 0.4346 - lcm_precision_2k: 0.3565 - lcm_precision_3k: 0.2958 - lcm_precision_5k: 0.2245 - lcm_recall_1k: 0.2609 - lcm_recall_2k: 0.4102 - lcm_recall_3k: 0.4989 - lcm_recall_5k: 0.6146 - lcm_f1_1k: 0.3260 - lcm_f1_2k: 0.3814 - lcm_f1_3k: 0.3713 - lcm_f1_5k: 0.3288 - lcm_accuracy_1k: 0.4346 - lcm_accuracy_2k: 0.5934 - lcm_accuracy_3k: 0.6745 - lcm_accuracy_5k: 0.7667 - lcm_hamming_loss_k: 0.0048 - val_loss: 0.3437 - val_lcm_precision_1k: 0.4671 - val_lcm_precision_2k: 0.3718 - val_lcm_precision_3k: 0.3080 - val_lcm_precision_5k: 0.2296 - val_lcm_recall_1k: 0.2812 - val_lcm_recall_2k: 0.4260 - val_lcm_recall_3k: 0.5160 - val_lcm_recall_5k: 0.6258 - val_lcm_f1_1k: 0.3508 - val_lcm_f1_2k: 0.3968 - val_lcm_f1_3k: 0.3855 - val_lcm_f1_5k: 0.3357 - val_lcm_accuracy_1k: 0.4671 - val_lcm_accuracy_2k: 0.6185 - val_lcm_accuracy_3k: 0.7000 - val_lcm_accuracy_5k: 0.7783 - val_lcm_hamming_loss_k: 0.0047
Epoch 4/150
27/27 [==============================] - ETA: 0s - loss: 0.3216 - lcm_precision_1k: 0.4867 - lcm_precision_2k: 0.3948 - lcm_precision_3k: 0.3259 - lcm_precision_5k: 0.2415 - lcm_recall_1k: 0.2978 - lcm_recall_2k: 0.4584 - lcm_recall_3k: 0.5540 - lcm_recall_5k: 0.6653 - lcm_f1_1k: 0.3694 - lcm_f1_2k: 0.4242 - lcm_f1_3k: 0.4103 - lcm_f1_5k: 0.3544 - lcm_accuracy_1k: 0.4867 - lcm_accuracy_2k: 0.6491 - lcm_accuracy_3k: 0.7292 - lcm_accuracy_5k: 0.8085 - lcm_hamming_loss_k: 0.0045
Epoch 00004: val_loss improved from 0.34374 to 0.33082, saving model to logs/gdhwyc-labs-0604-153754/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.3216 - lcm_precision_1k: 0.4867 - lcm_precision_2k: 0.3948 - lcm_precision_3k: 0.3259 - lcm_precision_5k: 0.2415 - lcm_recall_1k: 0.2978 - lcm_recall_2k: 0.4584 - lcm_recall_3k: 0.5540 - lcm_recall_5k: 0.6653 - lcm_f1_1k: 0.3694 - lcm_f1_2k: 0.4242 - lcm_f1_3k: 0.4103 - lcm_f1_5k: 0.3544 - lcm_accuracy_1k: 0.4867 - lcm_accuracy_2k: 0.6491 - lcm_accuracy_3k: 0.7292 - lcm_accuracy_5k: 0.8085 - lcm_hamming_loss_k: 0.0045 - val_loss: 0.3308 - val_lcm_precision_1k: 0.4906 - val_lcm_precision_2k: 0.3902 - val_lcm_precision_3k: 0.3253 - val_lcm_precision_5k: 0.2386 - val_lcm_recall_1k: 0.2977 - val_lcm_recall_2k: 0.4483 - val_lcm_recall_3k: 0.5454 - val_lcm_recall_5k: 0.6485 - val_lcm_f1_1k: 0.3704 - val_lcm_f1_2k: 0.4171 - val_lcm_f1_3k: 0.4073 - val_lcm_f1_5k: 0.3487 - val_lcm_accuracy_1k: 0.4906 - val_lcm_accuracy_2k: 0.6454 - val_lcm_accuracy_3k: 0.7246 - val_lcm_accuracy_5k: 0.7983 - val_lcm_hamming_loss_k: 0.0045
Epoch 5/150
27/27 [==============================] - ETA: 0s - loss: 0.3042 - lcm_precision_1k: 0.5265 - lcm_precision_2k: 0.4223 - lcm_precision_3k: 0.3450 - lcm_precision_5k: 0.2527 - lcm_recall_1k: 0.3233 - lcm_recall_2k: 0.4946 - lcm_recall_3k: 0.5892 - lcm_recall_5k: 0.6965 - lcm_f1_1k: 0.4005 - lcm_f1_2k: 0.4555 - lcm_f1_3k: 0.4351 - lcm_f1_5k: 0.3708 - lcm_accuracy_1k: 0.5265 - lcm_accuracy_2k: 0.6905 - lcm_accuracy_3k: 0.7655 - lcm_accuracy_5k: 0.8366 - lcm_hamming_loss_k: 0.0043
Epoch 00005: val_loss improved from 0.33082 to 0.31658, saving model to logs/gdhwyc-labs-0604-153754/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.3042 - lcm_precision_1k: 0.5265 - lcm_precision_2k: 0.4223 - lcm_precision_3k: 0.3450 - lcm_precision_5k: 0.2527 - lcm_recall_1k: 0.3233 - lcm_recall_2k: 0.4946 - lcm_recall_3k: 0.5892 - lcm_recall_5k: 0.6965 - lcm_f1_1k: 0.4005 - lcm_f1_2k: 0.4555 - lcm_f1_3k: 0.4351 - lcm_f1_5k: 0.3708 - lcm_accuracy_1k: 0.5265 - lcm_accuracy_2k: 0.6905 - lcm_accuracy_3k: 0.7655 - lcm_accuracy_5k: 0.8366 - lcm_hamming_loss_k: 0.0043 - val_loss: 0.3166 - val_lcm_precision_1k: 0.5337 - val_lcm_precision_2k: 0.4200 - val_lcm_precision_3k: 0.3449 - val_lcm_precision_5k: 0.2494 - val_lcm_recall_1k: 0.3276 - val_lcm_recall_2k: 0.4843 - val_lcm_recall_3k: 0.5795 - val_lcm_recall_5k: 0.6816 - val_lcm_f1_1k: 0.4058 - val_lcm_f1_2k: 0.4497 - val_lcm_f1_3k: 0.4322 - val_lcm_f1_5k: 0.3650 - val_lcm_accuracy_1k: 0.5337 - val_lcm_accuracy_2k: 0.6808 - val_lcm_accuracy_3k: 0.7554 - val_lcm_accuracy_5k: 0.8268 - val_lcm_hamming_loss_k: 0.0043
Epoch 6/150
27/27 [==============================] - ETA: 0s - loss: 0.2915 - lcm_precision_1k: 0.5586 - lcm_precision_2k: 0.4407 - lcm_precision_3k: 0.3586 - lcm_precision_5k: 0.2617 - lcm_recall_1k: 0.3460 - lcm_recall_2k: 0.5177 - lcm_recall_3k: 0.6133 - lcm_recall_5k: 0.7242 - lcm_f1_1k: 0.4272 - lcm_f1_2k: 0.4761 - lcm_f1_3k: 0.4525 - lcm_f1_5k: 0.3844 - lcm_accuracy_1k: 0.5586 - lcm_accuracy_2k: 0.7157 - lcm_accuracy_3k: 0.7861 - lcm_accuracy_5k: 0.8602 - lcm_hamming_loss_k: 0.0042
Epoch 00006: val_loss improved from 0.31658 to 0.30740, saving model to logs/gdhwyc-labs-0604-153754/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2915 - lcm_precision_1k: 0.5586 - lcm_precision_2k: 0.4407 - lcm_precision_3k: 0.3586 - lcm_precision_5k: 0.2617 - lcm_recall_1k: 0.3460 - lcm_recall_2k: 0.5177 - lcm_recall_3k: 0.6133 - lcm_recall_5k: 0.7242 - lcm_f1_1k: 0.4272 - lcm_f1_2k: 0.4761 - lcm_f1_3k: 0.4525 - lcm_f1_5k: 0.3844 - lcm_accuracy_1k: 0.5586 - lcm_accuracy_2k: 0.7157 - lcm_accuracy_3k: 0.7861 - lcm_accuracy_5k: 0.8602 - lcm_hamming_loss_k: 0.0042 - val_loss: 0.3074 - val_lcm_precision_1k: 0.5467 - val_lcm_precision_2k: 0.4246 - val_lcm_precision_3k: 0.3509 - val_lcm_precision_5k: 0.2542 - val_lcm_recall_1k: 0.3337 - val_lcm_recall_2k: 0.4908 - val_lcm_recall_3k: 0.5957 - val_lcm_recall_5k: 0.6965 - val_lcm_f1_1k: 0.4143 - val_lcm_f1_2k: 0.4551 - val_lcm_f1_3k: 0.4415 - val_lcm_f1_5k: 0.3723 - val_lcm_accuracy_1k: 0.5467 - val_lcm_accuracy_2k: 0.6919 - val_lcm_accuracy_3k: 0.7709 - val_lcm_accuracy_5k: 0.8379 - val_lcm_hamming_loss_k: 0.0043
Epoch 7/150
27/27 [==============================] - ETA: 0s - loss: 0.2800 - lcm_precision_1k: 0.5782 - lcm_precision_2k: 0.4596 - lcm_precision_3k: 0.3731 - lcm_precision_5k: 0.2687 - lcm_recall_1k: 0.3597 - lcm_recall_2k: 0.5415 - lcm_recall_3k: 0.6391 - lcm_recall_5k: 0.7435 - lcm_f1_1k: 0.4434 - lcm_f1_2k: 0.4971 - lcm_f1_3k: 0.4711 - lcm_f1_5k: 0.3947 - lcm_accuracy_1k: 0.5782 - lcm_accuracy_2k: 0.7383 - lcm_accuracy_3k: 0.8114 - lcm_accuracy_5k: 0.8751 - lcm_hamming_loss_k: 0.0041
Epoch 00007: val_loss improved from 0.30740 to 0.30152, saving model to logs/gdhwyc-labs-0604-153754/model/checkpoint_labs.h5
27/27 [==============================] - 11s 423ms/step - loss: 0.2800 - lcm_precision_1k: 0.5782 - lcm_precision_2k: 0.4596 - lcm_precision_3k: 0.3731 - lcm_precision_5k: 0.2687 - lcm_recall_1k: 0.3597 - lcm_recall_2k: 0.5415 - lcm_recall_3k: 0.6391 - lcm_recall_5k: 0.7435 - lcm_f1_1k: 0.4434 - lcm_f1_2k: 0.4971 - lcm_f1_3k: 0.4711 - lcm_f1_5k: 0.3947 - lcm_accuracy_1k: 0.5782 - lcm_accuracy_2k: 0.7383 - lcm_accuracy_3k: 0.8114 - lcm_accuracy_5k: 0.8751 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.3015 - val_lcm_precision_1k: 0.5533 - val_lcm_precision_2k: 0.4376 - val_lcm_precision_3k: 0.3599 - val_lcm_precision_5k: 0.2586 - val_lcm_recall_1k: 0.3399 - val_lcm_recall_2k: 0.5076 - val_lcm_recall_3k: 0.6107 - val_lcm_recall_5k: 0.7091 - val_lcm_f1_1k: 0.4209 - val_lcm_f1_2k: 0.4698 - val_lcm_f1_3k: 0.4527 - val_lcm_f1_5k: 0.3788 - val_lcm_accuracy_1k: 0.5533 - val_lcm_accuracy_2k: 0.7079 - val_lcm_accuracy_3k: 0.7858 - val_lcm_accuracy_5k: 0.8493 - val_lcm_hamming_loss_k: 0.0043
Epoch 8/150
27/27 [==============================] - ETA: 0s - loss: 0.2738 - lcm_precision_1k: 0.5975 - lcm_precision_2k: 0.4709 - lcm_precision_3k: 0.3807 - lcm_precision_5k: 0.2740 - lcm_recall_1k: 0.3735 - lcm_recall_2k: 0.5555 - lcm_recall_3k: 0.6522 - lcm_recall_5k: 0.7575 - lcm_f1_1k: 0.4596 - lcm_f1_2k: 0.5096 - lcm_f1_3k: 0.4807 - lcm_f1_5k: 0.4024 - lcm_accuracy_1k: 0.5975 - lcm_accuracy_2k: 0.7535 - lcm_accuracy_3k: 0.8233 - lcm_accuracy_5k: 0.8865 - lcm_hamming_loss_k: 0.0040
Epoch 00008: val_loss improved from 0.30152 to 0.29389, saving model to logs/gdhwyc-labs-0604-153754/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2738 - lcm_precision_1k: 0.5975 - lcm_precision_2k: 0.4709 - lcm_precision_3k: 0.3807 - lcm_precision_5k: 0.2740 - lcm_recall_1k: 0.3735 - lcm_recall_2k: 0.5555 - lcm_recall_3k: 0.6522 - lcm_recall_5k: 0.7575 - lcm_f1_1k: 0.4596 - lcm_f1_2k: 0.5096 - lcm_f1_3k: 0.4807 - lcm_f1_5k: 0.4024 - lcm_accuracy_1k: 0.5975 - lcm_accuracy_2k: 0.7535 - lcm_accuracy_3k: 0.8233 - lcm_accuracy_5k: 0.8865 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2939 - val_lcm_precision_1k: 0.5633 - val_lcm_precision_2k: 0.4402 - val_lcm_precision_3k: 0.3618 - val_lcm_precision_5k: 0.2610 - val_lcm_recall_1k: 0.3435 - val_lcm_recall_2k: 0.5106 - val_lcm_recall_3k: 0.6129 - val_lcm_recall_5k: 0.7155 - val_lcm_f1_1k: 0.4265 - val_lcm_f1_2k: 0.4726 - val_lcm_f1_3k: 0.4548 - val_lcm_f1_5k: 0.3823 - val_lcm_accuracy_1k: 0.5633 - val_lcm_accuracy_2k: 0.7111 - val_lcm_accuracy_3k: 0.7840 - val_lcm_accuracy_5k: 0.8543 - val_lcm_hamming_loss_k: 0.0042
Epoch 9/150
27/27 [==============================] - ETA: 0s - loss: 0.2647 - lcm_precision_1k: 0.6044 - lcm_precision_2k: 0.4815 - lcm_precision_3k: 0.3901 - lcm_precision_5k: 0.2796 - lcm_recall_1k: 0.3781 - lcm_recall_2k: 0.5689 - lcm_recall_3k: 0.6688 - lcm_recall_5k: 0.7729 - lcm_f1_1k: 0.4651 - lcm_f1_2k: 0.5215 - lcm_f1_3k: 0.4927 - lcm_f1_5k: 0.4106 - lcm_accuracy_1k: 0.6044 - lcm_accuracy_2k: 0.7667 - lcm_accuracy_3k: 0.8365 - lcm_accuracy_5k: 0.8976 - lcm_hamming_loss_k: 0.0040
Epoch 00009: val_loss improved from 0.29389 to 0.28851, saving model to logs/gdhwyc-labs-0604-153754/model/checkpoint_labs.h5
27/27 [==============================] - 11s 429ms/step - loss: 0.2647 - lcm_precision_1k: 0.6044 - lcm_precision_2k: 0.4815 - lcm_precision_3k: 0.3901 - lcm_precision_5k: 0.2796 - lcm_recall_1k: 0.3781 - lcm_recall_2k: 0.5689 - lcm_recall_3k: 0.6688 - lcm_recall_5k: 0.7729 - lcm_f1_1k: 0.4651 - lcm_f1_2k: 0.5215 - lcm_f1_3k: 0.4927 - lcm_f1_5k: 0.4106 - lcm_accuracy_1k: 0.6044 - lcm_accuracy_2k: 0.7667 - lcm_accuracy_3k: 0.8365 - lcm_accuracy_5k: 0.8976 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2885 - val_lcm_precision_1k: 0.5755 - val_lcm_precision_2k: 0.4503 - val_lcm_precision_3k: 0.3695 - val_lcm_precision_5k: 0.2644 - val_lcm_recall_1k: 0.3545 - val_lcm_recall_2k: 0.5259 - val_lcm_recall_3k: 0.6275 - val_lcm_recall_5k: 0.7264 - val_lcm_f1_1k: 0.4386 - val_lcm_f1_2k: 0.4850 - val_lcm_f1_3k: 0.4649 - val_lcm_f1_5k: 0.3875 - val_lcm_accuracy_1k: 0.5755 - val_lcm_accuracy_2k: 0.7256 - val_lcm_accuracy_3k: 0.8017 - val_lcm_accuracy_5k: 0.8649 - val_lcm_hamming_loss_k: 0.0041
Epoch 10/150
27/27 [==============================] - ETA: 0s - loss: 0.2559 - lcm_precision_1k: 0.6321 - lcm_precision_2k: 0.4961 - lcm_precision_3k: 0.3992 - lcm_precision_5k: 0.2849 - lcm_recall_1k: 0.3979 - lcm_recall_2k: 0.5864 - lcm_recall_3k: 0.6851 - lcm_recall_5k: 0.7874 - lcm_f1_1k: 0.4883 - lcm_f1_2k: 0.5374 - lcm_f1_3k: 0.5044 - lcm_f1_5k: 0.4184 - lcm_accuracy_1k: 0.6321 - lcm_accuracy_2k: 0.7864 - lcm_accuracy_3k: 0.8519 - lcm_accuracy_5k: 0.9075 - lcm_hamming_loss_k: 0.0038
Epoch 00010: val_loss improved from 0.28851 to 0.28655, saving model to logs/gdhwyc-labs-0604-153754/model/checkpoint_labs.h5
27/27 [==============================] - 12s 431ms/step - loss: 0.2559 - lcm_precision_1k: 0.6321 - lcm_precision_2k: 0.4961 - lcm_precision_3k: 0.3992 - lcm_precision_5k: 0.2849 - lcm_recall_1k: 0.3979 - lcm_recall_2k: 0.5864 - lcm_recall_3k: 0.6851 - lcm_recall_5k: 0.7874 - lcm_f1_1k: 0.4883 - lcm_f1_2k: 0.5374 - lcm_f1_3k: 0.5044 - lcm_f1_5k: 0.4184 - lcm_accuracy_1k: 0.6321 - lcm_accuracy_2k: 0.7864 - lcm_accuracy_3k: 0.8519 - lcm_accuracy_5k: 0.9075 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2865 - val_lcm_precision_1k: 0.5725 - val_lcm_precision_2k: 0.4485 - val_lcm_precision_3k: 0.3702 - val_lcm_precision_5k: 0.2653 - val_lcm_recall_1k: 0.3524 - val_lcm_recall_2k: 0.5235 - val_lcm_recall_3k: 0.6284 - val_lcm_recall_5k: 0.7255 - val_lcm_f1_1k: 0.4361 - val_lcm_f1_2k: 0.4829 - val_lcm_f1_3k: 0.4657 - val_lcm_f1_5k: 0.3884 - val_lcm_accuracy_1k: 0.5725 - val_lcm_accuracy_2k: 0.7234 - val_lcm_accuracy_3k: 0.8006 - val_lcm_accuracy_5k: 0.8630 - val_lcm_hamming_loss_k: 0.0042
Epoch 11/150
27/27 [==============================] - ETA: 0s - loss: 0.2513 - lcm_precision_1k: 0.6402 - lcm_precision_2k: 0.5030 - lcm_precision_3k: 0.4057 - lcm_precision_5k: 0.2879 - lcm_recall_1k: 0.4022 - lcm_recall_2k: 0.5947 - lcm_recall_3k: 0.6951 - lcm_recall_5k: 0.7965 - lcm_f1_1k: 0.4939 - lcm_f1_2k: 0.5450 - lcm_f1_3k: 0.5123 - lcm_f1_5k: 0.4229 - lcm_accuracy_1k: 0.6402 - lcm_accuracy_2k: 0.7950 - lcm_accuracy_3k: 0.8581 - lcm_accuracy_5k: 0.9146 - lcm_hamming_loss_k: 0.0038
Epoch 00011: val_loss did not improve from 0.28655
27/27 [==============================] - 11s 392ms/step - loss: 0.2513 - lcm_precision_1k: 0.6402 - lcm_precision_2k: 0.5030 - lcm_precision_3k: 0.4057 - lcm_precision_5k: 0.2879 - lcm_recall_1k: 0.4022 - lcm_recall_2k: 0.5947 - lcm_recall_3k: 0.6951 - lcm_recall_5k: 0.7965 - lcm_f1_1k: 0.4939 - lcm_f1_2k: 0.5450 - lcm_f1_3k: 0.5123 - lcm_f1_5k: 0.4229 - lcm_accuracy_1k: 0.6402 - lcm_accuracy_2k: 0.7950 - lcm_accuracy_3k: 0.8581 - lcm_accuracy_5k: 0.9146 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2866 - val_lcm_precision_1k: 0.5750 - val_lcm_precision_2k: 0.4562 - val_lcm_precision_3k: 0.3695 - val_lcm_precision_5k: 0.2651 - val_lcm_recall_1k: 0.3516 - val_lcm_recall_2k: 0.5303 - val_lcm_recall_3k: 0.6260 - val_lcm_recall_5k: 0.7256 - val_lcm_f1_1k: 0.4362 - val_lcm_f1_2k: 0.4902 - val_lcm_f1_3k: 0.4645 - val_lcm_f1_5k: 0.3881 - val_lcm_accuracy_1k: 0.5750 - val_lcm_accuracy_2k: 0.7287 - val_lcm_accuracy_3k: 0.7992 - val_lcm_accuracy_5k: 0.8660 - val_lcm_hamming_loss_k: 0.0041
Epoch 12/150
27/27 [==============================] - ETA: 0s - loss: 0.2435 - lcm_precision_1k: 0.6543 - lcm_precision_2k: 0.5137 - lcm_precision_3k: 0.4131 - lcm_precision_5k: 0.2924 - lcm_recall_1k: 0.4135 - lcm_recall_2k: 0.6080 - lcm_recall_3k: 0.7084 - lcm_recall_5k: 0.8092 - lcm_f1_1k: 0.5067 - lcm_f1_2k: 0.5568 - lcm_f1_3k: 0.5218 - lcm_f1_5k: 0.4295 - lcm_accuracy_1k: 0.6543 - lcm_accuracy_2k: 0.8057 - lcm_accuracy_3k: 0.8690 - lcm_accuracy_5k: 0.9229 - lcm_hamming_loss_k: 0.0037
Epoch 00012: val_loss improved from 0.28655 to 0.28051, saving model to logs/gdhwyc-labs-0604-153754/model/checkpoint_labs.h5
27/27 [==============================] - 11s 424ms/step - loss: 0.2435 - lcm_precision_1k: 0.6543 - lcm_precision_2k: 0.5137 - lcm_precision_3k: 0.4131 - lcm_precision_5k: 0.2924 - lcm_recall_1k: 0.4135 - lcm_recall_2k: 0.6080 - lcm_recall_3k: 0.7084 - lcm_recall_5k: 0.8092 - lcm_f1_1k: 0.5067 - lcm_f1_2k: 0.5568 - lcm_f1_3k: 0.5218 - lcm_f1_5k: 0.4295 - lcm_accuracy_1k: 0.6543 - lcm_accuracy_2k: 0.8057 - lcm_accuracy_3k: 0.8690 - lcm_accuracy_5k: 0.9229 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2805 - val_lcm_precision_1k: 0.5915 - val_lcm_precision_2k: 0.4615 - val_lcm_precision_3k: 0.3774 - val_lcm_precision_5k: 0.2721 - val_lcm_recall_1k: 0.3655 - val_lcm_recall_2k: 0.5399 - val_lcm_recall_3k: 0.6415 - val_lcm_recall_5k: 0.7459 - val_lcm_f1_1k: 0.4515 - val_lcm_f1_2k: 0.4974 - val_lcm_f1_3k: 0.4750 - val_lcm_f1_5k: 0.3985 - val_lcm_accuracy_1k: 0.5915 - val_lcm_accuracy_2k: 0.7350 - val_lcm_accuracy_3k: 0.8079 - val_lcm_accuracy_5k: 0.8752 - val_lcm_hamming_loss_k: 0.0041
Epoch 13/150
27/27 [==============================] - ETA: 0s - loss: 0.2362 - lcm_precision_1k: 0.6710 - lcm_precision_2k: 0.5259 - lcm_precision_3k: 0.4214 - lcm_precision_5k: 0.2975 - lcm_recall_1k: 0.4249 - lcm_recall_2k: 0.6224 - lcm_recall_3k: 0.7220 - lcm_recall_5k: 0.8215 - lcm_f1_1k: 0.5202 - lcm_f1_2k: 0.5701 - lcm_f1_3k: 0.5321 - lcm_f1_5k: 0.4368 - lcm_accuracy_1k: 0.6710 - lcm_accuracy_2k: 0.8206 - lcm_accuracy_3k: 0.8818 - lcm_accuracy_5k: 0.9302 - lcm_hamming_loss_k: 0.0037
Epoch 00013: val_loss improved from 0.28051 to 0.27727, saving model to logs/gdhwyc-labs-0604-153754/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2362 - lcm_precision_1k: 0.6710 - lcm_precision_2k: 0.5259 - lcm_precision_3k: 0.4214 - lcm_precision_5k: 0.2975 - lcm_recall_1k: 0.4249 - lcm_recall_2k: 0.6224 - lcm_recall_3k: 0.7220 - lcm_recall_5k: 0.8215 - lcm_f1_1k: 0.5202 - lcm_f1_2k: 0.5701 - lcm_f1_3k: 0.5321 - lcm_f1_5k: 0.4368 - lcm_accuracy_1k: 0.6710 - lcm_accuracy_2k: 0.8206 - lcm_accuracy_3k: 0.8818 - lcm_accuracy_5k: 0.9302 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2773 - val_lcm_precision_1k: 0.5960 - val_lcm_precision_2k: 0.4628 - val_lcm_precision_3k: 0.3750 - val_lcm_precision_5k: 0.2701 - val_lcm_recall_1k: 0.3665 - val_lcm_recall_2k: 0.5383 - val_lcm_recall_3k: 0.6376 - val_lcm_recall_5k: 0.7424 - val_lcm_f1_1k: 0.4536 - val_lcm_f1_2k: 0.4974 - val_lcm_f1_3k: 0.4721 - val_lcm_f1_5k: 0.3959 - val_lcm_accuracy_1k: 0.5960 - val_lcm_accuracy_2k: 0.7369 - val_lcm_accuracy_3k: 0.8065 - val_lcm_accuracy_5k: 0.8787 - val_lcm_hamming_loss_k: 0.0041
Epoch 14/150
27/27 [==============================] - ETA: 0s - loss: 0.2332 - lcm_precision_1k: 0.6818 - lcm_precision_2k: 0.5318 - lcm_precision_3k: 0.4268 - lcm_precision_5k: 0.3000 - lcm_recall_1k: 0.4329 - lcm_recall_2k: 0.6294 - lcm_recall_3k: 0.7311 - lcm_recall_5k: 0.8279 - lcm_f1_1k: 0.5295 - lcm_f1_2k: 0.5764 - lcm_f1_3k: 0.5389 - lcm_f1_5k: 0.4404 - lcm_accuracy_1k: 0.6818 - lcm_accuracy_2k: 0.8278 - lcm_accuracy_3k: 0.8873 - lcm_accuracy_5k: 0.9352 - lcm_hamming_loss_k: 0.0036
Epoch 00014: val_loss improved from 0.27727 to 0.27642, saving model to logs/gdhwyc-labs-0604-153754/model/checkpoint_labs.h5
27/27 [==============================] - 11s 428ms/step - loss: 0.2332 - lcm_precision_1k: 0.6818 - lcm_precision_2k: 0.5318 - lcm_precision_3k: 0.4268 - lcm_precision_5k: 0.3000 - lcm_recall_1k: 0.4329 - lcm_recall_2k: 0.6294 - lcm_recall_3k: 0.7311 - lcm_recall_5k: 0.8279 - lcm_f1_1k: 0.5295 - lcm_f1_2k: 0.5764 - lcm_f1_3k: 0.5389 - lcm_f1_5k: 0.4404 - lcm_accuracy_1k: 0.6818 - lcm_accuracy_2k: 0.8278 - lcm_accuracy_3k: 0.8873 - lcm_accuracy_5k: 0.9352 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2764 - val_lcm_precision_1k: 0.5957 - val_lcm_precision_2k: 0.4676 - val_lcm_precision_3k: 0.3768 - val_lcm_precision_5k: 0.2699 - val_lcm_recall_1k: 0.3693 - val_lcm_recall_2k: 0.5472 - val_lcm_recall_3k: 0.6426 - val_lcm_recall_5k: 0.7401 - val_lcm_f1_1k: 0.4557 - val_lcm_f1_2k: 0.5041 - val_lcm_f1_3k: 0.4749 - val_lcm_f1_5k: 0.3954 - val_lcm_accuracy_1k: 0.5957 - val_lcm_accuracy_2k: 0.7450 - val_lcm_accuracy_3k: 0.8133 - val_lcm_accuracy_5k: 0.8746 - val_lcm_hamming_loss_k: 0.0041
Epoch 15/150
27/27 [==============================] - ETA: 0s - loss: 0.2270 - lcm_precision_1k: 0.6944 - lcm_precision_2k: 0.5410 - lcm_precision_3k: 0.4312 - lcm_precision_5k: 0.3033 - lcm_recall_1k: 0.4416 - lcm_recall_2k: 0.6416 - lcm_recall_3k: 0.7397 - lcm_recall_5k: 0.8383 - lcm_f1_1k: 0.5398 - lcm_f1_2k: 0.5869 - lcm_f1_3k: 0.5448 - lcm_f1_5k: 0.4454 - lcm_accuracy_1k: 0.6944 - lcm_accuracy_2k: 0.8380 - lcm_accuracy_3k: 0.8938 - lcm_accuracy_5k: 0.9432 - lcm_hamming_loss_k: 0.0035 ETA: 5s - loss: 0.2255 - lcm_precision_1k: 0.6992 - lcm_precision_2k: 0.5466 - lcm_precision_3k: 0.4370 - lcm_precision_5k: 0.3045 - lcm_recall_1k: 0.4453 - lcm_recall_2k: 0.6465 - lcm_recall_3k: 0.7466 - lcm_recall_5k: 0.8402 - lcm_f1_1k: 0.5440 - lcm_f1_2k: 0.5923 - lcm_f1_3k: 0.5512 - lcm_f1_5k: 0.4470 - lcm_accuracy_1k: 0.6992 - lcm_accuracy_2k: 0.8427 - lcm_accuracy_3k: 0.8979 - lcm_accuracy_5k: 0.9
Epoch 00015: val_loss improved from 0.27642 to 0.27370, saving model to logs/gdhwyc-labs-0604-153754/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2270 - lcm_precision_1k: 0.6944 - lcm_precision_2k: 0.5410 - lcm_precision_3k: 0.4312 - lcm_precision_5k: 0.3033 - lcm_recall_1k: 0.4416 - lcm_recall_2k: 0.6416 - lcm_recall_3k: 0.7397 - lcm_recall_5k: 0.8383 - lcm_f1_1k: 0.5398 - lcm_f1_2k: 0.5869 - lcm_f1_3k: 0.5448 - lcm_f1_5k: 0.4454 - lcm_accuracy_1k: 0.6944 - lcm_accuracy_2k: 0.8380 - lcm_accuracy_3k: 0.8938 - lcm_accuracy_5k: 0.9432 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2737 - val_lcm_precision_1k: 0.5962 - val_lcm_precision_2k: 0.4707 - val_lcm_precision_3k: 0.3792 - val_lcm_precision_5k: 0.2703 - val_lcm_recall_1k: 0.3698 - val_lcm_recall_2k: 0.5505 - val_lcm_recall_3k: 0.6474 - val_lcm_recall_5k: 0.7436 - val_lcm_f1_1k: 0.4563 - val_lcm_f1_2k: 0.5072 - val_lcm_f1_3k: 0.4781 - val_lcm_f1_5k: 0.3964 - val_lcm_accuracy_1k: 0.5962 - val_lcm_accuracy_2k: 0.7481 - val_lcm_accuracy_3k: 0.8187 - val_lcm_accuracy_5k: 0.8806 - val_lcm_hamming_loss_k: 0.0041
Epoch 16/150
27/27 [==============================] - ETA: 0s - loss: 0.2201 - lcm_precision_1k: 0.7077 - lcm_precision_2k: 0.5515 - lcm_precision_3k: 0.4390 - lcm_precision_5k: 0.3071 - lcm_recall_1k: 0.4525 - lcm_recall_2k: 0.6550 - lcm_recall_3k: 0.7532 - lcm_recall_5k: 0.8494 - lcm_f1_1k: 0.5519 - lcm_f1_2k: 0.5987 - lcm_f1_3k: 0.5546 - lcm_f1_5k: 0.4510 - lcm_accuracy_1k: 0.7077 - lcm_accuracy_2k: 0.8511 - lcm_accuracy_3k: 0.9047 - lcm_accuracy_5k: 0.9500 - lcm_hamming_loss_k: 0.0035
Epoch 00016: val_loss did not improve from 0.27370
27/27 [==============================] - 10s 389ms/step - loss: 0.2201 - lcm_precision_1k: 0.7077 - lcm_precision_2k: 0.5515 - lcm_precision_3k: 0.4390 - lcm_precision_5k: 0.3071 - lcm_recall_1k: 0.4525 - lcm_recall_2k: 0.6550 - lcm_recall_3k: 0.7532 - lcm_recall_5k: 0.8494 - lcm_f1_1k: 0.5519 - lcm_f1_2k: 0.5987 - lcm_f1_3k: 0.5546 - lcm_f1_5k: 0.4510 - lcm_accuracy_1k: 0.7077 - lcm_accuracy_2k: 0.8511 - lcm_accuracy_3k: 0.9047 - lcm_accuracy_5k: 0.9500 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2743 - val_lcm_precision_1k: 0.6048 - val_lcm_precision_2k: 0.4728 - val_lcm_precision_3k: 0.3795 - val_lcm_precision_5k: 0.2710 - val_lcm_recall_1k: 0.3787 - val_lcm_recall_2k: 0.5512 - val_lcm_recall_3k: 0.6450 - val_lcm_recall_5k: 0.7439 - val_lcm_f1_1k: 0.4655 - val_lcm_f1_2k: 0.5088 - val_lcm_f1_3k: 0.4777 - val_lcm_f1_5k: 0.3971 - val_lcm_accuracy_1k: 0.6048 - val_lcm_accuracy_2k: 0.7430 - val_lcm_accuracy_3k: 0.8093 - val_lcm_accuracy_5k: 0.8773 - val_lcm_hamming_loss_k: 0.0040
Epoch 17/150
27/27 [==============================] - ETA: 0s - loss: 0.2144 - lcm_precision_1k: 0.7232 - lcm_precision_2k: 0.5597 - lcm_precision_3k: 0.4471 - lcm_precision_5k: 0.3114 - lcm_recall_1k: 0.4615 - lcm_recall_2k: 0.6624 - lcm_recall_3k: 0.7631 - lcm_recall_5k: 0.8563 - lcm_f1_1k: 0.5634 - lcm_f1_2k: 0.6066 - lcm_f1_3k: 0.5638 - lcm_f1_5k: 0.4567 - lcm_accuracy_1k: 0.7232 - lcm_accuracy_2k: 0.8588 - lcm_accuracy_3k: 0.9117 - lcm_accuracy_5k: 0.9536 - lcm_hamming_loss_k: 0.0034
Epoch 00017: val_loss improved from 0.27370 to 0.27365, saving model to logs/gdhwyc-labs-0604-153754/model/checkpoint_labs.h5
27/27 [==============================] - 11s 428ms/step - loss: 0.2144 - lcm_precision_1k: 0.7232 - lcm_precision_2k: 0.5597 - lcm_precision_3k: 0.4471 - lcm_precision_5k: 0.3114 - lcm_recall_1k: 0.4615 - lcm_recall_2k: 0.6624 - lcm_recall_3k: 0.7631 - lcm_recall_5k: 0.8563 - lcm_f1_1k: 0.5634 - lcm_f1_2k: 0.6066 - lcm_f1_3k: 0.5638 - lcm_f1_5k: 0.4567 - lcm_accuracy_1k: 0.7232 - lcm_accuracy_2k: 0.8588 - lcm_accuracy_3k: 0.9117 - lcm_accuracy_5k: 0.9536 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2737 - val_lcm_precision_1k: 0.5958 - val_lcm_precision_2k: 0.4747 - val_lcm_precision_3k: 0.3816 - val_lcm_precision_5k: 0.2725 - val_lcm_recall_1k: 0.3713 - val_lcm_recall_2k: 0.5570 - val_lcm_recall_3k: 0.6516 - val_lcm_recall_5k: 0.7502 - val_lcm_f1_1k: 0.4572 - val_lcm_f1_2k: 0.5124 - val_lcm_f1_3k: 0.4811 - val_lcm_f1_5k: 0.3995 - val_lcm_accuracy_1k: 0.5958 - val_lcm_accuracy_2k: 0.7556 - val_lcm_accuracy_3k: 0.8243 - val_lcm_accuracy_5k: 0.8847 - val_lcm_hamming_loss_k: 0.0041
Epoch 00017: early stopping
176/176 [==============================] - 8s 42ms/step - loss: 0.2265 - lcm_precision_1k: 0.6946 - lcm_precision_2k: 0.5366 - lcm_precision_3k: 0.4298 - lcm_precision_5k: 0.3002 - lcm_recall_1k: 0.4491 - lcm_recall_2k: 0.6404 - lcm_recall_3k: 0.7404 - lcm_recall_5k: 0.8326 - lcm_f1_1k: 0.5443 - lcm_f1_2k: 0.5828 - lcm_f1_3k: 0.5428 - lcm_f1_5k: 0.4406 - lcm_accuracy_1k: 0.6946 - lcm_accuracy_2k: 0.8351 - lcm_accuracy_3k: 0.8918 - lcm_accuracy_5k: 0.9370 - lcm_hamming_loss_k: 0.0035 3s - loss: 0.2278 - lcm_precision_1k: 0.6920 - lcm_precision_2k: 0.5342 - lcm_precision_3k: 0.4263 - lcm_precision_5k: 0.2984 - lcm_recall_1k: 0.4475 - lcm_recall_2k: 0.6390 - lcm_recall_3k: 0.7376 - lcm_recall_5k: 0.8307 - lcm_f1_1k: 0.5420 - lcm_f1_2k: 0.5806 - lcm_f1_3k: 0.5392 - lcm_f1_5k: 0.4384 - lcm_accuracy_1k: 0.6920 - lcm_accuracy
Best model result:  [0.22648495435714722, 0.6945668458938599, 0.5365623831748962, 0.42980384826660156, 0.3001857399940491, 0.44912683963775635, 0.6403734087944031, 0.7404005527496338, 0.8325536251068115, 0.5442716479301453, 0.582755446434021, 0.5428469181060791, 0.44057610630989075, 0.6945668458938599, 0.8350805640220642, 0.8917677402496338, 0.9369733333587646, 0.0035324750933796167]
13499
3374
5625
Model: "model_6"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_9 (Sl  (None, 15, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_9[0][0
                                                                 ]']                              
                                                                                                  
 permute_9 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_15 (Lambda)             (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_9[0][0]']              
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_15[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_16 (Lambda)             (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_6 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_16[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_3 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_6[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_9 (Dense)                (None, 1024)         2098176     ['tf.concat_3[0][0]']            
                                                                                                  
 dense_10 (Dense)               (None, 15)           15375       ['dense_9[0][0]']                
                                                                                                  
 tf.nn.softmax_3 (TFOpLambda)   (None, 15)           0           ['dense_10[0][0]']               
                                                                                                  
 tf.expand_dims_6 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_3[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_6[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_10 (Permute)           (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_17 (Lambda)             (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_10[0][0]']             
                                                                                                  
 dense_11 (Dense)               (None, 15, 150)      22650       ['lambda_17[0][0]']              
                                                                                                  
 tf.math.reduce_mean_7 (TFOpLam  (None, 150)         0           ['dense_11[0][0]']               
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_7 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_7[0][0]']  
                                                                                                  
 tf.__operators__.getitem_10 (S  (None, 427, 300)    0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 tf.math.multiply_3 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_7[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_10[0][
                                                                 0]']                             
                                                                                                  
 permute_11 (Permute)           (None, 1024, 150)    0           ['tf.math.multiply_3[0][0]']     
                                                                                                  
 lambda_18 (Lambda)             (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_11[0][0]']             
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_18[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_19 (Lambda)             (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_3[0][0]']     
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_19[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
==================================================================================================
Total params: 31,474,320
Trainable params: 6,695,820
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
2 patience
Model: "model_7"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_9 (Sl  (None, 15, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_9[0][0
                                                                 ]']                              
                                                                                                  
 permute_9 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_15 (Lambda)             (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_9[0][0]']              
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_15[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_16 (Lambda)             (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_6 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_16[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_3 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_6[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_9 (Dense)                (None, 1024)         2098176     ['tf.concat_3[0][0]']            
                                                                                                  
 dense_10 (Dense)               (None, 15)           15375       ['dense_9[0][0]']                
                                                                                                  
 tf.nn.softmax_3 (TFOpLambda)   (None, 15)           0           ['dense_10[0][0]']               
                                                                                                  
 tf.expand_dims_6 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_3[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_6[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_10 (Permute)           (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_17 (Lambda)             (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_10[0][0]']             
                                                                                                  
 dense_11 (Dense)               (None, 15, 150)      22650       ['lambda_17[0][0]']              
                                                                                                  
 tf.math.reduce_mean_7 (TFOpLam  (None, 150)         0           ['dense_11[0][0]']               
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_7 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_7[0][0]']  
                                                                                                  
 tf.__operators__.getitem_10 (S  (None, 427, 300)    0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 tf.math.multiply_3 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_7[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_10[0][
                                                                 0]']                             
                                                                                                  
 permute_11 (Permute)           (None, 1024, 150)    0           ['tf.math.multiply_3[0][0]']     
                                                                                                  
 lambda_18 (Lambda)             (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_11[0][0]']             
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_18[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_19 (Lambda)             (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_3[0][0]']     
                                                                                                  
 tf.__operators__.getitem_11 (S  (None, 427, 300)    0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_19[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 label_lcm_emb (Dense)          (None, 427, 1024)    308224      ['tf.__operators__.getitem_11[0][
                                                                 0]']                             
                                                                                                  
 dot_3 (Dot)                    (None, 427)          0           ['label_lcm_emb[0][0]',          
                                                                  '1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 label_sim_dict (Dense)         (None, 427)          182756      ['dot_3[0][0]']                  
                                                                                                  
 concatenate_3 (Concatenate)    (None, 854)          0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 31,965,300
Trainable params: 7,186,800
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
Epoch 1/150
/home/dzq/k12/atmk_system-master/MathByte/models/evaluation_metrics.py:260: RuntimeWarning: invalid value encountered in true_divide
  return (2 * p_k * r_k) / (p_k + r_k)
27/27 [==============================] - ETA: 0s - loss: 0.5386 - lcm_precision_1k: 0.0944 - lcm_precision_2k: 0.0933 - lcm_precision_3k: 0.0816 - lcm_precision_5k: 0.0668 - lcm_recall_1k: 0.0452 - lcm_recall_2k: 0.0947 - lcm_recall_3k: 0.1257 - lcm_recall_5k: 0.1729 - lcm_f1_1k: nan - lcm_f1_2k: 0.0939 - lcm_f1_3k: 0.0989 - lcm_f1_5k: 0.0963 - lcm_accuracy_1k: 0.0944 - lcm_accuracy_2k: 0.1786 - lcm_accuracy_3k: 0.2210 - lcm_accuracy_5k: 0.2834 - lcm_hamming_loss_k: 0.0064
Epoch 00001: val_loss improved from inf to 0.47305, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 13s 417ms/step - loss: 0.5386 - lcm_precision_1k: 0.0944 - lcm_precision_2k: 0.0933 - lcm_precision_3k: 0.0816 - lcm_precision_5k: 0.0668 - lcm_recall_1k: 0.0452 - lcm_recall_2k: 0.0947 - lcm_recall_3k: 0.1257 - lcm_recall_5k: 0.1729 - lcm_f1_1k: nan - lcm_f1_2k: 0.0939 - lcm_f1_3k: 0.0989 - lcm_f1_5k: 0.0963 - lcm_accuracy_1k: 0.0944 - lcm_accuracy_2k: 0.1786 - lcm_accuracy_3k: 0.2210 - lcm_accuracy_5k: 0.2834 - lcm_hamming_loss_k: 0.0064 - val_loss: 0.4730 - val_lcm_precision_1k: 0.0333 - val_lcm_precision_2k: 0.1333 - val_lcm_precision_3k: 0.1446 - val_lcm_precision_5k: 0.1292 - val_lcm_recall_1k: 0.0163 - val_lcm_recall_2k: 0.1458 - val_lcm_recall_3k: 0.2350 - val_lcm_recall_5k: 0.3510 - val_lcm_f1_1k: 0.0218 - val_lcm_f1_2k: 0.1391 - val_lcm_f1_3k: 0.1789 - val_lcm_f1_5k: 0.1888 - val_lcm_accuracy_1k: 0.0333 - val_lcm_accuracy_2k: 0.2639 - val_lcm_accuracy_3k: 0.3839 - val_lcm_accuracy_5k: 0.5107 - val_lcm_hamming_loss_k: 0.0066
Epoch 2/150
27/27 [==============================] - ETA: 0s - loss: 0.4112 - lcm_precision_1k: 0.2331 - lcm_precision_2k: 0.2430 - lcm_precision_3k: 0.2213 - lcm_precision_5k: 0.1806 - lcm_recall_1k: 0.1343 - lcm_recall_2k: 0.2748 - lcm_recall_3k: 0.3690 - lcm_recall_5k: 0.4906 - lcm_f1_1k: 0.1703 - lcm_f1_2k: 0.2579 - lcm_f1_3k: 0.2766 - lcm_f1_5k: 0.2640 - lcm_accuracy_1k: 0.2331 - lcm_accuracy_2k: 0.4343 - lcm_accuracy_3k: 0.5377 - lcm_accuracy_5k: 0.6476 - lcm_hamming_loss_k: 0.0057
Epoch 00002: val_loss improved from 0.47305 to 0.37550, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 11s 424ms/step - loss: 0.4112 - lcm_precision_1k: 0.2331 - lcm_precision_2k: 0.2430 - lcm_precision_3k: 0.2213 - lcm_precision_5k: 0.1806 - lcm_recall_1k: 0.1343 - lcm_recall_2k: 0.2748 - lcm_recall_3k: 0.3690 - lcm_recall_5k: 0.4906 - lcm_f1_1k: 0.1703 - lcm_f1_2k: 0.2579 - lcm_f1_3k: 0.2766 - lcm_f1_5k: 0.2640 - lcm_accuracy_1k: 0.2331 - lcm_accuracy_2k: 0.4343 - lcm_accuracy_3k: 0.5377 - lcm_accuracy_5k: 0.6476 - lcm_hamming_loss_k: 0.0057 - val_loss: 0.3755 - val_lcm_precision_1k: 0.3828 - val_lcm_precision_2k: 0.3145 - val_lcm_precision_3k: 0.2649 - val_lcm_precision_5k: 0.2052 - val_lcm_recall_1k: 0.2264 - val_lcm_recall_2k: 0.3562 - val_lcm_recall_3k: 0.4461 - val_lcm_recall_5k: 0.5600 - val_lcm_f1_1k: 0.2843 - val_lcm_f1_2k: 0.3338 - val_lcm_f1_3k: 0.3322 - val_lcm_f1_5k: 0.3002 - val_lcm_accuracy_1k: 0.3828 - val_lcm_accuracy_2k: 0.5295 - val_lcm_accuracy_3k: 0.6155 - val_lcm_accuracy_5k: 0.7132 - val_lcm_hamming_loss_k: 0.0050
Epoch 3/150
27/27 [==============================] - ETA: 0s - loss: 0.3489 - lcm_precision_1k: 0.4333 - lcm_precision_2k: 0.3538 - lcm_precision_3k: 0.2959 - lcm_precision_5k: 0.2239 - lcm_recall_1k: 0.2600 - lcm_recall_2k: 0.4071 - lcm_recall_3k: 0.5007 - lcm_recall_5k: 0.6139 - lcm_f1_1k: 0.3249 - lcm_f1_2k: 0.3785 - lcm_f1_3k: 0.3719 - lcm_f1_5k: 0.3281 - lcm_accuracy_1k: 0.4333 - lcm_accuracy_2k: 0.5918 - lcm_accuracy_3k: 0.6743 - lcm_accuracy_5k: 0.7633 - lcm_hamming_loss_k: 0.0048
Epoch 00003: val_loss improved from 0.37550 to 0.34323, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.3489 - lcm_precision_1k: 0.4333 - lcm_precision_2k: 0.3538 - lcm_precision_3k: 0.2959 - lcm_precision_5k: 0.2239 - lcm_recall_1k: 0.2600 - lcm_recall_2k: 0.4071 - lcm_recall_3k: 0.5007 - lcm_recall_5k: 0.6139 - lcm_f1_1k: 0.3249 - lcm_f1_2k: 0.3785 - lcm_f1_3k: 0.3719 - lcm_f1_5k: 0.3281 - lcm_accuracy_1k: 0.4333 - lcm_accuracy_2k: 0.5918 - lcm_accuracy_3k: 0.6743 - lcm_accuracy_5k: 0.7633 - lcm_hamming_loss_k: 0.0048 - val_loss: 0.3432 - val_lcm_precision_1k: 0.4468 - val_lcm_precision_2k: 0.3678 - val_lcm_precision_3k: 0.3038 - val_lcm_precision_5k: 0.2276 - val_lcm_recall_1k: 0.2706 - val_lcm_recall_2k: 0.4225 - val_lcm_recall_3k: 0.5126 - val_lcm_recall_5k: 0.6247 - val_lcm_f1_1k: 0.3368 - val_lcm_f1_2k: 0.3930 - val_lcm_f1_3k: 0.3813 - val_lcm_f1_5k: 0.3334 - val_lcm_accuracy_1k: 0.4468 - val_lcm_accuracy_2k: 0.6107 - val_lcm_accuracy_3k: 0.6965 - val_lcm_accuracy_5k: 0.7783 - val_lcm_hamming_loss_k: 0.0047
Epoch 4/150
27/27 [==============================] - ETA: 0s - loss: 0.3220 - lcm_precision_1k: 0.4935 - lcm_precision_2k: 0.3974 - lcm_precision_3k: 0.3279 - lcm_precision_5k: 0.2422 - lcm_recall_1k: 0.3011 - lcm_recall_2k: 0.4601 - lcm_recall_3k: 0.5569 - lcm_recall_5k: 0.6674 - lcm_f1_1k: 0.3740 - lcm_f1_2k: 0.4264 - lcm_f1_3k: 0.4126 - lcm_f1_5k: 0.3554 - lcm_accuracy_1k: 0.4935 - lcm_accuracy_2k: 0.6536 - lcm_accuracy_3k: 0.7354 - lcm_accuracy_5k: 0.8147 - lcm_hamming_loss_k: 0.0045
Epoch 00004: val_loss improved from 0.34323 to 0.32687, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.3220 - lcm_precision_1k: 0.4935 - lcm_precision_2k: 0.3974 - lcm_precision_3k: 0.3279 - lcm_precision_5k: 0.2422 - lcm_recall_1k: 0.3011 - lcm_recall_2k: 0.4601 - lcm_recall_3k: 0.5569 - lcm_recall_5k: 0.6674 - lcm_f1_1k: 0.3740 - lcm_f1_2k: 0.4264 - lcm_f1_3k: 0.4126 - lcm_f1_5k: 0.3554 - lcm_accuracy_1k: 0.4935 - lcm_accuracy_2k: 0.6536 - lcm_accuracy_3k: 0.7354 - lcm_accuracy_5k: 0.8147 - lcm_hamming_loss_k: 0.0045 - val_loss: 0.3269 - val_lcm_precision_1k: 0.4770 - val_lcm_precision_2k: 0.3901 - val_lcm_precision_3k: 0.3216 - val_lcm_precision_5k: 0.2385 - val_lcm_recall_1k: 0.2911 - val_lcm_recall_2k: 0.4545 - val_lcm_recall_3k: 0.5471 - val_lcm_recall_5k: 0.6551 - val_lcm_f1_1k: 0.3614 - val_lcm_f1_2k: 0.4196 - val_lcm_f1_3k: 0.4048 - val_lcm_f1_5k: 0.3495 - val_lcm_accuracy_1k: 0.4770 - val_lcm_accuracy_2k: 0.6414 - val_lcm_accuracy_3k: 0.7223 - val_lcm_accuracy_5k: 0.8059 - val_lcm_hamming_loss_k: 0.0046
Epoch 5/150
27/27 [==============================] - ETA: 0s - loss: 0.3059 - lcm_precision_1k: 0.5269 - lcm_precision_2k: 0.4220 - lcm_precision_3k: 0.3465 - lcm_precision_5k: 0.2519 - lcm_recall_1k: 0.3241 - lcm_recall_2k: 0.4914 - lcm_recall_3k: 0.5912 - lcm_recall_5k: 0.6956 - lcm_f1_1k: 0.4012 - lcm_f1_2k: 0.4540 - lcm_f1_3k: 0.4368 - lcm_f1_5k: 0.3698 - lcm_accuracy_1k: 0.5269 - lcm_accuracy_2k: 0.6849 - lcm_accuracy_3k: 0.7640 - lcm_accuracy_5k: 0.8347 - lcm_hamming_loss_k: 0.0043
Epoch 00005: val_loss improved from 0.32687 to 0.31918, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.3059 - lcm_precision_1k: 0.5269 - lcm_precision_2k: 0.4220 - lcm_precision_3k: 0.3465 - lcm_precision_5k: 0.2519 - lcm_recall_1k: 0.3241 - lcm_recall_2k: 0.4914 - lcm_recall_3k: 0.5912 - lcm_recall_5k: 0.6956 - lcm_f1_1k: 0.4012 - lcm_f1_2k: 0.4540 - lcm_f1_3k: 0.4368 - lcm_f1_5k: 0.3698 - lcm_accuracy_1k: 0.5269 - lcm_accuracy_2k: 0.6849 - lcm_accuracy_3k: 0.7640 - lcm_accuracy_5k: 0.8347 - lcm_hamming_loss_k: 0.0043 - val_loss: 0.3192 - val_lcm_precision_1k: 0.5036 - val_lcm_precision_2k: 0.4071 - val_lcm_precision_3k: 0.3322 - val_lcm_precision_5k: 0.2436 - val_lcm_recall_1k: 0.3107 - val_lcm_recall_2k: 0.4759 - val_lcm_recall_3k: 0.5679 - val_lcm_recall_5k: 0.6695 - val_lcm_f1_1k: 0.3841 - val_lcm_f1_2k: 0.4386 - val_lcm_f1_3k: 0.4190 - val_lcm_f1_5k: 0.3571 - val_lcm_accuracy_1k: 0.5036 - val_lcm_accuracy_2k: 0.6680 - val_lcm_accuracy_3k: 0.7495 - val_lcm_accuracy_5k: 0.8174 - val_lcm_hamming_loss_k: 0.0044
Epoch 6/150
27/27 [==============================] - ETA: 0s - loss: 0.2923 - lcm_precision_1k: 0.5553 - lcm_precision_2k: 0.4422 - lcm_precision_3k: 0.3610 - lcm_precision_5k: 0.2615 - lcm_recall_1k: 0.3437 - lcm_recall_2k: 0.5169 - lcm_recall_3k: 0.6168 - lcm_recall_5k: 0.7221 - lcm_f1_1k: 0.4245 - lcm_f1_2k: 0.4766 - lcm_f1_3k: 0.4554 - lcm_f1_5k: 0.3840 - lcm_accuracy_1k: 0.5553 - lcm_accuracy_2k: 0.7129 - lcm_accuracy_3k: 0.7880 - lcm_accuracy_5k: 0.8592 - lcm_hamming_loss_k: 0.0042
Epoch 00006: val_loss improved from 0.31918 to 0.30915, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 11s 429ms/step - loss: 0.2923 - lcm_precision_1k: 0.5553 - lcm_precision_2k: 0.4422 - lcm_precision_3k: 0.3610 - lcm_precision_5k: 0.2615 - lcm_recall_1k: 0.3437 - lcm_recall_2k: 0.5169 - lcm_recall_3k: 0.6168 - lcm_recall_5k: 0.7221 - lcm_f1_1k: 0.4245 - lcm_f1_2k: 0.4766 - lcm_f1_3k: 0.4554 - lcm_f1_5k: 0.3840 - lcm_accuracy_1k: 0.5553 - lcm_accuracy_2k: 0.7129 - lcm_accuracy_3k: 0.7880 - lcm_accuracy_5k: 0.8592 - lcm_hamming_loss_k: 0.0042 - val_loss: 0.3091 - val_lcm_precision_1k: 0.5373 - val_lcm_precision_2k: 0.4181 - val_lcm_precision_3k: 0.3411 - val_lcm_precision_5k: 0.2496 - val_lcm_recall_1k: 0.3349 - val_lcm_recall_2k: 0.4900 - val_lcm_recall_3k: 0.5842 - val_lcm_recall_5k: 0.6844 - val_lcm_f1_1k: 0.4124 - val_lcm_f1_2k: 0.4510 - val_lcm_f1_3k: 0.4304 - val_lcm_f1_5k: 0.3656 - val_lcm_accuracy_1k: 0.5373 - val_lcm_accuracy_2k: 0.6883 - val_lcm_accuracy_3k: 0.7627 - val_lcm_accuracy_5k: 0.8296 - val_lcm_hamming_loss_k: 0.0043
Epoch 7/150
27/27 [==============================] - ETA: 0s - loss: 0.2835 - lcm_precision_1k: 0.5744 - lcm_precision_2k: 0.4556 - lcm_precision_3k: 0.3712 - lcm_precision_5k: 0.2680 - lcm_recall_1k: 0.3567 - lcm_recall_2k: 0.5361 - lcm_recall_3k: 0.6347 - lcm_recall_5k: 0.7408 - lcm_f1_1k: 0.4400 - lcm_f1_2k: 0.4925 - lcm_f1_3k: 0.4684 - lcm_f1_5k: 0.3936 - lcm_accuracy_1k: 0.5744 - lcm_accuracy_2k: 0.7342 - lcm_accuracy_3k: 0.8069 - lcm_accuracy_5k: 0.8735 - lcm_hamming_loss_k: 0.0041
Epoch 00007: val_loss improved from 0.30915 to 0.30549, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 12s 431ms/step - loss: 0.2835 - lcm_precision_1k: 0.5744 - lcm_precision_2k: 0.4556 - lcm_precision_3k: 0.3712 - lcm_precision_5k: 0.2680 - lcm_recall_1k: 0.3567 - lcm_recall_2k: 0.5361 - lcm_recall_3k: 0.6347 - lcm_recall_5k: 0.7408 - lcm_f1_1k: 0.4400 - lcm_f1_2k: 0.4925 - lcm_f1_3k: 0.4684 - lcm_f1_5k: 0.3936 - lcm_accuracy_1k: 0.5744 - lcm_accuracy_2k: 0.7342 - lcm_accuracy_3k: 0.8069 - lcm_accuracy_5k: 0.8735 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.3055 - val_lcm_precision_1k: 0.5353 - val_lcm_precision_2k: 0.4227 - val_lcm_precision_3k: 0.3431 - val_lcm_precision_5k: 0.2505 - val_lcm_recall_1k: 0.3334 - val_lcm_recall_2k: 0.4974 - val_lcm_recall_3k: 0.5886 - val_lcm_recall_5k: 0.6920 - val_lcm_f1_1k: 0.4106 - val_lcm_f1_2k: 0.4567 - val_lcm_f1_3k: 0.4333 - val_lcm_f1_5k: 0.3676 - val_lcm_accuracy_1k: 0.5353 - val_lcm_accuracy_2k: 0.6937 - val_lcm_accuracy_3k: 0.7667 - val_lcm_accuracy_5k: 0.8398 - val_lcm_hamming_loss_k: 0.0043
Epoch 8/150
27/27 [==============================] - ETA: 0s - loss: 0.2758 - lcm_precision_1k: 0.5949 - lcm_precision_2k: 0.4712 - lcm_precision_3k: 0.3814 - lcm_precision_5k: 0.2739 - lcm_recall_1k: 0.3700 - lcm_recall_2k: 0.5541 - lcm_recall_3k: 0.6530 - lcm_recall_5k: 0.7577 - lcm_f1_1k: 0.4562 - lcm_f1_2k: 0.5092 - lcm_f1_3k: 0.4815 - lcm_f1_5k: 0.4023 - lcm_accuracy_1k: 0.5949 - lcm_accuracy_2k: 0.7536 - lcm_accuracy_3k: 0.8234 - lcm_accuracy_5k: 0.8873 - lcm_hamming_loss_k: 0.0040
Epoch 00008: val_loss improved from 0.30549 to 0.29494, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.2758 - lcm_precision_1k: 0.5949 - lcm_precision_2k: 0.4712 - lcm_precision_3k: 0.3814 - lcm_precision_5k: 0.2739 - lcm_recall_1k: 0.3700 - lcm_recall_2k: 0.5541 - lcm_recall_3k: 0.6530 - lcm_recall_5k: 0.7577 - lcm_f1_1k: 0.4562 - lcm_f1_2k: 0.5092 - lcm_f1_3k: 0.4815 - lcm_f1_5k: 0.4023 - lcm_accuracy_1k: 0.5949 - lcm_accuracy_2k: 0.7536 - lcm_accuracy_3k: 0.8234 - lcm_accuracy_5k: 0.8873 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2949 - val_lcm_precision_1k: 0.5322 - val_lcm_precision_2k: 0.4284 - val_lcm_precision_3k: 0.3507 - val_lcm_precision_5k: 0.2571 - val_lcm_recall_1k: 0.3298 - val_lcm_recall_2k: 0.5018 - val_lcm_recall_3k: 0.5969 - val_lcm_recall_5k: 0.7060 - val_lcm_f1_1k: 0.4070 - val_lcm_f1_2k: 0.4620 - val_lcm_f1_3k: 0.4416 - val_lcm_f1_5k: 0.3768 - val_lcm_accuracy_1k: 0.5322 - val_lcm_accuracy_2k: 0.6905 - val_lcm_accuracy_3k: 0.7718 - val_lcm_accuracy_5k: 0.8471 - val_lcm_hamming_loss_k: 0.0043
Epoch 9/150
27/27 [==============================] - ETA: 0s - loss: 0.2669 - lcm_precision_1k: 0.6051 - lcm_precision_2k: 0.4814 - lcm_precision_3k: 0.3895 - lcm_precision_5k: 0.2792 - lcm_recall_1k: 0.3781 - lcm_recall_2k: 0.5663 - lcm_recall_3k: 0.6671 - lcm_recall_5k: 0.7701 - lcm_f1_1k: 0.4654 - lcm_f1_2k: 0.5203 - lcm_f1_3k: 0.4918 - lcm_f1_5k: 0.4098 - lcm_accuracy_1k: 0.6051 - lcm_accuracy_2k: 0.7665 - lcm_accuracy_3k: 0.8359 - lcm_accuracy_5k: 0.8959 - lcm_hamming_loss_k: 0.0040
Epoch 00009: val_loss did not improve from 0.29494
27/27 [==============================] - 10s 387ms/step - loss: 0.2669 - lcm_precision_1k: 0.6051 - lcm_precision_2k: 0.4814 - lcm_precision_3k: 0.3895 - lcm_precision_5k: 0.2792 - lcm_recall_1k: 0.3781 - lcm_recall_2k: 0.5663 - lcm_recall_3k: 0.6671 - lcm_recall_5k: 0.7701 - lcm_f1_1k: 0.4654 - lcm_f1_2k: 0.5203 - lcm_f1_3k: 0.4918 - lcm_f1_5k: 0.4098 - lcm_accuracy_1k: 0.6051 - lcm_accuracy_2k: 0.7665 - lcm_accuracy_3k: 0.8359 - lcm_accuracy_5k: 0.8959 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2958 - val_lcm_precision_1k: 0.5560 - val_lcm_precision_2k: 0.4407 - val_lcm_precision_3k: 0.3571 - val_lcm_precision_5k: 0.2595 - val_lcm_recall_1k: 0.3464 - val_lcm_recall_2k: 0.5177 - val_lcm_recall_3k: 0.6114 - val_lcm_recall_5k: 0.7132 - val_lcm_f1_1k: 0.4266 - val_lcm_f1_2k: 0.4759 - val_lcm_f1_3k: 0.4506 - val_lcm_f1_5k: 0.3804 - val_lcm_accuracy_1k: 0.5560 - val_lcm_accuracy_2k: 0.7124 - val_lcm_accuracy_3k: 0.7892 - val_lcm_accuracy_5k: 0.8540 - val_lcm_hamming_loss_k: 0.0042
Epoch 10/150
27/27 [==============================] - ETA: 0s - loss: 0.2611 - lcm_precision_1k: 0.6216 - lcm_precision_2k: 0.4910 - lcm_precision_3k: 0.3975 - lcm_precision_5k: 0.2835 - lcm_recall_1k: 0.3890 - lcm_recall_2k: 0.5792 - lcm_recall_3k: 0.6810 - lcm_recall_5k: 0.7829 - lcm_f1_1k: 0.4785 - lcm_f1_2k: 0.5314 - lcm_f1_3k: 0.5019 - lcm_f1_5k: 0.4162 - lcm_accuracy_1k: 0.6216 - lcm_accuracy_2k: 0.7811 - lcm_accuracy_3k: 0.8482 - lcm_accuracy_5k: 0.9054 - lcm_hamming_loss_k: 0.0039
Epoch 00010: val_loss improved from 0.29494 to 0.28930, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.2611 - lcm_precision_1k: 0.6216 - lcm_precision_2k: 0.4910 - lcm_precision_3k: 0.3975 - lcm_precision_5k: 0.2835 - lcm_recall_1k: 0.3890 - lcm_recall_2k: 0.5792 - lcm_recall_3k: 0.6810 - lcm_recall_5k: 0.7829 - lcm_f1_1k: 0.4785 - lcm_f1_2k: 0.5314 - lcm_f1_3k: 0.5019 - lcm_f1_5k: 0.4162 - lcm_accuracy_1k: 0.6216 - lcm_accuracy_2k: 0.7811 - lcm_accuracy_3k: 0.8482 - lcm_accuracy_5k: 0.9054 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2893 - val_lcm_precision_1k: 0.5644 - val_lcm_precision_2k: 0.4439 - val_lcm_precision_3k: 0.3630 - val_lcm_precision_5k: 0.2613 - val_lcm_recall_1k: 0.3512 - val_lcm_recall_2k: 0.5194 - val_lcm_recall_3k: 0.6181 - val_lcm_recall_5k: 0.7190 - val_lcm_f1_1k: 0.4327 - val_lcm_f1_2k: 0.4785 - val_lcm_f1_3k: 0.4572 - val_lcm_f1_5k: 0.3832 - val_lcm_accuracy_1k: 0.5644 - val_lcm_accuracy_2k: 0.7154 - val_lcm_accuracy_3k: 0.7980 - val_lcm_accuracy_5k: 0.8564 - val_lcm_hamming_loss_k: 0.0042
Epoch 11/150
27/27 [==============================] - ETA: 0s - loss: 0.2545 - lcm_precision_1k: 0.6317 - lcm_precision_2k: 0.4991 - lcm_precision_3k: 0.4037 - lcm_precision_5k: 0.2872 - lcm_recall_1k: 0.3984 - lcm_recall_2k: 0.5897 - lcm_recall_3k: 0.6925 - lcm_recall_5k: 0.7936 - lcm_f1_1k: 0.4885 - lcm_f1_2k: 0.5405 - lcm_f1_3k: 0.5100 - lcm_f1_5k: 0.4217 - lcm_accuracy_1k: 0.6317 - lcm_accuracy_2k: 0.7890 - lcm_accuracy_3k: 0.8541 - lcm_accuracy_5k: 0.9129 - lcm_hamming_loss_k: 0.0038
Epoch 00011: val_loss improved from 0.28930 to 0.28708, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2545 - lcm_precision_1k: 0.6317 - lcm_precision_2k: 0.4991 - lcm_precision_3k: 0.4037 - lcm_precision_5k: 0.2872 - lcm_recall_1k: 0.3984 - lcm_recall_2k: 0.5897 - lcm_recall_3k: 0.6925 - lcm_recall_5k: 0.7936 - lcm_f1_1k: 0.4885 - lcm_f1_2k: 0.5405 - lcm_f1_3k: 0.5100 - lcm_f1_5k: 0.4217 - lcm_accuracy_1k: 0.6317 - lcm_accuracy_2k: 0.7890 - lcm_accuracy_3k: 0.8541 - lcm_accuracy_5k: 0.9129 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2871 - val_lcm_precision_1k: 0.5689 - val_lcm_precision_2k: 0.4496 - val_lcm_precision_3k: 0.3667 - val_lcm_precision_5k: 0.2636 - val_lcm_recall_1k: 0.3537 - val_lcm_recall_2k: 0.5279 - val_lcm_recall_3k: 0.6250 - val_lcm_recall_5k: 0.7238 - val_lcm_f1_1k: 0.4360 - val_lcm_f1_2k: 0.4854 - val_lcm_f1_3k: 0.4620 - val_lcm_f1_5k: 0.3863 - val_lcm_accuracy_1k: 0.5689 - val_lcm_accuracy_2k: 0.7223 - val_lcm_accuracy_3k: 0.7985 - val_lcm_accuracy_5k: 0.8590 - val_lcm_hamming_loss_k: 0.0041
Epoch 12/150
27/27 [==============================] - ETA: 0s - loss: 0.2474 - lcm_precision_1k: 0.6434 - lcm_precision_2k: 0.5101 - lcm_precision_3k: 0.4104 - lcm_precision_5k: 0.2919 - lcm_recall_1k: 0.4043 - lcm_recall_2k: 0.6021 - lcm_recall_3k: 0.7026 - lcm_recall_5k: 0.8047 - lcm_f1_1k: 0.4965 - lcm_f1_2k: 0.5522 - lcm_f1_3k: 0.5181 - lcm_f1_5k: 0.4284 - lcm_accuracy_1k: 0.6434 - lcm_accuracy_2k: 0.8023 - lcm_accuracy_3k: 0.8655 - lcm_accuracy_5k: 0.9204 - lcm_hamming_loss_k: 0.0038
Epoch 00012: val_loss improved from 0.28708 to 0.28076, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 12s 431ms/step - loss: 0.2474 - lcm_precision_1k: 0.6434 - lcm_precision_2k: 0.5101 - lcm_precision_3k: 0.4104 - lcm_precision_5k: 0.2919 - lcm_recall_1k: 0.4043 - lcm_recall_2k: 0.6021 - lcm_recall_3k: 0.7026 - lcm_recall_5k: 0.8047 - lcm_f1_1k: 0.4965 - lcm_f1_2k: 0.5522 - lcm_f1_3k: 0.5181 - lcm_f1_5k: 0.4284 - lcm_accuracy_1k: 0.6434 - lcm_accuracy_2k: 0.8023 - lcm_accuracy_3k: 0.8655 - lcm_accuracy_5k: 0.9204 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2808 - val_lcm_precision_1k: 0.5771 - val_lcm_precision_2k: 0.4591 - val_lcm_precision_3k: 0.3711 - val_lcm_precision_5k: 0.2675 - val_lcm_recall_1k: 0.3614 - val_lcm_recall_2k: 0.5387 - val_lcm_recall_3k: 0.6343 - val_lcm_recall_5k: 0.7355 - val_lcm_f1_1k: 0.4442 - val_lcm_f1_2k: 0.4955 - val_lcm_f1_3k: 0.4680 - val_lcm_f1_5k: 0.3921 - val_lcm_accuracy_1k: 0.5771 - val_lcm_accuracy_2k: 0.7368 - val_lcm_accuracy_3k: 0.8116 - val_lcm_accuracy_5k: 0.8692 - val_lcm_hamming_loss_k: 0.0041
Epoch 13/150
27/27 [==============================] - ETA: 0s - loss: 0.2405 - lcm_precision_1k: 0.6595 - lcm_precision_2k: 0.5186 - lcm_precision_3k: 0.4173 - lcm_precision_5k: 0.2955 - lcm_recall_1k: 0.4152 - lcm_recall_2k: 0.6127 - lcm_recall_3k: 0.7150 - lcm_recall_5k: 0.8158 - lcm_f1_1k: 0.5095 - lcm_f1_2k: 0.5617 - lcm_f1_3k: 0.5270 - lcm_f1_5k: 0.4338 - lcm_accuracy_1k: 0.6595 - lcm_accuracy_2k: 0.8115 - lcm_accuracy_3k: 0.8773 - lcm_accuracy_5k: 0.9290 - lcm_hamming_loss_k: 0.0037
Epoch 00013: val_loss improved from 0.28076 to 0.27982, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 11s 429ms/step - loss: 0.2405 - lcm_precision_1k: 0.6595 - lcm_precision_2k: 0.5186 - lcm_precision_3k: 0.4173 - lcm_precision_5k: 0.2955 - lcm_recall_1k: 0.4152 - lcm_recall_2k: 0.6127 - lcm_recall_3k: 0.7150 - lcm_recall_5k: 0.8158 - lcm_f1_1k: 0.5095 - lcm_f1_2k: 0.5617 - lcm_f1_3k: 0.5270 - lcm_f1_5k: 0.4338 - lcm_accuracy_1k: 0.6595 - lcm_accuracy_2k: 0.8115 - lcm_accuracy_3k: 0.8773 - lcm_accuracy_5k: 0.9290 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2798 - val_lcm_precision_1k: 0.5777 - val_lcm_precision_2k: 0.4577 - val_lcm_precision_3k: 0.3695 - val_lcm_precision_5k: 0.2649 - val_lcm_recall_1k: 0.3632 - val_lcm_recall_2k: 0.5405 - val_lcm_recall_3k: 0.6329 - val_lcm_recall_5k: 0.7302 - val_lcm_f1_1k: 0.4457 - val_lcm_f1_2k: 0.4954 - val_lcm_f1_3k: 0.4664 - val_lcm_f1_5k: 0.3886 - val_lcm_accuracy_1k: 0.5777 - val_lcm_accuracy_2k: 0.7331 - val_lcm_accuracy_3k: 0.8066 - val_lcm_accuracy_5k: 0.8686 - val_lcm_hamming_loss_k: 0.0041
Epoch 14/150
27/27 [==============================] - ETA: 0s - loss: 0.2354 - lcm_precision_1k: 0.6778 - lcm_precision_2k: 0.5273 - lcm_precision_3k: 0.4228 - lcm_precision_5k: 0.2991 - lcm_recall_1k: 0.4278 - lcm_recall_2k: 0.6235 - lcm_recall_3k: 0.7240 - lcm_recall_5k: 0.8251 - lcm_f1_1k: 0.5245 - lcm_f1_2k: 0.5714 - lcm_f1_3k: 0.5338 - lcm_f1_5k: 0.4390 - lcm_accuracy_1k: 0.6778 - lcm_accuracy_2k: 0.8213 - lcm_accuracy_3k: 0.8822 - lcm_accuracy_5k: 0.9355 - lcm_hamming_loss_k: 0.0036
Epoch 00014: val_loss improved from 0.27982 to 0.27669, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 12s 431ms/step - loss: 0.2354 - lcm_precision_1k: 0.6778 - lcm_precision_2k: 0.5273 - lcm_precision_3k: 0.4228 - lcm_precision_5k: 0.2991 - lcm_recall_1k: 0.4278 - lcm_recall_2k: 0.6235 - lcm_recall_3k: 0.7240 - lcm_recall_5k: 0.8251 - lcm_f1_1k: 0.5245 - lcm_f1_2k: 0.5714 - lcm_f1_3k: 0.5338 - lcm_f1_5k: 0.4390 - lcm_accuracy_1k: 0.6778 - lcm_accuracy_2k: 0.8213 - lcm_accuracy_3k: 0.8822 - lcm_accuracy_5k: 0.9355 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2767 - val_lcm_precision_1k: 0.5990 - val_lcm_precision_2k: 0.4642 - val_lcm_precision_3k: 0.3745 - val_lcm_precision_5k: 0.2674 - val_lcm_recall_1k: 0.3770 - val_lcm_recall_2k: 0.5495 - val_lcm_recall_3k: 0.6417 - val_lcm_recall_5k: 0.7351 - val_lcm_f1_1k: 0.4625 - val_lcm_f1_2k: 0.5030 - val_lcm_f1_3k: 0.4728 - val_lcm_f1_5k: 0.3920 - val_lcm_accuracy_1k: 0.5990 - val_lcm_accuracy_2k: 0.7491 - val_lcm_accuracy_3k: 0.8153 - val_lcm_accuracy_5k: 0.8681 - val_lcm_hamming_loss_k: 0.0040
Epoch 15/150
27/27 [==============================] - ETA: 0s - loss: 0.2291 - lcm_precision_1k: 0.6893 - lcm_precision_2k: 0.5395 - lcm_precision_3k: 0.4326 - lcm_precision_5k: 0.3035 - lcm_recall_1k: 0.4377 - lcm_recall_2k: 0.6382 - lcm_recall_3k: 0.7410 - lcm_recall_5k: 0.8371 - lcm_f1_1k: 0.5354 - lcm_f1_2k: 0.5846 - lcm_f1_3k: 0.5463 - lcm_f1_5k: 0.4455 - lcm_accuracy_1k: 0.6893 - lcm_accuracy_2k: 0.8350 - lcm_accuracy_3k: 0.8962 - lcm_accuracy_5k: 0.9420 - lcm_hamming_loss_k: 0.0036
Epoch 00015: val_loss improved from 0.27669 to 0.27577, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2291 - lcm_precision_1k: 0.6893 - lcm_precision_2k: 0.5395 - lcm_precision_3k: 0.4326 - lcm_precision_5k: 0.3035 - lcm_recall_1k: 0.4377 - lcm_recall_2k: 0.6382 - lcm_recall_3k: 0.7410 - lcm_recall_5k: 0.8371 - lcm_f1_1k: 0.5354 - lcm_f1_2k: 0.5846 - lcm_f1_3k: 0.5463 - lcm_f1_5k: 0.4455 - lcm_accuracy_1k: 0.6893 - lcm_accuracy_2k: 0.8350 - lcm_accuracy_3k: 0.8962 - lcm_accuracy_5k: 0.9420 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2758 - val_lcm_precision_1k: 0.6005 - val_lcm_precision_2k: 0.4680 - val_lcm_precision_3k: 0.3782 - val_lcm_precision_5k: 0.2696 - val_lcm_recall_1k: 0.3794 - val_lcm_recall_2k: 0.5507 - val_lcm_recall_3k: 0.6476 - val_lcm_recall_5k: 0.7446 - val_lcm_f1_1k: 0.4648 - val_lcm_f1_2k: 0.5058 - val_lcm_f1_3k: 0.4773 - val_lcm_f1_5k: 0.3957 - val_lcm_accuracy_1k: 0.6005 - val_lcm_accuracy_2k: 0.7467 - val_lcm_accuracy_3k: 0.8200 - val_lcm_accuracy_5k: 0.8747 - val_lcm_hamming_loss_k: 0.0040
Epoch 16/150
27/27 [==============================] - ETA: 0s - loss: 0.2243 - lcm_precision_1k: 0.7022 - lcm_precision_2k: 0.5480 - lcm_precision_3k: 0.4376 - lcm_precision_5k: 0.3073 - lcm_recall_1k: 0.4471 - lcm_recall_2k: 0.6479 - lcm_recall_3k: 0.7480 - lcm_recall_5k: 0.8441 - lcm_f1_1k: 0.5463 - lcm_f1_2k: 0.5937 - lcm_f1_3k: 0.5521 - lcm_f1_5k: 0.4505 - lcm_accuracy_1k: 0.7022 - lcm_accuracy_2k: 0.8444 - lcm_accuracy_3k: 0.9006 - lcm_accuracy_5k: 0.9462 - lcm_hamming_loss_k: 0.0035
Epoch 00016: val_loss improved from 0.27577 to 0.27541, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 11s 428ms/step - loss: 0.2243 - lcm_precision_1k: 0.7022 - lcm_precision_2k: 0.5480 - lcm_precision_3k: 0.4376 - lcm_precision_5k: 0.3073 - lcm_recall_1k: 0.4471 - lcm_recall_2k: 0.6479 - lcm_recall_3k: 0.7480 - lcm_recall_5k: 0.8441 - lcm_f1_1k: 0.5463 - lcm_f1_2k: 0.5937 - lcm_f1_3k: 0.5521 - lcm_f1_5k: 0.4505 - lcm_accuracy_1k: 0.7022 - lcm_accuracy_2k: 0.8444 - lcm_accuracy_3k: 0.9006 - lcm_accuracy_5k: 0.9462 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2754 - val_lcm_precision_1k: 0.5997 - val_lcm_precision_2k: 0.4689 - val_lcm_precision_3k: 0.3762 - val_lcm_precision_5k: 0.2702 - val_lcm_recall_1k: 0.3778 - val_lcm_recall_2k: 0.5529 - val_lcm_recall_3k: 0.6463 - val_lcm_recall_5k: 0.7465 - val_lcm_f1_1k: 0.4634 - val_lcm_f1_2k: 0.5072 - val_lcm_f1_3k: 0.4754 - val_lcm_f1_5k: 0.3966 - val_lcm_accuracy_1k: 0.5997 - val_lcm_accuracy_2k: 0.7507 - val_lcm_accuracy_3k: 0.8212 - val_lcm_accuracy_5k: 0.8793 - val_lcm_hamming_loss_k: 0.0040
Epoch 17/150
27/27 [==============================] - ETA: 0s - loss: 0.2176 - lcm_precision_1k: 0.7149 - lcm_precision_2k: 0.5585 - lcm_precision_3k: 0.4453 - lcm_precision_5k: 0.3117 - lcm_recall_1k: 0.4550 - lcm_recall_2k: 0.6611 - lcm_recall_3k: 0.7610 - lcm_recall_5k: 0.8555 - lcm_f1_1k: 0.5560 - lcm_f1_2k: 0.6054 - lcm_f1_3k: 0.5617 - lcm_f1_5k: 0.4569 - lcm_accuracy_1k: 0.7149 - lcm_accuracy_2k: 0.8556 - lcm_accuracy_3k: 0.9097 - lcm_accuracy_5k: 0.9528 - lcm_hamming_loss_k: 0.0035 ETA: 1s - loss: 0.2175 - lcm_precision_1k: 0.7154 - lcm_precision_2k: 0.5585 - lcm_precision_3k: 0.4448 - lcm_precision_5k: 0.3107 - lcm_recall_1k: 0.4577 - lcm_recall_2k: 0.6641 - lcm_recall_3k: 0.7635 - lcm_recall_5k: 0.8560 - lcm_f1_1k: 0.5581 - lcm_f1_2k: 0.6067 - lcm_f1_3k: 0.5621 - lcm_f1_5k: 0.4559 - lcm_accuracy_1k: 0.7154 - lcm_accuracy_2k: 0.8576 - lcm_accuracy_3k: 0.9110 - lcm_accuracy_5k: 0.9522 - lcm_hamming_loss
Epoch 00017: val_loss improved from 0.27541 to 0.27404, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 12s 432ms/step - loss: 0.2176 - lcm_precision_1k: 0.7149 - lcm_precision_2k: 0.5585 - lcm_precision_3k: 0.4453 - lcm_precision_5k: 0.3117 - lcm_recall_1k: 0.4550 - lcm_recall_2k: 0.6611 - lcm_recall_3k: 0.7610 - lcm_recall_5k: 0.8555 - lcm_f1_1k: 0.5560 - lcm_f1_2k: 0.6054 - lcm_f1_3k: 0.5617 - lcm_f1_5k: 0.4569 - lcm_accuracy_1k: 0.7149 - lcm_accuracy_2k: 0.8556 - lcm_accuracy_3k: 0.9097 - lcm_accuracy_5k: 0.9528 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2740 - val_lcm_precision_1k: 0.5980 - val_lcm_precision_2k: 0.4703 - val_lcm_precision_3k: 0.3788 - val_lcm_precision_5k: 0.2696 - val_lcm_recall_1k: 0.3776 - val_lcm_recall_2k: 0.5569 - val_lcm_recall_3k: 0.6523 - val_lcm_recall_5k: 0.7467 - val_lcm_f1_1k: 0.4627 - val_lcm_f1_2k: 0.5097 - val_lcm_f1_3k: 0.4791 - val_lcm_f1_5k: 0.3960 - val_lcm_accuracy_1k: 0.5980 - val_lcm_accuracy_2k: 0.7577 - val_lcm_accuracy_3k: 0.8256 - val_lcm_accuracy_5k: 0.8768 - val_lcm_hamming_loss_k: 0.0040
Epoch 18/150
27/27 [==============================] - ETA: 0s - loss: 0.2134 - lcm_precision_1k: 0.7280 - lcm_precision_2k: 0.5664 - lcm_precision_3k: 0.4505 - lcm_precision_5k: 0.3154 - lcm_recall_1k: 0.4648 - lcm_recall_2k: 0.6706 - lcm_recall_3k: 0.7711 - lcm_recall_5k: 0.8657 - lcm_f1_1k: 0.5673 - lcm_f1_2k: 0.6140 - lcm_f1_3k: 0.5686 - lcm_f1_5k: 0.4623 - lcm_accuracy_1k: 0.7280 - lcm_accuracy_2k: 0.8645 - lcm_accuracy_3k: 0.9166 - lcm_accuracy_5k: 0.9564 - lcm_hamming_loss_k: 0.0034
Epoch 00018: val_loss improved from 0.27404 to 0.27326, saving model to logs/nnbsot-labs-0604-154118/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2134 - lcm_precision_1k: 0.7280 - lcm_precision_2k: 0.5664 - lcm_precision_3k: 0.4505 - lcm_precision_5k: 0.3154 - lcm_recall_1k: 0.4648 - lcm_recall_2k: 0.6706 - lcm_recall_3k: 0.7711 - lcm_recall_5k: 0.8657 - lcm_f1_1k: 0.5673 - lcm_f1_2k: 0.6140 - lcm_f1_3k: 0.5686 - lcm_f1_5k: 0.4623 - lcm_accuracy_1k: 0.7280 - lcm_accuracy_2k: 0.8645 - lcm_accuracy_3k: 0.9166 - lcm_accuracy_5k: 0.9564 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2733 - val_lcm_precision_1k: 0.6042 - val_lcm_precision_2k: 0.4712 - val_lcm_precision_3k: 0.3782 - val_lcm_precision_5k: 0.2707 - val_lcm_recall_1k: 0.3825 - val_lcm_recall_2k: 0.5607 - val_lcm_recall_3k: 0.6508 - val_lcm_recall_5k: 0.7496 - val_lcm_f1_1k: 0.4683 - val_lcm_f1_2k: 0.5118 - val_lcm_f1_3k: 0.4782 - val_lcm_f1_5k: 0.3975 - val_lcm_accuracy_1k: 0.6042 - val_lcm_accuracy_2k: 0.7574 - val_lcm_accuracy_3k: 0.8222 - val_lcm_accuracy_5k: 0.8829 - val_lcm_hamming_loss_k: 0.0040
Epoch 19/150
27/27 [==============================] - ETA: 0s - loss: 0.2054 - lcm_precision_1k: 0.7402 - lcm_precision_2k: 0.5772 - lcm_precision_3k: 0.4593 - lcm_precision_5k: 0.3191 - lcm_recall_1k: 0.4746 - lcm_recall_2k: 0.6823 - lcm_recall_3k: 0.7831 - lcm_recall_5k: 0.8735 - lcm_f1_1k: 0.5783 - lcm_f1_2k: 0.6253 - lcm_f1_3k: 0.5789 - lcm_f1_5k: 0.4674 - lcm_accuracy_1k: 0.7402 - lcm_accuracy_2k: 0.8763 - lcm_accuracy_3k: 0.9253 - lcm_accuracy_5k: 0.9628 - lcm_hamming_loss_k: 0.0033
Epoch 00019: val_loss did not improve from 0.27326
27/27 [==============================] - 11s 392ms/step - loss: 0.2054 - lcm_precision_1k: 0.7402 - lcm_precision_2k: 0.5772 - lcm_precision_3k: 0.4593 - lcm_precision_5k: 0.3191 - lcm_recall_1k: 0.4746 - lcm_recall_2k: 0.6823 - lcm_recall_3k: 0.7831 - lcm_recall_5k: 0.8735 - lcm_f1_1k: 0.5783 - lcm_f1_2k: 0.6253 - lcm_f1_3k: 0.5789 - lcm_f1_5k: 0.4674 - lcm_accuracy_1k: 0.7402 - lcm_accuracy_2k: 0.8763 - lcm_accuracy_3k: 0.9253 - lcm_accuracy_5k: 0.9628 - lcm_hamming_loss_k: 0.0033 - val_loss: 0.2747 - val_lcm_precision_1k: 0.5992 - val_lcm_precision_2k: 0.4748 - val_lcm_precision_3k: 0.3776 - val_lcm_precision_5k: 0.2678 - val_lcm_recall_1k: 0.3804 - val_lcm_recall_2k: 0.5622 - val_lcm_recall_3k: 0.6527 - val_lcm_recall_5k: 0.7437 - val_lcm_f1_1k: 0.4652 - val_lcm_f1_2k: 0.5146 - val_lcm_f1_3k: 0.4782 - val_lcm_f1_5k: 0.3937 - val_lcm_accuracy_1k: 0.5992 - val_lcm_accuracy_2k: 0.7591 - val_lcm_accuracy_3k: 0.8257 - val_lcm_accuracy_5k: 0.8774 - val_lcm_hamming_loss_k: 0.0040
Epoch 20/150
27/27 [==============================] - ETA: 0s - loss: 0.2017 - lcm_precision_1k: 0.7530 - lcm_precision_2k: 0.5870 - lcm_precision_3k: 0.4647 - lcm_precision_5k: 0.3231 - lcm_recall_1k: 0.4815 - lcm_recall_2k: 0.6920 - lcm_recall_3k: 0.7898 - lcm_recall_5k: 0.8819 - lcm_f1_1k: 0.5873 - lcm_f1_2k: 0.6351 - lcm_f1_3k: 0.5850 - lcm_f1_5k: 0.4728 - lcm_accuracy_1k: 0.7530 - lcm_accuracy_2k: 0.8842 - lcm_accuracy_3k: 0.9295 - lcm_accuracy_5k: 0.9655 - lcm_hamming_loss_k: 0.0033
Epoch 00020: val_loss did not improve from 0.27326
27/27 [==============================] - 11s 393ms/step - loss: 0.2017 - lcm_precision_1k: 0.7530 - lcm_precision_2k: 0.5870 - lcm_precision_3k: 0.4647 - lcm_precision_5k: 0.3231 - lcm_recall_1k: 0.4815 - lcm_recall_2k: 0.6920 - lcm_recall_3k: 0.7898 - lcm_recall_5k: 0.8819 - lcm_f1_1k: 0.5873 - lcm_f1_2k: 0.6351 - lcm_f1_3k: 0.5850 - lcm_f1_5k: 0.4728 - lcm_accuracy_1k: 0.7530 - lcm_accuracy_2k: 0.8842 - lcm_accuracy_3k: 0.9295 - lcm_accuracy_5k: 0.9655 - lcm_hamming_loss_k: 0.0033 - val_loss: 0.2749 - val_lcm_precision_1k: 0.6042 - val_lcm_precision_2k: 0.4736 - val_lcm_precision_3k: 0.3795 - val_lcm_precision_5k: 0.2697 - val_lcm_recall_1k: 0.3826 - val_lcm_recall_2k: 0.5634 - val_lcm_recall_3k: 0.6525 - val_lcm_recall_5k: 0.7464 - val_lcm_f1_1k: 0.4684 - val_lcm_f1_2k: 0.5144 - val_lcm_f1_3k: 0.4797 - val_lcm_f1_5k: 0.3961 - val_lcm_accuracy_1k: 0.6042 - val_lcm_accuracy_2k: 0.7607 - val_lcm_accuracy_3k: 0.8232 - val_lcm_accuracy_5k: 0.8793 - val_lcm_hamming_loss_k: 0.0040
Epoch 00020: early stopping
176/176 [==============================] - 8s 41ms/step - loss: 0.2235 - lcm_precision_1k: 0.7109 - lcm_precision_2k: 0.5480 - lcm_precision_3k: 0.4337 - lcm_precision_5k: 0.3039 - lcm_recall_1k: 0.4571 - lcm_recall_2k: 0.6515 - lcm_recall_3k: 0.7479 - lcm_recall_5k: 0.8393 - lcm_f1_1k: 0.5551 - lcm_f1_2k: 0.5941 - lcm_f1_3k: 0.5480 - lcm_f1_5k: 0.4455 - lcm_accuracy_1k: 0.7109 - lcm_accuracy_2k: 0.8447 - lcm_accuracy_3k: 0.8977 - lcm_accuracy_5k: 0.9379 - lcm_hamming_loss_k: 0.0035 2s - loss: 0.2228 - lcm_precision_1k: 0.7115 - lcm_precision_2k: 0.5488 - lcm_precision_3k: 0.4335 - lcm_precision_5k: 0.3027 - lcm_recall_1k: 0.4570 - lcm_recall_2k: 0.6523 - lcm_recall_3k: 0.7488 - lcm_recall_5k: 0.8392 - lcm_f1_1k: 0.5552 - lcm_f1_2k: 0.5947 - lcm_f1_3k: 0.5480 - lcm_f1_5k: 0.4441 - lcm_accuracy_1k: 0.7115 - lcm_accuracy_2k: 0.8433 - lcm_accuracy_3k: 0.8970 - 
Best model result:  [0.22354069352149963, 0.7108925580978394, 0.548035204410553, 0.43369653820991516, 0.3038966953754425, 0.45706480741500854, 0.6514612436294556, 0.7479154467582703, 0.8393032550811768, 0.5550901889801025, 0.5940709710121155, 0.5480197668075562, 0.44548937678337097, 0.7108925580978394, 0.8447465300559998, 0.8977096080780029, 0.9379380941390991, 0.0034559632185846567]
13499
3374
5625
Model: "model_8"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_12 (S  (None, 15, 300)     0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_12[0][
                                                                 0]']                             
                                                                                                  
 permute_12 (Permute)           (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_20 (Lambda)             (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_12[0][0]']             
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_20[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_21 (Lambda)             (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_8 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_21[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_4 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_8[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_12 (Dense)               (None, 1024)         2098176     ['tf.concat_4[0][0]']            
                                                                                                  
 dense_13 (Dense)               (None, 15)           15375       ['dense_12[0][0]']               
                                                                                                  
 tf.nn.softmax_4 (TFOpLambda)   (None, 15)           0           ['dense_13[0][0]']               
                                                                                                  
 tf.expand_dims_8 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_4[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_8[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_13 (Permute)           (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_22 (Lambda)             (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_13[0][0]']             
                                                                                                  
 dense_14 (Dense)               (None, 15, 150)      22650       ['lambda_22[0][0]']              
                                                                                                  
 tf.math.reduce_mean_9 (TFOpLam  (None, 150)         0           ['dense_14[0][0]']               
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_9 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_9[0][0]']  
                                                                                                  
 tf.__operators__.getitem_13 (S  (None, 427, 300)    0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 tf.math.multiply_4 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_9[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_13[0][
                                                                 0]']                             
                                                                                                  
 permute_14 (Permute)           (None, 1024, 150)    0           ['tf.math.multiply_4[0][0]']     
                                                                                                  
 lambda_23 (Lambda)             (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_14[0][0]']             
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_23[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_24 (Lambda)             (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_4[0][0]']     
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_24[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
==================================================================================================
Total params: 31,474,320
Trainable params: 6,695,820
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
2 patience
Model: "model_9"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_12 (S  (None, 15, 300)     0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_12[0][
                                                                 0]']                             
                                                                                                  
 permute_12 (Permute)           (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_20 (Lambda)             (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_12[0][0]']             
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_20[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_21 (Lambda)             (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_8 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_21[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_4 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_8[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_12 (Dense)               (None, 1024)         2098176     ['tf.concat_4[0][0]']            
                                                                                                  
 dense_13 (Dense)               (None, 15)           15375       ['dense_12[0][0]']               
                                                                                                  
 tf.nn.softmax_4 (TFOpLambda)   (None, 15)           0           ['dense_13[0][0]']               
                                                                                                  
 tf.expand_dims_8 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_4[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_8[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_13 (Permute)           (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_22 (Lambda)             (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_13[0][0]']             
                                                                                                  
 dense_14 (Dense)               (None, 15, 150)      22650       ['lambda_22[0][0]']              
                                                                                                  
 tf.math.reduce_mean_9 (TFOpLam  (None, 150)         0           ['dense_14[0][0]']               
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_9 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_9[0][0]']  
                                                                                                  
 tf.__operators__.getitem_13 (S  (None, 427, 300)    0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 tf.math.multiply_4 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_9[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_13[0][
                                                                 0]']                             
                                                                                                  
 permute_14 (Permute)           (None, 1024, 150)    0           ['tf.math.multiply_4[0][0]']     
                                                                                                  
 lambda_23 (Lambda)             (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_14[0][0]']             
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_23[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_24 (Lambda)             (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_4[0][0]']     
                                                                                                  
 tf.__operators__.getitem_14 (S  (None, 427, 300)    0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_24[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 label_lcm_emb (Dense)          (None, 427, 1024)    308224      ['tf.__operators__.getitem_14[0][
                                                                 0]']                             
                                                                                                  
 dot_4 (Dot)                    (None, 427)          0           ['label_lcm_emb[0][0]',          
                                                                  '1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 label_sim_dict (Dense)         (None, 427)          182756      ['dot_4[0][0]']                  
                                                                                                  
 concatenate_4 (Concatenate)    (None, 854)          0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 31,965,300
Trainable params: 7,186,800
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
Epoch 1/150
27/27 [==============================] - ETA: 0s - loss: 0.5374 - lcm_precision_1k: 0.0462 - lcm_precision_2k: 0.0598 - lcm_precision_3k: 0.0640 - lcm_precision_5k: 0.0609 - lcm_recall_1k: 0.0260 - lcm_recall_2k: 0.0624 - lcm_recall_3k: 0.0997 - lcm_recall_5k: 0.1590 - lcm_f1_1k: 0.0332 - lcm_f1_2k: 0.0610 - lcm_f1_3k: 0.0779 - lcm_f1_5k: 0.0880 - lcm_accuracy_1k: 0.0462 - lcm_accuracy_2k: 0.1166 - lcm_accuracy_3k: 0.1818 - lcm_accuracy_5k: 0.2683 - lcm_hamming_loss_k: 0.0066 ETA: 1s - loss: 0.5499 - lcm_precision_1k: 0.0449 - lcm_precision_2k: 0.0625 - lcm_precision_3k: 0.0631 - lcm_precision_5k: 0.0573 - lcm_recall_1k: 0.0255 - lcm_recall_2k: 0.0652 - lcm_recall_3k: 0.0968 - lcm_recall_5k: 0.1462 - lcm_f1_1k: 0.0324 - lcm_f1_2k: 0.0638 - lcm_f1_3k: 0.0763 - lcm_f1_5k: 0.0823 - lcm_accuracy_1k: 0.0449 - lcm_accuracy_2k: 0.1230 - lcm_accuracy_3k: 0.1791 - lcm_accuracy_5k: 0.2526 - lcm_hamming_lo
Epoch 00001: val_loss improved from inf to 0.46787, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 13s 415ms/step - loss: 0.5374 - lcm_precision_1k: 0.0462 - lcm_precision_2k: 0.0598 - lcm_precision_3k: 0.0640 - lcm_precision_5k: 0.0609 - lcm_recall_1k: 0.0260 - lcm_recall_2k: 0.0624 - lcm_recall_3k: 0.0997 - lcm_recall_5k: 0.1590 - lcm_f1_1k: 0.0332 - lcm_f1_2k: 0.0610 - lcm_f1_3k: 0.0779 - lcm_f1_5k: 0.0880 - lcm_accuracy_1k: 0.0462 - lcm_accuracy_2k: 0.1166 - lcm_accuracy_3k: 0.1818 - lcm_accuracy_5k: 0.2683 - lcm_hamming_loss_k: 0.0066 - val_loss: 0.4679 - val_lcm_precision_1k: 0.0527 - val_lcm_precision_2k: 0.0548 - val_lcm_precision_3k: 0.0894 - val_lcm_precision_5k: 0.0990 - val_lcm_recall_1k: 0.0288 - val_lcm_recall_2k: 0.0578 - val_lcm_recall_3k: 0.1434 - val_lcm_recall_5k: 0.2749 - val_lcm_f1_1k: 0.0372 - val_lcm_f1_2k: 0.0563 - val_lcm_f1_3k: 0.1101 - val_lcm_f1_5k: 0.1456 - val_lcm_accuracy_1k: 0.0527 - val_lcm_accuracy_2k: 0.1060 - val_lcm_accuracy_3k: 0.2590 - val_lcm_accuracy_5k: 0.4213 - val_lcm_hamming_loss_k: 0.0065
Epoch 2/150
27/27 [==============================] - ETA: 0s - loss: 0.4123 - lcm_precision_1k: 0.2780 - lcm_precision_2k: 0.2337 - lcm_precision_3k: 0.2118 - lcm_precision_5k: 0.1764 - lcm_recall_1k: 0.1607 - lcm_recall_2k: 0.2622 - lcm_recall_3k: 0.3497 - lcm_recall_5k: 0.4765 - lcm_f1_1k: 0.2035 - lcm_f1_2k: 0.2470 - lcm_f1_3k: 0.2637 - lcm_f1_5k: 0.2574 - lcm_accuracy_1k: 0.2780 - lcm_accuracy_2k: 0.4060 - lcm_accuracy_3k: 0.5106 - lcm_accuracy_5k: 0.6339 - lcm_hamming_loss_k: 0.0055
Epoch 00002: val_loss improved from 0.46787 to 0.37118, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 11s 428ms/step - loss: 0.4123 - lcm_precision_1k: 0.2780 - lcm_precision_2k: 0.2337 - lcm_precision_3k: 0.2118 - lcm_precision_5k: 0.1764 - lcm_recall_1k: 0.1607 - lcm_recall_2k: 0.2622 - lcm_recall_3k: 0.3497 - lcm_recall_5k: 0.4765 - lcm_f1_1k: 0.2035 - lcm_f1_2k: 0.2470 - lcm_f1_3k: 0.2637 - lcm_f1_5k: 0.2574 - lcm_accuracy_1k: 0.2780 - lcm_accuracy_2k: 0.4060 - lcm_accuracy_3k: 0.5106 - lcm_accuracy_5k: 0.6339 - lcm_hamming_loss_k: 0.0055 - val_loss: 0.3712 - val_lcm_precision_1k: 0.3917 - val_lcm_precision_2k: 0.3192 - val_lcm_precision_3k: 0.2630 - val_lcm_precision_5k: 0.1995 - val_lcm_recall_1k: 0.2376 - val_lcm_recall_2k: 0.3687 - val_lcm_recall_3k: 0.4477 - val_lcm_recall_5k: 0.5489 - val_lcm_f1_1k: 0.2956 - val_lcm_f1_2k: 0.3420 - val_lcm_f1_3k: 0.3311 - val_lcm_f1_5k: 0.2925 - val_lcm_accuracy_1k: 0.3917 - val_lcm_accuracy_2k: 0.5406 - val_lcm_accuracy_3k: 0.6153 - val_lcm_accuracy_5k: 0.6989 - val_lcm_hamming_loss_k: 0.0049
Epoch 3/150
27/27 [==============================] - ETA: 0s - loss: 0.3493 - lcm_precision_1k: 0.4370 - lcm_precision_2k: 0.3557 - lcm_precision_3k: 0.2968 - lcm_precision_5k: 0.2243 - lcm_recall_1k: 0.2614 - lcm_recall_2k: 0.4072 - lcm_recall_3k: 0.4992 - lcm_recall_5k: 0.6127 - lcm_f1_1k: 0.3271 - lcm_f1_2k: 0.3797 - lcm_f1_3k: 0.3722 - lcm_f1_5k: 0.3283 - lcm_accuracy_1k: 0.4370 - lcm_accuracy_2k: 0.5929 - lcm_accuracy_3k: 0.6770 - lcm_accuracy_5k: 0.7651 - lcm_hamming_loss_k: 0.0048
Epoch 00003: val_loss improved from 0.37118 to 0.34054, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.3493 - lcm_precision_1k: 0.4370 - lcm_precision_2k: 0.3557 - lcm_precision_3k: 0.2968 - lcm_precision_5k: 0.2243 - lcm_recall_1k: 0.2614 - lcm_recall_2k: 0.4072 - lcm_recall_3k: 0.4992 - lcm_recall_5k: 0.6127 - lcm_f1_1k: 0.3271 - lcm_f1_2k: 0.3797 - lcm_f1_3k: 0.3722 - lcm_f1_5k: 0.3283 - lcm_accuracy_1k: 0.4370 - lcm_accuracy_2k: 0.5929 - lcm_accuracy_3k: 0.6770 - lcm_accuracy_5k: 0.7651 - lcm_hamming_loss_k: 0.0048 - val_loss: 0.3405 - val_lcm_precision_1k: 0.4587 - val_lcm_precision_2k: 0.3702 - val_lcm_precision_3k: 0.3064 - val_lcm_precision_5k: 0.2264 - val_lcm_recall_1k: 0.2780 - val_lcm_recall_2k: 0.4322 - val_lcm_recall_3k: 0.5252 - val_lcm_recall_5k: 0.6298 - val_lcm_f1_1k: 0.3461 - val_lcm_f1_2k: 0.3986 - val_lcm_f1_3k: 0.3868 - val_lcm_f1_5k: 0.3330 - val_lcm_accuracy_1k: 0.4587 - val_lcm_accuracy_2k: 0.6141 - val_lcm_accuracy_3k: 0.6963 - val_lcm_accuracy_5k: 0.7717 - val_lcm_hamming_loss_k: 0.0046
Epoch 4/150
27/27 [==============================] - ETA: 0s - loss: 0.3216 - lcm_precision_1k: 0.4917 - lcm_precision_2k: 0.3961 - lcm_precision_3k: 0.3282 - lcm_precision_5k: 0.2429 - lcm_recall_1k: 0.2978 - lcm_recall_2k: 0.4570 - lcm_recall_3k: 0.5556 - lcm_recall_5k: 0.6657 - lcm_f1_1k: 0.3709 - lcm_f1_2k: 0.4243 - lcm_f1_3k: 0.4126 - lcm_f1_5k: 0.3559 - lcm_accuracy_1k: 0.4917 - lcm_accuracy_2k: 0.6489 - lcm_accuracy_3k: 0.7325 - lcm_accuracy_5k: 0.8123 - lcm_hamming_loss_k: 0.0045
Epoch 00004: val_loss improved from 0.34054 to 0.32115, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 11s 428ms/step - loss: 0.3216 - lcm_precision_1k: 0.4917 - lcm_precision_2k: 0.3961 - lcm_precision_3k: 0.3282 - lcm_precision_5k: 0.2429 - lcm_recall_1k: 0.2978 - lcm_recall_2k: 0.4570 - lcm_recall_3k: 0.5556 - lcm_recall_5k: 0.6657 - lcm_f1_1k: 0.3709 - lcm_f1_2k: 0.4243 - lcm_f1_3k: 0.4126 - lcm_f1_5k: 0.3559 - lcm_accuracy_1k: 0.4917 - lcm_accuracy_2k: 0.6489 - lcm_accuracy_3k: 0.7325 - lcm_accuracy_5k: 0.8123 - lcm_hamming_loss_k: 0.0045 - val_loss: 0.3211 - val_lcm_precision_1k: 0.4954 - val_lcm_precision_2k: 0.3936 - val_lcm_precision_3k: 0.3197 - val_lcm_precision_5k: 0.2376 - val_lcm_recall_1k: 0.3052 - val_lcm_recall_2k: 0.4628 - val_lcm_recall_3k: 0.5539 - val_lcm_recall_5k: 0.6648 - val_lcm_f1_1k: 0.3776 - val_lcm_f1_2k: 0.4252 - val_lcm_f1_3k: 0.4052 - val_lcm_f1_5k: 0.3499 - val_lcm_accuracy_1k: 0.4954 - val_lcm_accuracy_2k: 0.6524 - val_lcm_accuracy_3k: 0.7253 - val_lcm_accuracy_5k: 0.8043 - val_lcm_hamming_loss_k: 0.0044
Epoch 5/150
27/27 [==============================] - ETA: 0s - loss: 0.3038 - lcm_precision_1k: 0.5336 - lcm_precision_2k: 0.4248 - lcm_precision_3k: 0.3487 - lcm_precision_5k: 0.2541 - lcm_recall_1k: 0.3268 - lcm_recall_2k: 0.4941 - lcm_recall_3k: 0.5918 - lcm_recall_5k: 0.6988 - lcm_f1_1k: 0.4052 - lcm_f1_2k: 0.4568 - lcm_f1_3k: 0.4388 - lcm_f1_5k: 0.3726 - lcm_accuracy_1k: 0.5336 - lcm_accuracy_2k: 0.6908 - lcm_accuracy_3k: 0.7676 - lcm_accuracy_5k: 0.8412 - lcm_hamming_loss_k: 0.0043
Epoch 00005: val_loss improved from 0.32115 to 0.30685, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.3038 - lcm_precision_1k: 0.5336 - lcm_precision_2k: 0.4248 - lcm_precision_3k: 0.3487 - lcm_precision_5k: 0.2541 - lcm_recall_1k: 0.3268 - lcm_recall_2k: 0.4941 - lcm_recall_3k: 0.5918 - lcm_recall_5k: 0.6988 - lcm_f1_1k: 0.4052 - lcm_f1_2k: 0.4568 - lcm_f1_3k: 0.4388 - lcm_f1_5k: 0.3726 - lcm_accuracy_1k: 0.5336 - lcm_accuracy_2k: 0.6908 - lcm_accuracy_3k: 0.7676 - lcm_accuracy_5k: 0.8412 - lcm_hamming_loss_k: 0.0043 - val_loss: 0.3068 - val_lcm_precision_1k: 0.5282 - val_lcm_precision_2k: 0.4210 - val_lcm_precision_3k: 0.3405 - val_lcm_precision_5k: 0.2455 - val_lcm_recall_1k: 0.3280 - val_lcm_recall_2k: 0.4953 - val_lcm_recall_3k: 0.5877 - val_lcm_recall_5k: 0.6870 - val_lcm_f1_1k: 0.4046 - val_lcm_f1_2k: 0.4549 - val_lcm_f1_3k: 0.4309 - val_lcm_f1_5k: 0.3616 - val_lcm_accuracy_1k: 0.5282 - val_lcm_accuracy_2k: 0.6850 - val_lcm_accuracy_3k: 0.7589 - val_lcm_accuracy_5k: 0.8246 - val_lcm_hamming_loss_k: 0.0043
Epoch 6/150
27/27 [==============================] - ETA: 0s - loss: 0.2922 - lcm_precision_1k: 0.5554 - lcm_precision_2k: 0.4436 - lcm_precision_3k: 0.3634 - lcm_precision_5k: 0.2627 - lcm_recall_1k: 0.3424 - lcm_recall_2k: 0.5186 - lcm_recall_3k: 0.6175 - lcm_recall_5k: 0.7228 - lcm_f1_1k: 0.4236 - lcm_f1_2k: 0.4781 - lcm_f1_3k: 0.4575 - lcm_f1_5k: 0.3853 - lcm_accuracy_1k: 0.5554 - lcm_accuracy_2k: 0.7168 - lcm_accuracy_3k: 0.7917 - lcm_accuracy_5k: 0.8619 - lcm_hamming_loss_k: 0.0042
Epoch 00006: val_loss improved from 0.30685 to 0.30248, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 11s 423ms/step - loss: 0.2922 - lcm_precision_1k: 0.5554 - lcm_precision_2k: 0.4436 - lcm_precision_3k: 0.3634 - lcm_precision_5k: 0.2627 - lcm_recall_1k: 0.3424 - lcm_recall_2k: 0.5186 - lcm_recall_3k: 0.6175 - lcm_recall_5k: 0.7228 - lcm_f1_1k: 0.4236 - lcm_f1_2k: 0.4781 - lcm_f1_3k: 0.4575 - lcm_f1_5k: 0.3853 - lcm_accuracy_1k: 0.5554 - lcm_accuracy_2k: 0.7168 - lcm_accuracy_3k: 0.7917 - lcm_accuracy_5k: 0.8619 - lcm_hamming_loss_k: 0.0042 - val_loss: 0.3025 - val_lcm_precision_1k: 0.5370 - val_lcm_precision_2k: 0.4248 - val_lcm_precision_3k: 0.3437 - val_lcm_precision_5k: 0.2506 - val_lcm_recall_1k: 0.3327 - val_lcm_recall_2k: 0.5016 - val_lcm_recall_3k: 0.5917 - val_lcm_recall_5k: 0.7000 - val_lcm_f1_1k: 0.4107 - val_lcm_f1_2k: 0.4598 - val_lcm_f1_3k: 0.4345 - val_lcm_f1_5k: 0.3689 - val_lcm_accuracy_1k: 0.5370 - val_lcm_accuracy_2k: 0.6899 - val_lcm_accuracy_3k: 0.7584 - val_lcm_accuracy_5k: 0.8338 - val_lcm_hamming_loss_k: 0.0042
Epoch 7/150
27/27 [==============================] - ETA: 0s - loss: 0.2839 - lcm_precision_1k: 0.5762 - lcm_precision_2k: 0.4567 - lcm_precision_3k: 0.3724 - lcm_precision_5k: 0.2688 - lcm_recall_1k: 0.3567 - lcm_recall_2k: 0.5347 - lcm_recall_3k: 0.6354 - lcm_recall_5k: 0.7415 - lcm_f1_1k: 0.4406 - lcm_f1_2k: 0.4926 - lcm_f1_3k: 0.4696 - lcm_f1_5k: 0.3945 - lcm_accuracy_1k: 0.5762 - lcm_accuracy_2k: 0.7319 - lcm_accuracy_3k: 0.8068 - lcm_accuracy_5k: 0.8760 - lcm_hamming_loss_k: 0.0041 ETA: 7s - loss: 0.2829 - lcm_precision_1k: 0.5762 - lcm_precision_2k: 0.4637 - lcm_precision_3k: 0.3757 - lcm_precision_5k: 0.2716 - lcm_recall_1k: 0.3535 - lcm_recall_2k: 0.5389 - lcm_recall_3k: 0.6362 - lcm_recall_5k: 0.7470 - lcm_f1_1k: 0.4381 - lcm_f1_2k: 0.4984 - lcm_f1_3k: 0.4724 - lcm_f1_5k: 0.3983 - lcm_accuracy_1k: 0.5762 - lcm_accuracy_2k: 0.7363 - lcm_accuracy_3k: 0.8074 - lcm_accu
Epoch 00007: val_loss improved from 0.30248 to 0.29547, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2839 - lcm_precision_1k: 0.5762 - lcm_precision_2k: 0.4567 - lcm_precision_3k: 0.3724 - lcm_precision_5k: 0.2688 - lcm_recall_1k: 0.3567 - lcm_recall_2k: 0.5347 - lcm_recall_3k: 0.6354 - lcm_recall_5k: 0.7415 - lcm_f1_1k: 0.4406 - lcm_f1_2k: 0.4926 - lcm_f1_3k: 0.4696 - lcm_f1_5k: 0.3945 - lcm_accuracy_1k: 0.5762 - lcm_accuracy_2k: 0.7319 - lcm_accuracy_3k: 0.8068 - lcm_accuracy_5k: 0.8760 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2955 - val_lcm_precision_1k: 0.5386 - val_lcm_precision_2k: 0.4330 - val_lcm_precision_3k: 0.3484 - val_lcm_precision_5k: 0.2529 - val_lcm_recall_1k: 0.3309 - val_lcm_recall_2k: 0.5102 - val_lcm_recall_3k: 0.6018 - val_lcm_recall_5k: 0.7053 - val_lcm_f1_1k: 0.4097 - val_lcm_f1_2k: 0.4682 - val_lcm_f1_3k: 0.4411 - val_lcm_f1_5k: 0.3721 - val_lcm_accuracy_1k: 0.5386 - val_lcm_accuracy_2k: 0.6988 - val_lcm_accuracy_3k: 0.7681 - val_lcm_accuracy_5k: 0.8359 - val_lcm_hamming_loss_k: 0.0042
Epoch 8/150
27/27 [==============================] - ETA: 0s - loss: 0.2748 - lcm_precision_1k: 0.5888 - lcm_precision_2k: 0.4696 - lcm_precision_3k: 0.3810 - lcm_precision_5k: 0.2748 - lcm_recall_1k: 0.3653 - lcm_recall_2k: 0.5504 - lcm_recall_3k: 0.6499 - lcm_recall_5k: 0.7561 - lcm_f1_1k: 0.4508 - lcm_f1_2k: 0.5067 - lcm_f1_3k: 0.4803 - lcm_f1_5k: 0.4030 - lcm_accuracy_1k: 0.5888 - lcm_accuracy_2k: 0.7494 - lcm_accuracy_3k: 0.8234 - lcm_accuracy_5k: 0.8885 - lcm_hamming_loss_k: 0.0041
Epoch 00008: val_loss improved from 0.29547 to 0.29361, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 11s 424ms/step - loss: 0.2748 - lcm_precision_1k: 0.5888 - lcm_precision_2k: 0.4696 - lcm_precision_3k: 0.3810 - lcm_precision_5k: 0.2748 - lcm_recall_1k: 0.3653 - lcm_recall_2k: 0.5504 - lcm_recall_3k: 0.6499 - lcm_recall_5k: 0.7561 - lcm_f1_1k: 0.4508 - lcm_f1_2k: 0.5067 - lcm_f1_3k: 0.4803 - lcm_f1_5k: 0.4030 - lcm_accuracy_1k: 0.5888 - lcm_accuracy_2k: 0.7494 - lcm_accuracy_3k: 0.8234 - lcm_accuracy_5k: 0.8885 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2936 - val_lcm_precision_1k: 0.5548 - val_lcm_precision_2k: 0.4347 - val_lcm_precision_3k: 0.3530 - val_lcm_precision_5k: 0.2554 - val_lcm_recall_1k: 0.3435 - val_lcm_recall_2k: 0.5174 - val_lcm_recall_3k: 0.6109 - val_lcm_recall_5k: 0.7122 - val_lcm_f1_1k: 0.4241 - val_lcm_f1_2k: 0.4723 - val_lcm_f1_3k: 0.4472 - val_lcm_f1_5k: 0.3758 - val_lcm_accuracy_1k: 0.5548 - val_lcm_accuracy_2k: 0.7026 - val_lcm_accuracy_3k: 0.7719 - val_lcm_accuracy_5k: 0.8418 - val_lcm_hamming_loss_k: 0.0042
Epoch 9/150
27/27 [==============================] - ETA: 0s - loss: 0.2660 - lcm_precision_1k: 0.6101 - lcm_precision_2k: 0.4832 - lcm_precision_3k: 0.3918 - lcm_precision_5k: 0.2808 - lcm_recall_1k: 0.3799 - lcm_recall_2k: 0.5672 - lcm_recall_3k: 0.6676 - lcm_recall_5k: 0.7728 - lcm_f1_1k: 0.4682 - lcm_f1_2k: 0.5218 - lcm_f1_3k: 0.4937 - lcm_f1_5k: 0.4119 - lcm_accuracy_1k: 0.6101 - lcm_accuracy_2k: 0.7673 - lcm_accuracy_3k: 0.8376 - lcm_accuracy_5k: 0.8992 - lcm_hamming_loss_k: 0.0040
Epoch 00009: val_loss improved from 0.29361 to 0.28873, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 11s 429ms/step - loss: 0.2660 - lcm_precision_1k: 0.6101 - lcm_precision_2k: 0.4832 - lcm_precision_3k: 0.3918 - lcm_precision_5k: 0.2808 - lcm_recall_1k: 0.3799 - lcm_recall_2k: 0.5672 - lcm_recall_3k: 0.6676 - lcm_recall_5k: 0.7728 - lcm_f1_1k: 0.4682 - lcm_f1_2k: 0.5218 - lcm_f1_3k: 0.4937 - lcm_f1_5k: 0.4119 - lcm_accuracy_1k: 0.6101 - lcm_accuracy_2k: 0.7673 - lcm_accuracy_3k: 0.8376 - lcm_accuracy_5k: 0.8992 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2887 - val_lcm_precision_1k: 0.5663 - val_lcm_precision_2k: 0.4535 - val_lcm_precision_3k: 0.3631 - val_lcm_precision_5k: 0.2596 - val_lcm_recall_1k: 0.3515 - val_lcm_recall_2k: 0.5375 - val_lcm_recall_3k: 0.6298 - val_lcm_recall_5k: 0.7275 - val_lcm_f1_1k: 0.4337 - val_lcm_f1_2k: 0.4917 - val_lcm_f1_3k: 0.4604 - val_lcm_f1_5k: 0.3825 - val_lcm_accuracy_1k: 0.5663 - val_lcm_accuracy_2k: 0.7272 - val_lcm_accuracy_3k: 0.7953 - val_lcm_accuracy_5k: 0.8574 - val_lcm_hamming_loss_k: 0.0041
Epoch 10/150
27/27 [==============================] - ETA: 0s - loss: 0.2589 - lcm_precision_1k: 0.6227 - lcm_precision_2k: 0.4932 - lcm_precision_3k: 0.3994 - lcm_precision_5k: 0.2845 - lcm_recall_1k: 0.3882 - lcm_recall_2k: 0.5786 - lcm_recall_3k: 0.6820 - lcm_recall_5k: 0.7830 - lcm_f1_1k: 0.4782 - lcm_f1_2k: 0.5324 - lcm_f1_3k: 0.5037 - lcm_f1_5k: 0.4173 - lcm_accuracy_1k: 0.6227 - lcm_accuracy_2k: 0.7796 - lcm_accuracy_3k: 0.8501 - lcm_accuracy_5k: 0.9060 - lcm_hamming_loss_k: 0.0039
Epoch 00010: val_loss improved from 0.28873 to 0.28062, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.2589 - lcm_precision_1k: 0.6227 - lcm_precision_2k: 0.4932 - lcm_precision_3k: 0.3994 - lcm_precision_5k: 0.2845 - lcm_recall_1k: 0.3882 - lcm_recall_2k: 0.5786 - lcm_recall_3k: 0.6820 - lcm_recall_5k: 0.7830 - lcm_f1_1k: 0.4782 - lcm_f1_2k: 0.5324 - lcm_f1_3k: 0.5037 - lcm_f1_5k: 0.4173 - lcm_accuracy_1k: 0.6227 - lcm_accuracy_2k: 0.7796 - lcm_accuracy_3k: 0.8501 - lcm_accuracy_5k: 0.9060 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2806 - val_lcm_precision_1k: 0.5825 - val_lcm_precision_2k: 0.4572 - val_lcm_precision_3k: 0.3681 - val_lcm_precision_5k: 0.2633 - val_lcm_recall_1k: 0.3647 - val_lcm_recall_2k: 0.5414 - val_lcm_recall_3k: 0.6361 - val_lcm_recall_5k: 0.7363 - val_lcm_f1_1k: 0.4484 - val_lcm_f1_2k: 0.4955 - val_lcm_f1_3k: 0.4661 - val_lcm_f1_5k: 0.3877 - val_lcm_accuracy_1k: 0.5825 - val_lcm_accuracy_2k: 0.7308 - val_lcm_accuracy_3k: 0.8020 - val_lcm_accuracy_5k: 0.8642 - val_lcm_hamming_loss_k: 0.0040
Epoch 11/150
27/27 [==============================] - ETA: 0s - loss: 0.2532 - lcm_precision_1k: 0.6322 - lcm_precision_2k: 0.5017 - lcm_precision_3k: 0.4058 - lcm_precision_5k: 0.2885 - lcm_recall_1k: 0.3957 - lcm_recall_2k: 0.5916 - lcm_recall_3k: 0.6939 - lcm_recall_5k: 0.7951 - lcm_f1_1k: 0.4866 - lcm_f1_2k: 0.5429 - lcm_f1_3k: 0.5121 - lcm_f1_5k: 0.4234 - lcm_accuracy_1k: 0.6322 - lcm_accuracy_2k: 0.7943 - lcm_accuracy_3k: 0.8617 - lcm_accuracy_5k: 0.9159 - lcm_hamming_loss_k: 0.0039
Epoch 00011: val_loss improved from 0.28062 to 0.27677, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.2532 - lcm_precision_1k: 0.6322 - lcm_precision_2k: 0.5017 - lcm_precision_3k: 0.4058 - lcm_precision_5k: 0.2885 - lcm_recall_1k: 0.3957 - lcm_recall_2k: 0.5916 - lcm_recall_3k: 0.6939 - lcm_recall_5k: 0.7951 - lcm_f1_1k: 0.4866 - lcm_f1_2k: 0.5429 - lcm_f1_3k: 0.5121 - lcm_f1_5k: 0.4234 - lcm_accuracy_1k: 0.6322 - lcm_accuracy_2k: 0.7943 - lcm_accuracy_3k: 0.8617 - lcm_accuracy_5k: 0.9159 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2768 - val_lcm_precision_1k: 0.5764 - val_lcm_precision_2k: 0.4567 - val_lcm_precision_3k: 0.3713 - val_lcm_precision_5k: 0.2652 - val_lcm_recall_1k: 0.3620 - val_lcm_recall_2k: 0.5433 - val_lcm_recall_3k: 0.6413 - val_lcm_recall_5k: 0.7393 - val_lcm_f1_1k: 0.4446 - val_lcm_f1_2k: 0.4960 - val_lcm_f1_3k: 0.4701 - val_lcm_f1_5k: 0.3902 - val_lcm_accuracy_1k: 0.5764 - val_lcm_accuracy_2k: 0.7353 - val_lcm_accuracy_3k: 0.8054 - val_lcm_accuracy_5k: 0.8643 - val_lcm_hamming_loss_k: 0.0041
Epoch 12/150
27/27 [==============================] - ETA: 0s - loss: 0.2457 - lcm_precision_1k: 0.6501 - lcm_precision_2k: 0.5121 - lcm_precision_3k: 0.4137 - lcm_precision_5k: 0.2923 - lcm_recall_1k: 0.4093 - lcm_recall_2k: 0.6053 - lcm_recall_3k: 0.7065 - lcm_recall_5k: 0.8056 - lcm_f1_1k: 0.5022 - lcm_f1_2k: 0.5547 - lcm_f1_3k: 0.5218 - lcm_f1_5k: 0.4289 - lcm_accuracy_1k: 0.6501 - lcm_accuracy_2k: 0.8057 - lcm_accuracy_3k: 0.8692 - lcm_accuracy_5k: 0.9229 - lcm_hamming_loss_k: 0.0038
Epoch 00012: val_loss improved from 0.27677 to 0.27318, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 12s 431ms/step - loss: 0.2457 - lcm_precision_1k: 0.6501 - lcm_precision_2k: 0.5121 - lcm_precision_3k: 0.4137 - lcm_precision_5k: 0.2923 - lcm_recall_1k: 0.4093 - lcm_recall_2k: 0.6053 - lcm_recall_3k: 0.7065 - lcm_recall_5k: 0.8056 - lcm_f1_1k: 0.5022 - lcm_f1_2k: 0.5547 - lcm_f1_3k: 0.5218 - lcm_f1_5k: 0.4289 - lcm_accuracy_1k: 0.6501 - lcm_accuracy_2k: 0.8057 - lcm_accuracy_3k: 0.8692 - lcm_accuracy_5k: 0.9229 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2732 - val_lcm_precision_1k: 0.5894 - val_lcm_precision_2k: 0.4621 - val_lcm_precision_3k: 0.3739 - val_lcm_precision_5k: 0.2673 - val_lcm_recall_1k: 0.3707 - val_lcm_recall_2k: 0.5475 - val_lcm_recall_3k: 0.6465 - val_lcm_recall_5k: 0.7463 - val_lcm_f1_1k: 0.4550 - val_lcm_f1_2k: 0.5010 - val_lcm_f1_3k: 0.4735 - val_lcm_f1_5k: 0.3935 - val_lcm_accuracy_1k: 0.5894 - val_lcm_accuracy_2k: 0.7384 - val_lcm_accuracy_3k: 0.8072 - val_lcm_accuracy_5k: 0.8698 - val_lcm_hamming_loss_k: 0.0040
Epoch 13/150
27/27 [==============================] - ETA: 0s - loss: 0.2407 - lcm_precision_1k: 0.6648 - lcm_precision_2k: 0.5211 - lcm_precision_3k: 0.4195 - lcm_precision_5k: 0.2961 - lcm_recall_1k: 0.4199 - lcm_recall_2k: 0.6139 - lcm_recall_3k: 0.7153 - lcm_recall_5k: 0.8143 - lcm_f1_1k: 0.5146 - lcm_f1_2k: 0.5636 - lcm_f1_3k: 0.5288 - lcm_f1_5k: 0.4342 - lcm_accuracy_1k: 0.6648 - lcm_accuracy_2k: 0.8123 - lcm_accuracy_3k: 0.8763 - lcm_accuracy_5k: 0.9290 - lcm_hamming_loss_k: 0.0037
Epoch 00013: val_loss did not improve from 0.27318
27/27 [==============================] - 10s 390ms/step - loss: 0.2407 - lcm_precision_1k: 0.6648 - lcm_precision_2k: 0.5211 - lcm_precision_3k: 0.4195 - lcm_precision_5k: 0.2961 - lcm_recall_1k: 0.4199 - lcm_recall_2k: 0.6139 - lcm_recall_3k: 0.7153 - lcm_recall_5k: 0.8143 - lcm_f1_1k: 0.5146 - lcm_f1_2k: 0.5636 - lcm_f1_3k: 0.5288 - lcm_f1_5k: 0.4342 - lcm_accuracy_1k: 0.6648 - lcm_accuracy_2k: 0.8123 - lcm_accuracy_3k: 0.8763 - lcm_accuracy_5k: 0.9290 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2761 - val_lcm_precision_1k: 0.6053 - val_lcm_precision_2k: 0.4692 - val_lcm_precision_3k: 0.3788 - val_lcm_precision_5k: 0.2686 - val_lcm_recall_1k: 0.3821 - val_lcm_recall_2k: 0.5580 - val_lcm_recall_3k: 0.6568 - val_lcm_recall_5k: 0.7538 - val_lcm_f1_1k: 0.4683 - val_lcm_f1_2k: 0.5096 - val_lcm_f1_3k: 0.4803 - val_lcm_f1_5k: 0.3960 - val_lcm_accuracy_1k: 0.6053 - val_lcm_accuracy_2k: 0.7516 - val_lcm_accuracy_3k: 0.8172 - val_lcm_accuracy_5k: 0.8803 - val_lcm_hamming_loss_k: 0.0039
Epoch 14/150
27/27 [==============================] - ETA: 0s - loss: 0.2341 - lcm_precision_1k: 0.6794 - lcm_precision_2k: 0.5337 - lcm_precision_3k: 0.4271 - lcm_precision_5k: 0.3004 - lcm_recall_1k: 0.4298 - lcm_recall_2k: 0.6303 - lcm_recall_3k: 0.7295 - lcm_recall_5k: 0.8264 - lcm_f1_1k: 0.5264 - lcm_f1_2k: 0.5779 - lcm_f1_3k: 0.5387 - lcm_f1_5k: 0.4406 - lcm_accuracy_1k: 0.6794 - lcm_accuracy_2k: 0.8281 - lcm_accuracy_3k: 0.8889 - lcm_accuracy_5k: 0.9364 - lcm_hamming_loss_k: 0.0036 ETA: 0s - loss: 0.2343 - lcm_precision_1k: 0.6820 - lcm_precision_2k: 0.5351 - lcm_precision_3k: 0.4278 - lcm_precision_5k: 0.3006 - lcm_recall_1k: 0.4306 - lcm_recall_2k: 0.6306 - lcm_recall_3k: 0.7293 - lcm_recall_5k: 0.8256 - lcm_f1_1k: 0.5278 - lcm_f1_2k: 0.5788 - lcm_f1_3k: 0.5392 - lcm_f1_5k: 0.4407 - lcm_accuracy_1k: 0.6820 - lcm_accuracy_2k: 0.8288 - lcm_accuracy_3k: 0.8891 - lcm_accuracy_5k: 0.9366 - lcm_hamming_loss_k: 0.
Epoch 00014: val_loss improved from 0.27318 to 0.27163, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2341 - lcm_precision_1k: 0.6794 - lcm_precision_2k: 0.5337 - lcm_precision_3k: 0.4271 - lcm_precision_5k: 0.3004 - lcm_recall_1k: 0.4298 - lcm_recall_2k: 0.6303 - lcm_recall_3k: 0.7295 - lcm_recall_5k: 0.8264 - lcm_f1_1k: 0.5264 - lcm_f1_2k: 0.5779 - lcm_f1_3k: 0.5387 - lcm_f1_5k: 0.4406 - lcm_accuracy_1k: 0.6794 - lcm_accuracy_2k: 0.8281 - lcm_accuracy_3k: 0.8889 - lcm_accuracy_5k: 0.9364 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2716 - val_lcm_precision_1k: 0.6020 - val_lcm_precision_2k: 0.4632 - val_lcm_precision_3k: 0.3736 - val_lcm_precision_5k: 0.2683 - val_lcm_recall_1k: 0.3810 - val_lcm_recall_2k: 0.5517 - val_lcm_recall_3k: 0.6476 - val_lcm_recall_5k: 0.7480 - val_lcm_f1_1k: 0.4665 - val_lcm_f1_2k: 0.5034 - val_lcm_f1_3k: 0.4737 - val_lcm_f1_5k: 0.3948 - val_lcm_accuracy_1k: 0.6020 - val_lcm_accuracy_2k: 0.7426 - val_lcm_accuracy_3k: 0.8117 - val_lcm_accuracy_5k: 0.8730 - val_lcm_hamming_loss_k: 0.0039
Epoch 15/150
27/27 [==============================] - ETA: 0s - loss: 0.2278 - lcm_precision_1k: 0.6934 - lcm_precision_2k: 0.5419 - lcm_precision_3k: 0.4330 - lcm_precision_5k: 0.3041 - lcm_recall_1k: 0.4394 - lcm_recall_2k: 0.6401 - lcm_recall_3k: 0.7391 - lcm_recall_5k: 0.8360 - lcm_f1_1k: 0.5379 - lcm_f1_2k: 0.5868 - lcm_f1_3k: 0.5461 - lcm_f1_5k: 0.4460 - lcm_accuracy_1k: 0.6934 - lcm_accuracy_2k: 0.8395 - lcm_accuracy_3k: 0.8965 - lcm_accuracy_5k: 0.9436 - lcm_hamming_loss_k: 0.0036
Epoch 00015: val_loss improved from 0.27163 to 0.26956, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.2278 - lcm_precision_1k: 0.6934 - lcm_precision_2k: 0.5419 - lcm_precision_3k: 0.4330 - lcm_precision_5k: 0.3041 - lcm_recall_1k: 0.4394 - lcm_recall_2k: 0.6401 - lcm_recall_3k: 0.7391 - lcm_recall_5k: 0.8360 - lcm_f1_1k: 0.5379 - lcm_f1_2k: 0.5868 - lcm_f1_3k: 0.5461 - lcm_f1_5k: 0.4460 - lcm_accuracy_1k: 0.6934 - lcm_accuracy_2k: 0.8395 - lcm_accuracy_3k: 0.8965 - lcm_accuracy_5k: 0.9436 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2696 - val_lcm_precision_1k: 0.6034 - val_lcm_precision_2k: 0.4717 - val_lcm_precision_3k: 0.3796 - val_lcm_precision_5k: 0.2703 - val_lcm_recall_1k: 0.3829 - val_lcm_recall_2k: 0.5628 - val_lcm_recall_3k: 0.6577 - val_lcm_recall_5k: 0.7573 - val_lcm_f1_1k: 0.4684 - val_lcm_f1_2k: 0.5131 - val_lcm_f1_3k: 0.4812 - val_lcm_f1_5k: 0.3983 - val_lcm_accuracy_1k: 0.6034 - val_lcm_accuracy_2k: 0.7532 - val_lcm_accuracy_3k: 0.8217 - val_lcm_accuracy_5k: 0.8813 - val_lcm_hamming_loss_k: 0.0039
Epoch 16/150
27/27 [==============================] - ETA: 0s - loss: 0.2236 - lcm_precision_1k: 0.7065 - lcm_precision_2k: 0.5468 - lcm_precision_3k: 0.4377 - lcm_precision_5k: 0.3065 - lcm_recall_1k: 0.4504 - lcm_recall_2k: 0.6484 - lcm_recall_3k: 0.7492 - lcm_recall_5k: 0.8427 - lcm_f1_1k: 0.5500 - lcm_f1_2k: 0.5931 - lcm_f1_3k: 0.5525 - lcm_f1_5k: 0.4494 - lcm_accuracy_1k: 0.7065 - lcm_accuracy_2k: 0.8461 - lcm_accuracy_3k: 0.9017 - lcm_accuracy_5k: 0.9452 - lcm_hamming_loss_k: 0.0035
Epoch 00016: val_loss improved from 0.26956 to 0.26856, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 12s 430ms/step - loss: 0.2236 - lcm_precision_1k: 0.7065 - lcm_precision_2k: 0.5468 - lcm_precision_3k: 0.4377 - lcm_precision_5k: 0.3065 - lcm_recall_1k: 0.4504 - lcm_recall_2k: 0.6484 - lcm_recall_3k: 0.7492 - lcm_recall_5k: 0.8427 - lcm_f1_1k: 0.5500 - lcm_f1_2k: 0.5931 - lcm_f1_3k: 0.5525 - lcm_f1_5k: 0.4494 - lcm_accuracy_1k: 0.7065 - lcm_accuracy_2k: 0.8461 - lcm_accuracy_3k: 0.9017 - lcm_accuracy_5k: 0.9452 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2686 - val_lcm_precision_1k: 0.6029 - val_lcm_precision_2k: 0.4769 - val_lcm_precision_3k: 0.3820 - val_lcm_precision_5k: 0.2711 - val_lcm_recall_1k: 0.3821 - val_lcm_recall_2k: 0.5679 - val_lcm_recall_3k: 0.6613 - val_lcm_recall_5k: 0.7597 - val_lcm_f1_1k: 0.4676 - val_lcm_f1_2k: 0.5182 - val_lcm_f1_3k: 0.4840 - val_lcm_f1_5k: 0.3994 - val_lcm_accuracy_1k: 0.6029 - val_lcm_accuracy_2k: 0.7626 - val_lcm_accuracy_3k: 0.8273 - val_lcm_accuracy_5k: 0.8825 - val_lcm_hamming_loss_k: 0.0039
Epoch 17/150
27/27 [==============================] - ETA: 0s - loss: 0.2162 - lcm_precision_1k: 0.7220 - lcm_precision_2k: 0.5625 - lcm_precision_3k: 0.4487 - lcm_precision_5k: 0.3124 - lcm_recall_1k: 0.4589 - lcm_recall_2k: 0.6634 - lcm_recall_3k: 0.7631 - lcm_recall_5k: 0.8544 - lcm_f1_1k: 0.5610 - lcm_f1_2k: 0.6087 - lcm_f1_3k: 0.5651 - lcm_f1_5k: 0.4575 - lcm_accuracy_1k: 0.7220 - lcm_accuracy_2k: 0.8599 - lcm_accuracy_3k: 0.9132 - lcm_accuracy_5k: 0.9527 - lcm_hamming_loss_k: 0.0034
Epoch 00017: val_loss improved from 0.26856 to 0.26792, saving model to logs/bdkwrm-labs-0604-154515/model/checkpoint_labs.h5
27/27 [==============================] - 11s 429ms/step - loss: 0.2162 - lcm_precision_1k: 0.7220 - lcm_precision_2k: 0.5625 - lcm_precision_3k: 0.4487 - lcm_precision_5k: 0.3124 - lcm_recall_1k: 0.4589 - lcm_recall_2k: 0.6634 - lcm_recall_3k: 0.7631 - lcm_recall_5k: 0.8544 - lcm_f1_1k: 0.5610 - lcm_f1_2k: 0.6087 - lcm_f1_3k: 0.5651 - lcm_f1_5k: 0.4575 - lcm_accuracy_1k: 0.7220 - lcm_accuracy_2k: 0.8599 - lcm_accuracy_3k: 0.9132 - lcm_accuracy_5k: 0.9527 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2679 - val_lcm_precision_1k: 0.6076 - val_lcm_precision_2k: 0.4779 - val_lcm_precision_3k: 0.3833 - val_lcm_precision_5k: 0.2731 - val_lcm_recall_1k: 0.3839 - val_lcm_recall_2k: 0.5685 - val_lcm_recall_3k: 0.6646 - val_lcm_recall_5k: 0.7631 - val_lcm_f1_1k: 0.4704 - val_lcm_f1_2k: 0.5191 - val_lcm_f1_3k: 0.4860 - val_lcm_f1_5k: 0.4021 - val_lcm_accuracy_1k: 0.6076 - val_lcm_accuracy_2k: 0.7653 - val_lcm_accuracy_3k: 0.8303 - val_lcm_accuracy_5k: 0.8847 - val_lcm_hamming_loss_k: 0.0039
Epoch 18/150
27/27 [==============================] - ETA: 0s - loss: 0.2106 - lcm_precision_1k: 0.7286 - lcm_precision_2k: 0.5721 - lcm_precision_3k: 0.4553 - lcm_precision_5k: 0.3164 - lcm_recall_1k: 0.4647 - lcm_recall_2k: 0.6750 - lcm_recall_3k: 0.7751 - lcm_recall_5k: 0.8659 - lcm_f1_1k: 0.5674 - lcm_f1_2k: 0.6192 - lcm_f1_3k: 0.5736 - lcm_f1_5k: 0.4634 - lcm_accuracy_1k: 0.7286 - lcm_accuracy_2k: 0.8701 - lcm_accuracy_3k: 0.9206 - lcm_accuracy_5k: 0.9606 - lcm_hamming_loss_k: 0.0034
Epoch 00018: val_loss did not improve from 0.26792
27/27 [==============================] - 10s 389ms/step - loss: 0.2106 - lcm_precision_1k: 0.7286 - lcm_precision_2k: 0.5721 - lcm_precision_3k: 0.4553 - lcm_precision_5k: 0.3164 - lcm_recall_1k: 0.4647 - lcm_recall_2k: 0.6750 - lcm_recall_3k: 0.7751 - lcm_recall_5k: 0.8659 - lcm_f1_1k: 0.5674 - lcm_f1_2k: 0.6192 - lcm_f1_3k: 0.5736 - lcm_f1_5k: 0.4634 - lcm_accuracy_1k: 0.7286 - lcm_accuracy_2k: 0.8701 - lcm_accuracy_3k: 0.9206 - lcm_accuracy_5k: 0.9606 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2686 - val_lcm_precision_1k: 0.6006 - val_lcm_precision_2k: 0.4746 - val_lcm_precision_3k: 0.3813 - val_lcm_precision_5k: 0.2726 - val_lcm_recall_1k: 0.3837 - val_lcm_recall_2k: 0.5645 - val_lcm_recall_3k: 0.6601 - val_lcm_recall_5k: 0.7625 - val_lcm_f1_1k: 0.4682 - val_lcm_f1_2k: 0.5155 - val_lcm_f1_3k: 0.4832 - val_lcm_f1_5k: 0.4015 - val_lcm_accuracy_1k: 0.6006 - val_lcm_accuracy_2k: 0.7582 - val_lcm_accuracy_3k: 0.8242 - val_lcm_accuracy_5k: 0.8859 - val_lcm_hamming_loss_k: 0.0039
Epoch 19/150
27/27 [==============================] - ETA: 0s - loss: 0.2057 - lcm_precision_1k: 0.7470 - lcm_precision_2k: 0.5796 - lcm_precision_3k: 0.4619 - lcm_precision_5k: 0.3208 - lcm_recall_1k: 0.4774 - lcm_recall_2k: 0.6839 - lcm_recall_3k: 0.7847 - lcm_recall_5k: 0.8761 - lcm_f1_1k: 0.5824 - lcm_f1_2k: 0.6274 - lcm_f1_3k: 0.5814 - lcm_f1_5k: 0.4696 - lcm_accuracy_1k: 0.7470 - lcm_accuracy_2k: 0.8765 - lcm_accuracy_3k: 0.9270 - lcm_accuracy_5k: 0.9630 - lcm_hamming_loss_k: 0.0033 ETA: 5s - loss: 0.2044 - lcm_precision_1k: 0.7432 - lcm_precision_2k: 0.5813 - lcm_precision_3k: 0.4626 - lcm_precision_5k: 0.3220 - lcm_recall_1k: 0.4726 - lcm_recall_2k: 0.6832 - lcm_recall_3k: 0.7835 - lcm_recall_5k: 0.8774 - lcm_f1_1k: 0.5777 - lcm_f1_2k: 0.6280 - lcm_f1_3k: 0.5817 - lcm_f1_5k: 0.4710 - lcm_accuracy_1k: 0.7432 - lcm_accuracy_2k: 0.8738 - lcm_accuracy_3k: 0.9229 - lcm_accuracy_5k: 0
Epoch 00019: val_loss did not improve from 0.26792
27/27 [==============================] - 11s 391ms/step - loss: 0.2057 - lcm_precision_1k: 0.7470 - lcm_precision_2k: 0.5796 - lcm_precision_3k: 0.4619 - lcm_precision_5k: 0.3208 - lcm_recall_1k: 0.4774 - lcm_recall_2k: 0.6839 - lcm_recall_3k: 0.7847 - lcm_recall_5k: 0.8761 - lcm_f1_1k: 0.5824 - lcm_f1_2k: 0.6274 - lcm_f1_3k: 0.5814 - lcm_f1_5k: 0.4696 - lcm_accuracy_1k: 0.7470 - lcm_accuracy_2k: 0.8765 - lcm_accuracy_3k: 0.9270 - lcm_accuracy_5k: 0.9630 - lcm_hamming_loss_k: 0.0033 - val_loss: 0.2712 - val_lcm_precision_1k: 0.5997 - val_lcm_precision_2k: 0.4753 - val_lcm_precision_3k: 0.3810 - val_lcm_precision_5k: 0.2718 - val_lcm_recall_1k: 0.3782 - val_lcm_recall_2k: 0.5634 - val_lcm_recall_3k: 0.6566 - val_lcm_recall_5k: 0.7573 - val_lcm_f1_1k: 0.4637 - val_lcm_f1_2k: 0.5154 - val_lcm_f1_3k: 0.4820 - val_lcm_f1_5k: 0.3999 - val_lcm_accuracy_1k: 0.5997 - val_lcm_accuracy_2k: 0.7577 - val_lcm_accuracy_3k: 0.8199 - val_lcm_accuracy_5k: 0.8784 - val_lcm_hamming_loss_k: 0.0039
Epoch 00019: early stopping
176/176 [==============================] - 8s 41ms/step - loss: 0.2233 - lcm_precision_1k: 0.7037 - lcm_precision_2k: 0.5454 - lcm_precision_3k: 0.4339 - lcm_precision_5k: 0.3044 - lcm_recall_1k: 0.4518 - lcm_recall_2k: 0.6508 - lcm_recall_3k: 0.7474 - lcm_recall_5k: 0.8414 - lcm_f1_1k: 0.5489 - lcm_f1_2k: 0.5922 - lcm_f1_3k: 0.5480 - lcm_f1_5k: 0.4463 - lcm_accuracy_1k: 0.7037 - lcm_accuracy_2k: 0.8435 - lcm_accuracy_3k: 0.8978 - lcm_accuracy_5k: 0.9379 - lcm_hamming_loss_k: 0.0035 1s - loss: 0.2242 - lcm_precision_1k: 0.7048 - lcm_precision_2k: 0.5422 - lcm_precision_3k: 0.4316 - lcm_precision_5k: 0.3024 - lcm_recall_1k: 0.4542 - lcm_recall_2k: 0.6487 - lcm_recall_3k: 0.7459 - lcm_recall_5k: 0.8395 - lcm_f1_1k: 0.5511 - lcm_f1_2k: 0.5895 - lcm_f1_3k: 0.5458 - lcm_f1_5k: 0.4439 - lcm_accuracy_1k: 0.7048 - lcm_accuracy_2k: 0.8410 - lcm_accuracy_3k: 0.8964 - lcm_accuracy
Best model result:  [0.2232678234577179, 0.7036649584770203, 0.5454167127609253, 0.43392661213874817, 0.30443641543388367, 0.45175161957740784, 0.6507567763328552, 0.7474169135093689, 0.8413777947425842, 0.5489437580108643, 0.5922452211380005, 0.5480191111564636, 0.4463478922843933, 0.7036649584770203, 0.8435494899749756, 0.8978071212768555, 0.9378602504730225, 0.003489827271550894]
fold_result:  [[0.2351495921611786, 0.6821318864822388, 0.5252103209495544, 0.41941431164741516, 0.29490920901298523, 0.43692609667778015, 0.6267563104629517, 0.7237006425857544, 0.8177171349525452, 0.5313565731048584, 0.5702890753746033, 0.5300061702728271, 0.4327174425125122, 0.6821318864822388, 0.8198381066322327, 0.8755115270614624, 0.9235553741455078, 0.003590688342228532], [0.2315511703491211, 0.6888749599456787, 0.5300329923629761, 0.4263506233692169, 0.2978267967700958, 0.44189146161079407, 0.6321953535079956, 0.7340865731239319, 0.8264983892440796, 0.5371054410934448, 0.5753656625747681, 0.5383042693138123, 0.43711748719215393, 0.6888749599456787, 0.8271154761314392, 0.8824829459190369, 0.9305791258811951, 0.003559085540473461], [0.22648495435714722, 0.6945668458938599, 0.5365623831748962, 0.42980384826660156, 0.3001857399940491, 0.44912683963775635, 0.6403734087944031, 0.7404005527496338, 0.8325536251068115, 0.5442716479301453, 0.582755446434021, 0.5428469181060791, 0.44057610630989075, 0.6945668458938599, 0.8350805640220642, 0.8917677402496338, 0.9369733333587646, 0.0035324750933796167], [0.22354069352149963, 0.7108925580978394, 0.548035204410553, 0.43369653820991516, 0.3038966953754425, 0.45706480741500854, 0.6514612436294556, 0.7479154467582703, 0.8393032550811768, 0.5550901889801025, 0.5940709710121155, 0.5480197668075562, 0.44548937678337097, 0.7108925580978394, 0.8447465300559998, 0.8977096080780029, 0.9379380941390991, 0.0034559632185846567], [0.2232678234577179, 0.7036649584770203, 0.5454167127609253, 0.43392661213874817, 0.30443641543388367, 0.45175161957740784, 0.6507567763328552, 0.7474169135093689, 0.8413777947425842, 0.5489437580108643, 0.5922452211380005, 0.5480191111564636, 0.4463478922843933, 0.7036649584770203, 0.8435494899749756, 0.8978071212768555, 0.9378602504730225, 0.003489827271550894]]
average_result:  [0.22799884676933288, 0.6960262417793274, 0.537051522731781, 0.4286383867263794, 0.3002509713172913, 0.4473521649837494, 0.6403086185455322, 0.7387040257453918, 0.8314900398254395, 0.5433535218238831, 0.5829452753067017, 0.5414392471313476, 0.4404496610164642, 0.6960262417793274, 0.8340660333633423, 0.8890557885169983, 0.9333812355995178, 0.003525607893243432]
2024-06-04 15:49:00,607 : INFO : =======End=======
