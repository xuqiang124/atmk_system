/home/dzq/anaconda3/envs/k121/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/home/dzq/anaconda3/envs/k121/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). 
 The versions of TensorFlow you are currently using is 2.7.0 and is not supported. 
Some things might work, some things might not.
If you were to encounter a bug, do not file an issue.
If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. 
You can find the compatibility matrix in TensorFlow Addon's readme:
https://github.com/tensorflow/addons
  warnings.warn(
2024-06-04 15:12:55,736 : INFO : Loading config...
2024-06-04 15:12:55,737 : INFO : {'cache_file_h5py': '../file_data/a30/math_data_parse.h5', 'cache_file_pickle': '../file_data/a32/vocab_label.pkl', 'embeddings': '../file_data/a32/embeddings.pkl', 'maxlen': 150, 'emb_size': 300, 'epochs': 150, 'batch_size': 512, 'alpha': 4, 'hidden_size': 512, 'num_classes_list': [15, 427], 'l_patience': 2, 'b_patience': 3}
2024-06-04 15:12:55,737 : INFO : Loading data...
2024-06-04 15:12:56,451 : INFO : Loading embeddings...
2024-06-04 15:12:56,525 : INFO : model name labs
TOTAL: 22498 TRAIN: [[ 126    3 1315 ...    0    0    0]
 [  44    3   17 ...    0    0    0]
 [ 216    3   11 ...    0    0    0]
 ...
 [ 130    3   78 ...    0    0    0]
 [ 238    3  134 ...    0    0    0]
 [  59    3   78 ...    0    0    0]] 16873 TEST: [[ 105    3 1490 ...    0    0    0]
 [ 238    3 2235 ...    0    0    0]
 [ 172    3  134 ...    0    0    0]
 ...
 [ 161    3 2144 ...    0    0    0]
 [ 161    3 4753 ...    0    0    0]
 [ 189    3   17 ...    0    0    0]] 5625
2024-06-04 15:12:56,559 : INFO : =====Start final=====
13498
3375
5625
2024-06-04 15:12:56.991338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:12:57.014560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:12:57.014665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:12:57.014923: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-04 15:12:57.015919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:12:57.016033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:12:57.016089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:12:57.354169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:12:57.354290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:12:57.354361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 15:12:57.354431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22102 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem (Slic  (None, 15, 300)     0           ['label_emb[0][0]']              
 ingOpLambda)                                                                                     
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem[0][0]'
                                                                 ]                                
                                                                                                  
 permute (Permute)              (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda (Lambda)                (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute[0][0]']                
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda[0][0]']                 
 Dense)                                                                                           
                                                                                                  
 lambda_1 (Lambda)              (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean (TFOpLambd  (None, 1024)        0           ['BiLSTM[0][0]']                 
 a)                                                                                               
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_1[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 tf.concat (TFOpLambda)         (None, 2048)         0           ['tf.math.reduce_mean[0][0]',    
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense (Dense)                  (None, 1024)         2098176     ['tf.concat[0][0]']              
                                                                                                  
 dense_1 (Dense)                (None, 15)           15375       ['dense[0][0]']                  
                                                                                                  
 tf.nn.softmax (TFOpLambda)     (None, 15)           0           ['dense_1[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 15, 1)        0           ['tf.nn.softmax[0][0]']          
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims[0][0]']         
 (Dense)                                                                                          
                                                                                                  
 permute_1 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_2 (Lambda)              (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_1[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 15, 150)      22650       ['lambda_2[0][0]']               
                                                                                                  
 tf.math.reduce_mean_1 (TFOpLam  (None, 150)         0           ['dense_2[0][0]']                
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_1 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_1[0][0]']  
                                                                                                  
 tf.__operators__.getitem_1 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 tf.math.multiply (TFOpLambda)  (None, 150, 1024)    0           ['BiLSTM[0][0]',                 
                                                                  'tf.expand_dims_1[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_1[0][0
                                                                 ]']                              
                                                                                                  
 permute_2 (Permute)            (None, 1024, 150)    0           ['tf.math.multiply[0][0]']       
                                                                                                  
 lambda_3 (Lambda)              (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_2[0][0]']              
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_3[0][0]']               
 Dense)                                                                                           
                                                                                                  
 lambda_4 (Lambda)              (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply[0][0]']       
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_4[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
==================================================================================================
Total params: 31,474,320
Trainable params: 6,695,820
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
2 patience
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem (Slic  (None, 15, 300)     0           ['label_emb[0][0]']              
 ingOpLambda)                                                                                     
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem[0][0]'
                                                                 ]                                
                                                                                                  
 permute (Permute)              (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda (Lambda)                (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute[0][0]']                
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda[0][0]']                 
 Dense)                                                                                           
                                                                                                  
 lambda_1 (Lambda)              (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean (TFOpLambd  (None, 1024)        0           ['BiLSTM[0][0]']                 
 a)                                                                                               
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_1[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 tf.concat (TFOpLambda)         (None, 2048)         0           ['tf.math.reduce_mean[0][0]',    
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense (Dense)                  (None, 1024)         2098176     ['tf.concat[0][0]']              
                                                                                                  
 dense_1 (Dense)                (None, 15)           15375       ['dense[0][0]']                  
                                                                                                  
 tf.nn.softmax (TFOpLambda)     (None, 15)           0           ['dense_1[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 15, 1)        0           ['tf.nn.softmax[0][0]']          
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims[0][0]']         
 (Dense)                                                                                          
                                                                                                  
 permute_1 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_2 (Lambda)              (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_1[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 15, 150)      22650       ['lambda_2[0][0]']               
                                                                                                  
 tf.math.reduce_mean_1 (TFOpLam  (None, 150)         0           ['dense_2[0][0]']                
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_1 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_1[0][0]']  
                                                                                                  
 tf.__operators__.getitem_1 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 tf.math.multiply (TFOpLambda)  (None, 150, 1024)    0           ['BiLSTM[0][0]',                 
                                                                  'tf.expand_dims_1[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_1[0][0
                                                                 ]']                              
                                                                                                  
 permute_2 (Permute)            (None, 1024, 150)    0           ['tf.math.multiply[0][0]']       
                                                                                                  
 lambda_3 (Lambda)              (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_2[0][0]']              
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_3[0][0]']               
 Dense)                                                                                           
                                                                                                  
 lambda_4 (Lambda)              (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply[0][0]']       
                                                                                                  
 tf.__operators__.getitem_2 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_4[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 label_lcm_emb (Dense)          (None, 427, 1024)    308224      ['tf.__operators__.getitem_2[0][0
                                                                 ]']                              
                                                                                                  
 dot (Dot)                      (None, 427)          0           ['label_lcm_emb[0][0]',          
                                                                  '1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 label_sim_dict (Dense)         (None, 427)          182756      ['dot[0][0]']                    
                                                                                                  
 concatenate (Concatenate)      (None, 854)          0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 31,965,300
Trainable params: 7,186,800
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
Epoch 1/150
2024-06-04 15:13:00.846349: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2024-06-04 15:13:00.880171: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8906
27/27 [==============================] - ETA: 0s - loss: 0.4886 - lcm_precision_1k: 0.1881 - lcm_precision_2k: 0.1667 - lcm_precision_3k: 0.1491 - lcm_precision_5k: 0.1231 - lcm_recall_1k: 0.1019 - lcm_recall_2k: 0.1804 - lcm_recall_3k: 0.2415 - lcm_recall_5k: 0.3276 - lcm_f1_1k: 0.1320 - lcm_f1_2k: 0.1731 - lcm_f1_3k: 0.1843 - lcm_f1_5k: 0.1790 - lcm_accuracy_1k: 0.1881 - lcm_accuracy_2k: 0.2951 - lcm_accuracy_3k: 0.3715 - lcm_accuracy_5k: 0.4682 - lcm_hamming_loss_k: 0.0059
Epoch 00001: val_loss improved from inf to 0.41720, saving model to logs/aqfzeo-labs-0604-151256/model/checkpoint_labs.h5
27/27 [==============================] - 14s 419ms/step - loss: 0.4886 - lcm_precision_1k: 0.1881 - lcm_precision_2k: 0.1667 - lcm_precision_3k: 0.1491 - lcm_precision_5k: 0.1231 - lcm_recall_1k: 0.1019 - lcm_recall_2k: 0.1804 - lcm_recall_3k: 0.2415 - lcm_recall_5k: 0.3276 - lcm_f1_1k: 0.1320 - lcm_f1_2k: 0.1731 - lcm_f1_3k: 0.1843 - lcm_f1_5k: 0.1790 - lcm_accuracy_1k: 0.1881 - lcm_accuracy_2k: 0.2951 - lcm_accuracy_3k: 0.3715 - lcm_accuracy_5k: 0.4682 - lcm_hamming_loss_k: 0.0059 - val_loss: 0.4172 - val_lcm_precision_1k: 0.3040 - val_lcm_precision_2k: 0.2579 - val_lcm_precision_3k: 0.2187 - val_lcm_precision_5k: 0.1707 - val_lcm_recall_1k: 0.1792 - val_lcm_recall_2k: 0.2963 - val_lcm_recall_3k: 0.3717 - val_lcm_recall_5k: 0.4714 - val_lcm_f1_1k: 0.2253 - val_lcm_f1_2k: 0.2757 - val_lcm_f1_3k: 0.2753 - val_lcm_f1_5k: 0.2505 - val_lcm_accuracy_1k: 0.3040 - val_lcm_accuracy_2k: 0.4531 - val_lcm_accuracy_3k: 0.5413 - val_lcm_accuracy_5k: 0.6337 - val_lcm_hamming_loss_k: 0.0053
Epoch 2/150
27/27 [==============================] - ETA: 0s - loss: 0.3655 - lcm_precision_1k: 0.4047 - lcm_precision_2k: 0.3346 - lcm_precision_3k: 0.2829 - lcm_precision_5k: 0.2178 - lcm_recall_1k: 0.2394 - lcm_recall_2k: 0.3802 - lcm_recall_3k: 0.4719 - lcm_recall_5k: 0.5908 - lcm_f1_1k: 0.3008 - lcm_f1_2k: 0.3559 - lcm_f1_3k: 0.3537 - lcm_f1_5k: 0.3182 - lcm_accuracy_1k: 0.4047 - lcm_accuracy_2k: 0.5621 - lcm_accuracy_3k: 0.6470 - lcm_accuracy_5k: 0.7413 - lcm_hamming_loss_k: 0.0049
Epoch 00002: val_loss improved from 0.41720 to 0.34112, saving model to logs/aqfzeo-labs-0604-151256/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.3655 - lcm_precision_1k: 0.4047 - lcm_precision_2k: 0.3346 - lcm_precision_3k: 0.2829 - lcm_precision_5k: 0.2178 - lcm_recall_1k: 0.2394 - lcm_recall_2k: 0.3802 - lcm_recall_3k: 0.4719 - lcm_recall_5k: 0.5908 - lcm_f1_1k: 0.3008 - lcm_f1_2k: 0.3559 - lcm_f1_3k: 0.3537 - lcm_f1_5k: 0.3182 - lcm_accuracy_1k: 0.4047 - lcm_accuracy_2k: 0.5621 - lcm_accuracy_3k: 0.6470 - lcm_accuracy_5k: 0.7413 - lcm_hamming_loss_k: 0.0049 - val_loss: 0.3411 - val_lcm_precision_1k: 0.4517 - val_lcm_precision_2k: 0.3640 - val_lcm_precision_3k: 0.3018 - val_lcm_precision_5k: 0.2268 - val_lcm_recall_1k: 0.2802 - val_lcm_recall_2k: 0.4280 - val_lcm_recall_3k: 0.5213 - val_lcm_recall_5k: 0.6344 - val_lcm_f1_1k: 0.3458 - val_lcm_f1_2k: 0.3932 - val_lcm_f1_3k: 0.3821 - val_lcm_f1_5k: 0.3341 - val_lcm_accuracy_1k: 0.4517 - val_lcm_accuracy_2k: 0.6124 - val_lcm_accuracy_3k: 0.6979 - val_lcm_accuracy_5k: 0.7832 - val_lcm_hamming_loss_k: 0.0046
Epoch 3/150
27/27 [==============================] - ETA: 0s - loss: 0.3156 - lcm_precision_1k: 0.5051 - lcm_precision_2k: 0.4056 - lcm_precision_3k: 0.3348 - lcm_precision_5k: 0.2487 - lcm_recall_1k: 0.3062 - lcm_recall_2k: 0.4669 - lcm_recall_3k: 0.5652 - lcm_recall_5k: 0.6802 - lcm_f1_1k: 0.3812 - lcm_f1_2k: 0.4341 - lcm_f1_3k: 0.4204 - lcm_f1_5k: 0.3642 - lcm_accuracy_1k: 0.5051 - lcm_accuracy_2k: 0.6632 - lcm_accuracy_3k: 0.7413 - lcm_accuracy_5k: 0.8238 - lcm_hamming_loss_k: 0.0045 ETA: 1s - loss: 0.3167 - lcm_precision_1k: 0.5003 - lcm_precision_2k: 0.4028 - lcm_precision_3k: 0.3325 - lcm_precision_5k: 0.2473 - lcm_recall_1k: 0.3042 - lcm_recall_2k: 0.4650 - lcm_recall_3k: 0.5629 - lcm_recall_5k: 0.6775 - lcm_f1_1k: 0.3783 - lcm_f1_2k: 0.4316 - lcm_f1_3k: 0.4180 - lcm_f1_5k: 0.3623 - lcm_accuracy_1k: 0.5003 - lcm_accuracy_2k: 0.6615 - lcm_accuracy_3k: 0.7394 - lcm_accuracy_5k: 0.8212 - lcm_hamming_loss_k
Epoch 00003: val_loss improved from 0.34112 to 0.31915, saving model to logs/aqfzeo-labs-0604-151256/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.3156 - lcm_precision_1k: 0.5051 - lcm_precision_2k: 0.4056 - lcm_precision_3k: 0.3348 - lcm_precision_5k: 0.2487 - lcm_recall_1k: 0.3062 - lcm_recall_2k: 0.4669 - lcm_recall_3k: 0.5652 - lcm_recall_5k: 0.6802 - lcm_f1_1k: 0.3812 - lcm_f1_2k: 0.4341 - lcm_f1_3k: 0.4204 - lcm_f1_5k: 0.3642 - lcm_accuracy_1k: 0.5051 - lcm_accuracy_2k: 0.6632 - lcm_accuracy_3k: 0.7413 - lcm_accuracy_5k: 0.8238 - lcm_hamming_loss_k: 0.0045 - val_loss: 0.3191 - val_lcm_precision_1k: 0.5055 - val_lcm_precision_2k: 0.4004 - val_lcm_precision_3k: 0.3266 - val_lcm_precision_5k: 0.2395 - val_lcm_recall_1k: 0.3121 - val_lcm_recall_2k: 0.4715 - val_lcm_recall_3k: 0.5643 - val_lcm_recall_5k: 0.6697 - val_lcm_f1_1k: 0.3858 - val_lcm_f1_2k: 0.4329 - val_lcm_f1_3k: 0.4136 - val_lcm_f1_5k: 0.3527 - val_lcm_accuracy_1k: 0.5055 - val_lcm_accuracy_2k: 0.6601 - val_lcm_accuracy_3k: 0.7390 - val_lcm_accuracy_5k: 0.8170 - val_lcm_hamming_loss_k: 0.0044
Epoch 4/150
27/27 [==============================] - ETA: 0s - loss: 0.2941 - lcm_precision_1k: 0.5582 - lcm_precision_2k: 0.4426 - lcm_precision_3k: 0.3617 - lcm_precision_5k: 0.2638 - lcm_recall_1k: 0.3452 - lcm_recall_2k: 0.5158 - lcm_recall_3k: 0.6142 - lcm_recall_5k: 0.7239 - lcm_f1_1k: 0.4265 - lcm_f1_2k: 0.4763 - lcm_f1_3k: 0.4552 - lcm_f1_5k: 0.3867 - lcm_accuracy_1k: 0.5582 - lcm_accuracy_2k: 0.7139 - lcm_accuracy_3k: 0.7887 - lcm_accuracy_5k: 0.8606 - lcm_hamming_loss_k: 0.0042
Epoch 00004: val_loss improved from 0.31915 to 0.30457, saving model to logs/aqfzeo-labs-0604-151256/model/checkpoint_labs.h5
27/27 [==============================] - 11s 424ms/step - loss: 0.2941 - lcm_precision_1k: 0.5582 - lcm_precision_2k: 0.4426 - lcm_precision_3k: 0.3617 - lcm_precision_5k: 0.2638 - lcm_recall_1k: 0.3452 - lcm_recall_2k: 0.5158 - lcm_recall_3k: 0.6142 - lcm_recall_5k: 0.7239 - lcm_f1_1k: 0.4265 - lcm_f1_2k: 0.4763 - lcm_f1_3k: 0.4552 - lcm_f1_5k: 0.3867 - lcm_accuracy_1k: 0.5582 - lcm_accuracy_2k: 0.7139 - lcm_accuracy_3k: 0.7887 - lcm_accuracy_5k: 0.8606 - lcm_hamming_loss_k: 0.0042 - val_loss: 0.3046 - val_lcm_precision_1k: 0.5175 - val_lcm_precision_2k: 0.4164 - val_lcm_precision_3k: 0.3437 - val_lcm_precision_5k: 0.2505 - val_lcm_recall_1k: 0.3229 - val_lcm_recall_2k: 0.4932 - val_lcm_recall_3k: 0.5968 - val_lcm_recall_5k: 0.7027 - val_lcm_f1_1k: 0.3975 - val_lcm_f1_2k: 0.4515 - val_lcm_f1_3k: 0.4361 - val_lcm_f1_5k: 0.3693 - val_lcm_accuracy_1k: 0.5175 - val_lcm_accuracy_2k: 0.6831 - val_lcm_accuracy_3k: 0.7712 - val_lcm_accuracy_5k: 0.8438 - val_lcm_hamming_loss_k: 0.0043
Epoch 5/150
27/27 [==============================] - ETA: 0s - loss: 0.2793 - lcm_precision_1k: 0.5868 - lcm_precision_2k: 0.4614 - lcm_precision_3k: 0.3782 - lcm_precision_5k: 0.2745 - lcm_recall_1k: 0.3646 - lcm_recall_2k: 0.5395 - lcm_recall_3k: 0.6446 - lcm_recall_5k: 0.7545 - lcm_f1_1k: 0.4496 - lcm_f1_2k: 0.4973 - lcm_f1_3k: 0.4767 - lcm_f1_5k: 0.4025 - lcm_accuracy_1k: 0.5868 - lcm_accuracy_2k: 0.7412 - lcm_accuracy_3k: 0.8180 - lcm_accuracy_5k: 0.8852 - lcm_hamming_loss_k: 0.0041
Epoch 00005: val_loss improved from 0.30457 to 0.29955, saving model to logs/aqfzeo-labs-0604-151256/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2793 - lcm_precision_1k: 0.5868 - lcm_precision_2k: 0.4614 - lcm_precision_3k: 0.3782 - lcm_precision_5k: 0.2745 - lcm_recall_1k: 0.3646 - lcm_recall_2k: 0.5395 - lcm_recall_3k: 0.6446 - lcm_recall_5k: 0.7545 - lcm_f1_1k: 0.4496 - lcm_f1_2k: 0.4973 - lcm_f1_3k: 0.4767 - lcm_f1_5k: 0.4025 - lcm_accuracy_1k: 0.5868 - lcm_accuracy_2k: 0.7412 - lcm_accuracy_3k: 0.8180 - lcm_accuracy_5k: 0.8852 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2996 - val_lcm_precision_1k: 0.5394 - val_lcm_precision_2k: 0.4356 - val_lcm_precision_3k: 0.3524 - val_lcm_precision_5k: 0.2538 - val_lcm_recall_1k: 0.3397 - val_lcm_recall_2k: 0.5184 - val_lcm_recall_3k: 0.6130 - val_lcm_recall_5k: 0.7142 - val_lcm_f1_1k: 0.4167 - val_lcm_f1_2k: 0.4733 - val_lcm_f1_3k: 0.4474 - val_lcm_f1_5k: 0.3744 - val_lcm_accuracy_1k: 0.5394 - val_lcm_accuracy_2k: 0.7075 - val_lcm_accuracy_3k: 0.7839 - val_lcm_accuracy_5k: 0.8553 - val_lcm_hamming_loss_k: 0.0042
Epoch 6/150
27/27 [==============================] - ETA: 0s - loss: 0.2682 - lcm_precision_1k: 0.6152 - lcm_precision_2k: 0.4834 - lcm_precision_3k: 0.3916 - lcm_precision_5k: 0.2813 - lcm_recall_1k: 0.3840 - lcm_recall_2k: 0.5666 - lcm_recall_3k: 0.6673 - lcm_recall_5k: 0.7715 - lcm_f1_1k: 0.4728 - lcm_f1_2k: 0.5217 - lcm_f1_3k: 0.4935 - lcm_f1_5k: 0.4122 - lcm_accuracy_1k: 0.6152 - lcm_accuracy_2k: 0.7680 - lcm_accuracy_3k: 0.8377 - lcm_accuracy_5k: 0.8965 - lcm_hamming_loss_k: 0.0039
Epoch 00006: val_loss improved from 0.29955 to 0.29117, saving model to logs/aqfzeo-labs-0604-151256/model/checkpoint_labs.h5
27/27 [==============================] - 11s 424ms/step - loss: 0.2682 - lcm_precision_1k: 0.6152 - lcm_precision_2k: 0.4834 - lcm_precision_3k: 0.3916 - lcm_precision_5k: 0.2813 - lcm_recall_1k: 0.3840 - lcm_recall_2k: 0.5666 - lcm_recall_3k: 0.6673 - lcm_recall_5k: 0.7715 - lcm_f1_1k: 0.4728 - lcm_f1_2k: 0.5217 - lcm_f1_3k: 0.4935 - lcm_f1_5k: 0.4122 - lcm_accuracy_1k: 0.6152 - lcm_accuracy_2k: 0.7680 - lcm_accuracy_3k: 0.8377 - lcm_accuracy_5k: 0.8965 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2912 - val_lcm_precision_1k: 0.5554 - val_lcm_precision_2k: 0.4474 - val_lcm_precision_3k: 0.3618 - val_lcm_precision_5k: 0.2589 - val_lcm_recall_1k: 0.3471 - val_lcm_recall_2k: 0.5315 - val_lcm_recall_3k: 0.6286 - val_lcm_recall_5k: 0.7274 - val_lcm_f1_1k: 0.4271 - val_lcm_f1_2k: 0.4857 - val_lcm_f1_3k: 0.4591 - val_lcm_f1_5k: 0.3818 - val_lcm_accuracy_1k: 0.5554 - val_lcm_accuracy_2k: 0.7201 - val_lcm_accuracy_3k: 0.7993 - val_lcm_accuracy_5k: 0.8613 - val_lcm_hamming_loss_k: 0.0041
Epoch 7/150
27/27 [==============================] - ETA: 0s - loss: 0.2580 - lcm_precision_1k: 0.6336 - lcm_precision_2k: 0.4975 - lcm_precision_3k: 0.4039 - lcm_precision_5k: 0.2884 - lcm_recall_1k: 0.3950 - lcm_recall_2k: 0.5853 - lcm_recall_3k: 0.6890 - lcm_recall_5k: 0.7906 - lcm_f1_1k: 0.4865 - lcm_f1_2k: 0.5377 - lcm_f1_3k: 0.5091 - lcm_f1_5k: 0.4225 - lcm_accuracy_1k: 0.6336 - lcm_accuracy_2k: 0.7871 - lcm_accuracy_3k: 0.8567 - lcm_accuracy_5k: 0.9113 - lcm_hamming_loss_k: 0.0039
Epoch 00007: val_loss improved from 0.29117 to 0.28659, saving model to logs/aqfzeo-labs-0604-151256/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.2580 - lcm_precision_1k: 0.6336 - lcm_precision_2k: 0.4975 - lcm_precision_3k: 0.4039 - lcm_precision_5k: 0.2884 - lcm_recall_1k: 0.3950 - lcm_recall_2k: 0.5853 - lcm_recall_3k: 0.6890 - lcm_recall_5k: 0.7906 - lcm_f1_1k: 0.4865 - lcm_f1_2k: 0.5377 - lcm_f1_3k: 0.5091 - lcm_f1_5k: 0.4225 - lcm_accuracy_1k: 0.6336 - lcm_accuracy_2k: 0.7871 - lcm_accuracy_3k: 0.8567 - lcm_accuracy_5k: 0.9113 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2866 - val_lcm_precision_1k: 0.5575 - val_lcm_precision_2k: 0.4462 - val_lcm_precision_3k: 0.3649 - val_lcm_precision_5k: 0.2607 - val_lcm_recall_1k: 0.3528 - val_lcm_recall_2k: 0.5296 - val_lcm_recall_3k: 0.6339 - val_lcm_recall_5k: 0.7321 - val_lcm_f1_1k: 0.4320 - val_lcm_f1_2k: 0.4842 - val_lcm_f1_3k: 0.4630 - val_lcm_f1_5k: 0.3844 - val_lcm_accuracy_1k: 0.5575 - val_lcm_accuracy_2k: 0.7216 - val_lcm_accuracy_3k: 0.8083 - val_lcm_accuracy_5k: 0.8673 - val_lcm_hamming_loss_k: 0.0041
Epoch 8/150
27/27 [==============================] - ETA: 0s - loss: 0.2508 - lcm_precision_1k: 0.6478 - lcm_precision_2k: 0.5095 - lcm_precision_3k: 0.4130 - lcm_precision_5k: 0.2945 - lcm_recall_1k: 0.4072 - lcm_recall_2k: 0.5991 - lcm_recall_3k: 0.7037 - lcm_recall_5k: 0.8073 - lcm_f1_1k: 0.5000 - lcm_f1_2k: 0.5506 - lcm_f1_3k: 0.5204 - lcm_f1_5k: 0.4315 - lcm_accuracy_1k: 0.6478 - lcm_accuracy_2k: 0.8018 - lcm_accuracy_3k: 0.8671 - lcm_accuracy_5k: 0.9225 - lcm_hamming_loss_k: 0.0038
Epoch 00008: val_loss improved from 0.28659 to 0.28639, saving model to logs/aqfzeo-labs-0604-151256/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.2508 - lcm_precision_1k: 0.6478 - lcm_precision_2k: 0.5095 - lcm_precision_3k: 0.4130 - lcm_precision_5k: 0.2945 - lcm_recall_1k: 0.4072 - lcm_recall_2k: 0.5991 - lcm_recall_3k: 0.7037 - lcm_recall_5k: 0.8073 - lcm_f1_1k: 0.5000 - lcm_f1_2k: 0.5506 - lcm_f1_3k: 0.5204 - lcm_f1_5k: 0.4315 - lcm_accuracy_1k: 0.6478 - lcm_accuracy_2k: 0.8018 - lcm_accuracy_3k: 0.8671 - lcm_accuracy_5k: 0.9225 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2864 - val_lcm_precision_1k: 0.5701 - val_lcm_precision_2k: 0.4545 - val_lcm_precision_3k: 0.3659 - val_lcm_precision_5k: 0.2617 - val_lcm_recall_1k: 0.3614 - val_lcm_recall_2k: 0.5450 - val_lcm_recall_3k: 0.6377 - val_lcm_recall_5k: 0.7356 - val_lcm_f1_1k: 0.4422 - val_lcm_f1_2k: 0.4955 - val_lcm_f1_3k: 0.4649 - val_lcm_f1_5k: 0.3860 - val_lcm_accuracy_1k: 0.5701 - val_lcm_accuracy_2k: 0.7354 - val_lcm_accuracy_3k: 0.8064 - val_lcm_accuracy_5k: 0.8675 - val_lcm_hamming_loss_k: 0.0041
Epoch 9/150
27/27 [==============================] - ETA: 0s - loss: 0.2437 - lcm_precision_1k: 0.6685 - lcm_precision_2k: 0.5221 - lcm_precision_3k: 0.4224 - lcm_precision_5k: 0.2982 - lcm_recall_1k: 0.4216 - lcm_recall_2k: 0.6153 - lcm_recall_3k: 0.7199 - lcm_recall_5k: 0.8177 - lcm_f1_1k: 0.5169 - lcm_f1_2k: 0.5648 - lcm_f1_3k: 0.5323 - lcm_f1_5k: 0.4370 - lcm_accuracy_1k: 0.6685 - lcm_accuracy_2k: 0.8170 - lcm_accuracy_3k: 0.8796 - lcm_accuracy_5k: 0.9283 - lcm_hamming_loss_k: 0.0037 ETA: 6s - loss: 0.2421 - lcm_precision_1k: 0.6738 - lcm_precision_2k: 0.5298 - lcm_precision_3k: 0.4325 - lcm_precision_5k: 0.3029 - lcm_recall_1k: 0.4195 - lcm_recall_2k: 0.6161 - lcm_recall_3k: 0.7289 - lcm_recall_5k: 0.8241 - lcm_f1_1k: 0.5170 - lcm_f1_2k: 0.5696 - lcm_f1_3k: 0.5429 - lcm_f1_5k: 0.4430 - lcm_accuracy_1k: 0.6738 - lcm_accuracy_2k: 0.8180 - lcm_accuracy_3k: 0.8825 - lcm_accura
Epoch 00009: val_loss improved from 0.28639 to 0.27845, saving model to logs/aqfzeo-labs-0604-151256/model/checkpoint_labs.h5
27/27 [==============================] - 11s 424ms/step - loss: 0.2437 - lcm_precision_1k: 0.6685 - lcm_precision_2k: 0.5221 - lcm_precision_3k: 0.4224 - lcm_precision_5k: 0.2982 - lcm_recall_1k: 0.4216 - lcm_recall_2k: 0.6153 - lcm_recall_3k: 0.7199 - lcm_recall_5k: 0.8177 - lcm_f1_1k: 0.5169 - lcm_f1_2k: 0.5648 - lcm_f1_3k: 0.5323 - lcm_f1_5k: 0.4370 - lcm_accuracy_1k: 0.6685 - lcm_accuracy_2k: 0.8170 - lcm_accuracy_3k: 0.8796 - lcm_accuracy_5k: 0.9283 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2784 - val_lcm_precision_1k: 0.5772 - val_lcm_precision_2k: 0.4616 - val_lcm_precision_3k: 0.3725 - val_lcm_precision_5k: 0.2643 - val_lcm_recall_1k: 0.3647 - val_lcm_recall_2k: 0.5522 - val_lcm_recall_3k: 0.6486 - val_lcm_recall_5k: 0.7431 - val_lcm_f1_1k: 0.4468 - val_lcm_f1_2k: 0.5027 - val_lcm_f1_3k: 0.4731 - val_lcm_f1_5k: 0.3898 - val_lcm_accuracy_1k: 0.5772 - val_lcm_accuracy_2k: 0.7447 - val_lcm_accuracy_3k: 0.8172 - val_lcm_accuracy_5k: 0.8724 - val_lcm_hamming_loss_k: 0.0040
Epoch 10/150
27/27 [==============================] - ETA: 0s - loss: 0.2350 - lcm_precision_1k: 0.6841 - lcm_precision_2k: 0.5347 - lcm_precision_3k: 0.4308 - lcm_precision_5k: 0.3052 - lcm_recall_1k: 0.4315 - lcm_recall_2k: 0.6273 - lcm_recall_3k: 0.7316 - lcm_recall_5k: 0.8335 - lcm_f1_1k: 0.5291 - lcm_f1_2k: 0.5772 - lcm_f1_3k: 0.5422 - lcm_f1_5k: 0.4467 - lcm_accuracy_1k: 0.6841 - lcm_accuracy_2k: 0.8294 - lcm_accuracy_3k: 0.8892 - lcm_accuracy_5k: 0.9396 - lcm_hamming_loss_k: 0.0036
Epoch 00010: val_loss improved from 0.27845 to 0.27755, saving model to logs/aqfzeo-labs-0604-151256/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2350 - lcm_precision_1k: 0.6841 - lcm_precision_2k: 0.5347 - lcm_precision_3k: 0.4308 - lcm_precision_5k: 0.3052 - lcm_recall_1k: 0.4315 - lcm_recall_2k: 0.6273 - lcm_recall_3k: 0.7316 - lcm_recall_5k: 0.8335 - lcm_f1_1k: 0.5291 - lcm_f1_2k: 0.5772 - lcm_f1_3k: 0.5422 - lcm_f1_5k: 0.4467 - lcm_accuracy_1k: 0.6841 - lcm_accuracy_2k: 0.8294 - lcm_accuracy_3k: 0.8892 - lcm_accuracy_5k: 0.9396 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2775 - val_lcm_precision_1k: 0.5791 - val_lcm_precision_2k: 0.4639 - val_lcm_precision_3k: 0.3751 - val_lcm_precision_5k: 0.2675 - val_lcm_recall_1k: 0.3673 - val_lcm_recall_2k: 0.5566 - val_lcm_recall_3k: 0.6540 - val_lcm_recall_5k: 0.7514 - val_lcm_f1_1k: 0.4494 - val_lcm_f1_2k: 0.5059 - val_lcm_f1_3k: 0.4766 - val_lcm_f1_5k: 0.3945 - val_lcm_accuracy_1k: 0.5791 - val_lcm_accuracy_2k: 0.7512 - val_lcm_accuracy_3k: 0.8198 - val_lcm_accuracy_5k: 0.8824 - val_lcm_hamming_loss_k: 0.0040
Epoch 11/150
27/27 [==============================] - ETA: 0s - loss: 0.2286 - lcm_precision_1k: 0.6989 - lcm_precision_2k: 0.5455 - lcm_precision_3k: 0.4379 - lcm_precision_5k: 0.3087 - lcm_recall_1k: 0.4429 - lcm_recall_2k: 0.6434 - lcm_recall_3k: 0.7466 - lcm_recall_5k: 0.8452 - lcm_f1_1k: 0.5422 - lcm_f1_2k: 0.5903 - lcm_f1_3k: 0.5519 - lcm_f1_5k: 0.4522 - lcm_accuracy_1k: 0.6989 - lcm_accuracy_2k: 0.8444 - lcm_accuracy_3k: 0.9029 - lcm_accuracy_5k: 0.9474 - lcm_hamming_loss_k: 0.0036
Epoch 00011: val_loss improved from 0.27755 to 0.27415, saving model to logs/aqfzeo-labs-0604-151256/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.2286 - lcm_precision_1k: 0.6989 - lcm_precision_2k: 0.5455 - lcm_precision_3k: 0.4379 - lcm_precision_5k: 0.3087 - lcm_recall_1k: 0.4429 - lcm_recall_2k: 0.6434 - lcm_recall_3k: 0.7466 - lcm_recall_5k: 0.8452 - lcm_f1_1k: 0.5422 - lcm_f1_2k: 0.5903 - lcm_f1_3k: 0.5519 - lcm_f1_5k: 0.4522 - lcm_accuracy_1k: 0.6989 - lcm_accuracy_2k: 0.8444 - lcm_accuracy_3k: 0.9029 - lcm_accuracy_5k: 0.9474 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2742 - val_lcm_precision_1k: 0.5941 - val_lcm_precision_2k: 0.4674 - val_lcm_precision_3k: 0.3770 - val_lcm_precision_5k: 0.2658 - val_lcm_recall_1k: 0.3767 - val_lcm_recall_2k: 0.5587 - val_lcm_recall_3k: 0.6560 - val_lcm_recall_5k: 0.7474 - val_lcm_f1_1k: 0.4610 - val_lcm_f1_2k: 0.5089 - val_lcm_f1_3k: 0.4787 - val_lcm_f1_5k: 0.3921 - val_lcm_accuracy_1k: 0.5941 - val_lcm_accuracy_2k: 0.7525 - val_lcm_accuracy_3k: 0.8229 - val_lcm_accuracy_5k: 0.8765 - val_lcm_hamming_loss_k: 0.0040
Epoch 12/150
27/27 [==============================] - ETA: 0s - loss: 0.2222 - lcm_precision_1k: 0.7116 - lcm_precision_2k: 0.5562 - lcm_precision_3k: 0.4458 - lcm_precision_5k: 0.3126 - lcm_recall_1k: 0.4519 - lcm_recall_2k: 0.6555 - lcm_recall_3k: 0.7589 - lcm_recall_5k: 0.8552 - lcm_f1_1k: 0.5527 - lcm_f1_2k: 0.6017 - lcm_f1_3k: 0.5616 - lcm_f1_5k: 0.4578 - lcm_accuracy_1k: 0.7116 - lcm_accuracy_2k: 0.8551 - lcm_accuracy_3k: 0.9111 - lcm_accuracy_5k: 0.9532 - lcm_hamming_loss_k: 0.0035 ETA: 7s - loss: 0.2180 - lcm_precision_1k: 0.7339 - lcm_precision_2k: 0.5605 - lcm_precision_3k: 0.4474 - lcm_precision_5k: 0.3124 - lcm_recall_1k: 0.4746 - lcm_recall_2k: 0.6675 - lcm_recall_3k: 0.7685 - lcm_recall_5k: 0.8597 - lcm_f1_1k: 0.5764 - lcm_f1_2k: 0.6094 - lcm_f1_3k: 0.5656 - lcm_f1_5k: 0.4583 - lcm_accuracy_1k: 0.7339 - lcm_accuracy_2k: 0.8647 - lcm_accuracy_3k: 0.9224 - lcm_ac
Epoch 00012: val_loss improved from 0.27415 to 0.27101, saving model to logs/aqfzeo-labs-0604-151256/model/checkpoint_labs.h5
27/27 [==============================] - 11s 429ms/step - loss: 0.2222 - lcm_precision_1k: 0.7116 - lcm_precision_2k: 0.5562 - lcm_precision_3k: 0.4458 - lcm_precision_5k: 0.3126 - lcm_recall_1k: 0.4519 - lcm_recall_2k: 0.6555 - lcm_recall_3k: 0.7589 - lcm_recall_5k: 0.8552 - lcm_f1_1k: 0.5527 - lcm_f1_2k: 0.6017 - lcm_f1_3k: 0.5616 - lcm_f1_5k: 0.4578 - lcm_accuracy_1k: 0.7116 - lcm_accuracy_2k: 0.8551 - lcm_accuracy_3k: 0.9111 - lcm_accuracy_5k: 0.9532 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2710 - val_lcm_precision_1k: 0.6035 - val_lcm_precision_2k: 0.4751 - val_lcm_precision_3k: 0.3812 - val_lcm_precision_5k: 0.2701 - val_lcm_recall_1k: 0.3834 - val_lcm_recall_2k: 0.5692 - val_lcm_recall_3k: 0.6647 - val_lcm_recall_5k: 0.7579 - val_lcm_f1_1k: 0.4688 - val_lcm_f1_2k: 0.5178 - val_lcm_f1_3k: 0.4844 - val_lcm_f1_5k: 0.3981 - val_lcm_accuracy_1k: 0.6035 - val_lcm_accuracy_2k: 0.7637 - val_lcm_accuracy_3k: 0.8302 - val_lcm_accuracy_5k: 0.8857 - val_lcm_hamming_loss_k: 0.0039
Epoch 13/150
27/27 [==============================] - ETA: 0s - loss: 0.2157 - lcm_precision_1k: 0.7244 - lcm_precision_2k: 0.5670 - lcm_precision_3k: 0.4543 - lcm_precision_5k: 0.3180 - lcm_recall_1k: 0.4600 - lcm_recall_2k: 0.6668 - lcm_recall_3k: 0.7712 - lcm_recall_5k: 0.8665 - lcm_f1_1k: 0.5626 - lcm_f1_2k: 0.6128 - lcm_f1_3k: 0.5717 - lcm_f1_5k: 0.4652 - lcm_accuracy_1k: 0.7244 - lcm_accuracy_2k: 0.8660 - lcm_accuracy_3k: 0.9205 - lcm_accuracy_5k: 0.9592 - lcm_hamming_loss_k: 0.0034
Epoch 00013: val_loss did not improve from 0.27101
27/27 [==============================] - 10s 389ms/step - loss: 0.2157 - lcm_precision_1k: 0.7244 - lcm_precision_2k: 0.5670 - lcm_precision_3k: 0.4543 - lcm_precision_5k: 0.3180 - lcm_recall_1k: 0.4600 - lcm_recall_2k: 0.6668 - lcm_recall_3k: 0.7712 - lcm_recall_5k: 0.8665 - lcm_f1_1k: 0.5626 - lcm_f1_2k: 0.6128 - lcm_f1_3k: 0.5717 - lcm_f1_5k: 0.4652 - lcm_accuracy_1k: 0.7244 - lcm_accuracy_2k: 0.8660 - lcm_accuracy_3k: 0.9205 - lcm_accuracy_5k: 0.9592 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2732 - val_lcm_precision_1k: 0.5964 - val_lcm_precision_2k: 0.4788 - val_lcm_precision_3k: 0.3828 - val_lcm_precision_5k: 0.2714 - val_lcm_recall_1k: 0.3760 - val_lcm_recall_2k: 0.5718 - val_lcm_recall_3k: 0.6669 - val_lcm_recall_5k: 0.7612 - val_lcm_f1_1k: 0.4611 - val_lcm_f1_2k: 0.5211 - val_lcm_f1_3k: 0.4863 - val_lcm_f1_5k: 0.4001 - val_lcm_accuracy_1k: 0.5964 - val_lcm_accuracy_2k: 0.7625 - val_lcm_accuracy_3k: 0.8323 - val_lcm_accuracy_5k: 0.8880 - val_lcm_hamming_loss_k: 0.0040
Epoch 14/150
27/27 [==============================] - ETA: 0s - loss: 0.2082 - lcm_precision_1k: 0.7457 - lcm_precision_2k: 0.5800 - lcm_precision_3k: 0.4633 - lcm_precision_5k: 0.3221 - lcm_recall_1k: 0.4735 - lcm_recall_2k: 0.6809 - lcm_recall_3k: 0.7840 - lcm_recall_5k: 0.8760 - lcm_f1_1k: 0.5791 - lcm_f1_2k: 0.6263 - lcm_f1_3k: 0.5824 - lcm_f1_5k: 0.4710 - lcm_accuracy_1k: 0.7457 - lcm_accuracy_2k: 0.8778 - lcm_accuracy_3k: 0.9264 - lcm_accuracy_5k: 0.9629 - lcm_hamming_loss_k: 0.0033
Epoch 00014: val_loss did not improve from 0.27101
27/27 [==============================] - 11s 391ms/step - loss: 0.2082 - lcm_precision_1k: 0.7457 - lcm_precision_2k: 0.5800 - lcm_precision_3k: 0.4633 - lcm_precision_5k: 0.3221 - lcm_recall_1k: 0.4735 - lcm_recall_2k: 0.6809 - lcm_recall_3k: 0.7840 - lcm_recall_5k: 0.8760 - lcm_f1_1k: 0.5791 - lcm_f1_2k: 0.6263 - lcm_f1_3k: 0.5824 - lcm_f1_5k: 0.4710 - lcm_accuracy_1k: 0.7457 - lcm_accuracy_2k: 0.8778 - lcm_accuracy_3k: 0.9264 - lcm_accuracy_5k: 0.9629 - lcm_hamming_loss_k: 0.0033 - val_loss: 0.2711 - val_lcm_precision_1k: 0.5952 - val_lcm_precision_2k: 0.4761 - val_lcm_precision_3k: 0.3823 - val_lcm_precision_5k: 0.2704 - val_lcm_recall_1k: 0.3756 - val_lcm_recall_2k: 0.5668 - val_lcm_recall_3k: 0.6629 - val_lcm_recall_5k: 0.7598 - val_lcm_f1_1k: 0.4604 - val_lcm_f1_2k: 0.5173 - val_lcm_f1_3k: 0.4848 - val_lcm_f1_5k: 0.3988 - val_lcm_accuracy_1k: 0.5952 - val_lcm_accuracy_2k: 0.7583 - val_lcm_accuracy_3k: 0.8289 - val_lcm_accuracy_5k: 0.8855 - val_lcm_hamming_loss_k: 0.0040
Epoch 00014: early stopping
176/176 [==============================] - 8s 42ms/step - loss: 0.2375 - lcm_precision_1k: 0.6823 - lcm_precision_2k: 0.5284 - lcm_precision_3k: 0.4207 - lcm_precision_5k: 0.2974 - lcm_recall_1k: 0.4323 - lcm_recall_2k: 0.6266 - lcm_recall_3k: 0.7230 - lcm_recall_5k: 0.8223 - lcm_f1_1k: 0.5280 - lcm_f1_2k: 0.5722 - lcm_f1_3k: 0.5309 - lcm_f1_5k: 0.4362 - lcm_accuracy_1k: 0.6823 - lcm_accuracy_2k: 0.8223 - lcm_accuracy_3k: 0.8785 - lcm_accuracy_5k: 0.9269 - lcm_hamming_loss_k: 0.0036
Best model result:  [0.23745344579219818, 0.6823062300682068, 0.5284346342086792, 0.4207136929035187, 0.2974296510219574, 0.4322556257247925, 0.626583456993103, 0.7229995131492615, 0.8222770690917969, 0.5279738903045654, 0.57217937707901, 0.5309174656867981, 0.43615010380744934, 0.6823062300682068, 0.8223247528076172, 0.8785291910171509, 0.9268772602081299, 0.0035898564383387566]
13498
3375
5625
Model: "model_2"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_3 (Sl  (None, 15, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_3[0][0
                                                                 ]']                              
                                                                                                  
 permute_3 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_5 (Lambda)              (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_3[0][0]']              
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_5[0][0]']               
 Dense)                                                                                           
                                                                                                  
 lambda_6 (Lambda)              (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_2 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_6[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_1 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_2[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_3 (Dense)                (None, 1024)         2098176     ['tf.concat_1[0][0]']            
                                                                                                  
 dense_4 (Dense)                (None, 15)           15375       ['dense_3[0][0]']                
                                                                                                  
 tf.nn.softmax_1 (TFOpLambda)   (None, 15)           0           ['dense_4[0][0]']                
                                                                                                  
 tf.expand_dims_2 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_1[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_2[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_4 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_7 (Lambda)              (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_4[0][0]']              
                                                                                                  
 dense_5 (Dense)                (None, 15, 150)      22650       ['lambda_7[0][0]']               
                                                                                                  
 tf.math.reduce_mean_3 (TFOpLam  (None, 150)         0           ['dense_5[0][0]']                
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_3 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_3[0][0]']  
                                                                                                  
 tf.__operators__.getitem_4 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 tf.math.multiply_1 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_3[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_4[0][0
                                                                 ]']                              
                                                                                                  
 permute_5 (Permute)            (None, 1024, 150)    0           ['tf.math.multiply_1[0][0]']     
                                                                                                  
 lambda_8 (Lambda)              (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_5[0][0]']              
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_8[0][0]']               
 Dense)                                                                                           
                                                                                                  
 lambda_9 (Lambda)              (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_1[0][0]']     
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_9[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
==================================================================================================
Total params: 31,474,320
Trainable params: 6,695,820
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
2 patience
Model: "model_3"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_3 (Sl  (None, 15, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_3[0][0
                                                                 ]']                              
                                                                                                  
 permute_3 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_5 (Lambda)              (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_3[0][0]']              
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_5[0][0]']               
 Dense)                                                                                           
                                                                                                  
 lambda_6 (Lambda)              (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_2 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_6[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_1 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_2[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_3 (Dense)                (None, 1024)         2098176     ['tf.concat_1[0][0]']            
                                                                                                  
 dense_4 (Dense)                (None, 15)           15375       ['dense_3[0][0]']                
                                                                                                  
 tf.nn.softmax_1 (TFOpLambda)   (None, 15)           0           ['dense_4[0][0]']                
                                                                                                  
 tf.expand_dims_2 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_1[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_2[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_4 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_7 (Lambda)              (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_4[0][0]']              
                                                                                                  
 dense_5 (Dense)                (None, 15, 150)      22650       ['lambda_7[0][0]']               
                                                                                                  
 tf.math.reduce_mean_3 (TFOpLam  (None, 150)         0           ['dense_5[0][0]']                
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_3 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_3[0][0]']  
                                                                                                  
 tf.__operators__.getitem_4 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 tf.math.multiply_1 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_3[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_4[0][0
                                                                 ]']                              
                                                                                                  
 permute_5 (Permute)            (None, 1024, 150)    0           ['tf.math.multiply_1[0][0]']     
                                                                                                  
 lambda_8 (Lambda)              (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_5[0][0]']              
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_8[0][0]']               
 Dense)                                                                                           
                                                                                                  
 lambda_9 (Lambda)              (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_1[0][0]']     
                                                                                                  
 tf.__operators__.getitem_5 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_9[0][0]']               
 (Lambda)                                                                                         
                                                                                                  
 label_lcm_emb (Dense)          (None, 427, 1024)    308224      ['tf.__operators__.getitem_5[0][0
                                                                 ]']                              
                                                                                                  
 dot_1 (Dot)                    (None, 427)          0           ['label_lcm_emb[0][0]',          
                                                                  '1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 label_sim_dict (Dense)         (None, 427)          182756      ['dot_1[0][0]']                  
                                                                                                  
 concatenate_1 (Concatenate)    (None, 854)          0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 31,965,300
Trainable params: 7,186,800
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
Epoch 1/150
27/27 [==============================] - ETA: 0s - loss: 0.4917 - lcm_precision_1k: 0.1505 - lcm_precision_2k: 0.1578 - lcm_precision_3k: 0.1447 - lcm_precision_5k: 0.1194 - lcm_recall_1k: 0.0813 - lcm_recall_2k: 0.1742 - lcm_recall_3k: 0.2389 - lcm_recall_5k: 0.3217 - lcm_f1_1k: 0.1054 - lcm_f1_2k: 0.1655 - lcm_f1_3k: 0.1802 - lcm_f1_5k: 0.1742 - lcm_accuracy_1k: 0.1505 - lcm_accuracy_2k: 0.2889 - lcm_accuracy_3k: 0.3650 - lcm_accuracy_5k: 0.4562 - lcm_hamming_loss_k: 0.0061
Epoch 00001: val_loss improved from inf to 0.42356, saving model to logs/ozfhtp-labs-0604-151547/model/checkpoint_labs.h5
27/27 [==============================] - 13s 416ms/step - loss: 0.4917 - lcm_precision_1k: 0.1505 - lcm_precision_2k: 0.1578 - lcm_precision_3k: 0.1447 - lcm_precision_5k: 0.1194 - lcm_recall_1k: 0.0813 - lcm_recall_2k: 0.1742 - lcm_recall_3k: 0.2389 - lcm_recall_5k: 0.3217 - lcm_f1_1k: 0.1054 - lcm_f1_2k: 0.1655 - lcm_f1_3k: 0.1802 - lcm_f1_5k: 0.1742 - lcm_accuracy_1k: 0.1505 - lcm_accuracy_2k: 0.2889 - lcm_accuracy_3k: 0.3650 - lcm_accuracy_5k: 0.4562 - lcm_hamming_loss_k: 0.0061 - val_loss: 0.4236 - val_lcm_precision_1k: 0.2910 - val_lcm_precision_2k: 0.2498 - val_lcm_precision_3k: 0.2178 - val_lcm_precision_5k: 0.1832 - val_lcm_recall_1k: 0.1783 - val_lcm_recall_2k: 0.2862 - val_lcm_recall_3k: 0.3676 - val_lcm_recall_5k: 0.4944 - val_lcm_f1_1k: 0.2209 - val_lcm_f1_2k: 0.2666 - val_lcm_f1_3k: 0.2734 - val_lcm_f1_5k: 0.2672 - val_lcm_accuracy_1k: 0.2910 - val_lcm_accuracy_2k: 0.4361 - val_lcm_accuracy_3k: 0.5247 - val_lcm_accuracy_5k: 0.6528 - val_lcm_hamming_loss_k: 0.0055
Epoch 2/150
27/27 [==============================] - ETA: 0s - loss: 0.3680 - lcm_precision_1k: 0.4032 - lcm_precision_2k: 0.3331 - lcm_precision_3k: 0.2799 - lcm_precision_5k: 0.2153 - lcm_recall_1k: 0.2405 - lcm_recall_2k: 0.3810 - lcm_recall_3k: 0.4703 - lcm_recall_5k: 0.5862 - lcm_f1_1k: 0.3012 - lcm_f1_2k: 0.3554 - lcm_f1_3k: 0.3508 - lcm_f1_5k: 0.3149 - lcm_accuracy_1k: 0.4032 - lcm_accuracy_2k: 0.5591 - lcm_accuracy_3k: 0.6458 - lcm_accuracy_5k: 0.7388 - lcm_hamming_loss_k: 0.0049
Epoch 00002: val_loss improved from 0.42356 to 0.33920, saving model to logs/ozfhtp-labs-0604-151547/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.3680 - lcm_precision_1k: 0.4032 - lcm_precision_2k: 0.3331 - lcm_precision_3k: 0.2799 - lcm_precision_5k: 0.2153 - lcm_recall_1k: 0.2405 - lcm_recall_2k: 0.3810 - lcm_recall_3k: 0.4703 - lcm_recall_5k: 0.5862 - lcm_f1_1k: 0.3012 - lcm_f1_2k: 0.3554 - lcm_f1_3k: 0.3508 - lcm_f1_5k: 0.3149 - lcm_accuracy_1k: 0.4032 - lcm_accuracy_2k: 0.5591 - lcm_accuracy_3k: 0.6458 - lcm_accuracy_5k: 0.7388 - lcm_hamming_loss_k: 0.0049 - val_loss: 0.3392 - val_lcm_precision_1k: 0.4661 - val_lcm_precision_2k: 0.3715 - val_lcm_precision_3k: 0.3093 - val_lcm_precision_5k: 0.2360 - val_lcm_recall_1k: 0.2823 - val_lcm_recall_2k: 0.4298 - val_lcm_recall_3k: 0.5242 - val_lcm_recall_5k: 0.6454 - val_lcm_f1_1k: 0.3514 - val_lcm_f1_2k: 0.3984 - val_lcm_f1_3k: 0.3889 - val_lcm_f1_5k: 0.3455 - val_lcm_accuracy_1k: 0.4661 - val_lcm_accuracy_2k: 0.6186 - val_lcm_accuracy_3k: 0.7040 - val_lcm_accuracy_5k: 0.7982 - val_lcm_hamming_loss_k: 0.0047
Epoch 3/150
27/27 [==============================] - ETA: 0s - loss: 0.3159 - lcm_precision_1k: 0.5001 - lcm_precision_2k: 0.4001 - lcm_precision_3k: 0.3302 - lcm_precision_5k: 0.2468 - lcm_recall_1k: 0.3048 - lcm_recall_2k: 0.4633 - lcm_recall_3k: 0.5616 - lcm_recall_5k: 0.6801 - lcm_f1_1k: 0.3787 - lcm_f1_2k: 0.4293 - lcm_f1_3k: 0.4158 - lcm_f1_5k: 0.3622 - lcm_accuracy_1k: 0.5001 - lcm_accuracy_2k: 0.6574 - lcm_accuracy_3k: 0.7410 - lcm_accuracy_5k: 0.8242 - lcm_hamming_loss_k: 0.0045
Epoch 00003: val_loss improved from 0.33920 to 0.31757, saving model to logs/ozfhtp-labs-0604-151547/model/checkpoint_labs.h5
27/27 [==============================] - 11s 423ms/step - loss: 0.3159 - lcm_precision_1k: 0.5001 - lcm_precision_2k: 0.4001 - lcm_precision_3k: 0.3302 - lcm_precision_5k: 0.2468 - lcm_recall_1k: 0.3048 - lcm_recall_2k: 0.4633 - lcm_recall_3k: 0.5616 - lcm_recall_5k: 0.6801 - lcm_f1_1k: 0.3787 - lcm_f1_2k: 0.4293 - lcm_f1_3k: 0.4158 - lcm_f1_5k: 0.3622 - lcm_accuracy_1k: 0.5001 - lcm_accuracy_2k: 0.6574 - lcm_accuracy_3k: 0.7410 - lcm_accuracy_5k: 0.8242 - lcm_hamming_loss_k: 0.0045 - val_loss: 0.3176 - val_lcm_precision_1k: 0.5161 - val_lcm_precision_2k: 0.4137 - val_lcm_precision_3k: 0.3387 - val_lcm_precision_5k: 0.2491 - val_lcm_recall_1k: 0.3129 - val_lcm_recall_2k: 0.4742 - val_lcm_recall_3k: 0.5713 - val_lcm_recall_5k: 0.6800 - val_lcm_f1_1k: 0.3894 - val_lcm_f1_2k: 0.4417 - val_lcm_f1_3k: 0.4251 - val_lcm_f1_5k: 0.3645 - val_lcm_accuracy_1k: 0.5161 - val_lcm_accuracy_2k: 0.6670 - val_lcm_accuracy_3k: 0.7498 - val_lcm_accuracy_5k: 0.8236 - val_lcm_hamming_loss_k: 0.0044
Epoch 4/150
27/27 [==============================] - ETA: 0s - loss: 0.2942 - lcm_precision_1k: 0.5486 - lcm_precision_2k: 0.4355 - lcm_precision_3k: 0.3583 - lcm_precision_5k: 0.2623 - lcm_recall_1k: 0.3398 - lcm_recall_2k: 0.5089 - lcm_recall_3k: 0.6122 - lcm_recall_5k: 0.7225 - lcm_f1_1k: 0.4196 - lcm_f1_2k: 0.4692 - lcm_f1_3k: 0.4519 - lcm_f1_5k: 0.3848 - lcm_accuracy_1k: 0.5486 - lcm_accuracy_2k: 0.7058 - lcm_accuracy_3k: 0.7875 - lcm_accuracy_5k: 0.8591 - lcm_hamming_loss_k: 0.0042
Epoch 00004: val_loss improved from 0.31757 to 0.30361, saving model to logs/ozfhtp-labs-0604-151547/model/checkpoint_labs.h5
27/27 [==============================] - 11s 424ms/step - loss: 0.2942 - lcm_precision_1k: 0.5486 - lcm_precision_2k: 0.4355 - lcm_precision_3k: 0.3583 - lcm_precision_5k: 0.2623 - lcm_recall_1k: 0.3398 - lcm_recall_2k: 0.5089 - lcm_recall_3k: 0.6122 - lcm_recall_5k: 0.7225 - lcm_f1_1k: 0.4196 - lcm_f1_2k: 0.4692 - lcm_f1_3k: 0.4519 - lcm_f1_5k: 0.3848 - lcm_accuracy_1k: 0.5486 - lcm_accuracy_2k: 0.7058 - lcm_accuracy_3k: 0.7875 - lcm_accuracy_5k: 0.8591 - lcm_hamming_loss_k: 0.0042 - val_loss: 0.3036 - val_lcm_precision_1k: 0.5340 - val_lcm_precision_2k: 0.4337 - val_lcm_precision_3k: 0.3558 - val_lcm_precision_5k: 0.2577 - val_lcm_recall_1k: 0.3251 - val_lcm_recall_2k: 0.5019 - val_lcm_recall_3k: 0.6025 - val_lcm_recall_5k: 0.7073 - val_lcm_f1_1k: 0.4039 - val_lcm_f1_2k: 0.4651 - val_lcm_f1_3k: 0.4472 - val_lcm_f1_5k: 0.3776 - val_lcm_accuracy_1k: 0.5340 - val_lcm_accuracy_2k: 0.7055 - val_lcm_accuracy_3k: 0.7844 - val_lcm_accuracy_5k: 0.8504 - val_lcm_hamming_loss_k: 0.0043
Epoch 5/150
27/27 [==============================] - ETA: 0s - loss: 0.2806 - lcm_precision_1k: 0.5811 - lcm_precision_2k: 0.4585 - lcm_precision_3k: 0.3752 - lcm_precision_5k: 0.2729 - lcm_recall_1k: 0.3633 - lcm_recall_2k: 0.5389 - lcm_recall_3k: 0.6411 - lcm_recall_5k: 0.7524 - lcm_f1_1k: 0.4470 - lcm_f1_2k: 0.4954 - lcm_f1_3k: 0.4733 - lcm_f1_5k: 0.4005 - lcm_accuracy_1k: 0.5811 - lcm_accuracy_2k: 0.7363 - lcm_accuracy_3k: 0.8142 - lcm_accuracy_5k: 0.8827 - lcm_hamming_loss_k: 0.0041
Epoch 00005: val_loss improved from 0.30361 to 0.29635, saving model to logs/ozfhtp-labs-0604-151547/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2806 - lcm_precision_1k: 0.5811 - lcm_precision_2k: 0.4585 - lcm_precision_3k: 0.3752 - lcm_precision_5k: 0.2729 - lcm_recall_1k: 0.3633 - lcm_recall_2k: 0.5389 - lcm_recall_3k: 0.6411 - lcm_recall_5k: 0.7524 - lcm_f1_1k: 0.4470 - lcm_f1_2k: 0.4954 - lcm_f1_3k: 0.4733 - lcm_f1_5k: 0.4005 - lcm_accuracy_1k: 0.5811 - lcm_accuracy_2k: 0.7363 - lcm_accuracy_3k: 0.8142 - lcm_accuracy_5k: 0.8827 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2963 - val_lcm_precision_1k: 0.5650 - val_lcm_precision_2k: 0.4536 - val_lcm_precision_3k: 0.3654 - val_lcm_precision_5k: 0.2633 - val_lcm_recall_1k: 0.3456 - val_lcm_recall_2k: 0.5286 - val_lcm_recall_3k: 0.6211 - val_lcm_recall_5k: 0.7221 - val_lcm_f1_1k: 0.4287 - val_lcm_f1_2k: 0.4881 - val_lcm_f1_3k: 0.4599 - val_lcm_f1_5k: 0.3857 - val_lcm_accuracy_1k: 0.5650 - val_lcm_accuracy_2k: 0.7249 - val_lcm_accuracy_3k: 0.7924 - val_lcm_accuracy_5k: 0.8586 - val_lcm_hamming_loss_k: 0.0042
Epoch 6/150
27/27 [==============================] - ETA: 0s - loss: 0.2689 - lcm_precision_1k: 0.6051 - lcm_precision_2k: 0.4787 - lcm_precision_3k: 0.3892 - lcm_precision_5k: 0.2804 - lcm_recall_1k: 0.3791 - lcm_recall_2k: 0.5641 - lcm_recall_3k: 0.6671 - lcm_recall_5k: 0.7746 - lcm_f1_1k: 0.4661 - lcm_f1_2k: 0.5179 - lcm_f1_3k: 0.4916 - lcm_f1_5k: 0.4118 - lcm_accuracy_1k: 0.6051 - lcm_accuracy_2k: 0.7634 - lcm_accuracy_3k: 0.8375 - lcm_accuracy_5k: 0.8991 - lcm_hamming_loss_k: 0.0040
Epoch 00006: val_loss improved from 0.29635 to 0.29455, saving model to logs/ozfhtp-labs-0604-151547/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2689 - lcm_precision_1k: 0.6051 - lcm_precision_2k: 0.4787 - lcm_precision_3k: 0.3892 - lcm_precision_5k: 0.2804 - lcm_recall_1k: 0.3791 - lcm_recall_2k: 0.5641 - lcm_recall_3k: 0.6671 - lcm_recall_5k: 0.7746 - lcm_f1_1k: 0.4661 - lcm_f1_2k: 0.5179 - lcm_f1_3k: 0.4916 - lcm_f1_5k: 0.4118 - lcm_accuracy_1k: 0.6051 - lcm_accuracy_2k: 0.7634 - lcm_accuracy_3k: 0.8375 - lcm_accuracy_5k: 0.8991 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2945 - val_lcm_precision_1k: 0.5744 - val_lcm_precision_2k: 0.4545 - val_lcm_precision_3k: 0.3691 - val_lcm_precision_5k: 0.2656 - val_lcm_recall_1k: 0.3544 - val_lcm_recall_2k: 0.5309 - val_lcm_recall_3k: 0.6305 - val_lcm_recall_5k: 0.7303 - val_lcm_f1_1k: 0.4383 - val_lcm_f1_2k: 0.4895 - val_lcm_f1_3k: 0.4655 - val_lcm_f1_5k: 0.3894 - val_lcm_accuracy_1k: 0.5744 - val_lcm_accuracy_2k: 0.7356 - val_lcm_accuracy_3k: 0.8081 - val_lcm_accuracy_5k: 0.8665 - val_lcm_hamming_loss_k: 0.0041
Epoch 7/150
27/27 [==============================] - ETA: 0s - loss: 0.2593 - lcm_precision_1k: 0.6284 - lcm_precision_2k: 0.4926 - lcm_precision_3k: 0.3986 - lcm_precision_5k: 0.2868 - lcm_recall_1k: 0.3942 - lcm_recall_2k: 0.5804 - lcm_recall_3k: 0.6824 - lcm_recall_5k: 0.7915 - lcm_f1_1k: 0.4844 - lcm_f1_2k: 0.5329 - lcm_f1_3k: 0.5032 - lcm_f1_5k: 0.4210 - lcm_accuracy_1k: 0.6284 - lcm_accuracy_2k: 0.7823 - lcm_accuracy_3k: 0.8515 - lcm_accuracy_5k: 0.9121 - lcm_hamming_loss_k: 0.0039
Epoch 00007: val_loss improved from 0.29455 to 0.28746, saving model to logs/ozfhtp-labs-0604-151547/model/checkpoint_labs.h5
27/27 [==============================] - 11s 424ms/step - loss: 0.2593 - lcm_precision_1k: 0.6284 - lcm_precision_2k: 0.4926 - lcm_precision_3k: 0.3986 - lcm_precision_5k: 0.2868 - lcm_recall_1k: 0.3942 - lcm_recall_2k: 0.5804 - lcm_recall_3k: 0.6824 - lcm_recall_5k: 0.7915 - lcm_f1_1k: 0.4844 - lcm_f1_2k: 0.5329 - lcm_f1_3k: 0.5032 - lcm_f1_5k: 0.4210 - lcm_accuracy_1k: 0.6284 - lcm_accuracy_2k: 0.7823 - lcm_accuracy_3k: 0.8515 - lcm_accuracy_5k: 0.9121 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2875 - val_lcm_precision_1k: 0.5903 - val_lcm_precision_2k: 0.4661 - val_lcm_precision_3k: 0.3759 - val_lcm_precision_5k: 0.2696 - val_lcm_recall_1k: 0.3654 - val_lcm_recall_2k: 0.5457 - val_lcm_recall_3k: 0.6423 - val_lcm_recall_5k: 0.7410 - val_lcm_f1_1k: 0.4512 - val_lcm_f1_2k: 0.5026 - val_lcm_f1_3k: 0.4741 - val_lcm_f1_5k: 0.3952 - val_lcm_accuracy_1k: 0.5903 - val_lcm_accuracy_2k: 0.7487 - val_lcm_accuracy_3k: 0.8209 - val_lcm_accuracy_5k: 0.8743 - val_lcm_hamming_loss_k: 0.0041
Epoch 8/150
27/27 [==============================] - ETA: 0s - loss: 0.2511 - lcm_precision_1k: 0.6444 - lcm_precision_2k: 0.5070 - lcm_precision_3k: 0.4104 - lcm_precision_5k: 0.2929 - lcm_recall_1k: 0.4060 - lcm_recall_2k: 0.5990 - lcm_recall_3k: 0.7043 - lcm_recall_5k: 0.8090 - lcm_f1_1k: 0.4980 - lcm_f1_2k: 0.5490 - lcm_f1_3k: 0.5185 - lcm_f1_5k: 0.4301 - lcm_accuracy_1k: 0.6444 - lcm_accuracy_2k: 0.7994 - lcm_accuracy_3k: 0.8679 - lcm_accuracy_5k: 0.9235 - lcm_hamming_loss_k: 0.0038
Epoch 00008: val_loss improved from 0.28746 to 0.28506, saving model to logs/ozfhtp-labs-0604-151547/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.2511 - lcm_precision_1k: 0.6444 - lcm_precision_2k: 0.5070 - lcm_precision_3k: 0.4104 - lcm_precision_5k: 0.2929 - lcm_recall_1k: 0.4060 - lcm_recall_2k: 0.5990 - lcm_recall_3k: 0.7043 - lcm_recall_5k: 0.8090 - lcm_f1_1k: 0.4980 - lcm_f1_2k: 0.5490 - lcm_f1_3k: 0.5185 - lcm_f1_5k: 0.4301 - lcm_accuracy_1k: 0.6444 - lcm_accuracy_2k: 0.7994 - lcm_accuracy_3k: 0.8679 - lcm_accuracy_5k: 0.9235 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2851 - val_lcm_precision_1k: 0.6000 - val_lcm_precision_2k: 0.4703 - val_lcm_precision_3k: 0.3795 - val_lcm_precision_5k: 0.2697 - val_lcm_recall_1k: 0.3716 - val_lcm_recall_2k: 0.5529 - val_lcm_recall_3k: 0.6467 - val_lcm_recall_5k: 0.7436 - val_lcm_f1_1k: 0.4588 - val_lcm_f1_2k: 0.5081 - val_lcm_f1_3k: 0.4782 - val_lcm_f1_5k: 0.3957 - val_lcm_accuracy_1k: 0.6000 - val_lcm_accuracy_2k: 0.7548 - val_lcm_accuracy_3k: 0.8213 - val_lcm_accuracy_5k: 0.8782 - val_lcm_hamming_loss_k: 0.0040
Epoch 9/150
27/27 [==============================] - ETA: 0s - loss: 0.2435 - lcm_precision_1k: 0.6577 - lcm_precision_2k: 0.5191 - lcm_precision_3k: 0.4186 - lcm_precision_5k: 0.2984 - lcm_recall_1k: 0.4156 - lcm_recall_2k: 0.6143 - lcm_recall_3k: 0.7172 - lcm_recall_5k: 0.8231 - lcm_f1_1k: 0.5093 - lcm_f1_2k: 0.5626 - lcm_f1_3k: 0.5286 - lcm_f1_5k: 0.4379 - lcm_accuracy_1k: 0.6577 - lcm_accuracy_2k: 0.8164 - lcm_accuracy_3k: 0.8817 - lcm_accuracy_5k: 0.9339 - lcm_hamming_loss_k: 0.0037
Epoch 00009: val_loss improved from 0.28506 to 0.28455, saving model to logs/ozfhtp-labs-0604-151547/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.2435 - lcm_precision_1k: 0.6577 - lcm_precision_2k: 0.5191 - lcm_precision_3k: 0.4186 - lcm_precision_5k: 0.2984 - lcm_recall_1k: 0.4156 - lcm_recall_2k: 0.6143 - lcm_recall_3k: 0.7172 - lcm_recall_5k: 0.8231 - lcm_f1_1k: 0.5093 - lcm_f1_2k: 0.5626 - lcm_f1_3k: 0.5286 - lcm_f1_5k: 0.4379 - lcm_accuracy_1k: 0.6577 - lcm_accuracy_2k: 0.8164 - lcm_accuracy_3k: 0.8817 - lcm_accuracy_5k: 0.9339 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2846 - val_lcm_precision_1k: 0.5965 - val_lcm_precision_2k: 0.4679 - val_lcm_precision_3k: 0.3795 - val_lcm_precision_5k: 0.2717 - val_lcm_recall_1k: 0.3721 - val_lcm_recall_2k: 0.5502 - val_lcm_recall_3k: 0.6498 - val_lcm_recall_5k: 0.7483 - val_lcm_f1_1k: 0.4581 - val_lcm_f1_2k: 0.5055 - val_lcm_f1_3k: 0.4789 - val_lcm_f1_5k: 0.3984 - val_lcm_accuracy_1k: 0.5965 - val_lcm_accuracy_2k: 0.7486 - val_lcm_accuracy_3k: 0.8234 - val_lcm_accuracy_5k: 0.8823 - val_lcm_hamming_loss_k: 0.0040
Epoch 10/150
27/27 [==============================] - ETA: 0s - loss: 0.2360 - lcm_precision_1k: 0.6777 - lcm_precision_2k: 0.5300 - lcm_precision_3k: 0.4259 - lcm_precision_5k: 0.3020 - lcm_recall_1k: 0.4292 - lcm_recall_2k: 0.6272 - lcm_recall_3k: 0.7287 - lcm_recall_5k: 0.8322 - lcm_f1_1k: 0.5255 - lcm_f1_2k: 0.5745 - lcm_f1_3k: 0.5375 - lcm_f1_5k: 0.4432 - lcm_accuracy_1k: 0.6777 - lcm_accuracy_2k: 0.8289 - lcm_accuracy_3k: 0.8880 - lcm_accuracy_5k: 0.9398 - lcm_hamming_loss_k: 0.0036
Epoch 00010: val_loss improved from 0.28455 to 0.28223, saving model to logs/ozfhtp-labs-0604-151547/model/checkpoint_labs.h5
27/27 [==============================] - 11s 424ms/step - loss: 0.2360 - lcm_precision_1k: 0.6777 - lcm_precision_2k: 0.5300 - lcm_precision_3k: 0.4259 - lcm_precision_5k: 0.3020 - lcm_recall_1k: 0.4292 - lcm_recall_2k: 0.6272 - lcm_recall_3k: 0.7287 - lcm_recall_5k: 0.8322 - lcm_f1_1k: 0.5255 - lcm_f1_2k: 0.5745 - lcm_f1_3k: 0.5375 - lcm_f1_5k: 0.4432 - lcm_accuracy_1k: 0.6777 - lcm_accuracy_2k: 0.8289 - lcm_accuracy_3k: 0.8880 - lcm_accuracy_5k: 0.9398 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2822 - val_lcm_precision_1k: 0.5982 - val_lcm_precision_2k: 0.4750 - val_lcm_precision_3k: 0.3839 - val_lcm_precision_5k: 0.2726 - val_lcm_recall_1k: 0.3688 - val_lcm_recall_2k: 0.5586 - val_lcm_recall_3k: 0.6553 - val_lcm_recall_5k: 0.7496 - val_lcm_f1_1k: 0.4561 - val_lcm_f1_2k: 0.5132 - val_lcm_f1_3k: 0.4839 - val_lcm_f1_5k: 0.3997 - val_lcm_accuracy_1k: 0.5982 - val_lcm_accuracy_2k: 0.7625 - val_lcm_accuracy_3k: 0.8284 - val_lcm_accuracy_5k: 0.8795 - val_lcm_hamming_loss_k: 0.0040
Epoch 11/150
27/27 [==============================] - ETA: 0s - loss: 0.2298 - lcm_precision_1k: 0.6890 - lcm_precision_2k: 0.5400 - lcm_precision_3k: 0.4345 - lcm_precision_5k: 0.3069 - lcm_recall_1k: 0.4384 - lcm_recall_2k: 0.6386 - lcm_recall_3k: 0.7427 - lcm_recall_5k: 0.8442 - lcm_f1_1k: 0.5358 - lcm_f1_2k: 0.5851 - lcm_f1_3k: 0.5482 - lcm_f1_5k: 0.4501 - lcm_accuracy_1k: 0.6890 - lcm_accuracy_2k: 0.8381 - lcm_accuracy_3k: 0.8983 - lcm_accuracy_5k: 0.9466 - lcm_hamming_loss_k: 0.0036
Epoch 00011: val_loss improved from 0.28223 to 0.27370, saving model to logs/ozfhtp-labs-0604-151547/model/checkpoint_labs.h5
27/27 [==============================] - 11s 424ms/step - loss: 0.2298 - lcm_precision_1k: 0.6890 - lcm_precision_2k: 0.5400 - lcm_precision_3k: 0.4345 - lcm_precision_5k: 0.3069 - lcm_recall_1k: 0.4384 - lcm_recall_2k: 0.6386 - lcm_recall_3k: 0.7427 - lcm_recall_5k: 0.8442 - lcm_f1_1k: 0.5358 - lcm_f1_2k: 0.5851 - lcm_f1_3k: 0.5482 - lcm_f1_5k: 0.4501 - lcm_accuracy_1k: 0.6890 - lcm_accuracy_2k: 0.8381 - lcm_accuracy_3k: 0.8983 - lcm_accuracy_5k: 0.9466 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2737 - val_lcm_precision_1k: 0.6069 - val_lcm_precision_2k: 0.4862 - val_lcm_precision_3k: 0.3889 - val_lcm_precision_5k: 0.2760 - val_lcm_recall_1k: 0.3778 - val_lcm_recall_2k: 0.5682 - val_lcm_recall_3k: 0.6625 - val_lcm_recall_5k: 0.7573 - val_lcm_f1_1k: 0.4655 - val_lcm_f1_2k: 0.5238 - val_lcm_f1_3k: 0.4899 - val_lcm_f1_5k: 0.4044 - val_lcm_accuracy_1k: 0.6069 - val_lcm_accuracy_2k: 0.7705 - val_lcm_accuracy_3k: 0.8342 - val_lcm_accuracy_5k: 0.8854 - val_lcm_hamming_loss_k: 0.0040
Epoch 12/150
27/27 [==============================] - ETA: 0s - loss: 0.2234 - lcm_precision_1k: 0.7064 - lcm_precision_2k: 0.5529 - lcm_precision_3k: 0.4420 - lcm_precision_5k: 0.3123 - lcm_recall_1k: 0.4498 - lcm_recall_2k: 0.6547 - lcm_recall_3k: 0.7565 - lcm_recall_5k: 0.8579 - lcm_f1_1k: 0.5495 - lcm_f1_2k: 0.5994 - lcm_f1_3k: 0.5579 - lcm_f1_5k: 0.4578 - lcm_accuracy_1k: 0.7064 - lcm_accuracy_2k: 0.8543 - lcm_accuracy_3k: 0.9096 - lcm_accuracy_5k: 0.9541 - lcm_hamming_loss_k: 0.0035
Epoch 00012: val_loss did not improve from 0.27370
27/27 [==============================] - 10s 389ms/step - loss: 0.2234 - lcm_precision_1k: 0.7064 - lcm_precision_2k: 0.5529 - lcm_precision_3k: 0.4420 - lcm_precision_5k: 0.3123 - lcm_recall_1k: 0.4498 - lcm_recall_2k: 0.6547 - lcm_recall_3k: 0.7565 - lcm_recall_5k: 0.8579 - lcm_f1_1k: 0.5495 - lcm_f1_2k: 0.5994 - lcm_f1_3k: 0.5579 - lcm_f1_5k: 0.4578 - lcm_accuracy_1k: 0.7064 - lcm_accuracy_2k: 0.8543 - lcm_accuracy_3k: 0.9096 - lcm_accuracy_5k: 0.9541 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2758 - val_lcm_precision_1k: 0.6188 - val_lcm_precision_2k: 0.4848 - val_lcm_precision_3k: 0.3894 - val_lcm_precision_5k: 0.2759 - val_lcm_recall_1k: 0.3851 - val_lcm_recall_2k: 0.5668 - val_lcm_recall_3k: 0.6608 - val_lcm_recall_5k: 0.7568 - val_lcm_f1_1k: 0.4746 - val_lcm_f1_2k: 0.5224 - val_lcm_f1_3k: 0.4898 - val_lcm_f1_5k: 0.4042 - val_lcm_accuracy_1k: 0.6188 - val_lcm_accuracy_2k: 0.7680 - val_lcm_accuracy_3k: 0.8315 - val_lcm_accuracy_5k: 0.8857 - val_lcm_hamming_loss_k: 0.0039
Epoch 13/150
27/27 [==============================] - ETA: 0s - loss: 0.2166 - lcm_precision_1k: 0.7190 - lcm_precision_2k: 0.5630 - lcm_precision_3k: 0.4496 - lcm_precision_5k: 0.3156 - lcm_recall_1k: 0.4596 - lcm_recall_2k: 0.6669 - lcm_recall_3k: 0.7692 - lcm_recall_5k: 0.8662 - lcm_f1_1k: 0.5606 - lcm_f1_2k: 0.6105 - lcm_f1_3k: 0.5674 - lcm_f1_5k: 0.4626 - lcm_accuracy_1k: 0.7190 - lcm_accuracy_2k: 0.8641 - lcm_accuracy_3k: 0.9178 - lcm_accuracy_5k: 0.9581 - lcm_hamming_loss_k: 0.0034
Epoch 00013: val_loss did not improve from 0.27370
27/27 [==============================] - 10s 389ms/step - loss: 0.2166 - lcm_precision_1k: 0.7190 - lcm_precision_2k: 0.5630 - lcm_precision_3k: 0.4496 - lcm_precision_5k: 0.3156 - lcm_recall_1k: 0.4596 - lcm_recall_2k: 0.6669 - lcm_recall_3k: 0.7692 - lcm_recall_5k: 0.8662 - lcm_f1_1k: 0.5606 - lcm_f1_2k: 0.6105 - lcm_f1_3k: 0.5674 - lcm_f1_5k: 0.4626 - lcm_accuracy_1k: 0.7190 - lcm_accuracy_2k: 0.8641 - lcm_accuracy_3k: 0.9178 - lcm_accuracy_5k: 0.9581 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2743 - val_lcm_precision_1k: 0.6202 - val_lcm_precision_2k: 0.4881 - val_lcm_precision_3k: 0.3877 - val_lcm_precision_5k: 0.2752 - val_lcm_recall_1k: 0.3847 - val_lcm_recall_2k: 0.5705 - val_lcm_recall_3k: 0.6591 - val_lcm_recall_5k: 0.7550 - val_lcm_f1_1k: 0.4747 - val_lcm_f1_2k: 0.5259 - val_lcm_f1_3k: 0.4880 - val_lcm_f1_5k: 0.4032 - val_lcm_accuracy_1k: 0.6202 - val_lcm_accuracy_2k: 0.7696 - val_lcm_accuracy_3k: 0.8279 - val_lcm_accuracy_5k: 0.8830 - val_lcm_hamming_loss_k: 0.0039
Epoch 00013: early stopping
176/176 [==============================] - 8s 44ms/step - loss: 0.2387 - lcm_precision_1k: 0.6740 - lcm_precision_2k: 0.5250 - lcm_precision_3k: 0.4205 - lcm_precision_5k: 0.2973 - lcm_recall_1k: 0.4274 - lcm_recall_2k: 0.6227 - lcm_recall_3k: 0.7231 - lcm_recall_5k: 0.8217 - lcm_f1_1k: 0.5218 - lcm_f1_2k: 0.5685 - lcm_f1_3k: 0.5307 - lcm_f1_5k: 0.4359 - lcm_accuracy_1k: 0.6740 - lcm_accuracy_2k: 0.8192 - lcm_accuracy_3k: 0.8805 - lcm_accuracy_5k: 0.9262 - lcm_hamming_loss_k: 0.0036 5s - loss: 0.2404 - lcm_precision_1k: 0.6868 - lcm_precision_2k: 0.5233 - lcm_precision_3k: 0.4185 - lcm_precision_5k: 0.2940 - lcm_recall_1k: 0.4368 - lcm_recall_2k: 0.6202 - lcm_recall_3k: 0.7259 - lcm_recall_5k: 0.8234 - lcm_f1_1k: 0.5326 - lcm_f1_2k: 0.5663 - lcm_f1_3k: 0.5299 - lcm_f1_5k: 0.4327 
Best model result:  [0.23870518803596497, 0.6739595532417297, 0.5250454545021057, 0.4204505980014801, 0.2973363697528839, 0.42738017439842224, 0.6227350831031799, 0.7231236696243286, 0.8216749429702759, 0.5217517018318176, 0.5685025453567505, 0.5306895971298218, 0.4359329044818878, 0.6739595532417297, 0.8192262053489685, 0.8805307745933533, 0.9261636137962341, 0.003628944046795368]
13498
3375
5625
Model: "model_4"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_6 (Sl  (None, 15, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_6[0][0
                                                                 ]']                              
                                                                                                  
 permute_6 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_10 (Lambda)             (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_6[0][0]']              
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_10[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_11 (Lambda)             (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_4 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_11[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_2 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_4[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_6 (Dense)                (None, 1024)         2098176     ['tf.concat_2[0][0]']            
                                                                                                  
 dense_7 (Dense)                (None, 15)           15375       ['dense_6[0][0]']                
                                                                                                  
 tf.nn.softmax_2 (TFOpLambda)   (None, 15)           0           ['dense_7[0][0]']                
                                                                                                  
 tf.expand_dims_4 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_2[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_4[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_7 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_12 (Lambda)             (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_7[0][0]']              
                                                                                                  
 dense_8 (Dense)                (None, 15, 150)      22650       ['lambda_12[0][0]']              
                                                                                                  
 tf.math.reduce_mean_5 (TFOpLam  (None, 150)         0           ['dense_8[0][0]']                
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_5 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_5[0][0]']  
                                                                                                  
 tf.__operators__.getitem_7 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 tf.math.multiply_2 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_5[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_7[0][0
                                                                 ]']                              
                                                                                                  
 permute_8 (Permute)            (None, 1024, 150)    0           ['tf.math.multiply_2[0][0]']     
                                                                                                  
 lambda_13 (Lambda)             (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_8[0][0]']              
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_13[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_14 (Lambda)             (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_2[0][0]']     
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_14[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
==================================================================================================
Total params: 31,474,320
Trainable params: 6,695,820
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
2 patience
Model: "model_5"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_6 (Sl  (None, 15, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_6[0][0
                                                                 ]']                              
                                                                                                  
 permute_6 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_10 (Lambda)             (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_6[0][0]']              
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_10[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_11 (Lambda)             (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_4 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_11[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_2 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_4[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_6 (Dense)                (None, 1024)         2098176     ['tf.concat_2[0][0]']            
                                                                                                  
 dense_7 (Dense)                (None, 15)           15375       ['dense_6[0][0]']                
                                                                                                  
 tf.nn.softmax_2 (TFOpLambda)   (None, 15)           0           ['dense_7[0][0]']                
                                                                                                  
 tf.expand_dims_4 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_2[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_4[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_7 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_12 (Lambda)             (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_7[0][0]']              
                                                                                                  
 dense_8 (Dense)                (None, 15, 150)      22650       ['lambda_12[0][0]']              
                                                                                                  
 tf.math.reduce_mean_5 (TFOpLam  (None, 150)         0           ['dense_8[0][0]']                
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_5 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_5[0][0]']  
                                                                                                  
 tf.__operators__.getitem_7 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 tf.math.multiply_2 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_5[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_7[0][0
                                                                 ]']                              
                                                                                                  
 permute_8 (Permute)            (None, 1024, 150)    0           ['tf.math.multiply_2[0][0]']     
                                                                                                  
 lambda_13 (Lambda)             (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_8[0][0]']              
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_13[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_14 (Lambda)             (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_2[0][0]']     
                                                                                                  
 tf.__operators__.getitem_8 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_14[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 label_lcm_emb (Dense)          (None, 427, 1024)    308224      ['tf.__operators__.getitem_8[0][0
                                                                 ]']                              
                                                                                                  
 dot_2 (Dot)                    (None, 427)          0           ['label_lcm_emb[0][0]',          
                                                                  '1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 label_sim_dict (Dense)         (None, 427)          182756      ['dot_2[0][0]']                  
                                                                                                  
 concatenate_2 (Concatenate)    (None, 854)          0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 31,965,300
Trainable params: 7,186,800
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
Epoch 1/150
27/27 [==============================] - ETA: 0s - loss: 0.4883 - lcm_precision_1k: 0.1971 - lcm_precision_2k: 0.1674 - lcm_precision_3k: 0.1448 - lcm_precision_5k: 0.1187 - lcm_recall_1k: 0.1124 - lcm_recall_2k: 0.1856 - lcm_recall_3k: 0.2368 - lcm_recall_5k: 0.3177 - lcm_f1_1k: 0.1430 - lcm_f1_2k: 0.1759 - lcm_f1_3k: 0.1796 - lcm_f1_5k: 0.1727 - lcm_accuracy_1k: 0.1971 - lcm_accuracy_2k: 0.2941 - lcm_accuracy_3k: 0.3590 - lcm_accuracy_5k: 0.4524 - lcm_hamming_loss_k: 0.0059
Epoch 00001: val_loss improved from inf to 0.42365, saving model to logs/rkewze-labs-0604-151825/model/checkpoint_labs.h5
27/27 [==============================] - 13s 424ms/step - loss: 0.4883 - lcm_precision_1k: 0.1971 - lcm_precision_2k: 0.1674 - lcm_precision_3k: 0.1448 - lcm_precision_5k: 0.1187 - lcm_recall_1k: 0.1124 - lcm_recall_2k: 0.1856 - lcm_recall_3k: 0.2368 - lcm_recall_5k: 0.3177 - lcm_f1_1k: 0.1430 - lcm_f1_2k: 0.1759 - lcm_f1_3k: 0.1796 - lcm_f1_5k: 0.1727 - lcm_accuracy_1k: 0.1971 - lcm_accuracy_2k: 0.2941 - lcm_accuracy_3k: 0.3590 - lcm_accuracy_5k: 0.4524 - lcm_hamming_loss_k: 0.0059 - val_loss: 0.4236 - val_lcm_precision_1k: 0.3517 - val_lcm_precision_2k: 0.2821 - val_lcm_precision_3k: 0.2362 - val_lcm_precision_5k: 0.1814 - val_lcm_recall_1k: 0.2034 - val_lcm_recall_2k: 0.3190 - val_lcm_recall_3k: 0.3909 - val_lcm_recall_5k: 0.4881 - val_lcm_f1_1k: 0.2575 - val_lcm_f1_2k: 0.2992 - val_lcm_f1_3k: 0.2944 - val_lcm_f1_5k: 0.2644 - val_lcm_accuracy_1k: 0.3517 - val_lcm_accuracy_2k: 0.4867 - val_lcm_accuracy_3k: 0.5616 - val_lcm_accuracy_5k: 0.6447 - val_lcm_hamming_loss_k: 0.0052
Epoch 2/150
27/27 [==============================] - ETA: 0s - loss: 0.3668 - lcm_precision_1k: 0.4080 - lcm_precision_2k: 0.3324 - lcm_precision_3k: 0.2816 - lcm_precision_5k: 0.2151 - lcm_recall_1k: 0.2427 - lcm_recall_2k: 0.3805 - lcm_recall_3k: 0.4733 - lcm_recall_5k: 0.5872 - lcm_f1_1k: 0.3043 - lcm_f1_2k: 0.3548 - lcm_f1_3k: 0.3530 - lcm_f1_5k: 0.3148 - lcm_accuracy_1k: 0.4080 - lcm_accuracy_2k: 0.5586 - lcm_accuracy_3k: 0.6495 - lcm_accuracy_5k: 0.7405 - lcm_hamming_loss_k: 0.0049
Epoch 00002: val_loss improved from 0.42365 to 0.34714, saving model to logs/rkewze-labs-0604-151825/model/checkpoint_labs.h5
27/27 [==============================] - 11s 428ms/step - loss: 0.3668 - lcm_precision_1k: 0.4080 - lcm_precision_2k: 0.3324 - lcm_precision_3k: 0.2816 - lcm_precision_5k: 0.2151 - lcm_recall_1k: 0.2427 - lcm_recall_2k: 0.3805 - lcm_recall_3k: 0.4733 - lcm_recall_5k: 0.5872 - lcm_f1_1k: 0.3043 - lcm_f1_2k: 0.3548 - lcm_f1_3k: 0.3530 - lcm_f1_5k: 0.3148 - lcm_accuracy_1k: 0.4080 - lcm_accuracy_2k: 0.5586 - lcm_accuracy_3k: 0.6495 - lcm_accuracy_5k: 0.7405 - lcm_hamming_loss_k: 0.0049 - val_loss: 0.3471 - val_lcm_precision_1k: 0.4611 - val_lcm_precision_2k: 0.3679 - val_lcm_precision_3k: 0.3064 - val_lcm_precision_5k: 0.2311 - val_lcm_recall_1k: 0.2792 - val_lcm_recall_2k: 0.4165 - val_lcm_recall_3k: 0.5108 - val_lcm_recall_5k: 0.6247 - val_lcm_f1_1k: 0.3475 - val_lcm_f1_2k: 0.3905 - val_lcm_f1_3k: 0.3828 - val_lcm_f1_5k: 0.3372 - val_lcm_accuracy_1k: 0.4611 - val_lcm_accuracy_2k: 0.6079 - val_lcm_accuracy_3k: 0.6880 - val_lcm_accuracy_5k: 0.7737 - val_lcm_hamming_loss_k: 0.0047
Epoch 3/150
27/27 [==============================] - ETA: 0s - loss: 0.3149 - lcm_precision_1k: 0.4992 - lcm_precision_2k: 0.4045 - lcm_precision_3k: 0.3346 - lcm_precision_5k: 0.2488 - lcm_recall_1k: 0.3047 - lcm_recall_2k: 0.4680 - lcm_recall_3k: 0.5686 - lcm_recall_5k: 0.6832 - lcm_f1_1k: 0.3783 - lcm_f1_2k: 0.4338 - lcm_f1_3k: 0.4212 - lcm_f1_5k: 0.3647 - lcm_accuracy_1k: 0.4992 - lcm_accuracy_2k: 0.6619 - lcm_accuracy_3k: 0.7470 - lcm_accuracy_5k: 0.8274 - lcm_hamming_loss_k: 0.0045
Epoch 00003: val_loss improved from 0.34714 to 0.32204, saving model to logs/rkewze-labs-0604-151825/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.3149 - lcm_precision_1k: 0.4992 - lcm_precision_2k: 0.4045 - lcm_precision_3k: 0.3346 - lcm_precision_5k: 0.2488 - lcm_recall_1k: 0.3047 - lcm_recall_2k: 0.4680 - lcm_recall_3k: 0.5686 - lcm_recall_5k: 0.6832 - lcm_f1_1k: 0.3783 - lcm_f1_2k: 0.4338 - lcm_f1_3k: 0.4212 - lcm_f1_5k: 0.3647 - lcm_accuracy_1k: 0.4992 - lcm_accuracy_2k: 0.6619 - lcm_accuracy_3k: 0.7470 - lcm_accuracy_5k: 0.8274 - lcm_hamming_loss_k: 0.0045 - val_loss: 0.3220 - val_lcm_precision_1k: 0.5141 - val_lcm_precision_2k: 0.3996 - val_lcm_precision_3k: 0.3306 - val_lcm_precision_5k: 0.2453 - val_lcm_recall_1k: 0.3135 - val_lcm_recall_2k: 0.4624 - val_lcm_recall_3k: 0.5599 - val_lcm_recall_5k: 0.6723 - val_lcm_f1_1k: 0.3891 - val_lcm_f1_2k: 0.4284 - val_lcm_f1_3k: 0.4155 - val_lcm_f1_5k: 0.3592 - val_lcm_accuracy_1k: 0.5141 - val_lcm_accuracy_2k: 0.6573 - val_lcm_accuracy_3k: 0.7383 - val_lcm_accuracy_5k: 0.8175 - val_lcm_hamming_loss_k: 0.0044
Epoch 4/150
27/27 [==============================] - ETA: 0s - loss: 0.2939 - lcm_precision_1k: 0.5467 - lcm_precision_2k: 0.4396 - lcm_precision_3k: 0.3608 - lcm_precision_5k: 0.2628 - lcm_recall_1k: 0.3392 - lcm_recall_2k: 0.5148 - lcm_recall_3k: 0.6159 - lcm_recall_5k: 0.7250 - lcm_f1_1k: 0.4186 - lcm_f1_2k: 0.4742 - lcm_f1_3k: 0.4550 - lcm_f1_5k: 0.3857 - lcm_accuracy_1k: 0.5467 - lcm_accuracy_2k: 0.7115 - lcm_accuracy_3k: 0.7890 - lcm_accuracy_5k: 0.8591 - lcm_hamming_loss_k: 0.0042
Epoch 00004: val_loss improved from 0.32204 to 0.31081, saving model to logs/rkewze-labs-0604-151825/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2939 - lcm_precision_1k: 0.5467 - lcm_precision_2k: 0.4396 - lcm_precision_3k: 0.3608 - lcm_precision_5k: 0.2628 - lcm_recall_1k: 0.3392 - lcm_recall_2k: 0.5148 - lcm_recall_3k: 0.6159 - lcm_recall_5k: 0.7250 - lcm_f1_1k: 0.4186 - lcm_f1_2k: 0.4742 - lcm_f1_3k: 0.4550 - lcm_f1_5k: 0.3857 - lcm_accuracy_1k: 0.5467 - lcm_accuracy_2k: 0.7115 - lcm_accuracy_3k: 0.7890 - lcm_accuracy_5k: 0.8591 - lcm_hamming_loss_k: 0.0042 - val_loss: 0.3108 - val_lcm_precision_1k: 0.5396 - val_lcm_precision_2k: 0.4175 - val_lcm_precision_3k: 0.3490 - val_lcm_precision_5k: 0.2559 - val_lcm_recall_1k: 0.3318 - val_lcm_recall_2k: 0.4847 - val_lcm_recall_3k: 0.5909 - val_lcm_recall_5k: 0.7025 - val_lcm_f1_1k: 0.4106 - val_lcm_f1_2k: 0.4484 - val_lcm_f1_3k: 0.4386 - val_lcm_f1_5k: 0.3750 - val_lcm_accuracy_1k: 0.5396 - val_lcm_accuracy_2k: 0.6851 - val_lcm_accuracy_3k: 0.7681 - val_lcm_accuracy_5k: 0.8481 - val_lcm_hamming_loss_k: 0.0043
Epoch 5/150
27/27 [==============================] - ETA: 0s - loss: 0.2785 - lcm_precision_1k: 0.5840 - lcm_precision_2k: 0.4632 - lcm_precision_3k: 0.3770 - lcm_precision_5k: 0.2735 - lcm_recall_1k: 0.3639 - lcm_recall_2k: 0.5447 - lcm_recall_3k: 0.6462 - lcm_recall_5k: 0.7549 - lcm_f1_1k: 0.4484 - lcm_f1_2k: 0.5006 - lcm_f1_3k: 0.4761 - lcm_f1_5k: 0.4015 - lcm_accuracy_1k: 0.5840 - lcm_accuracy_2k: 0.7437 - lcm_accuracy_3k: 0.8173 - lcm_accuracy_5k: 0.8838 - lcm_hamming_loss_k: 0.0041
Epoch 00005: val_loss improved from 0.31081 to 0.29939, saving model to logs/rkewze-labs-0604-151825/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.2785 - lcm_precision_1k: 0.5840 - lcm_precision_2k: 0.4632 - lcm_precision_3k: 0.3770 - lcm_precision_5k: 0.2735 - lcm_recall_1k: 0.3639 - lcm_recall_2k: 0.5447 - lcm_recall_3k: 0.6462 - lcm_recall_5k: 0.7549 - lcm_f1_1k: 0.4484 - lcm_f1_2k: 0.5006 - lcm_f1_3k: 0.4761 - lcm_f1_5k: 0.4015 - lcm_accuracy_1k: 0.5840 - lcm_accuracy_2k: 0.7437 - lcm_accuracy_3k: 0.8173 - lcm_accuracy_5k: 0.8838 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2994 - val_lcm_precision_1k: 0.5610 - val_lcm_precision_2k: 0.4359 - val_lcm_precision_3k: 0.3585 - val_lcm_precision_5k: 0.2604 - val_lcm_recall_1k: 0.3436 - val_lcm_recall_2k: 0.5074 - val_lcm_recall_3k: 0.6088 - val_lcm_recall_5k: 0.7105 - val_lcm_f1_1k: 0.4260 - val_lcm_f1_2k: 0.4687 - val_lcm_f1_3k: 0.4510 - val_lcm_f1_5k: 0.3809 - val_lcm_accuracy_1k: 0.5610 - val_lcm_accuracy_2k: 0.7071 - val_lcm_accuracy_3k: 0.7851 - val_lcm_accuracy_5k: 0.8523 - val_lcm_hamming_loss_k: 0.0042
Epoch 6/150
27/27 [==============================] - ETA: 0s - loss: 0.2667 - lcm_precision_1k: 0.6099 - lcm_precision_2k: 0.4808 - lcm_precision_3k: 0.3904 - lcm_precision_5k: 0.2800 - lcm_recall_1k: 0.3835 - lcm_recall_2k: 0.5677 - lcm_recall_3k: 0.6693 - lcm_recall_5k: 0.7740 - lcm_f1_1k: 0.4709 - lcm_f1_2k: 0.5206 - lcm_f1_3k: 0.4931 - lcm_f1_5k: 0.4112 - lcm_accuracy_1k: 0.6099 - lcm_accuracy_2k: 0.7667 - lcm_accuracy_3k: 0.8395 - lcm_accuracy_5k: 0.8991 - lcm_hamming_loss_k: 0.0039
Epoch 00006: val_loss improved from 0.29939 to 0.29937, saving model to logs/rkewze-labs-0604-151825/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2667 - lcm_precision_1k: 0.6099 - lcm_precision_2k: 0.4808 - lcm_precision_3k: 0.3904 - lcm_precision_5k: 0.2800 - lcm_recall_1k: 0.3835 - lcm_recall_2k: 0.5677 - lcm_recall_3k: 0.6693 - lcm_recall_5k: 0.7740 - lcm_f1_1k: 0.4709 - lcm_f1_2k: 0.5206 - lcm_f1_3k: 0.4931 - lcm_f1_5k: 0.4112 - lcm_accuracy_1k: 0.6099 - lcm_accuracy_2k: 0.7667 - lcm_accuracy_3k: 0.8395 - lcm_accuracy_5k: 0.8991 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2994 - val_lcm_precision_1k: 0.5672 - val_lcm_precision_2k: 0.4477 - val_lcm_precision_3k: 0.3655 - val_lcm_precision_5k: 0.2642 - val_lcm_recall_1k: 0.3479 - val_lcm_recall_2k: 0.5207 - val_lcm_recall_3k: 0.6216 - val_lcm_recall_5k: 0.7235 - val_lcm_f1_1k: 0.4311 - val_lcm_f1_2k: 0.4812 - val_lcm_f1_3k: 0.4601 - val_lcm_f1_5k: 0.3869 - val_lcm_accuracy_1k: 0.5672 - val_lcm_accuracy_2k: 0.7228 - val_lcm_accuracy_3k: 0.7954 - val_lcm_accuracy_5k: 0.8615 - val_lcm_hamming_loss_k: 0.0042
Epoch 7/150
27/27 [==============================] - ETA: 0s - loss: 0.2584 - lcm_precision_1k: 0.6302 - lcm_precision_2k: 0.4972 - lcm_precision_3k: 0.4021 - lcm_precision_5k: 0.2867 - lcm_recall_1k: 0.3977 - lcm_recall_2k: 0.5884 - lcm_recall_3k: 0.6892 - lcm_recall_5k: 0.7920 - lcm_f1_1k: 0.4876 - lcm_f1_2k: 0.5389 - lcm_f1_3k: 0.5078 - lcm_f1_5k: 0.4209 - lcm_accuracy_1k: 0.6302 - lcm_accuracy_2k: 0.7875 - lcm_accuracy_3k: 0.8548 - lcm_accuracy_5k: 0.9093 - lcm_hamming_loss_k: 0.0038
Epoch 00007: val_loss improved from 0.29937 to 0.28875, saving model to logs/rkewze-labs-0604-151825/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2584 - lcm_precision_1k: 0.6302 - lcm_precision_2k: 0.4972 - lcm_precision_3k: 0.4021 - lcm_precision_5k: 0.2867 - lcm_recall_1k: 0.3977 - lcm_recall_2k: 0.5884 - lcm_recall_3k: 0.6892 - lcm_recall_5k: 0.7920 - lcm_f1_1k: 0.4876 - lcm_f1_2k: 0.5389 - lcm_f1_3k: 0.5078 - lcm_f1_5k: 0.4209 - lcm_accuracy_1k: 0.6302 - lcm_accuracy_2k: 0.7875 - lcm_accuracy_3k: 0.8548 - lcm_accuracy_5k: 0.9093 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2887 - val_lcm_precision_1k: 0.5725 - val_lcm_precision_2k: 0.4518 - val_lcm_precision_3k: 0.3704 - val_lcm_precision_5k: 0.2670 - val_lcm_recall_1k: 0.3531 - val_lcm_recall_2k: 0.5259 - val_lcm_recall_3k: 0.6287 - val_lcm_recall_5k: 0.7310 - val_lcm_f1_1k: 0.4365 - val_lcm_f1_2k: 0.4858 - val_lcm_f1_3k: 0.4659 - val_lcm_f1_5k: 0.3910 - val_lcm_accuracy_1k: 0.5725 - val_lcm_accuracy_2k: 0.7263 - val_lcm_accuracy_3k: 0.7998 - val_lcm_accuracy_5k: 0.8680 - val_lcm_hamming_loss_k: 0.0042
Epoch 8/150
27/27 [==============================] - ETA: 0s - loss: 0.2502 - lcm_precision_1k: 0.6509 - lcm_precision_2k: 0.5095 - lcm_precision_3k: 0.4105 - lcm_precision_5k: 0.2916 - lcm_recall_1k: 0.4117 - lcm_recall_2k: 0.6028 - lcm_recall_3k: 0.7028 - lcm_recall_5k: 0.8045 - lcm_f1_1k: 0.5043 - lcm_f1_2k: 0.5521 - lcm_f1_3k: 0.5182 - lcm_f1_5k: 0.4280 - lcm_accuracy_1k: 0.6509 - lcm_accuracy_2k: 0.8049 - lcm_accuracy_3k: 0.8647 - lcm_accuracy_5k: 0.9190 - lcm_hamming_loss_k: 0.0038 ETA: 7s - loss: 0.2451 - lcm_precision_1k: 0.6672 - lcm_precision_2k: 0.5227 - lcm_precision_3k: 0.4172 - lcm_precision_5k: 0.2967 - lcm_recall_1k: 0.4168 - lcm_recall_2k: 0.6086 - lcm_recall_3k: 0.7065 - lcm_recall_5k: 0.8100 - lcm_f1_1k: 0.5130 - lcm_f1_2k: 0.5623 - lcm_f1_3k: 0.5245 - lcm_f1_5k: 0.4343 - lcm_accuracy_1k: 0.6672 - lcm_accuracy_2k: 0.8086 - lcm_accuracy_3k: 0.8696 - lcm_accu
Epoch 00008: val_loss improved from 0.28875 to 0.28521, saving model to logs/rkewze-labs-0604-151825/model/checkpoint_labs.h5
27/27 [==============================] - 11s 429ms/step - loss: 0.2502 - lcm_precision_1k: 0.6509 - lcm_precision_2k: 0.5095 - lcm_precision_3k: 0.4105 - lcm_precision_5k: 0.2916 - lcm_recall_1k: 0.4117 - lcm_recall_2k: 0.6028 - lcm_recall_3k: 0.7028 - lcm_recall_5k: 0.8045 - lcm_f1_1k: 0.5043 - lcm_f1_2k: 0.5521 - lcm_f1_3k: 0.5182 - lcm_f1_5k: 0.4280 - lcm_accuracy_1k: 0.6509 - lcm_accuracy_2k: 0.8049 - lcm_accuracy_3k: 0.8647 - lcm_accuracy_5k: 0.9190 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2852 - val_lcm_precision_1k: 0.5868 - val_lcm_precision_2k: 0.4615 - val_lcm_precision_3k: 0.3729 - val_lcm_precision_5k: 0.2681 - val_lcm_recall_1k: 0.3617 - val_lcm_recall_2k: 0.5373 - val_lcm_recall_3k: 0.6329 - val_lcm_recall_5k: 0.7359 - val_lcm_f1_1k: 0.4474 - val_lcm_f1_2k: 0.4963 - val_lcm_f1_3k: 0.4691 - val_lcm_f1_5k: 0.3928 - val_lcm_accuracy_1k: 0.5868 - val_lcm_accuracy_2k: 0.7334 - val_lcm_accuracy_3k: 0.8002 - val_lcm_accuracy_5k: 0.8732 - val_lcm_hamming_loss_k: 0.0041
Epoch 9/150
27/27 [==============================] - ETA: 0s - loss: 0.2425 - lcm_precision_1k: 0.6619 - lcm_precision_2k: 0.5214 - lcm_precision_3k: 0.4178 - lcm_precision_5k: 0.2967 - lcm_recall_1k: 0.4191 - lcm_recall_2k: 0.6172 - lcm_recall_3k: 0.7156 - lcm_recall_5k: 0.8184 - lcm_f1_1k: 0.5132 - lcm_f1_2k: 0.5652 - lcm_f1_3k: 0.5275 - lcm_f1_5k: 0.4355 - lcm_accuracy_1k: 0.6619 - lcm_accuracy_2k: 0.8170 - lcm_accuracy_3k: 0.8764 - lcm_accuracy_5k: 0.9288 - lcm_hamming_loss_k: 0.0037 ETA: 3s - loss: 0.2409 - lcm_precision_1k: 0.6622 - lcm_precision_2k: 0.5219 - lcm_precision_3k: 0.4178 - lcm_precision_5k: 0.2972 - lcm_recall_1k: 0.4200 - lcm_recall_2k: 0.6197 - lcm_recall_3k: 0.7168 - lcm_recall_5k: 0.8205 - lcm_f1_1k: 0.5139 - lcm_f1_2k: 0.5666 - lcm_f1_3k: 0.5279 - lcm_f1_5k: 0.4363 - lcm_accuracy_1k: 0.6622 - lcm_accuracy_2k: 0.8193 - lcm_accuracy_3k: 0.8776 - lcm_accuracy_5k: 0.9298 - lcm_
Epoch 00009: val_loss did not improve from 0.28521
27/27 [==============================] - 11s 392ms/step - loss: 0.2425 - lcm_precision_1k: 0.6619 - lcm_precision_2k: 0.5214 - lcm_precision_3k: 0.4178 - lcm_precision_5k: 0.2967 - lcm_recall_1k: 0.4191 - lcm_recall_2k: 0.6172 - lcm_recall_3k: 0.7156 - lcm_recall_5k: 0.8184 - lcm_f1_1k: 0.5132 - lcm_f1_2k: 0.5652 - lcm_f1_3k: 0.5275 - lcm_f1_5k: 0.4355 - lcm_accuracy_1k: 0.6619 - lcm_accuracy_2k: 0.8170 - lcm_accuracy_3k: 0.8764 - lcm_accuracy_5k: 0.9288 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2902 - val_lcm_precision_1k: 0.5981 - val_lcm_precision_2k: 0.4583 - val_lcm_precision_3k: 0.3716 - val_lcm_precision_5k: 0.2693 - val_lcm_recall_1k: 0.3685 - val_lcm_recall_2k: 0.5351 - val_lcm_recall_3k: 0.6332 - val_lcm_recall_5k: 0.7391 - val_lcm_f1_1k: 0.4558 - val_lcm_f1_2k: 0.4935 - val_lcm_f1_3k: 0.4681 - val_lcm_f1_5k: 0.3946 - val_lcm_accuracy_1k: 0.5981 - val_lcm_accuracy_2k: 0.7347 - val_lcm_accuracy_3k: 0.8063 - val_lcm_accuracy_5k: 0.8750 - val_lcm_hamming_loss_k: 0.0040
Epoch 10/150
27/27 [==============================] - ETA: 0s - loss: 0.2349 - lcm_precision_1k: 0.6849 - lcm_precision_2k: 0.5319 - lcm_precision_3k: 0.4263 - lcm_precision_5k: 0.3015 - lcm_recall_1k: 0.4346 - lcm_recall_2k: 0.6304 - lcm_recall_3k: 0.7308 - lcm_recall_5k: 0.8311 - lcm_f1_1k: 0.5317 - lcm_f1_2k: 0.5769 - lcm_f1_3k: 0.5384 - lcm_f1_5k: 0.4424 - lcm_accuracy_1k: 0.6849 - lcm_accuracy_2k: 0.8296 - lcm_accuracy_3k: 0.8878 - lcm_accuracy_5k: 0.9374 - lcm_hamming_loss_k: 0.0036
Epoch 00010: val_loss improved from 0.28521 to 0.28097, saving model to logs/rkewze-labs-0604-151825/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2349 - lcm_precision_1k: 0.6849 - lcm_precision_2k: 0.5319 - lcm_precision_3k: 0.4263 - lcm_precision_5k: 0.3015 - lcm_recall_1k: 0.4346 - lcm_recall_2k: 0.6304 - lcm_recall_3k: 0.7308 - lcm_recall_5k: 0.8311 - lcm_f1_1k: 0.5317 - lcm_f1_2k: 0.5769 - lcm_f1_3k: 0.5384 - lcm_f1_5k: 0.4424 - lcm_accuracy_1k: 0.6849 - lcm_accuracy_2k: 0.8296 - lcm_accuracy_3k: 0.8878 - lcm_accuracy_5k: 0.9374 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2810 - val_lcm_precision_1k: 0.6042 - val_lcm_precision_2k: 0.4625 - val_lcm_precision_3k: 0.3769 - val_lcm_precision_5k: 0.2723 - val_lcm_recall_1k: 0.3732 - val_lcm_recall_2k: 0.5374 - val_lcm_recall_3k: 0.6411 - val_lcm_recall_5k: 0.7458 - val_lcm_f1_1k: 0.4611 - val_lcm_f1_2k: 0.4969 - val_lcm_f1_3k: 0.4745 - val_lcm_f1_5k: 0.3988 - val_lcm_accuracy_1k: 0.6042 - val_lcm_accuracy_2k: 0.7371 - val_lcm_accuracy_3k: 0.8104 - val_lcm_accuracy_5k: 0.8803 - val_lcm_hamming_loss_k: 0.0040
Epoch 11/150
27/27 [==============================] - ETA: 0s - loss: 0.2276 - lcm_precision_1k: 0.6936 - lcm_precision_2k: 0.5411 - lcm_precision_3k: 0.4353 - lcm_precision_5k: 0.3064 - lcm_recall_1k: 0.4407 - lcm_recall_2k: 0.6405 - lcm_recall_3k: 0.7451 - lcm_recall_5k: 0.8437 - lcm_f1_1k: 0.5389 - lcm_f1_2k: 0.5865 - lcm_f1_3k: 0.5495 - lcm_f1_5k: 0.4495 - lcm_accuracy_1k: 0.6936 - lcm_accuracy_2k: 0.8381 - lcm_accuracy_3k: 0.8986 - lcm_accuracy_5k: 0.9441 - lcm_hamming_loss_k: 0.0035
Epoch 00011: val_loss did not improve from 0.28097
27/27 [==============================] - 11s 392ms/step - loss: 0.2276 - lcm_precision_1k: 0.6936 - lcm_precision_2k: 0.5411 - lcm_precision_3k: 0.4353 - lcm_precision_5k: 0.3064 - lcm_recall_1k: 0.4407 - lcm_recall_2k: 0.6405 - lcm_recall_3k: 0.7451 - lcm_recall_5k: 0.8437 - lcm_f1_1k: 0.5389 - lcm_f1_2k: 0.5865 - lcm_f1_3k: 0.5495 - lcm_f1_5k: 0.4495 - lcm_accuracy_1k: 0.6936 - lcm_accuracy_2k: 0.8381 - lcm_accuracy_3k: 0.8986 - lcm_accuracy_5k: 0.9441 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2819 - val_lcm_precision_1k: 0.6116 - val_lcm_precision_2k: 0.4714 - val_lcm_precision_3k: 0.3799 - val_lcm_precision_5k: 0.2718 - val_lcm_recall_1k: 0.3784 - val_lcm_recall_2k: 0.5480 - val_lcm_recall_3k: 0.6435 - val_lcm_recall_5k: 0.7431 - val_lcm_f1_1k: 0.4673 - val_lcm_f1_2k: 0.5066 - val_lcm_f1_3k: 0.4776 - val_lcm_f1_5k: 0.3979 - val_lcm_accuracy_1k: 0.6116 - val_lcm_accuracy_2k: 0.7490 - val_lcm_accuracy_3k: 0.8118 - val_lcm_accuracy_5k: 0.8768 - val_lcm_hamming_loss_k: 0.0040
Epoch 12/150
27/27 [==============================] - ETA: 0s - loss: 0.2211 - lcm_precision_1k: 0.7106 - lcm_precision_2k: 0.5550 - lcm_precision_3k: 0.4438 - lcm_precision_5k: 0.3114 - lcm_recall_1k: 0.4528 - lcm_recall_2k: 0.6578 - lcm_recall_3k: 0.7583 - lcm_recall_5k: 0.8566 - lcm_f1_1k: 0.5530 - lcm_f1_2k: 0.6020 - lcm_f1_3k: 0.5599 - lcm_f1_5k: 0.4567 - lcm_accuracy_1k: 0.7106 - lcm_accuracy_2k: 0.8552 - lcm_accuracy_3k: 0.9080 - lcm_accuracy_5k: 0.9537 - lcm_hamming_loss_k: 0.0035
Epoch 00012: val_loss improved from 0.28097 to 0.27580, saving model to logs/rkewze-labs-0604-151825/model/checkpoint_labs.h5
27/27 [==============================] - 11s 428ms/step - loss: 0.2211 - lcm_precision_1k: 0.7106 - lcm_precision_2k: 0.5550 - lcm_precision_3k: 0.4438 - lcm_precision_5k: 0.3114 - lcm_recall_1k: 0.4528 - lcm_recall_2k: 0.6578 - lcm_recall_3k: 0.7583 - lcm_recall_5k: 0.8566 - lcm_f1_1k: 0.5530 - lcm_f1_2k: 0.6020 - lcm_f1_3k: 0.5599 - lcm_f1_5k: 0.4567 - lcm_accuracy_1k: 0.7106 - lcm_accuracy_2k: 0.8552 - lcm_accuracy_3k: 0.9080 - lcm_accuracy_5k: 0.9537 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2758 - val_lcm_precision_1k: 0.6082 - val_lcm_precision_2k: 0.4756 - val_lcm_precision_3k: 0.3837 - val_lcm_precision_5k: 0.2758 - val_lcm_recall_1k: 0.3771 - val_lcm_recall_2k: 0.5543 - val_lcm_recall_3k: 0.6532 - val_lcm_recall_5k: 0.7541 - val_lcm_f1_1k: 0.4653 - val_lcm_f1_2k: 0.5117 - val_lcm_f1_3k: 0.4832 - val_lcm_f1_5k: 0.4037 - val_lcm_accuracy_1k: 0.6082 - val_lcm_accuracy_2k: 0.7509 - val_lcm_accuracy_3k: 0.8214 - val_lcm_accuracy_5k: 0.8843 - val_lcm_hamming_loss_k: 0.0040
Epoch 13/150
27/27 [==============================] - ETA: 0s - loss: 0.2140 - lcm_precision_1k: 0.7270 - lcm_precision_2k: 0.5672 - lcm_precision_3k: 0.4507 - lcm_precision_5k: 0.3166 - lcm_recall_1k: 0.4655 - lcm_recall_2k: 0.6706 - lcm_recall_3k: 0.7696 - lcm_recall_5k: 0.8685 - lcm_f1_1k: 0.5676 - lcm_f1_2k: 0.6145 - lcm_f1_3k: 0.5685 - lcm_f1_5k: 0.4640 - lcm_accuracy_1k: 0.7270 - lcm_accuracy_2k: 0.8667 - lcm_accuracy_3k: 0.9165 - lcm_accuracy_5k: 0.9596 - lcm_hamming_loss_k: 0.0034
Epoch 00013: val_loss did not improve from 0.27580
27/27 [==============================] - 10s 390ms/step - loss: 0.2140 - lcm_precision_1k: 0.7270 - lcm_precision_2k: 0.5672 - lcm_precision_3k: 0.4507 - lcm_precision_5k: 0.3166 - lcm_recall_1k: 0.4655 - lcm_recall_2k: 0.6706 - lcm_recall_3k: 0.7696 - lcm_recall_5k: 0.8685 - lcm_f1_1k: 0.5676 - lcm_f1_2k: 0.6145 - lcm_f1_3k: 0.5685 - lcm_f1_5k: 0.4640 - lcm_accuracy_1k: 0.7270 - lcm_accuracy_2k: 0.8667 - lcm_accuracy_3k: 0.9165 - lcm_accuracy_5k: 0.9596 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2785 - val_lcm_precision_1k: 0.6043 - val_lcm_precision_2k: 0.4710 - val_lcm_precision_3k: 0.3813 - val_lcm_precision_5k: 0.2734 - val_lcm_recall_1k: 0.3773 - val_lcm_recall_2k: 0.5500 - val_lcm_recall_3k: 0.6495 - val_lcm_recall_5k: 0.7507 - val_lcm_f1_1k: 0.4642 - val_lcm_f1_2k: 0.5072 - val_lcm_f1_3k: 0.4803 - val_lcm_f1_5k: 0.4006 - val_lcm_accuracy_1k: 0.6043 - val_lcm_accuracy_2k: 0.7468 - val_lcm_accuracy_3k: 0.8208 - val_lcm_accuracy_5k: 0.8856 - val_lcm_hamming_loss_k: 0.0040
Epoch 14/150
27/27 [==============================] - ETA: 0s - loss: 0.2086 - lcm_precision_1k: 0.7397 - lcm_precision_2k: 0.5750 - lcm_precision_3k: 0.4590 - lcm_precision_5k: 0.3209 - lcm_recall_1k: 0.4731 - lcm_recall_2k: 0.6807 - lcm_recall_3k: 0.7821 - lcm_recall_5k: 0.8791 - lcm_f1_1k: 0.5770 - lcm_f1_2k: 0.6233 - lcm_f1_3k: 0.5784 - lcm_f1_5k: 0.4701 - lcm_accuracy_1k: 0.7397 - lcm_accuracy_2k: 0.8770 - lcm_accuracy_3k: 0.9244 - lcm_accuracy_5k: 0.9642 - lcm_hamming_loss_k: 0.0033 ETA: 2s - loss: 0.2074 - lcm_precision_1k: 0.7465 - lcm_precision_2k: 0.5813 - lcm_precision_3k: 0.4631 - lcm_precision_5k: 0.3227 - lcm_recall_1k: 0.4777 - lcm_recall_2k: 0.6877 - lcm_recall_3k: 0.7889 - lcm_recall_5k: 0.8830 - lcm_f1_1k: 0.5825 - lcm_f1_2k: 0.6300 - lcm_f1_3k: 0.5835 - lcm_f1_5k: 0.4726 - lcm_accuracy_1k: 0.7465 - lcm_accuracy_2k: 0.8839 - lcm_accuracy_3k: 0.9294 - lcm_accuracy_5k: 0.9673 - lcm_hamm
Epoch 00014: val_loss improved from 0.27580 to 0.27499, saving model to logs/rkewze-labs-0604-151825/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.2086 - lcm_precision_1k: 0.7397 - lcm_precision_2k: 0.5750 - lcm_precision_3k: 0.4590 - lcm_precision_5k: 0.3209 - lcm_recall_1k: 0.4731 - lcm_recall_2k: 0.6807 - lcm_recall_3k: 0.7821 - lcm_recall_5k: 0.8791 - lcm_f1_1k: 0.5770 - lcm_f1_2k: 0.6233 - lcm_f1_3k: 0.5784 - lcm_f1_5k: 0.4701 - lcm_accuracy_1k: 0.7397 - lcm_accuracy_2k: 0.8770 - lcm_accuracy_3k: 0.9244 - lcm_accuracy_5k: 0.9642 - lcm_hamming_loss_k: 0.0033 - val_loss: 0.2750 - val_lcm_precision_1k: 0.5987 - val_lcm_precision_2k: 0.4752 - val_lcm_precision_3k: 0.3833 - val_lcm_precision_5k: 0.2748 - val_lcm_recall_1k: 0.3752 - val_lcm_recall_2k: 0.5535 - val_lcm_recall_3k: 0.6536 - val_lcm_recall_5k: 0.7540 - val_lcm_f1_1k: 0.4610 - val_lcm_f1_2k: 0.5112 - val_lcm_f1_3k: 0.4830 - val_lcm_f1_5k: 0.4026 - val_lcm_accuracy_1k: 0.5987 - val_lcm_accuracy_2k: 0.7508 - val_lcm_accuracy_3k: 0.8215 - val_lcm_accuracy_5k: 0.8854 - val_lcm_hamming_loss_k: 0.0040
Epoch 15/150
27/27 [==============================] - ETA: 0s - loss: 0.2042 - lcm_precision_1k: 0.7506 - lcm_precision_2k: 0.5853 - lcm_precision_3k: 0.4648 - lcm_precision_5k: 0.3238 - lcm_recall_1k: 0.4826 - lcm_recall_2k: 0.6928 - lcm_recall_3k: 0.7927 - lcm_recall_5k: 0.8868 - lcm_f1_1k: 0.5874 - lcm_f1_2k: 0.6344 - lcm_f1_3k: 0.5859 - lcm_f1_5k: 0.4743 - lcm_accuracy_1k: 0.7506 - lcm_accuracy_2k: 0.8854 - lcm_accuracy_3k: 0.9327 - lcm_accuracy_5k: 0.9690 - lcm_hamming_loss_k: 0.0033
Epoch 00015: val_loss improved from 0.27499 to 0.27396, saving model to logs/rkewze-labs-0604-151825/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2042 - lcm_precision_1k: 0.7506 - lcm_precision_2k: 0.5853 - lcm_precision_3k: 0.4648 - lcm_precision_5k: 0.3238 - lcm_recall_1k: 0.4826 - lcm_recall_2k: 0.6928 - lcm_recall_3k: 0.7927 - lcm_recall_5k: 0.8868 - lcm_f1_1k: 0.5874 - lcm_f1_2k: 0.6344 - lcm_f1_3k: 0.5859 - lcm_f1_5k: 0.4743 - lcm_accuracy_1k: 0.7506 - lcm_accuracy_2k: 0.8854 - lcm_accuracy_3k: 0.9327 - lcm_accuracy_5k: 0.9690 - lcm_hamming_loss_k: 0.0033 - val_loss: 0.2740 - val_lcm_precision_1k: 0.6178 - val_lcm_precision_2k: 0.4793 - val_lcm_precision_3k: 0.3872 - val_lcm_precision_5k: 0.2748 - val_lcm_recall_1k: 0.3858 - val_lcm_recall_2k: 0.5617 - val_lcm_recall_3k: 0.6595 - val_lcm_recall_5k: 0.7540 - val_lcm_f1_1k: 0.4747 - val_lcm_f1_2k: 0.5169 - val_lcm_f1_3k: 0.4877 - val_lcm_f1_5k: 0.4026 - val_lcm_accuracy_1k: 0.6178 - val_lcm_accuracy_2k: 0.7555 - val_lcm_accuracy_3k: 0.8279 - val_lcm_accuracy_5k: 0.8846 - val_lcm_hamming_loss_k: 0.0039
Epoch 16/150
27/27 [==============================] - ETA: 0s - loss: 0.1957 - lcm_precision_1k: 0.7694 - lcm_precision_2k: 0.5978 - lcm_precision_3k: 0.4738 - lcm_precision_5k: 0.3276 - lcm_recall_1k: 0.4955 - lcm_recall_2k: 0.7076 - lcm_recall_3k: 0.8066 - lcm_recall_5k: 0.8958 - lcm_f1_1k: 0.6027 - lcm_f1_2k: 0.6479 - lcm_f1_3k: 0.5969 - lcm_f1_5k: 0.4797 - lcm_accuracy_1k: 0.7694 - lcm_accuracy_2k: 0.8966 - lcm_accuracy_3k: 0.9400 - lcm_accuracy_5k: 0.9722 - lcm_hamming_loss_k: 0.0032
Epoch 00016: val_loss improved from 0.27396 to 0.27213, saving model to logs/rkewze-labs-0604-151825/model/checkpoint_labs.h5
27/27 [==============================] - 11s 429ms/step - loss: 0.1957 - lcm_precision_1k: 0.7694 - lcm_precision_2k: 0.5978 - lcm_precision_3k: 0.4738 - lcm_precision_5k: 0.3276 - lcm_recall_1k: 0.4955 - lcm_recall_2k: 0.7076 - lcm_recall_3k: 0.8066 - lcm_recall_5k: 0.8958 - lcm_f1_1k: 0.6027 - lcm_f1_2k: 0.6479 - lcm_f1_3k: 0.5969 - lcm_f1_5k: 0.4797 - lcm_accuracy_1k: 0.7694 - lcm_accuracy_2k: 0.8966 - lcm_accuracy_3k: 0.9400 - lcm_accuracy_5k: 0.9722 - lcm_hamming_loss_k: 0.0032 - val_loss: 0.2721 - val_lcm_precision_1k: 0.6159 - val_lcm_precision_2k: 0.4802 - val_lcm_precision_3k: 0.3893 - val_lcm_precision_5k: 0.2764 - val_lcm_recall_1k: 0.3841 - val_lcm_recall_2k: 0.5586 - val_lcm_recall_3k: 0.6602 - val_lcm_recall_5k: 0.7583 - val_lcm_f1_1k: 0.4728 - val_lcm_f1_2k: 0.5161 - val_lcm_f1_3k: 0.4896 - val_lcm_f1_5k: 0.4050 - val_lcm_accuracy_1k: 0.6159 - val_lcm_accuracy_2k: 0.7533 - val_lcm_accuracy_3k: 0.8233 - val_lcm_accuracy_5k: 0.8884 - val_lcm_hamming_loss_k: 0.0040
Epoch 17/150
27/27 [==============================] - ETA: 0s - loss: 0.1900 - lcm_precision_1k: 0.7844 - lcm_precision_2k: 0.6078 - lcm_precision_3k: 0.4829 - lcm_precision_5k: 0.3325 - lcm_recall_1k: 0.5045 - lcm_recall_2k: 0.7165 - lcm_recall_3k: 0.8183 - lcm_recall_5k: 0.9050 - lcm_f1_1k: 0.6140 - lcm_f1_2k: 0.6577 - lcm_f1_3k: 0.6073 - lcm_f1_5k: 0.4863 - lcm_accuracy_1k: 0.7844 - lcm_accuracy_2k: 0.9054 - lcm_accuracy_3k: 0.9480 - lcm_accuracy_5k: 0.9766 - lcm_hamming_loss_k: 0.0031
Epoch 00017: val_loss did not improve from 0.27213
27/27 [==============================] - 11s 392ms/step - loss: 0.1900 - lcm_precision_1k: 0.7844 - lcm_precision_2k: 0.6078 - lcm_precision_3k: 0.4829 - lcm_precision_5k: 0.3325 - lcm_recall_1k: 0.5045 - lcm_recall_2k: 0.7165 - lcm_recall_3k: 0.8183 - lcm_recall_5k: 0.9050 - lcm_f1_1k: 0.6140 - lcm_f1_2k: 0.6577 - lcm_f1_3k: 0.6073 - lcm_f1_5k: 0.4863 - lcm_accuracy_1k: 0.7844 - lcm_accuracy_2k: 0.9054 - lcm_accuracy_3k: 0.9480 - lcm_accuracy_5k: 0.9766 - lcm_hamming_loss_k: 0.0031 - val_loss: 0.2762 - val_lcm_precision_1k: 0.6194 - val_lcm_precision_2k: 0.4800 - val_lcm_precision_3k: 0.3863 - val_lcm_precision_5k: 0.2744 - val_lcm_recall_1k: 0.3896 - val_lcm_recall_2k: 0.5626 - val_lcm_recall_3k: 0.6600 - val_lcm_recall_5k: 0.7554 - val_lcm_f1_1k: 0.4781 - val_lcm_f1_2k: 0.5178 - val_lcm_f1_3k: 0.4871 - val_lcm_f1_5k: 0.4024 - val_lcm_accuracy_1k: 0.6194 - val_lcm_accuracy_2k: 0.7585 - val_lcm_accuracy_3k: 0.8307 - val_lcm_accuracy_5k: 0.8896 - val_lcm_hamming_loss_k: 0.0039
Epoch 18/150
27/27 [==============================] - ETA: 0s - loss: 0.1843 - lcm_precision_1k: 0.7976 - lcm_precision_2k: 0.6204 - lcm_precision_3k: 0.4906 - lcm_precision_5k: 0.3375 - lcm_recall_1k: 0.5145 - lcm_recall_2k: 0.7306 - lcm_recall_3k: 0.8297 - lcm_recall_5k: 0.9169 - lcm_f1_1k: 0.6254 - lcm_f1_2k: 0.6709 - lcm_f1_3k: 0.6165 - lcm_f1_5k: 0.4933 - lcm_accuracy_1k: 0.7976 - lcm_accuracy_2k: 0.9158 - lcm_accuracy_3k: 0.9538 - lcm_accuracy_5k: 0.9813 - lcm_hamming_loss_k: 0.0031
Epoch 00018: val_loss did not improve from 0.27213
27/27 [==============================] - 10s 389ms/step - loss: 0.1843 - lcm_precision_1k: 0.7976 - lcm_precision_2k: 0.6204 - lcm_precision_3k: 0.4906 - lcm_precision_5k: 0.3375 - lcm_recall_1k: 0.5145 - lcm_recall_2k: 0.7306 - lcm_recall_3k: 0.8297 - lcm_recall_5k: 0.9169 - lcm_f1_1k: 0.6254 - lcm_f1_2k: 0.6709 - lcm_f1_3k: 0.6165 - lcm_f1_5k: 0.4933 - lcm_accuracy_1k: 0.7976 - lcm_accuracy_2k: 0.9158 - lcm_accuracy_3k: 0.9538 - lcm_accuracy_5k: 0.9813 - lcm_hamming_loss_k: 0.0031 - val_loss: 0.2760 - val_lcm_precision_1k: 0.6120 - val_lcm_precision_2k: 0.4839 - val_lcm_precision_3k: 0.3915 - val_lcm_precision_5k: 0.2760 - val_lcm_recall_1k: 0.3840 - val_lcm_recall_2k: 0.5654 - val_lcm_recall_3k: 0.6663 - val_lcm_recall_5k: 0.7581 - val_lcm_f1_1k: 0.4716 - val_lcm_f1_2k: 0.5213 - val_lcm_f1_3k: 0.4930 - val_lcm_f1_5k: 0.4044 - val_lcm_accuracy_1k: 0.6120 - val_lcm_accuracy_2k: 0.7607 - val_lcm_accuracy_3k: 0.8337 - val_lcm_accuracy_5k: 0.8910 - val_lcm_hamming_loss_k: 0.0040
Epoch 00018: early stopping
176/176 [==============================] - 8s 43ms/step - loss: 0.2145 - lcm_precision_1k: 0.7247 - lcm_precision_2k: 0.5681 - lcm_precision_3k: 0.4533 - lcm_precision_5k: 0.3129 - lcm_recall_1k: 0.4658 - lcm_recall_2k: 0.6721 - lcm_recall_3k: 0.7734 - lcm_recall_5k: 0.8598 - lcm_f1_1k: 0.5658 - lcm_f1_2k: 0.6145 - lcm_f1_3k: 0.5705 - lcm_f1_5k: 0.4581 - lcm_accuracy_1k: 0.7247 - lcm_accuracy_2k: 0.8572 - lcm_accuracy_3k: 0.9085 - lcm_accuracy_5k: 0.9472 - lcm_hamming_loss_k: 0.0034
Best model result:  [0.21451519429683685, 0.7247431874275208, 0.5681016445159912, 0.4532892107963562, 0.31290343403816223, 0.465823769569397, 0.6721140146255493, 0.7733692526817322, 0.8598095178604126, 0.5658276677131653, 0.6145312786102295, 0.5705329179763794, 0.4580952823162079, 0.7247431874275208, 0.8572218418121338, 0.9085334539413452, 0.947222888469696, 0.003391094272956252]
13499
3374
5625
Model: "model_6"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_9 (Sl  (None, 15, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_9[0][0
                                                                 ]']                              
                                                                                                  
 permute_9 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_15 (Lambda)             (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_9[0][0]']              
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_15[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_16 (Lambda)             (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_6 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_16[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_3 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_6[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_9 (Dense)                (None, 1024)         2098176     ['tf.concat_3[0][0]']            
                                                                                                  
 dense_10 (Dense)               (None, 15)           15375       ['dense_9[0][0]']                
                                                                                                  
 tf.nn.softmax_3 (TFOpLambda)   (None, 15)           0           ['dense_10[0][0]']               
                                                                                                  
 tf.expand_dims_6 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_3[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_6[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_10 (Permute)           (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_17 (Lambda)             (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_10[0][0]']             
                                                                                                  
 dense_11 (Dense)               (None, 15, 150)      22650       ['lambda_17[0][0]']              
                                                                                                  
 tf.math.reduce_mean_7 (TFOpLam  (None, 150)         0           ['dense_11[0][0]']               
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_7 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_7[0][0]']  
                                                                                                  
 tf.__operators__.getitem_10 (S  (None, 427, 300)    0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 tf.math.multiply_3 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_7[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_10[0][
                                                                 0]']                             
                                                                                                  
 permute_11 (Permute)           (None, 1024, 150)    0           ['tf.math.multiply_3[0][0]']     
                                                                                                  
 lambda_18 (Lambda)             (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_11[0][0]']             
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_18[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_19 (Lambda)             (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_3[0][0]']     
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_19[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
==================================================================================================
Total params: 31,474,320
Trainable params: 6,695,820
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
2 patience
Model: "model_7"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_9 (Sl  (None, 15, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_9[0][0
                                                                 ]']                              
                                                                                                  
 permute_9 (Permute)            (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_15 (Lambda)             (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_9[0][0]']              
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_15[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_16 (Lambda)             (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_6 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_16[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_3 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_6[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_9 (Dense)                (None, 1024)         2098176     ['tf.concat_3[0][0]']            
                                                                                                  
 dense_10 (Dense)               (None, 15)           15375       ['dense_9[0][0]']                
                                                                                                  
 tf.nn.softmax_3 (TFOpLambda)   (None, 15)           0           ['dense_10[0][0]']               
                                                                                                  
 tf.expand_dims_6 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_3[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_6[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_10 (Permute)           (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_17 (Lambda)             (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_10[0][0]']             
                                                                                                  
 dense_11 (Dense)               (None, 15, 150)      22650       ['lambda_17[0][0]']              
                                                                                                  
 tf.math.reduce_mean_7 (TFOpLam  (None, 150)         0           ['dense_11[0][0]']               
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_7 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_7[0][0]']  
                                                                                                  
 tf.__operators__.getitem_10 (S  (None, 427, 300)    0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 tf.math.multiply_3 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_7[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_10[0][
                                                                 0]']                             
                                                                                                  
 permute_11 (Permute)           (None, 1024, 150)    0           ['tf.math.multiply_3[0][0]']     
                                                                                                  
 lambda_18 (Lambda)             (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_11[0][0]']             
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_18[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_19 (Lambda)             (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_3[0][0]']     
                                                                                                  
 tf.__operators__.getitem_11 (S  (None, 427, 300)    0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_19[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 label_lcm_emb (Dense)          (None, 427, 1024)    308224      ['tf.__operators__.getitem_11[0][
                                                                 0]']                             
                                                                                                  
 dot_3 (Dot)                    (None, 427)          0           ['label_lcm_emb[0][0]',          
                                                                  '1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 label_sim_dict (Dense)         (None, 427)          182756      ['dot_3[0][0]']                  
                                                                                                  
 concatenate_3 (Concatenate)    (None, 854)          0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 31,965,300
Trainable params: 7,186,800
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
Epoch 1/150
27/27 [==============================] - ETA: 0s - loss: 0.4898 - lcm_precision_1k: 0.2120 - lcm_precision_2k: 0.1788 - lcm_precision_3k: 0.1546 - lcm_precision_5k: 0.1253 - lcm_recall_1k: 0.1162 - lcm_recall_2k: 0.1961 - lcm_recall_3k: 0.2520 - lcm_recall_5k: 0.3356 - lcm_f1_1k: 0.1499 - lcm_f1_2k: 0.1870 - lcm_f1_3k: 0.1916 - lcm_f1_5k: 0.1824 - lcm_accuracy_1k: 0.2120 - lcm_accuracy_2k: 0.3173 - lcm_accuracy_3k: 0.3819 - lcm_accuracy_5k: 0.4711 - lcm_hamming_loss_k: 0.0058
Epoch 00001: val_loss improved from inf to 0.41843, saving model to logs/jbptag-labs-0604-152157/model/checkpoint_labs.h5
27/27 [==============================] - 13s 415ms/step - loss: 0.4898 - lcm_precision_1k: 0.2120 - lcm_precision_2k: 0.1788 - lcm_precision_3k: 0.1546 - lcm_precision_5k: 0.1253 - lcm_recall_1k: 0.1162 - lcm_recall_2k: 0.1961 - lcm_recall_3k: 0.2520 - lcm_recall_5k: 0.3356 - lcm_f1_1k: 0.1499 - lcm_f1_2k: 0.1870 - lcm_f1_3k: 0.1916 - lcm_f1_5k: 0.1824 - lcm_accuracy_1k: 0.2120 - lcm_accuracy_2k: 0.3173 - lcm_accuracy_3k: 0.3819 - lcm_accuracy_5k: 0.4711 - lcm_hamming_loss_k: 0.0058 - val_loss: 0.4184 - val_lcm_precision_1k: 0.3521 - val_lcm_precision_2k: 0.2751 - val_lcm_precision_3k: 0.2389 - val_lcm_precision_5k: 0.1850 - val_lcm_recall_1k: 0.2069 - val_lcm_recall_2k: 0.3153 - val_lcm_recall_3k: 0.3981 - val_lcm_recall_5k: 0.4999 - val_lcm_f1_1k: 0.2604 - val_lcm_f1_2k: 0.2936 - val_lcm_f1_3k: 0.2984 - val_lcm_f1_5k: 0.2699 - val_lcm_accuracy_1k: 0.3521 - val_lcm_accuracy_2k: 0.4865 - val_lcm_accuracy_3k: 0.5680 - val_lcm_accuracy_5k: 0.6540 - val_lcm_hamming_loss_k: 0.0052
Epoch 2/150
27/27 [==============================] - ETA: 0s - loss: 0.3656 - lcm_precision_1k: 0.4138 - lcm_precision_2k: 0.3349 - lcm_precision_3k: 0.2807 - lcm_precision_5k: 0.2150 - lcm_recall_1k: 0.2468 - lcm_recall_2k: 0.3824 - lcm_recall_3k: 0.4713 - lcm_recall_5k: 0.5858 - lcm_f1_1k: 0.3091 - lcm_f1_2k: 0.3570 - lcm_f1_3k: 0.3518 - lcm_f1_5k: 0.3145 - lcm_accuracy_1k: 0.4138 - lcm_accuracy_2k: 0.5634 - lcm_accuracy_3k: 0.6468 - lcm_accuracy_5k: 0.7369 - lcm_hamming_loss_k: 0.0049
Epoch 00002: val_loss improved from 0.41843 to 0.34484, saving model to logs/jbptag-labs-0604-152157/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.3656 - lcm_precision_1k: 0.4138 - lcm_precision_2k: 0.3349 - lcm_precision_3k: 0.2807 - lcm_precision_5k: 0.2150 - lcm_recall_1k: 0.2468 - lcm_recall_2k: 0.3824 - lcm_recall_3k: 0.4713 - lcm_recall_5k: 0.5858 - lcm_f1_1k: 0.3091 - lcm_f1_2k: 0.3570 - lcm_f1_3k: 0.3518 - lcm_f1_5k: 0.3145 - lcm_accuracy_1k: 0.4138 - lcm_accuracy_2k: 0.5634 - lcm_accuracy_3k: 0.6468 - lcm_accuracy_5k: 0.7369 - lcm_hamming_loss_k: 0.0049 - val_loss: 0.3448 - val_lcm_precision_1k: 0.4501 - val_lcm_precision_2k: 0.3644 - val_lcm_precision_3k: 0.3022 - val_lcm_precision_5k: 0.2294 - val_lcm_recall_1k: 0.2743 - val_lcm_recall_2k: 0.4251 - val_lcm_recall_3k: 0.5159 - val_lcm_recall_5k: 0.6290 - val_lcm_f1_1k: 0.3405 - val_lcm_f1_2k: 0.3922 - val_lcm_f1_3k: 0.3809 - val_lcm_f1_5k: 0.3360 - val_lcm_accuracy_1k: 0.4501 - val_lcm_accuracy_2k: 0.6095 - val_lcm_accuracy_3k: 0.6959 - val_lcm_accuracy_5k: 0.7814 - val_lcm_hamming_loss_k: 0.0047
Epoch 3/150
27/27 [==============================] - ETA: 0s - loss: 0.3168 - lcm_precision_1k: 0.4990 - lcm_precision_2k: 0.4026 - lcm_precision_3k: 0.3320 - lcm_precision_5k: 0.2463 - lcm_recall_1k: 0.3059 - lcm_recall_2k: 0.4675 - lcm_recall_3k: 0.5662 - lcm_recall_5k: 0.6783 - lcm_f1_1k: 0.3792 - lcm_f1_2k: 0.4326 - lcm_f1_3k: 0.4186 - lcm_f1_5k: 0.3613 - lcm_accuracy_1k: 0.4990 - lcm_accuracy_2k: 0.6603 - lcm_accuracy_3k: 0.7429 - lcm_accuracy_5k: 0.8241 - lcm_hamming_loss_k: 0.0045 ETA: 3s - loss: 0.3211 - lcm_precision_1k: 0.4887 - lcm_precision_2k: 0.3985 - lcm_precision_3k: 0.3298 - lcm_precision_5k: 0.2455 - lcm_recall_1k: 0.2970 - lcm_recall_2k: 0.4594 - lcm_recall_3k: 0.5583 - lcm_recall_5k: 0.6717 - lcm_f1_1k: 0.3694 - lcm_f1_2k: 0.4267 - lcm_f1_3k: 0.4146 - lcm_f1_5k: 0.3595 - lcm_accuracy_1k: 0.4887 - lcm_accuracy_2k: 0.6534 - lcm_accuracy_3k: 0.7387 - lcm_accuracy_5k: 0.8188 - lcm_hamming_lo - ETA: 1s - loss: 0.3183 - lcm_precision_1k: 0.4949 - lcm_precision_2k: 0.4013 - lcm_precision_3k: 0.3317 - lcm_precision_5k: 0.2467 - lcm_recall_1k: 0.3017 - lcm_recall_2k: 0.4640 - lcm_recall_3k: 0.5627 - lcm_recall_5k: 0.6761 - lcm_f1_1k: 0.3748 - lcm_f1_2k: 0.4303 - lcm_f1_3k: 0.4173 - lcm_f1_5k: 0.3615 - lcm_accuracy_1k: 0.4949 - lcm_accuracy_2k: 0.6582 - lcm_accuracy_3k: 0.7417 - lcm_accuracy_5k: 0.8235 - lcm_hamming_loss_k
Epoch 00003: val_loss improved from 0.34484 to 0.31894, saving model to logs/jbptag-labs-0604-152157/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.3168 - lcm_precision_1k: 0.4990 - lcm_precision_2k: 0.4026 - lcm_precision_3k: 0.3320 - lcm_precision_5k: 0.2463 - lcm_recall_1k: 0.3059 - lcm_recall_2k: 0.4675 - lcm_recall_3k: 0.5662 - lcm_recall_5k: 0.6783 - lcm_f1_1k: 0.3792 - lcm_f1_2k: 0.4326 - lcm_f1_3k: 0.4186 - lcm_f1_5k: 0.3613 - lcm_accuracy_1k: 0.4990 - lcm_accuracy_2k: 0.6603 - lcm_accuracy_3k: 0.7429 - lcm_accuracy_5k: 0.8241 - lcm_hamming_loss_k: 0.0045 - val_loss: 0.3189 - val_lcm_precision_1k: 0.4975 - val_lcm_precision_2k: 0.4027 - val_lcm_precision_3k: 0.3317 - val_lcm_precision_5k: 0.2442 - val_lcm_recall_1k: 0.3044 - val_lcm_recall_2k: 0.4679 - val_lcm_recall_3k: 0.5626 - val_lcm_recall_5k: 0.6709 - val_lcm_f1_1k: 0.3774 - val_lcm_f1_2k: 0.4326 - val_lcm_f1_3k: 0.4171 - val_lcm_f1_5k: 0.3579 - val_lcm_accuracy_1k: 0.4975 - val_lcm_accuracy_2k: 0.6621 - val_lcm_accuracy_3k: 0.7463 - val_lcm_accuracy_5k: 0.8201 - val_lcm_hamming_loss_k: 0.0045
Epoch 4/150
27/27 [==============================] - ETA: 0s - loss: 0.2953 - lcm_precision_1k: 0.5505 - lcm_precision_2k: 0.4376 - lcm_precision_3k: 0.3599 - lcm_precision_5k: 0.2621 - lcm_recall_1k: 0.3412 - lcm_recall_2k: 0.5108 - lcm_recall_3k: 0.6156 - lcm_recall_5k: 0.7225 - lcm_f1_1k: 0.4212 - lcm_f1_2k: 0.4713 - lcm_f1_3k: 0.4542 - lcm_f1_5k: 0.3846 - lcm_accuracy_1k: 0.5505 - lcm_accuracy_2k: 0.7078 - lcm_accuracy_3k: 0.7893 - lcm_accuracy_5k: 0.8608 - lcm_hamming_loss_k: 0.0042
Epoch 00004: val_loss improved from 0.31894 to 0.31094, saving model to logs/jbptag-labs-0604-152157/model/checkpoint_labs.h5
27/27 [==============================] - 11s 422ms/step - loss: 0.2953 - lcm_precision_1k: 0.5505 - lcm_precision_2k: 0.4376 - lcm_precision_3k: 0.3599 - lcm_precision_5k: 0.2621 - lcm_recall_1k: 0.3412 - lcm_recall_2k: 0.5108 - lcm_recall_3k: 0.6156 - lcm_recall_5k: 0.7225 - lcm_f1_1k: 0.4212 - lcm_f1_2k: 0.4713 - lcm_f1_3k: 0.4542 - lcm_f1_5k: 0.3846 - lcm_accuracy_1k: 0.5505 - lcm_accuracy_2k: 0.7078 - lcm_accuracy_3k: 0.7893 - lcm_accuracy_5k: 0.8608 - lcm_hamming_loss_k: 0.0042 - val_loss: 0.3109 - val_lcm_precision_1k: 0.5131 - val_lcm_precision_2k: 0.4109 - val_lcm_precision_3k: 0.3398 - val_lcm_precision_5k: 0.2474 - val_lcm_recall_1k: 0.3173 - val_lcm_recall_2k: 0.4774 - val_lcm_recall_3k: 0.5788 - val_lcm_recall_5k: 0.6821 - val_lcm_f1_1k: 0.3919 - val_lcm_f1_2k: 0.4415 - val_lcm_f1_3k: 0.4280 - val_lcm_f1_5k: 0.3630 - val_lcm_accuracy_1k: 0.5131 - val_lcm_accuracy_2k: 0.6719 - val_lcm_accuracy_3k: 0.7584 - val_lcm_accuracy_5k: 0.8256 - val_lcm_hamming_loss_k: 0.0044
Epoch 5/150
27/27 [==============================] - ETA: 0s - loss: 0.2806 - lcm_precision_1k: 0.5817 - lcm_precision_2k: 0.4615 - lcm_precision_3k: 0.3766 - lcm_precision_5k: 0.2722 - lcm_recall_1k: 0.3613 - lcm_recall_2k: 0.5416 - lcm_recall_3k: 0.6440 - lcm_recall_5k: 0.7521 - lcm_f1_1k: 0.4456 - lcm_f1_2k: 0.4982 - lcm_f1_3k: 0.4752 - lcm_f1_5k: 0.3997 - lcm_accuracy_1k: 0.5817 - lcm_accuracy_2k: 0.7397 - lcm_accuracy_3k: 0.8155 - lcm_accuracy_5k: 0.8835 - lcm_hamming_loss_k: 0.0041
Epoch 00005: val_loss improved from 0.31094 to 0.29861, saving model to logs/jbptag-labs-0604-152157/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2806 - lcm_precision_1k: 0.5817 - lcm_precision_2k: 0.4615 - lcm_precision_3k: 0.3766 - lcm_precision_5k: 0.2722 - lcm_recall_1k: 0.3613 - lcm_recall_2k: 0.5416 - lcm_recall_3k: 0.6440 - lcm_recall_5k: 0.7521 - lcm_f1_1k: 0.4456 - lcm_f1_2k: 0.4982 - lcm_f1_3k: 0.4752 - lcm_f1_5k: 0.3997 - lcm_accuracy_1k: 0.5817 - lcm_accuracy_2k: 0.7397 - lcm_accuracy_3k: 0.8155 - lcm_accuracy_5k: 0.8835 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2986 - val_lcm_precision_1k: 0.5403 - val_lcm_precision_2k: 0.4306 - val_lcm_precision_3k: 0.3519 - val_lcm_precision_5k: 0.2579 - val_lcm_recall_1k: 0.3360 - val_lcm_recall_2k: 0.5042 - val_lcm_recall_3k: 0.6011 - val_lcm_recall_5k: 0.7089 - val_lcm_f1_1k: 0.4141 - val_lcm_f1_2k: 0.4642 - val_lcm_f1_3k: 0.4436 - val_lcm_f1_5k: 0.3781 - val_lcm_accuracy_1k: 0.5403 - val_lcm_accuracy_2k: 0.6983 - val_lcm_accuracy_3k: 0.7769 - val_lcm_accuracy_5k: 0.8428 - val_lcm_hamming_loss_k: 0.0043
Epoch 6/150
27/27 [==============================] - ETA: 0s - loss: 0.2679 - lcm_precision_1k: 0.6085 - lcm_precision_2k: 0.4807 - lcm_precision_3k: 0.3888 - lcm_precision_5k: 0.2802 - lcm_recall_1k: 0.3795 - lcm_recall_2k: 0.5651 - lcm_recall_3k: 0.6649 - lcm_recall_5k: 0.7724 - lcm_f1_1k: 0.4674 - lcm_f1_2k: 0.5195 - lcm_f1_3k: 0.4906 - lcm_f1_5k: 0.4112 - lcm_accuracy_1k: 0.6085 - lcm_accuracy_2k: 0.7649 - lcm_accuracy_3k: 0.8350 - lcm_accuracy_5k: 0.8980 - lcm_hamming_loss_k: 0.0040
Epoch 00006: val_loss improved from 0.29861 to 0.29305, saving model to logs/jbptag-labs-0604-152157/model/checkpoint_labs.h5
27/27 [==============================] - 11s 428ms/step - loss: 0.2679 - lcm_precision_1k: 0.6085 - lcm_precision_2k: 0.4807 - lcm_precision_3k: 0.3888 - lcm_precision_5k: 0.2802 - lcm_recall_1k: 0.3795 - lcm_recall_2k: 0.5651 - lcm_recall_3k: 0.6649 - lcm_recall_5k: 0.7724 - lcm_f1_1k: 0.4674 - lcm_f1_2k: 0.5195 - lcm_f1_3k: 0.4906 - lcm_f1_5k: 0.4112 - lcm_accuracy_1k: 0.6085 - lcm_accuracy_2k: 0.7649 - lcm_accuracy_3k: 0.8350 - lcm_accuracy_5k: 0.8980 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2930 - val_lcm_precision_1k: 0.5490 - val_lcm_precision_2k: 0.4370 - val_lcm_precision_3k: 0.3562 - val_lcm_precision_5k: 0.2607 - val_lcm_recall_1k: 0.3407 - val_lcm_recall_2k: 0.5097 - val_lcm_recall_3k: 0.6062 - val_lcm_recall_5k: 0.7131 - val_lcm_f1_1k: 0.4202 - val_lcm_f1_2k: 0.4703 - val_lcm_f1_3k: 0.4485 - val_lcm_f1_5k: 0.3816 - val_lcm_accuracy_1k: 0.5490 - val_lcm_accuracy_2k: 0.7095 - val_lcm_accuracy_3k: 0.7821 - val_lcm_accuracy_5k: 0.8503 - val_lcm_hamming_loss_k: 0.0042
Epoch 7/150
27/27 [==============================] - ETA: 0s - loss: 0.2594 - lcm_precision_1k: 0.6304 - lcm_precision_2k: 0.4963 - lcm_precision_3k: 0.4004 - lcm_precision_5k: 0.2864 - lcm_recall_1k: 0.3956 - lcm_recall_2k: 0.5853 - lcm_recall_3k: 0.6855 - lcm_recall_5k: 0.7901 - lcm_f1_1k: 0.4861 - lcm_f1_2k: 0.5371 - lcm_f1_3k: 0.5055 - lcm_f1_5k: 0.4204 - lcm_accuracy_1k: 0.6304 - lcm_accuracy_2k: 0.7876 - lcm_accuracy_3k: 0.8523 - lcm_accuracy_5k: 0.9121 - lcm_hamming_loss_k: 0.0039
Epoch 00007: val_loss improved from 0.29305 to 0.29006, saving model to logs/jbptag-labs-0604-152157/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.2594 - lcm_precision_1k: 0.6304 - lcm_precision_2k: 0.4963 - lcm_precision_3k: 0.4004 - lcm_precision_5k: 0.2864 - lcm_recall_1k: 0.3956 - lcm_recall_2k: 0.5853 - lcm_recall_3k: 0.6855 - lcm_recall_5k: 0.7901 - lcm_f1_1k: 0.4861 - lcm_f1_2k: 0.5371 - lcm_f1_3k: 0.5055 - lcm_f1_5k: 0.4204 - lcm_accuracy_1k: 0.6304 - lcm_accuracy_2k: 0.7876 - lcm_accuracy_3k: 0.8523 - lcm_accuracy_5k: 0.9121 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2901 - val_lcm_precision_1k: 0.5531 - val_lcm_precision_2k: 0.4461 - val_lcm_precision_3k: 0.3638 - val_lcm_precision_5k: 0.2639 - val_lcm_recall_1k: 0.3479 - val_lcm_recall_2k: 0.5254 - val_lcm_recall_3k: 0.6209 - val_lcm_recall_5k: 0.7262 - val_lcm_f1_1k: 0.4269 - val_lcm_f1_2k: 0.4823 - val_lcm_f1_3k: 0.4585 - val_lcm_f1_5k: 0.3870 - val_lcm_accuracy_1k: 0.5531 - val_lcm_accuracy_2k: 0.7214 - val_lcm_accuracy_3k: 0.7926 - val_lcm_accuracy_5k: 0.8581 - val_lcm_hamming_loss_k: 0.0042
Epoch 8/150
27/27 [==============================] - ETA: 0s - loss: 0.2510 - lcm_precision_1k: 0.6492 - lcm_precision_2k: 0.5068 - lcm_precision_3k: 0.4086 - lcm_precision_5k: 0.2921 - lcm_recall_1k: 0.4080 - lcm_recall_2k: 0.5970 - lcm_recall_3k: 0.6992 - lcm_recall_5k: 0.8048 - lcm_f1_1k: 0.5010 - lcm_f1_2k: 0.5482 - lcm_f1_3k: 0.5158 - lcm_f1_5k: 0.4286 - lcm_accuracy_1k: 0.6492 - lcm_accuracy_2k: 0.7990 - lcm_accuracy_3k: 0.8630 - lcm_accuracy_5k: 0.9214 - lcm_hamming_loss_k: 0.0038
Epoch 00008: val_loss improved from 0.29006 to 0.28507, saving model to logs/jbptag-labs-0604-152157/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2510 - lcm_precision_1k: 0.6492 - lcm_precision_2k: 0.5068 - lcm_precision_3k: 0.4086 - lcm_precision_5k: 0.2921 - lcm_recall_1k: 0.4080 - lcm_recall_2k: 0.5970 - lcm_recall_3k: 0.6992 - lcm_recall_5k: 0.8048 - lcm_f1_1k: 0.5010 - lcm_f1_2k: 0.5482 - lcm_f1_3k: 0.5158 - lcm_f1_5k: 0.4286 - lcm_accuracy_1k: 0.6492 - lcm_accuracy_2k: 0.7990 - lcm_accuracy_3k: 0.8630 - lcm_accuracy_5k: 0.9214 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2851 - val_lcm_precision_1k: 0.5600 - val_lcm_precision_2k: 0.4465 - val_lcm_precision_3k: 0.3627 - val_lcm_precision_5k: 0.2641 - val_lcm_recall_1k: 0.3506 - val_lcm_recall_2k: 0.5239 - val_lcm_recall_3k: 0.6204 - val_lcm_recall_5k: 0.7245 - val_lcm_f1_1k: 0.4310 - val_lcm_f1_2k: 0.4819 - val_lcm_f1_3k: 0.4575 - val_lcm_f1_5k: 0.3870 - val_lcm_accuracy_1k: 0.5600 - val_lcm_accuracy_2k: 0.7207 - val_lcm_accuracy_3k: 0.7976 - val_lcm_accuracy_5k: 0.8606 - val_lcm_hamming_loss_k: 0.0042
Epoch 9/150
27/27 [==============================] - ETA: 0s - loss: 0.2437 - lcm_precision_1k: 0.6629 - lcm_precision_2k: 0.5183 - lcm_precision_3k: 0.4184 - lcm_precision_5k: 0.2977 - lcm_recall_1k: 0.4188 - lcm_recall_2k: 0.6124 - lcm_recall_3k: 0.7156 - lcm_recall_5k: 0.8192 - lcm_f1_1k: 0.5133 - lcm_f1_2k: 0.5614 - lcm_f1_3k: 0.5280 - lcm_f1_5k: 0.4366 - lcm_accuracy_1k: 0.6629 - lcm_accuracy_2k: 0.8151 - lcm_accuracy_3k: 0.8777 - lcm_accuracy_5k: 0.9331 - lcm_hamming_loss_k: 0.0037
Epoch 00009: val_loss improved from 0.28507 to 0.28264, saving model to logs/jbptag-labs-0604-152157/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.2437 - lcm_precision_1k: 0.6629 - lcm_precision_2k: 0.5183 - lcm_precision_3k: 0.4184 - lcm_precision_5k: 0.2977 - lcm_recall_1k: 0.4188 - lcm_recall_2k: 0.6124 - lcm_recall_3k: 0.7156 - lcm_recall_5k: 0.8192 - lcm_f1_1k: 0.5133 - lcm_f1_2k: 0.5614 - lcm_f1_3k: 0.5280 - lcm_f1_5k: 0.4366 - lcm_accuracy_1k: 0.6629 - lcm_accuracy_2k: 0.8151 - lcm_accuracy_3k: 0.8777 - lcm_accuracy_5k: 0.9331 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2826 - val_lcm_precision_1k: 0.5755 - val_lcm_precision_2k: 0.4557 - val_lcm_precision_3k: 0.3710 - val_lcm_precision_5k: 0.2673 - val_lcm_recall_1k: 0.3604 - val_lcm_recall_2k: 0.5340 - val_lcm_recall_3k: 0.6334 - val_lcm_recall_5k: 0.7344 - val_lcm_f1_1k: 0.4430 - val_lcm_f1_2k: 0.4915 - val_lcm_f1_3k: 0.4676 - val_lcm_f1_5k: 0.3917 - val_lcm_accuracy_1k: 0.5755 - val_lcm_accuracy_2k: 0.7300 - val_lcm_accuracy_3k: 0.8038 - val_lcm_accuracy_5k: 0.8660 - val_lcm_hamming_loss_k: 0.0041
Epoch 10/150
27/27 [==============================] - ETA: 0s - loss: 0.2373 - lcm_precision_1k: 0.6755 - lcm_precision_2k: 0.5300 - lcm_precision_3k: 0.4264 - lcm_precision_5k: 0.3023 - lcm_recall_1k: 0.4276 - lcm_recall_2k: 0.6266 - lcm_recall_3k: 0.7290 - lcm_recall_5k: 0.8319 - lcm_f1_1k: 0.5236 - lcm_f1_2k: 0.5742 - lcm_f1_3k: 0.5380 - lcm_f1_5k: 0.4434 - lcm_accuracy_1k: 0.6755 - lcm_accuracy_2k: 0.8266 - lcm_accuracy_3k: 0.8869 - lcm_accuracy_5k: 0.9396 - lcm_hamming_loss_k: 0.0036
Epoch 00010: val_loss did not improve from 0.28264
27/27 [==============================] - 10s 386ms/step - loss: 0.2373 - lcm_precision_1k: 0.6755 - lcm_precision_2k: 0.5300 - lcm_precision_3k: 0.4264 - lcm_precision_5k: 0.3023 - lcm_recall_1k: 0.4276 - lcm_recall_2k: 0.6266 - lcm_recall_3k: 0.7290 - lcm_recall_5k: 0.8319 - lcm_f1_1k: 0.5236 - lcm_f1_2k: 0.5742 - lcm_f1_3k: 0.5380 - lcm_f1_5k: 0.4434 - lcm_accuracy_1k: 0.6755 - lcm_accuracy_2k: 0.8266 - lcm_accuracy_3k: 0.8869 - lcm_accuracy_5k: 0.9396 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2836 - val_lcm_precision_1k: 0.5797 - val_lcm_precision_2k: 0.4588 - val_lcm_precision_3k: 0.3702 - val_lcm_precision_5k: 0.2670 - val_lcm_recall_1k: 0.3626 - val_lcm_recall_2k: 0.5393 - val_lcm_recall_3k: 0.6335 - val_lcm_recall_5k: 0.7337 - val_lcm_f1_1k: 0.4459 - val_lcm_f1_2k: 0.4956 - val_lcm_f1_3k: 0.4670 - val_lcm_f1_5k: 0.3913 - val_lcm_accuracy_1k: 0.5797 - val_lcm_accuracy_2k: 0.7357 - val_lcm_accuracy_3k: 0.8033 - val_lcm_accuracy_5k: 0.8643 - val_lcm_hamming_loss_k: 0.0041
Epoch 11/150
27/27 [==============================] - ETA: 0s - loss: 0.2307 - lcm_precision_1k: 0.6929 - lcm_precision_2k: 0.5387 - lcm_precision_3k: 0.4340 - lcm_precision_5k: 0.3062 - lcm_recall_1k: 0.4396 - lcm_recall_2k: 0.6371 - lcm_recall_3k: 0.7420 - lcm_recall_5k: 0.8416 - lcm_f1_1k: 0.5378 - lcm_f1_2k: 0.5837 - lcm_f1_3k: 0.5476 - lcm_f1_5k: 0.4490 - lcm_accuracy_1k: 0.6929 - lcm_accuracy_2k: 0.8371 - lcm_accuracy_3k: 0.8985 - lcm_accuracy_5k: 0.9454 - lcm_hamming_loss_k: 0.0036
Epoch 00011: val_loss improved from 0.28264 to 0.27920, saving model to logs/jbptag-labs-0604-152157/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.2307 - lcm_precision_1k: 0.6929 - lcm_precision_2k: 0.5387 - lcm_precision_3k: 0.4340 - lcm_precision_5k: 0.3062 - lcm_recall_1k: 0.4396 - lcm_recall_2k: 0.6371 - lcm_recall_3k: 0.7420 - lcm_recall_5k: 0.8416 - lcm_f1_1k: 0.5378 - lcm_f1_2k: 0.5837 - lcm_f1_3k: 0.5476 - lcm_f1_5k: 0.4490 - lcm_accuracy_1k: 0.6929 - lcm_accuracy_2k: 0.8371 - lcm_accuracy_3k: 0.8985 - lcm_accuracy_5k: 0.9454 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2792 - val_lcm_precision_1k: 0.5860 - val_lcm_precision_2k: 0.4628 - val_lcm_precision_3k: 0.3739 - val_lcm_precision_5k: 0.2699 - val_lcm_recall_1k: 0.3680 - val_lcm_recall_2k: 0.5407 - val_lcm_recall_3k: 0.6366 - val_lcm_recall_5k: 0.7424 - val_lcm_f1_1k: 0.4518 - val_lcm_f1_2k: 0.4985 - val_lcm_f1_3k: 0.4709 - val_lcm_f1_5k: 0.3957 - val_lcm_accuracy_1k: 0.5860 - val_lcm_accuracy_2k: 0.7380 - val_lcm_accuracy_3k: 0.8086 - val_lcm_accuracy_5k: 0.8706 - val_lcm_hamming_loss_k: 0.0041
Epoch 12/150
27/27 [==============================] - ETA: 0s - loss: 0.2228 - lcm_precision_1k: 0.7058 - lcm_precision_2k: 0.5512 - lcm_precision_3k: 0.4433 - lcm_precision_5k: 0.3121 - lcm_recall_1k: 0.4459 - lcm_recall_2k: 0.6507 - lcm_recall_3k: 0.7555 - lcm_recall_5k: 0.8552 - lcm_f1_1k: 0.5464 - lcm_f1_2k: 0.5968 - lcm_f1_3k: 0.5587 - lcm_f1_5k: 0.4573 - lcm_accuracy_1k: 0.7058 - lcm_accuracy_2k: 0.8490 - lcm_accuracy_3k: 0.9070 - lcm_accuracy_5k: 0.9535 - lcm_hamming_loss_k: 0.0035
Epoch 00012: val_loss improved from 0.27920 to 0.27432, saving model to logs/jbptag-labs-0604-152157/model/checkpoint_labs.h5
27/27 [==============================] - 11s 428ms/step - loss: 0.2228 - lcm_precision_1k: 0.7058 - lcm_precision_2k: 0.5512 - lcm_precision_3k: 0.4433 - lcm_precision_5k: 0.3121 - lcm_recall_1k: 0.4459 - lcm_recall_2k: 0.6507 - lcm_recall_3k: 0.7555 - lcm_recall_5k: 0.8552 - lcm_f1_1k: 0.5464 - lcm_f1_2k: 0.5968 - lcm_f1_3k: 0.5587 - lcm_f1_5k: 0.4573 - lcm_accuracy_1k: 0.7058 - lcm_accuracy_2k: 0.8490 - lcm_accuracy_3k: 0.9070 - lcm_accuracy_5k: 0.9535 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2743 - val_lcm_precision_1k: 0.5915 - val_lcm_precision_2k: 0.4660 - val_lcm_precision_3k: 0.3764 - val_lcm_precision_5k: 0.2714 - val_lcm_recall_1k: 0.3717 - val_lcm_recall_2k: 0.5477 - val_lcm_recall_3k: 0.6411 - val_lcm_recall_5k: 0.7454 - val_lcm_f1_1k: 0.4562 - val_lcm_f1_2k: 0.5033 - val_lcm_f1_3k: 0.4741 - val_lcm_f1_5k: 0.3977 - val_lcm_accuracy_1k: 0.5915 - val_lcm_accuracy_2k: 0.7446 - val_lcm_accuracy_3k: 0.8137 - val_lcm_accuracy_5k: 0.8731 - val_lcm_hamming_loss_k: 0.0040
Epoch 13/150
27/27 [==============================] - ETA: 0s - loss: 0.2181 - lcm_precision_1k: 0.7176 - lcm_precision_2k: 0.5606 - lcm_precision_3k: 0.4487 - lcm_precision_5k: 0.3153 - lcm_recall_1k: 0.4561 - lcm_recall_2k: 0.6625 - lcm_recall_3k: 0.7656 - lcm_recall_5k: 0.8644 - lcm_f1_1k: 0.5576 - lcm_f1_2k: 0.6072 - lcm_f1_3k: 0.5657 - lcm_f1_5k: 0.4620 - lcm_accuracy_1k: 0.7176 - lcm_accuracy_2k: 0.8614 - lcm_accuracy_3k: 0.9188 - lcm_accuracy_5k: 0.9582 - lcm_hamming_loss_k: 0.0035
Epoch 00013: val_loss did not improve from 0.27432
27/27 [==============================] - 10s 390ms/step - loss: 0.2181 - lcm_precision_1k: 0.7176 - lcm_precision_2k: 0.5606 - lcm_precision_3k: 0.4487 - lcm_precision_5k: 0.3153 - lcm_recall_1k: 0.4561 - lcm_recall_2k: 0.6625 - lcm_recall_3k: 0.7656 - lcm_recall_5k: 0.8644 - lcm_f1_1k: 0.5576 - lcm_f1_2k: 0.6072 - lcm_f1_3k: 0.5657 - lcm_f1_5k: 0.4620 - lcm_accuracy_1k: 0.7176 - lcm_accuracy_2k: 0.8614 - lcm_accuracy_3k: 0.9188 - lcm_accuracy_5k: 0.9582 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2745 - val_lcm_precision_1k: 0.5904 - val_lcm_precision_2k: 0.4646 - val_lcm_precision_3k: 0.3754 - val_lcm_precision_5k: 0.2718 - val_lcm_recall_1k: 0.3720 - val_lcm_recall_2k: 0.5501 - val_lcm_recall_3k: 0.6422 - val_lcm_recall_5k: 0.7477 - val_lcm_f1_1k: 0.4561 - val_lcm_f1_2k: 0.5034 - val_lcm_f1_3k: 0.4735 - val_lcm_f1_5k: 0.3986 - val_lcm_accuracy_1k: 0.5904 - val_lcm_accuracy_2k: 0.7451 - val_lcm_accuracy_3k: 0.8087 - val_lcm_accuracy_5k: 0.8751 - val_lcm_hamming_loss_k: 0.0040
Epoch 14/150
27/27 [==============================] - ETA: 0s - loss: 0.2108 - lcm_precision_1k: 0.7349 - lcm_precision_2k: 0.5731 - lcm_precision_3k: 0.4577 - lcm_precision_5k: 0.3198 - lcm_recall_1k: 0.4683 - lcm_recall_2k: 0.6767 - lcm_recall_3k: 0.7786 - lcm_recall_5k: 0.8735 - lcm_f1_1k: 0.5720 - lcm_f1_2k: 0.6205 - lcm_f1_3k: 0.5765 - lcm_f1_5k: 0.4681 - lcm_accuracy_1k: 0.7349 - lcm_accuracy_2k: 0.8730 - lcm_accuracy_3k: 0.9258 - lcm_accuracy_5k: 0.9624 - lcm_hamming_loss_k: 0.0034
Epoch 00014: val_loss did not improve from 0.27432
27/27 [==============================] - 10s 389ms/step - loss: 0.2108 - lcm_precision_1k: 0.7349 - lcm_precision_2k: 0.5731 - lcm_precision_3k: 0.4577 - lcm_precision_5k: 0.3198 - lcm_recall_1k: 0.4683 - lcm_recall_2k: 0.6767 - lcm_recall_3k: 0.7786 - lcm_recall_5k: 0.8735 - lcm_f1_1k: 0.5720 - lcm_f1_2k: 0.6205 - lcm_f1_3k: 0.5765 - lcm_f1_5k: 0.4681 - lcm_accuracy_1k: 0.7349 - lcm_accuracy_2k: 0.8730 - lcm_accuracy_3k: 0.9258 - lcm_accuracy_5k: 0.9624 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2745 - val_lcm_precision_1k: 0.5906 - val_lcm_precision_2k: 0.4664 - val_lcm_precision_3k: 0.3787 - val_lcm_precision_5k: 0.2709 - val_lcm_recall_1k: 0.3717 - val_lcm_recall_2k: 0.5499 - val_lcm_recall_3k: 0.6465 - val_lcm_recall_5k: 0.7445 - val_lcm_f1_1k: 0.4560 - val_lcm_f1_2k: 0.5045 - val_lcm_f1_3k: 0.4773 - val_lcm_f1_5k: 0.3971 - val_lcm_accuracy_1k: 0.5906 - val_lcm_accuracy_2k: 0.7529 - val_lcm_accuracy_3k: 0.8150 - val_lcm_accuracy_5k: 0.8730 - val_lcm_hamming_loss_k: 0.0040
Epoch 00014: early stopping
176/176 [==============================] - 8s 42ms/step - loss: 0.2300 - lcm_precision_1k: 0.6874 - lcm_precision_2k: 0.5365 - lcm_precision_3k: 0.4293 - lcm_precision_5k: 0.3020 - lcm_recall_1k: 0.4383 - lcm_recall_2k: 0.6367 - lcm_recall_3k: 0.7355 - lcm_recall_5k: 0.8344 - lcm_f1_1k: 0.5340 - lcm_f1_2k: 0.5811 - lcm_f1_3k: 0.5411 - lcm_f1_5k: 0.4428 - lcm_accuracy_1k: 0.6874 - lcm_accuracy_2k: 0.8320 - lcm_accuracy_3k: 0.8869 - lcm_accuracy_5k: 0.9338 - lcm_hamming_loss_k: 0.0036
Best model result:  [0.2299502193927765, 0.6874050498008728, 0.5364726185798645, 0.42925453186035156, 0.30200791358947754, 0.438304603099823, 0.6366746425628662, 0.7354772090911865, 0.8344349265098572, 0.5339589715003967, 0.5810732245445251, 0.5410746932029724, 0.4427700936794281, 0.6874050498008728, 0.8320102691650391, 0.8868710994720459, 0.9337539076805115, 0.00356597313657403]
13499
3374
5625
Model: "model_8"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_12 (S  (None, 15, 300)     0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_12[0][
                                                                 0]']                             
                                                                                                  
 permute_12 (Permute)           (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_20 (Lambda)             (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_12[0][0]']             
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_20[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_21 (Lambda)             (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_8 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_21[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_4 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_8[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_12 (Dense)               (None, 1024)         2098176     ['tf.concat_4[0][0]']            
                                                                                                  
 dense_13 (Dense)               (None, 15)           15375       ['dense_12[0][0]']               
                                                                                                  
 tf.nn.softmax_4 (TFOpLambda)   (None, 15)           0           ['dense_13[0][0]']               
                                                                                                  
 tf.expand_dims_8 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_4[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_8[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_13 (Permute)           (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_22 (Lambda)             (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_13[0][0]']             
                                                                                                  
 dense_14 (Dense)               (None, 15, 150)      22650       ['lambda_22[0][0]']              
                                                                                                  
 tf.math.reduce_mean_9 (TFOpLam  (None, 150)         0           ['dense_14[0][0]']               
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_9 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_9[0][0]']  
                                                                                                  
 tf.__operators__.getitem_13 (S  (None, 427, 300)    0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 tf.math.multiply_4 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_9[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_13[0][
                                                                 0]']                             
                                                                                                  
 permute_14 (Permute)           (None, 1024, 150)    0           ['tf.math.multiply_4[0][0]']     
                                                                                                  
 lambda_23 (Lambda)             (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_14[0][0]']             
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_23[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_24 (Lambda)             (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_4[0][0]']     
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_24[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
==================================================================================================
Total params: 31,474,320
Trainable params: 6,695,820
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
2 patience
Model: "model_9"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 150, 1024)    3330048     ['text_emb[0][0]']               
                                                                                                  
 tf.__operators__.getitem_12 (S  (None, 15, 300)     0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 0_level_label_emb (Dense)      (None, 15, 1024)     308224      ['tf.__operators__.getitem_12[0][
                                                                 0]']                             
                                                                                                  
 permute_12 (Permute)           (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_20 (Lambda)             (None, 15, 150)      0           ['0_level_label_emb[0][0]',      
                                                                  'permute_12[0][0]']             
                                                                                                  
 0_attention_layer_att_weight (  (None, 15, 150)     22650       ['lambda_20[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_21 (Lambda)             (None, 15, 1024)     0           ['0_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 tf.math.reduce_mean_8 (TFOpLam  (None, 1024)        0           ['BiLSTM[0][0]']                 
 bda)                                                                                             
                                                                                                  
 0_attention_layer_att_context   (None, 1024)        0           ['lambda_21[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 tf.concat_4 (TFOpLambda)       (None, 2048)         0           ['tf.math.reduce_mean_8[0][0]',  
                                                                  '0_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 dense_12 (Dense)               (None, 1024)         2098176     ['tf.concat_4[0][0]']            
                                                                                                  
 dense_13 (Dense)               (None, 15)           15375       ['dense_12[0][0]']               
                                                                                                  
 tf.nn.softmax_4 (TFOpLambda)   (None, 15)           0           ['dense_13[0][0]']               
                                                                                                  
 tf.expand_dims_8 (TFOpLambda)  (None, 15, 1)        0           ['tf.nn.softmax_4[0][0]']        
                                                                                                  
 0_local_layer_predict_att_emb   (None, 15, 1024)    2048        ['tf.expand_dims_8[0][0]']       
 (Dense)                                                                                          
                                                                                                  
 permute_13 (Permute)           (None, 1024, 150)    0           ['BiLSTM[0][0]']                 
                                                                                                  
 lambda_22 (Lambda)             (None, 15, 150)      0           ['0_local_layer_predict_att_emb[0
                                                                 ][0]',                           
                                                                  'permute_13[0][0]']             
                                                                                                  
 dense_14 (Dense)               (None, 15, 150)      22650       ['lambda_22[0][0]']              
                                                                                                  
 tf.math.reduce_mean_9 (TFOpLam  (None, 150)         0           ['dense_14[0][0]']               
 bda)                                                                                             
                                                                                                  
 tf.expand_dims_9 (TFOpLambda)  (None, 150, 1)       0           ['tf.math.reduce_mean_9[0][0]']  
                                                                                                  
 tf.__operators__.getitem_13 (S  (None, 427, 300)    0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 tf.math.multiply_4 (TFOpLambda  (None, 150, 1024)   0           ['BiLSTM[0][0]',                 
 )                                                                'tf.expand_dims_9[0][0]']       
                                                                                                  
 1_level_label_emb (Dense)      (None, 427, 1024)    308224      ['tf.__operators__.getitem_13[0][
                                                                 0]']                             
                                                                                                  
 permute_14 (Permute)           (None, 1024, 150)    0           ['tf.math.multiply_4[0][0]']     
                                                                                                  
 lambda_23 (Lambda)             (None, 427, 150)     0           ['1_level_label_emb[0][0]',      
                                                                  'permute_14[0][0]']             
                                                                                                  
 1_attention_layer_att_weight (  (None, 427, 150)    22650       ['lambda_23[0][0]']              
 Dense)                                                                                           
                                                                                                  
 lambda_24 (Lambda)             (None, 427, 1024)    0           ['1_attention_layer_att_weight[0]
                                                                 [0]',                            
                                                                  'tf.math.multiply_4[0][0]']     
                                                                                                  
 tf.__operators__.getitem_14 (S  (None, 427, 300)    0           ['label_emb[0][0]']              
 licingOpLambda)                                                                                  
                                                                                                  
 1_attention_layer_att_context   (None, 1024)        0           ['lambda_24[0][0]']              
 (Lambda)                                                                                         
                                                                                                  
 label_lcm_emb (Dense)          (None, 427, 1024)    308224      ['tf.__operators__.getitem_14[0][
                                                                 0]']                             
                                                                                                  
 dot_4 (Dot)                    (None, 427)          0           ['label_lcm_emb[0][0]',          
                                                                  '1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['1_attention_layer_att_context[0
                                                                 ][0]']                           
                                                                                                  
 label_sim_dict (Dense)         (None, 427)          182756      ['dot_4[0][0]']                  
                                                                                                  
 concatenate_4 (Concatenate)    (None, 854)          0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 31,965,300
Trainable params: 7,186,800
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
Epoch 1/150
27/27 [==============================] - ETA: 0s - loss: 0.4923 - lcm_precision_1k: 0.2121 - lcm_precision_2k: 0.1711 - lcm_precision_3k: 0.1458 - lcm_precision_5k: 0.1191 - lcm_recall_1k: 0.1212 - lcm_recall_2k: 0.1904 - lcm_recall_3k: 0.2384 - lcm_recall_5k: 0.3172 - lcm_f1_1k: 0.1541 - lcm_f1_2k: 0.1801 - lcm_f1_3k: 0.1808 - lcm_f1_5k: 0.1731 - lcm_accuracy_1k: 0.2121 - lcm_accuracy_2k: 0.3053 - lcm_accuracy_3k: 0.3670 - lcm_accuracy_5k: 0.4544 - lcm_hamming_loss_k: 0.0058
Epoch 00001: val_loss improved from inf to 0.41634, saving model to logs/hztdjr-labs-0604-152445/model/checkpoint_labs.h5
27/27 [==============================] - 13s 425ms/step - loss: 0.4923 - lcm_precision_1k: 0.2121 - lcm_precision_2k: 0.1711 - lcm_precision_3k: 0.1458 - lcm_precision_5k: 0.1191 - lcm_recall_1k: 0.1212 - lcm_recall_2k: 0.1904 - lcm_recall_3k: 0.2384 - lcm_recall_5k: 0.3172 - lcm_f1_1k: 0.1541 - lcm_f1_2k: 0.1801 - lcm_f1_3k: 0.1808 - lcm_f1_5k: 0.1731 - lcm_accuracy_1k: 0.2121 - lcm_accuracy_2k: 0.3053 - lcm_accuracy_3k: 0.3670 - lcm_accuracy_5k: 0.4544 - lcm_hamming_loss_k: 0.0058 - val_loss: 0.4163 - val_lcm_precision_1k: 0.3390 - val_lcm_precision_2k: 0.2783 - val_lcm_precision_3k: 0.2288 - val_lcm_precision_5k: 0.1832 - val_lcm_recall_1k: 0.2003 - val_lcm_recall_2k: 0.3152 - val_lcm_recall_3k: 0.3796 - val_lcm_recall_5k: 0.5010 - val_lcm_f1_1k: 0.2517 - val_lcm_f1_2k: 0.2955 - val_lcm_f1_3k: 0.2854 - val_lcm_f1_5k: 0.2682 - val_lcm_accuracy_1k: 0.3390 - val_lcm_accuracy_2k: 0.4746 - val_lcm_accuracy_3k: 0.5489 - val_lcm_accuracy_5k: 0.6602 - val_lcm_hamming_loss_k: 0.0052
Epoch 2/150
27/27 [==============================] - ETA: 0s - loss: 0.3691 - lcm_precision_1k: 0.4040 - lcm_precision_2k: 0.3312 - lcm_precision_3k: 0.2774 - lcm_precision_5k: 0.2131 - lcm_recall_1k: 0.2394 - lcm_recall_2k: 0.3769 - lcm_recall_3k: 0.4630 - lcm_recall_5k: 0.5770 - lcm_f1_1k: 0.3006 - lcm_f1_2k: 0.3525 - lcm_f1_3k: 0.3468 - lcm_f1_5k: 0.3112 - lcm_accuracy_1k: 0.4040 - lcm_accuracy_2k: 0.5536 - lcm_accuracy_3k: 0.6381 - lcm_accuracy_5k: 0.7343 - lcm_hamming_loss_k: 0.0049
Epoch 00002: val_loss improved from 0.41634 to 0.34562, saving model to logs/hztdjr-labs-0604-152445/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.3691 - lcm_precision_1k: 0.4040 - lcm_precision_2k: 0.3312 - lcm_precision_3k: 0.2774 - lcm_precision_5k: 0.2131 - lcm_recall_1k: 0.2394 - lcm_recall_2k: 0.3769 - lcm_recall_3k: 0.4630 - lcm_recall_5k: 0.5770 - lcm_f1_1k: 0.3006 - lcm_f1_2k: 0.3525 - lcm_f1_3k: 0.3468 - lcm_f1_5k: 0.3112 - lcm_accuracy_1k: 0.4040 - lcm_accuracy_2k: 0.5536 - lcm_accuracy_3k: 0.6381 - lcm_accuracy_5k: 0.7343 - lcm_hamming_loss_k: 0.0049 - val_loss: 0.3456 - val_lcm_precision_1k: 0.4468 - val_lcm_precision_2k: 0.3576 - val_lcm_precision_3k: 0.2927 - val_lcm_precision_5k: 0.2229 - val_lcm_recall_1k: 0.2741 - val_lcm_recall_2k: 0.4130 - val_lcm_recall_3k: 0.4978 - val_lcm_recall_5k: 0.6174 - val_lcm_f1_1k: 0.3396 - val_lcm_f1_2k: 0.3831 - val_lcm_f1_3k: 0.3684 - val_lcm_f1_5k: 0.3274 - val_lcm_accuracy_1k: 0.4468 - val_lcm_accuracy_2k: 0.5934 - val_lcm_accuracy_3k: 0.6737 - val_lcm_accuracy_5k: 0.7627 - val_lcm_hamming_loss_k: 0.0047
Epoch 3/150
27/27 [==============================] - ETA: 0s - loss: 0.3200 - lcm_precision_1k: 0.4987 - lcm_precision_2k: 0.4008 - lcm_precision_3k: 0.3313 - lcm_precision_5k: 0.2468 - lcm_recall_1k: 0.3038 - lcm_recall_2k: 0.4630 - lcm_recall_3k: 0.5609 - lcm_recall_5k: 0.6762 - lcm_f1_1k: 0.3775 - lcm_f1_2k: 0.4296 - lcm_f1_3k: 0.4164 - lcm_f1_5k: 0.3616 - lcm_accuracy_1k: 0.4987 - lcm_accuracy_2k: 0.6560 - lcm_accuracy_3k: 0.7395 - lcm_accuracy_5k: 0.8232 - lcm_hamming_loss_k: 0.0045
Epoch 00003: val_loss improved from 0.34562 to 0.31712, saving model to logs/hztdjr-labs-0604-152445/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.3200 - lcm_precision_1k: 0.4987 - lcm_precision_2k: 0.4008 - lcm_precision_3k: 0.3313 - lcm_precision_5k: 0.2468 - lcm_recall_1k: 0.3038 - lcm_recall_2k: 0.4630 - lcm_recall_3k: 0.5609 - lcm_recall_5k: 0.6762 - lcm_f1_1k: 0.3775 - lcm_f1_2k: 0.4296 - lcm_f1_3k: 0.4164 - lcm_f1_5k: 0.3616 - lcm_accuracy_1k: 0.4987 - lcm_accuracy_2k: 0.6560 - lcm_accuracy_3k: 0.7395 - lcm_accuracy_5k: 0.8232 - lcm_hamming_loss_k: 0.0045 - val_loss: 0.3171 - val_lcm_precision_1k: 0.5039 - val_lcm_precision_2k: 0.4028 - val_lcm_precision_3k: 0.3307 - val_lcm_precision_5k: 0.2424 - val_lcm_recall_1k: 0.3112 - val_lcm_recall_2k: 0.4719 - val_lcm_recall_3k: 0.5664 - val_lcm_recall_5k: 0.6756 - val_lcm_f1_1k: 0.3846 - val_lcm_f1_2k: 0.4344 - val_lcm_f1_3k: 0.4174 - val_lcm_f1_5k: 0.3567 - val_lcm_accuracy_1k: 0.5039 - val_lcm_accuracy_2k: 0.6612 - val_lcm_accuracy_3k: 0.7378 - val_lcm_accuracy_5k: 0.8163 - val_lcm_hamming_loss_k: 0.0044
Epoch 4/150
27/27 [==============================] - ETA: 0s - loss: 0.2964 - lcm_precision_1k: 0.5438 - lcm_precision_2k: 0.4378 - lcm_precision_3k: 0.3593 - lcm_precision_5k: 0.2624 - lcm_recall_1k: 0.3337 - lcm_recall_2k: 0.5107 - lcm_recall_3k: 0.6109 - lcm_recall_5k: 0.7212 - lcm_f1_1k: 0.4135 - lcm_f1_2k: 0.4714 - lcm_f1_3k: 0.4524 - lcm_f1_5k: 0.3848 - lcm_accuracy_1k: 0.5438 - lcm_accuracy_2k: 0.7091 - lcm_accuracy_3k: 0.7880 - lcm_accuracy_5k: 0.8604 - lcm_hamming_loss_k: 0.0043 ETA: 7s - loss: 0.3014 - lcm_precision_1k: 0.5400 - lcm_precision_2k: 0.4341 - lcm_precision_3k: 0.3587 - lcm_precision_5k: 0.2613 - lcm_recall_1k: 0.3277 - lcm_recall_2k: 0.5041 - lcm_recall_3k: 0.6075 - lcm_recall_5k: 0.7156 - lcm_f1_1k: 0.4078 - lcm_f1_2k: 0.4664 - lcm_f1_3k: 0.4510 - lcm_f1_5k: 0.3828 - lcm_accuracy_1k: 0.5400 - lcm_accuracy_2k: 0.7017 - lcm_accuracy_3k: 0.7896 - lcm_ac
Epoch 00004: val_loss improved from 0.31712 to 0.30248, saving model to logs/hztdjr-labs-0604-152445/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2964 - lcm_precision_1k: 0.5438 - lcm_precision_2k: 0.4378 - lcm_precision_3k: 0.3593 - lcm_precision_5k: 0.2624 - lcm_recall_1k: 0.3337 - lcm_recall_2k: 0.5107 - lcm_recall_3k: 0.6109 - lcm_recall_5k: 0.7212 - lcm_f1_1k: 0.4135 - lcm_f1_2k: 0.4714 - lcm_f1_3k: 0.4524 - lcm_f1_5k: 0.3848 - lcm_accuracy_1k: 0.5438 - lcm_accuracy_2k: 0.7091 - lcm_accuracy_3k: 0.7880 - lcm_accuracy_5k: 0.8604 - lcm_hamming_loss_k: 0.0043 - val_loss: 0.3025 - val_lcm_precision_1k: 0.5340 - val_lcm_precision_2k: 0.4210 - val_lcm_precision_3k: 0.3425 - val_lcm_precision_5k: 0.2525 - val_lcm_recall_1k: 0.3311 - val_lcm_recall_2k: 0.4964 - val_lcm_recall_3k: 0.5924 - val_lcm_recall_5k: 0.7066 - val_lcm_f1_1k: 0.4087 - val_lcm_f1_2k: 0.4555 - val_lcm_f1_3k: 0.4339 - val_lcm_f1_5k: 0.3720 - val_lcm_accuracy_1k: 0.5340 - val_lcm_accuracy_2k: 0.6827 - val_lcm_accuracy_3k: 0.7602 - val_lcm_accuracy_5k: 0.8418 - val_lcm_hamming_loss_k: 0.0043
Epoch 5/150
27/27 [==============================] - ETA: 0s - loss: 0.2805 - lcm_precision_1k: 0.5805 - lcm_precision_2k: 0.4618 - lcm_precision_3k: 0.3761 - lcm_precision_5k: 0.2725 - lcm_recall_1k: 0.3606 - lcm_recall_2k: 0.5431 - lcm_recall_3k: 0.6420 - lcm_recall_5k: 0.7501 - lcm_f1_1k: 0.4448 - lcm_f1_2k: 0.4991 - lcm_f1_3k: 0.4743 - lcm_f1_5k: 0.3997 - lcm_accuracy_1k: 0.5805 - lcm_accuracy_2k: 0.7447 - lcm_accuracy_3k: 0.8176 - lcm_accuracy_5k: 0.8839 - lcm_hamming_loss_k: 0.00 - ETA: 0s - loss: 0.2805 - lcm_precision_1k: 0.5802 - lcm_precision_2k: 0.4632 - lcm_precision_3k: 0.3767 - lcm_precision_5k: 0.2726 - lcm_recall_1k: 0.3597 - lcm_recall_2k: 0.5442 - lcm_recall_3k: 0.6427 - lcm_recall_5k: 0.7504 - lcm_f1_1k: 0.4440 - lcm_f1_2k: 0.5004 - lcm_f1_3k: 0.4749 - lcm_f1_5k: 0.3999 - lcm_accuracy_1k: 0.5802 - lcm_accuracy_2k: 0.7452 - lcm_accuracy_3k: 0.8180 - lcm_accuracy_5k: 0.8845 - lcm_hamming_loss_k: 0.0041
Epoch 00005: val_loss improved from 0.30248 to 0.29453, saving model to logs/hztdjr-labs-0604-152445/model/checkpoint_labs.h5
27/27 [==============================] - 11s 426ms/step - loss: 0.2805 - lcm_precision_1k: 0.5802 - lcm_precision_2k: 0.4632 - lcm_precision_3k: 0.3767 - lcm_precision_5k: 0.2726 - lcm_recall_1k: 0.3597 - lcm_recall_2k: 0.5442 - lcm_recall_3k: 0.6427 - lcm_recall_5k: 0.7504 - lcm_f1_1k: 0.4440 - lcm_f1_2k: 0.5004 - lcm_f1_3k: 0.4749 - lcm_f1_5k: 0.3999 - lcm_accuracy_1k: 0.5802 - lcm_accuracy_2k: 0.7452 - lcm_accuracy_3k: 0.8180 - lcm_accuracy_5k: 0.8845 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2945 - val_lcm_precision_1k: 0.5569 - val_lcm_precision_2k: 0.4406 - val_lcm_precision_3k: 0.3573 - val_lcm_precision_5k: 0.2578 - val_lcm_recall_1k: 0.3463 - val_lcm_recall_2k: 0.5187 - val_lcm_recall_3k: 0.6184 - val_lcm_recall_5k: 0.7210 - val_lcm_f1_1k: 0.4269 - val_lcm_f1_2k: 0.4763 - val_lcm_f1_3k: 0.4527 - val_lcm_f1_5k: 0.3797 - val_lcm_accuracy_1k: 0.5569 - val_lcm_accuracy_2k: 0.7108 - val_lcm_accuracy_3k: 0.7843 - val_lcm_accuracy_5k: 0.8527 - val_lcm_hamming_loss_k: 0.0041
Epoch 6/150
27/27 [==============================] - ETA: 0s - loss: 0.2693 - lcm_precision_1k: 0.6075 - lcm_precision_2k: 0.4797 - lcm_precision_3k: 0.3897 - lcm_precision_5k: 0.2807 - lcm_recall_1k: 0.3792 - lcm_recall_2k: 0.5632 - lcm_recall_3k: 0.6643 - lcm_recall_5k: 0.7711 - lcm_f1_1k: 0.4669 - lcm_f1_2k: 0.5181 - lcm_f1_3k: 0.4912 - lcm_f1_5k: 0.4116 - lcm_accuracy_1k: 0.6075 - lcm_accuracy_2k: 0.7660 - lcm_accuracy_3k: 0.8363 - lcm_accuracy_5k: 0.8988 - lcm_hamming_loss_k: 0.0040
Epoch 00006: val_loss improved from 0.29453 to 0.28899, saving model to logs/hztdjr-labs-0604-152445/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.2693 - lcm_precision_1k: 0.6075 - lcm_precision_2k: 0.4797 - lcm_precision_3k: 0.3897 - lcm_precision_5k: 0.2807 - lcm_recall_1k: 0.3792 - lcm_recall_2k: 0.5632 - lcm_recall_3k: 0.6643 - lcm_recall_5k: 0.7711 - lcm_f1_1k: 0.4669 - lcm_f1_2k: 0.5181 - lcm_f1_3k: 0.4912 - lcm_f1_5k: 0.4116 - lcm_accuracy_1k: 0.6075 - lcm_accuracy_2k: 0.7660 - lcm_accuracy_3k: 0.8363 - lcm_accuracy_5k: 0.8988 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2890 - val_lcm_precision_1k: 0.5584 - val_lcm_precision_2k: 0.4428 - val_lcm_precision_3k: 0.3579 - val_lcm_precision_5k: 0.2608 - val_lcm_recall_1k: 0.3495 - val_lcm_recall_2k: 0.5246 - val_lcm_recall_3k: 0.6200 - val_lcm_recall_5k: 0.7271 - val_lcm_f1_1k: 0.4298 - val_lcm_f1_2k: 0.4801 - val_lcm_f1_3k: 0.4536 - val_lcm_f1_5k: 0.3838 - val_lcm_accuracy_1k: 0.5584 - val_lcm_accuracy_2k: 0.7147 - val_lcm_accuracy_3k: 0.7873 - val_lcm_accuracy_5k: 0.8560 - val_lcm_hamming_loss_k: 0.0041
Epoch 7/150
27/27 [==============================] - ETA: 0s - loss: 0.2603 - lcm_precision_1k: 0.6280 - lcm_precision_2k: 0.4962 - lcm_precision_3k: 0.3994 - lcm_precision_5k: 0.2874 - lcm_recall_1k: 0.3943 - lcm_recall_2k: 0.5843 - lcm_recall_3k: 0.6822 - lcm_recall_5k: 0.7908 - lcm_f1_1k: 0.4844 - lcm_f1_2k: 0.5366 - lcm_f1_3k: 0.5038 - lcm_f1_5k: 0.4215 - lcm_accuracy_1k: 0.6280 - lcm_accuracy_2k: 0.7875 - lcm_accuracy_3k: 0.8527 - lcm_accuracy_5k: 0.9120 - lcm_hamming_loss_k: 0.0039
Epoch 00007: val_loss improved from 0.28899 to 0.28350, saving model to logs/hztdjr-labs-0604-152445/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2603 - lcm_precision_1k: 0.6280 - lcm_precision_2k: 0.4962 - lcm_precision_3k: 0.3994 - lcm_precision_5k: 0.2874 - lcm_recall_1k: 0.3943 - lcm_recall_2k: 0.5843 - lcm_recall_3k: 0.6822 - lcm_recall_5k: 0.7908 - lcm_f1_1k: 0.4844 - lcm_f1_2k: 0.5366 - lcm_f1_3k: 0.5038 - lcm_f1_5k: 0.4215 - lcm_accuracy_1k: 0.6280 - lcm_accuracy_2k: 0.7875 - lcm_accuracy_3k: 0.8527 - lcm_accuracy_5k: 0.9120 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2835 - val_lcm_precision_1k: 0.5764 - val_lcm_precision_2k: 0.4552 - val_lcm_precision_3k: 0.3654 - val_lcm_precision_5k: 0.2645 - val_lcm_recall_1k: 0.3592 - val_lcm_recall_2k: 0.5372 - val_lcm_recall_3k: 0.6324 - val_lcm_recall_5k: 0.7395 - val_lcm_f1_1k: 0.4424 - val_lcm_f1_2k: 0.4927 - val_lcm_f1_3k: 0.4630 - val_lcm_f1_5k: 0.3895 - val_lcm_accuracy_1k: 0.5764 - val_lcm_accuracy_2k: 0.7309 - val_lcm_accuracy_3k: 0.8005 - val_lcm_accuracy_5k: 0.8663 - val_lcm_hamming_loss_k: 0.0041
Epoch 8/150
27/27 [==============================] - ETA: 0s - loss: 0.2530 - lcm_precision_1k: 0.6460 - lcm_precision_2k: 0.5069 - lcm_precision_3k: 0.4095 - lcm_precision_5k: 0.2925 - lcm_recall_1k: 0.4051 - lcm_recall_2k: 0.5965 - lcm_recall_3k: 0.6992 - lcm_recall_5k: 0.8029 - lcm_f1_1k: 0.4978 - lcm_f1_2k: 0.5480 - lcm_f1_3k: 0.5164 - lcm_f1_5k: 0.4287 - lcm_accuracy_1k: 0.6460 - lcm_accuracy_2k: 0.8007 - lcm_accuracy_3k: 0.8680 - lcm_accuracy_5k: 0.9214 - lcm_hamming_loss_k: 0.0038 ETA: 3s - loss: 0.2528 - lcm_precision_1k: 0.6454 - lcm_precision_2k: 0.5066 - lcm_precision_3k: 0.4099 - lcm_precision_5k: 0.2927 - lcm_recall_1k: 0.4071 - lcm_recall_2k: 0.5980 - lcm_recall_3k: 0.7021 - lcm_recall_5k: 0.8060 - lcm_f1_1k: 0.4992 - lcm_f1_2k: 0.5485 - lcm_f1_3k: 0.5176 - lcm_f1_5k: 0.4294 - lcm_accuracy_1k: 0.6454 - lcm_accuracy_2k: 0.7996 - lcm_accuracy_3k: 0.8699 - lcm_accuracy_5k: 0.9232 - lcm_
Epoch 00008: val_loss did not improve from 0.28350
27/27 [==============================] - 11s 393ms/step - loss: 0.2530 - lcm_precision_1k: 0.6460 - lcm_precision_2k: 0.5069 - lcm_precision_3k: 0.4095 - lcm_precision_5k: 0.2925 - lcm_recall_1k: 0.4051 - lcm_recall_2k: 0.5965 - lcm_recall_3k: 0.6992 - lcm_recall_5k: 0.8029 - lcm_f1_1k: 0.4978 - lcm_f1_2k: 0.5480 - lcm_f1_3k: 0.5164 - lcm_f1_5k: 0.4287 - lcm_accuracy_1k: 0.6460 - lcm_accuracy_2k: 0.8007 - lcm_accuracy_3k: 0.8680 - lcm_accuracy_5k: 0.9214 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2847 - val_lcm_precision_1k: 0.5809 - val_lcm_precision_2k: 0.4581 - val_lcm_precision_3k: 0.3684 - val_lcm_precision_5k: 0.2641 - val_lcm_recall_1k: 0.3637 - val_lcm_recall_2k: 0.5435 - val_lcm_recall_3k: 0.6355 - val_lcm_recall_5k: 0.7370 - val_lcm_f1_1k: 0.4472 - val_lcm_f1_2k: 0.4970 - val_lcm_f1_3k: 0.4662 - val_lcm_f1_5k: 0.3888 - val_lcm_accuracy_1k: 0.5809 - val_lcm_accuracy_2k: 0.7377 - val_lcm_accuracy_3k: 0.7967 - val_lcm_accuracy_5k: 0.8628 - val_lcm_hamming_loss_k: 0.0040
Epoch 9/150
27/27 [==============================] - ETA: 0s - loss: 0.2438 - lcm_precision_1k: 0.6646 - lcm_precision_2k: 0.5206 - lcm_precision_3k: 0.4200 - lcm_precision_5k: 0.2985 - lcm_recall_1k: 0.4183 - lcm_recall_2k: 0.6135 - lcm_recall_3k: 0.7175 - lcm_recall_5k: 0.8196 - lcm_f1_1k: 0.5134 - lcm_f1_2k: 0.5632 - lcm_f1_3k: 0.5298 - lcm_f1_5k: 0.4375 - lcm_accuracy_1k: 0.6646 - lcm_accuracy_2k: 0.8166 - lcm_accuracy_3k: 0.8820 - lcm_accuracy_5k: 0.9338 - lcm_hamming_loss_k: 0.0037
Epoch 00009: val_loss improved from 0.28350 to 0.27879, saving model to logs/hztdjr-labs-0604-152445/model/checkpoint_labs.h5
27/27 [==============================] - 11s 428ms/step - loss: 0.2438 - lcm_precision_1k: 0.6646 - lcm_precision_2k: 0.5206 - lcm_precision_3k: 0.4200 - lcm_precision_5k: 0.2985 - lcm_recall_1k: 0.4183 - lcm_recall_2k: 0.6135 - lcm_recall_3k: 0.7175 - lcm_recall_5k: 0.8196 - lcm_f1_1k: 0.5134 - lcm_f1_2k: 0.5632 - lcm_f1_3k: 0.5298 - lcm_f1_5k: 0.4375 - lcm_accuracy_1k: 0.6646 - lcm_accuracy_2k: 0.8166 - lcm_accuracy_3k: 0.8820 - lcm_accuracy_5k: 0.9338 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2788 - val_lcm_precision_1k: 0.5923 - val_lcm_precision_2k: 0.4683 - val_lcm_precision_3k: 0.3730 - val_lcm_precision_5k: 0.2665 - val_lcm_recall_1k: 0.3710 - val_lcm_recall_2k: 0.5556 - val_lcm_recall_3k: 0.6478 - val_lcm_recall_5k: 0.7453 - val_lcm_f1_1k: 0.4560 - val_lcm_f1_2k: 0.5080 - val_lcm_f1_3k: 0.4732 - val_lcm_f1_5k: 0.3924 - val_lcm_accuracy_1k: 0.5923 - val_lcm_accuracy_2k: 0.7531 - val_lcm_accuracy_3k: 0.8144 - val_lcm_accuracy_5k: 0.8709 - val_lcm_hamming_loss_k: 0.0040
Epoch 10/150
27/27 [==============================] - ETA: 0s - loss: 0.2366 - lcm_precision_1k: 0.6780 - lcm_precision_2k: 0.5319 - lcm_precision_3k: 0.4272 - lcm_precision_5k: 0.3026 - lcm_recall_1k: 0.4272 - lcm_recall_2k: 0.6257 - lcm_recall_3k: 0.7291 - lcm_recall_5k: 0.8299 - lcm_f1_1k: 0.5241 - lcm_f1_2k: 0.5749 - lcm_f1_3k: 0.5387 - lcm_f1_5k: 0.4435 - lcm_accuracy_1k: 0.6780 - lcm_accuracy_2k: 0.8289 - lcm_accuracy_3k: 0.8914 - lcm_accuracy_5k: 0.9389 - lcm_hamming_loss_k: 0.0036
Epoch 00010: val_loss did not improve from 0.27879
27/27 [==============================] - 11s 393ms/step - loss: 0.2366 - lcm_precision_1k: 0.6780 - lcm_precision_2k: 0.5319 - lcm_precision_3k: 0.4272 - lcm_precision_5k: 0.3026 - lcm_recall_1k: 0.4272 - lcm_recall_2k: 0.6257 - lcm_recall_3k: 0.7291 - lcm_recall_5k: 0.8299 - lcm_f1_1k: 0.5241 - lcm_f1_2k: 0.5749 - lcm_f1_3k: 0.5387 - lcm_f1_5k: 0.4435 - lcm_accuracy_1k: 0.6780 - lcm_accuracy_2k: 0.8289 - lcm_accuracy_3k: 0.8914 - lcm_accuracy_5k: 0.9389 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2799 - val_lcm_precision_1k: 0.5966 - val_lcm_precision_2k: 0.4693 - val_lcm_precision_3k: 0.3751 - val_lcm_precision_5k: 0.2675 - val_lcm_recall_1k: 0.3748 - val_lcm_recall_2k: 0.5579 - val_lcm_recall_3k: 0.6478 - val_lcm_recall_5k: 0.7451 - val_lcm_f1_1k: 0.4603 - val_lcm_f1_2k: 0.5096 - val_lcm_f1_3k: 0.4749 - val_lcm_f1_5k: 0.3935 - val_lcm_accuracy_1k: 0.5966 - val_lcm_accuracy_2k: 0.7512 - val_lcm_accuracy_3k: 0.8075 - val_lcm_accuracy_5k: 0.8664 - val_lcm_hamming_loss_k: 0.0040
Epoch 11/150
27/27 [==============================] - ETA: 0s - loss: 0.2321 - lcm_precision_1k: 0.6917 - lcm_precision_2k: 0.5406 - lcm_precision_3k: 0.4359 - lcm_precision_5k: 0.3063 - lcm_recall_1k: 0.4370 - lcm_recall_2k: 0.6381 - lcm_recall_3k: 0.7430 - lcm_recall_5k: 0.8400 - lcm_f1_1k: 0.5355 - lcm_f1_2k: 0.5853 - lcm_f1_3k: 0.5494 - lcm_f1_5k: 0.4489 - lcm_accuracy_1k: 0.6917 - lcm_accuracy_2k: 0.8413 - lcm_accuracy_3k: 0.9031 - lcm_accuracy_5k: 0.9463 - lcm_hamming_loss_k: 0.0036 ETA: 2s - loss: 0.2324 - lcm_precision_1k: 0.6947 - lcm_precision_2k: 0.5425 - lcm_precision_3k: 0.4374 - lcm_precision_5k: 0.3073 - lcm_recall_1k: 0.4395 - lcm_recall_2k: 0.6405 - lcm_recall_3k: 0.7453 - lcm_recall_5k: 0.8408 - lcm_f1_1k: 0.5383 - lcm_f1_2k: 0.5874 - lcm_f1_3k: 0.5513 - lcm_f1_5k: 0.4501 - lcm_accuracy_1k: 0.6947 - lcm_accuracy_2k: 0.8448 - lcm_accuracy_3k: 0.9058 - lcm_accuracy_5k: 0.9468 - lcm_hamming_loss_k: 0. - ETA: 2s - loss: 0.2317 - lcm_precision_1k: 0.6958 - lcm_precision_2k: 0.5432 - lcm_precision_3k: 0.4379 - lcm_precision_5k: 0.3075 - lcm_recall_1k: 0.4399 - lcm_recall_2k: 0.6410 - lcm_recall_3k: 0.7460 - lcm_recall_5k: 0.8415 - lcm_f1_1k: 0.5390 - lcm_f1_2k: 0.5880 - lcm_f1_3k: 0.5518 - lcm_f1_5k: 0.4504 - lcm_accuracy_1k: 0.6958 - lcm_accuracy_2k: 0.8446 - lcm_accuracy_3k: 0.9056 - lcm_accuracy_5k: 0.9469 - lcm_hamming_
Epoch 00011: val_loss improved from 0.27879 to 0.27515, saving model to logs/hztdjr-labs-0604-152445/model/checkpoint_labs.h5
27/27 [==============================] - 11s 428ms/step - loss: 0.2321 - lcm_precision_1k: 0.6917 - lcm_precision_2k: 0.5406 - lcm_precision_3k: 0.4359 - lcm_precision_5k: 0.3063 - lcm_recall_1k: 0.4370 - lcm_recall_2k: 0.6381 - lcm_recall_3k: 0.7430 - lcm_recall_5k: 0.8400 - lcm_f1_1k: 0.5355 - lcm_f1_2k: 0.5853 - lcm_f1_3k: 0.5494 - lcm_f1_5k: 0.4489 - lcm_accuracy_1k: 0.6917 - lcm_accuracy_2k: 0.8413 - lcm_accuracy_3k: 0.9031 - lcm_accuracy_5k: 0.9463 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2752 - val_lcm_precision_1k: 0.5954 - val_lcm_precision_2k: 0.4720 - val_lcm_precision_3k: 0.3810 - val_lcm_precision_5k: 0.2698 - val_lcm_recall_1k: 0.3748 - val_lcm_recall_2k: 0.5586 - val_lcm_recall_3k: 0.6561 - val_lcm_recall_5k: 0.7515 - val_lcm_f1_1k: 0.4599 - val_lcm_f1_2k: 0.5115 - val_lcm_f1_3k: 0.4819 - val_lcm_f1_5k: 0.3969 - val_lcm_accuracy_1k: 0.5954 - val_lcm_accuracy_2k: 0.7496 - val_lcm_accuracy_3k: 0.8164 - val_lcm_accuracy_5k: 0.8745 - val_lcm_hamming_loss_k: 0.0040
Epoch 12/150
27/27 [==============================] - ETA: 0s - loss: 0.2246 - lcm_precision_1k: 0.7054 - lcm_precision_2k: 0.5489 - lcm_precision_3k: 0.4411 - lcm_precision_5k: 0.3113 - lcm_recall_1k: 0.4477 - lcm_recall_2k: 0.6476 - lcm_recall_3k: 0.7535 - lcm_recall_5k: 0.8524 - lcm_f1_1k: 0.5477 - lcm_f1_2k: 0.5941 - lcm_f1_3k: 0.5564 - lcm_f1_5k: 0.4560 - lcm_accuracy_1k: 0.7054 - lcm_accuracy_2k: 0.8480 - lcm_accuracy_3k: 0.9086 - lcm_accuracy_5k: 0.9515 - lcm_hamming_loss_k: 0.0035
Epoch 00012: val_loss improved from 0.27515 to 0.27184, saving model to logs/hztdjr-labs-0604-152445/model/checkpoint_labs.h5
27/27 [==============================] - 12s 430ms/step - loss: 0.2246 - lcm_precision_1k: 0.7054 - lcm_precision_2k: 0.5489 - lcm_precision_3k: 0.4411 - lcm_precision_5k: 0.3113 - lcm_recall_1k: 0.4477 - lcm_recall_2k: 0.6476 - lcm_recall_3k: 0.7535 - lcm_recall_5k: 0.8524 - lcm_f1_1k: 0.5477 - lcm_f1_2k: 0.5941 - lcm_f1_3k: 0.5564 - lcm_f1_5k: 0.4560 - lcm_accuracy_1k: 0.7054 - lcm_accuracy_2k: 0.8480 - lcm_accuracy_3k: 0.9086 - lcm_accuracy_5k: 0.9515 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2718 - val_lcm_precision_1k: 0.6025 - val_lcm_precision_2k: 0.4731 - val_lcm_precision_3k: 0.3801 - val_lcm_precision_5k: 0.2693 - val_lcm_recall_1k: 0.3798 - val_lcm_recall_2k: 0.5630 - val_lcm_recall_3k: 0.6576 - val_lcm_recall_5k: 0.7508 - val_lcm_f1_1k: 0.4658 - val_lcm_f1_2k: 0.5140 - val_lcm_f1_3k: 0.4816 - val_lcm_f1_5k: 0.3962 - val_lcm_accuracy_1k: 0.6025 - val_lcm_accuracy_2k: 0.7543 - val_lcm_accuracy_3k: 0.8155 - val_lcm_accuracy_5k: 0.8711 - val_lcm_hamming_loss_k: 0.0039
Epoch 13/150
27/27 [==============================] - ETA: 0s - loss: 0.2179 - lcm_precision_1k: 0.7199 - lcm_precision_2k: 0.5626 - lcm_precision_3k: 0.4515 - lcm_precision_5k: 0.3169 - lcm_recall_1k: 0.4579 - lcm_recall_2k: 0.6636 - lcm_recall_3k: 0.7680 - lcm_recall_5k: 0.8654 - lcm_f1_1k: 0.5597 - lcm_f1_2k: 0.6089 - lcm_f1_3k: 0.5686 - lcm_f1_5k: 0.4639 - lcm_accuracy_1k: 0.7199 - lcm_accuracy_2k: 0.8617 - lcm_accuracy_3k: 0.9189 - lcm_accuracy_5k: 0.9590 - lcm_hamming_loss_k: 0.0035
Epoch 00013: val_loss did not improve from 0.27184
27/27 [==============================] - 11s 393ms/step - loss: 0.2179 - lcm_precision_1k: 0.7199 - lcm_precision_2k: 0.5626 - lcm_precision_3k: 0.4515 - lcm_precision_5k: 0.3169 - lcm_recall_1k: 0.4579 - lcm_recall_2k: 0.6636 - lcm_recall_3k: 0.7680 - lcm_recall_5k: 0.8654 - lcm_f1_1k: 0.5597 - lcm_f1_2k: 0.6089 - lcm_f1_3k: 0.5686 - lcm_f1_5k: 0.4639 - lcm_accuracy_1k: 0.7199 - lcm_accuracy_2k: 0.8617 - lcm_accuracy_3k: 0.9189 - lcm_accuracy_5k: 0.9590 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2728 - val_lcm_precision_1k: 0.6012 - val_lcm_precision_2k: 0.4783 - val_lcm_precision_3k: 0.3839 - val_lcm_precision_5k: 0.2710 - val_lcm_recall_1k: 0.3772 - val_lcm_recall_2k: 0.5675 - val_lcm_recall_3k: 0.6619 - val_lcm_recall_5k: 0.7550 - val_lcm_f1_1k: 0.4634 - val_lcm_f1_2k: 0.5189 - val_lcm_f1_3k: 0.4857 - val_lcm_f1_5k: 0.3987 - val_lcm_accuracy_1k: 0.6012 - val_lcm_accuracy_2k: 0.7600 - val_lcm_accuracy_3k: 0.8205 - val_lcm_accuracy_5k: 0.8763 - val_lcm_hamming_loss_k: 0.0039
Epoch 14/150
27/27 [==============================] - ETA: 0s - loss: 0.2126 - lcm_precision_1k: 0.7355 - lcm_precision_2k: 0.5759 - lcm_precision_3k: 0.4580 - lcm_precision_5k: 0.3195 - lcm_recall_1k: 0.4685 - lcm_recall_2k: 0.6784 - lcm_recall_3k: 0.7794 - lcm_recall_5k: 0.8719 - lcm_f1_1k: 0.5723 - lcm_f1_2k: 0.6229 - lcm_f1_3k: 0.5769 - lcm_f1_5k: 0.4676 - lcm_accuracy_1k: 0.7355 - lcm_accuracy_2k: 0.8762 - lcm_accuracy_3k: 0.9263 - lcm_accuracy_5k: 0.9615 - lcm_hamming_loss_k: 0.0034
Epoch 00014: val_loss improved from 0.27184 to 0.27019, saving model to logs/hztdjr-labs-0604-152445/model/checkpoint_labs.h5
27/27 [==============================] - 11s 425ms/step - loss: 0.2126 - lcm_precision_1k: 0.7355 - lcm_precision_2k: 0.5759 - lcm_precision_3k: 0.4580 - lcm_precision_5k: 0.3195 - lcm_recall_1k: 0.4685 - lcm_recall_2k: 0.6784 - lcm_recall_3k: 0.7794 - lcm_recall_5k: 0.8719 - lcm_f1_1k: 0.5723 - lcm_f1_2k: 0.6229 - lcm_f1_3k: 0.5769 - lcm_f1_5k: 0.4676 - lcm_accuracy_1k: 0.7355 - lcm_accuracy_2k: 0.8762 - lcm_accuracy_3k: 0.9263 - lcm_accuracy_5k: 0.9615 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2702 - val_lcm_precision_1k: 0.6063 - val_lcm_precision_2k: 0.4772 - val_lcm_precision_3k: 0.3836 - val_lcm_precision_5k: 0.2724 - val_lcm_recall_1k: 0.3835 - val_lcm_recall_2k: 0.5679 - val_lcm_recall_3k: 0.6633 - val_lcm_recall_5k: 0.7589 - val_lcm_f1_1k: 0.4696 - val_lcm_f1_2k: 0.5184 - val_lcm_f1_3k: 0.4859 - val_lcm_f1_5k: 0.4008 - val_lcm_accuracy_1k: 0.6063 - val_lcm_accuracy_2k: 0.7620 - val_lcm_accuracy_3k: 0.8228 - val_lcm_accuracy_5k: 0.8786 - val_lcm_hamming_loss_k: 0.0039
Epoch 15/150
27/27 [==============================] - ETA: 0s - loss: 0.2050 - lcm_precision_1k: 0.7496 - lcm_precision_2k: 0.5858 - lcm_precision_3k: 0.4657 - lcm_precision_5k: 0.3256 - lcm_recall_1k: 0.4783 - lcm_recall_2k: 0.6904 - lcm_recall_3k: 0.7902 - lcm_recall_5k: 0.8864 - lcm_f1_1k: 0.5839 - lcm_f1_2k: 0.6338 - lcm_f1_3k: 0.5860 - lcm_f1_5k: 0.4763 - lcm_accuracy_1k: 0.7496 - lcm_accuracy_2k: 0.8873 - lcm_accuracy_3k: 0.9346 - lcm_accuracy_5k: 0.9703 - lcm_hamming_loss_k: 0.0033
Epoch 00015: val_loss improved from 0.27019 to 0.26810, saving model to logs/hztdjr-labs-0604-152445/model/checkpoint_labs.h5
27/27 [==============================] - 11s 427ms/step - loss: 0.2050 - lcm_precision_1k: 0.7496 - lcm_precision_2k: 0.5858 - lcm_precision_3k: 0.4657 - lcm_precision_5k: 0.3256 - lcm_recall_1k: 0.4783 - lcm_recall_2k: 0.6904 - lcm_recall_3k: 0.7902 - lcm_recall_5k: 0.8864 - lcm_f1_1k: 0.5839 - lcm_f1_2k: 0.6338 - lcm_f1_3k: 0.5860 - lcm_f1_5k: 0.4763 - lcm_accuracy_1k: 0.7496 - lcm_accuracy_2k: 0.8873 - lcm_accuracy_3k: 0.9346 - lcm_accuracy_5k: 0.9703 - lcm_hamming_loss_k: 0.0033 - val_loss: 0.2681 - val_lcm_precision_1k: 0.6115 - val_lcm_precision_2k: 0.4869 - val_lcm_precision_3k: 0.3874 - val_lcm_precision_5k: 0.2735 - val_lcm_recall_1k: 0.3868 - val_lcm_recall_2k: 0.5790 - val_lcm_recall_3k: 0.6716 - val_lcm_recall_5k: 0.7669 - val_lcm_f1_1k: 0.4737 - val_lcm_f1_2k: 0.5288 - val_lcm_f1_3k: 0.4912 - val_lcm_f1_5k: 0.4031 - val_lcm_accuracy_1k: 0.6115 - val_lcm_accuracy_2k: 0.7660 - val_lcm_accuracy_3k: 0.8268 - val_lcm_accuracy_5k: 0.8856 - val_lcm_hamming_loss_k: 0.0039
Epoch 16/150
27/27 [==============================] - ETA: 0s - loss: 0.1991 - lcm_precision_1k: 0.7651 - lcm_precision_2k: 0.5955 - lcm_precision_3k: 0.4730 - lcm_precision_5k: 0.3276 - lcm_recall_1k: 0.4907 - lcm_recall_2k: 0.7023 - lcm_recall_3k: 0.8022 - lcm_recall_5k: 0.8918 - lcm_f1_1k: 0.5978 - lcm_f1_2k: 0.6444 - lcm_f1_3k: 0.5950 - lcm_f1_5k: 0.4792 - lcm_accuracy_1k: 0.7651 - lcm_accuracy_2k: 0.8948 - lcm_accuracy_3k: 0.9404 - lcm_accuracy_5k: 0.9711 - lcm_hamming_loss_k: 0.0032
Epoch 00016: val_loss did not improve from 0.26810
27/27 [==============================] - 11s 392ms/step - loss: 0.1991 - lcm_precision_1k: 0.7651 - lcm_precision_2k: 0.5955 - lcm_precision_3k: 0.4730 - lcm_precision_5k: 0.3276 - lcm_recall_1k: 0.4907 - lcm_recall_2k: 0.7023 - lcm_recall_3k: 0.8022 - lcm_recall_5k: 0.8918 - lcm_f1_1k: 0.5978 - lcm_f1_2k: 0.6444 - lcm_f1_3k: 0.5950 - lcm_f1_5k: 0.4792 - lcm_accuracy_1k: 0.7651 - lcm_accuracy_2k: 0.8948 - lcm_accuracy_3k: 0.9404 - lcm_accuracy_5k: 0.9711 - lcm_hamming_loss_k: 0.0032 - val_loss: 0.2699 - val_lcm_precision_1k: 0.6070 - val_lcm_precision_2k: 0.4825 - val_lcm_precision_3k: 0.3866 - val_lcm_precision_5k: 0.2730 - val_lcm_recall_1k: 0.3827 - val_lcm_recall_2k: 0.5736 - val_lcm_recall_3k: 0.6672 - val_lcm_recall_5k: 0.7626 - val_lcm_f1_1k: 0.4693 - val_lcm_f1_2k: 0.5239 - val_lcm_f1_3k: 0.4893 - val_lcm_f1_5k: 0.4020 - val_lcm_accuracy_1k: 0.6070 - val_lcm_accuracy_2k: 0.7651 - val_lcm_accuracy_3k: 0.8240 - val_lcm_accuracy_5k: 0.8857 - val_lcm_hamming_loss_k: 0.0039
Epoch 17/150
27/27 [==============================] - ETA: 0s - loss: 0.1931 - lcm_precision_1k: 0.7798 - lcm_precision_2k: 0.6081 - lcm_precision_3k: 0.4831 - lcm_precision_5k: 0.3340 - lcm_recall_1k: 0.4978 - lcm_recall_2k: 0.7128 - lcm_recall_3k: 0.8142 - lcm_recall_5k: 0.9037 - lcm_f1_1k: 0.6076 - lcm_f1_2k: 0.6562 - lcm_f1_3k: 0.6063 - lcm_f1_5k: 0.4877 - lcm_accuracy_1k: 0.7798 - lcm_accuracy_2k: 0.9042 - lcm_accuracy_3k: 0.9465 - lcm_accuracy_5k: 0.9761 - lcm_hamming_loss_k: 0.0032
Epoch 00017: val_loss did not improve from 0.26810
27/27 [==============================] - 10s 388ms/step - loss: 0.1931 - lcm_precision_1k: 0.7798 - lcm_precision_2k: 0.6081 - lcm_precision_3k: 0.4831 - lcm_precision_5k: 0.3340 - lcm_recall_1k: 0.4978 - lcm_recall_2k: 0.7128 - lcm_recall_3k: 0.8142 - lcm_recall_5k: 0.9037 - lcm_f1_1k: 0.6076 - lcm_f1_2k: 0.6562 - lcm_f1_3k: 0.6063 - lcm_f1_5k: 0.4877 - lcm_accuracy_1k: 0.7798 - lcm_accuracy_2k: 0.9042 - lcm_accuracy_3k: 0.9465 - lcm_accuracy_5k: 0.9761 - lcm_hamming_loss_k: 0.0032 - val_loss: 0.2694 - val_lcm_precision_1k: 0.6140 - val_lcm_precision_2k: 0.4825 - val_lcm_precision_3k: 0.3839 - val_lcm_precision_5k: 0.2718 - val_lcm_recall_1k: 0.3876 - val_lcm_recall_2k: 0.5729 - val_lcm_recall_3k: 0.6656 - val_lcm_recall_5k: 0.7612 - val_lcm_f1_1k: 0.4751 - val_lcm_f1_2k: 0.5237 - val_lcm_f1_3k: 0.4867 - val_lcm_f1_5k: 0.4005 - val_lcm_accuracy_1k: 0.6140 - val_lcm_accuracy_2k: 0.7622 - val_lcm_accuracy_3k: 0.8224 - val_lcm_accuracy_5k: 0.8812 - val_lcm_hamming_loss_k: 0.0039
Epoch 00017: early stopping
176/176 [==============================] - 8s 42ms/step - loss: 0.2155 - lcm_precision_1k: 0.7350 - lcm_precision_2k: 0.5710 - lcm_precision_3k: 0.4521 - lcm_precision_5k: 0.3154 - lcm_recall_1k: 0.4723 - lcm_recall_2k: 0.6756 - lcm_recall_3k: 0.7722 - lcm_recall_5k: 0.8649 - lcm_f1_1k: 0.5738 - lcm_f1_2k: 0.6176 - lcm_f1_3k: 0.5692 - lcm_f1_5k: 0.4615 - lcm_accuracy_1k: 0.7350 - lcm_accuracy_2k: 0.8660 - lcm_accuracy_3k: 0.9114 - lcm_accuracy_5k: 0.9503 - lcm_hamming_loss_k: 0.0033 2s - loss: 0.2160 - lcm_precision_1k: 0.7379 - lcm_precision_2k: 0.5707 - lcm_precision_3k: 0.4496 - lcm_precision_5k: 0.3129 - lcm_recall_1k: 0.4746 - lcm_recall_2k: 0.6768 - lcm_recall_3k: 0.7721 - lcm_recall_5k: 0.8620 - lcm_f1_1k: 0.5762 - lcm_f1_2k: 0.6179 - lcm_f1_3k: 0.5672 - lcm_f1_5k: 0.4584 - lcm_accuracy_1k: 0.7379 - lcm_accuracy_2k: 0.8665 - lcm_accuracy_3k: 0.9 - ETA: 0s - loss: 0.2157 - lcm_precision_1k: 0.7363 - lcm_precision_2k: 0.5718 - lcm_precision_3k: 0.4525 - lcm_precision_5k: 0.3155 - lcm_recall_1k: 0.4727 - lcm_recall_2k: 0.6760 - lcm_recall_3k: 0.7726 - lcm_recall_5k: 0.8646 - lcm_f1_1k: 0.5745 - lcm_f1_2k: 0.6183 - lcm_f1_3k: 0.5696 - lcm_f1_5k: 0.4616 - lcm_accuracy_1k: 0.7363 - lcm_accuracy_2k: 0.8670 - lcm_accuracy_3k: 0.9123 - lcm_accuracy_5k: 0.9505 - lcm_hamming_loss_k: 
Best model result:  [0.21546709537506104, 0.7349924445152283, 0.5710057020187378, 0.4521210789680481, 0.31543195247650146, 0.4723372161388397, 0.6755784749984741, 0.7721872925758362, 0.8649401068687439, 0.5738109946250916, 0.6176123023033142, 0.5692166090011597, 0.46150514483451843, 0.7349924445152283, 0.8659732937812805, 0.9114259481430054, 0.9502914547920227, 0.003343090647831559]
fold_result:  [[0.23745344579219818, 0.6823062300682068, 0.5284346342086792, 0.4207136929035187, 0.2974296510219574, 0.4322556257247925, 0.626583456993103, 0.7229995131492615, 0.8222770690917969, 0.5279738903045654, 0.57217937707901, 0.5309174656867981, 0.43615010380744934, 0.6823062300682068, 0.8223247528076172, 0.8785291910171509, 0.9268772602081299, 0.0035898564383387566], [0.23870518803596497, 0.6739595532417297, 0.5250454545021057, 0.4204505980014801, 0.2973363697528839, 0.42738017439842224, 0.6227350831031799, 0.7231236696243286, 0.8216749429702759, 0.5217517018318176, 0.5685025453567505, 0.5306895971298218, 0.4359329044818878, 0.6739595532417297, 0.8192262053489685, 0.8805307745933533, 0.9261636137962341, 0.003628944046795368], [0.21451519429683685, 0.7247431874275208, 0.5681016445159912, 0.4532892107963562, 0.31290343403816223, 0.465823769569397, 0.6721140146255493, 0.7733692526817322, 0.8598095178604126, 0.5658276677131653, 0.6145312786102295, 0.5705329179763794, 0.4580952823162079, 0.7247431874275208, 0.8572218418121338, 0.9085334539413452, 0.947222888469696, 0.003391094272956252], [0.2299502193927765, 0.6874050498008728, 0.5364726185798645, 0.42925453186035156, 0.30200791358947754, 0.438304603099823, 0.6366746425628662, 0.7354772090911865, 0.8344349265098572, 0.5339589715003967, 0.5810732245445251, 0.5410746932029724, 0.4427700936794281, 0.6874050498008728, 0.8320102691650391, 0.8868710994720459, 0.9337539076805115, 0.00356597313657403], [0.21546709537506104, 0.7349924445152283, 0.5710057020187378, 0.4521210789680481, 0.31543195247650146, 0.4723372161388397, 0.6755784749984741, 0.7721872925758362, 0.8649401068687439, 0.5738109946250916, 0.6176123023033142, 0.5692166090011597, 0.46150514483451843, 0.7349924445152283, 0.8659732937812805, 0.9114259481430054, 0.9502914547920227, 0.003343090647831559]]
average_result:  [0.2272182285785675, 0.7006812930107117, 0.5458120107650757, 0.4351658225059509, 0.3050218641757965, 0.4472202777862549, 0.6467371344566345, 0.745431387424469, 0.8406273126602173, 0.5446646451950073, 0.5907797455787659, 0.5484862565994263, 0.44689070582389834, 0.7006812930107117, 0.8393512725830078, 0.8931780934333802, 0.9368618249893188, 0.0035037917084991934]
2024-06-04 15:28:06,082 : INFO : =======End=======
