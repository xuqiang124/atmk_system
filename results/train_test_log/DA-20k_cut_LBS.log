/home/dzq/anaconda3/envs/k121/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/home/dzq/anaconda3/envs/k121/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). 
 The versions of TensorFlow you are currently using is 2.7.0 and is not supported. 
Some things might work, some things might not.
If you were to encounter a bug, do not file an issue.
If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. 
You can find the compatibility matrix in TensorFlow Addon's readme:
https://github.com/tensorflow/addons
  warnings.warn(
2024-06-04 12:34:49,509 : INFO : Loading config...
2024-06-04 12:34:49,511 : INFO : {'cache_file_h5py': '../file_data/a30/math_data_cut.h5', 'cache_file_pickle': '../file_data/a32/vocab_label.pkl', 'embeddings': '../file_data/a32/embeddings.pkl', 'maxlen': 150, 'emb_size': 300, 'epochs': 150, 'batch_size': 512, 'alpha': 4, 'hidden_size': 512, 'num_classes_list': [15, 427], 'l_patience': 2, 'b_patience': 10}
2024-06-04 12:34:49,511 : INFO : Loading data...
2024-06-04 12:34:49,593 : INFO : Loading embeddings...
2024-06-04 12:34:49,664 : INFO : model name lbs
TOTAL: 22498 TRAIN: [[ 126    3 1315 ...    0    0    0]
 [  44    3   17 ...    0    0    0]
 [ 216    3   11 ...    0    0    0]
 ...
 [ 130    3   78 ...    0    0    0]
 [ 238    3  134 ...    0    0    0]
 [  59    3   78 ...    0    0    0]] 16873 TEST: [[ 105    3 1490 ...   38    0    0]
 [ 238    3 2235 ...    0    0    0]
 [ 172    3  134 ...    0    0    0]
 ...
 [ 161    3 2144 ...    0    0    0]
 [ 161    3 4753 ...    0    0    0]
 [ 189    3   17 ...    0    0    0]] 5625
2024-06-04 12:34:49,697 : INFO : =====Start final=====
13498
3375
5625
2024-06-04 12:34:50.127602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 12:34:50.150744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 12:34:50.150855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 12:34:50.151061: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-04 12:34:50.152822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 12:34:50.152917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 12:34:50.152978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 12:34:50.481916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 12:34:50.482041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 12:34:50.482110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 12:34:50.482182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22102 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['BiLSTM[0][0]']                 
                                                                                                  
==================================================================================================
Total params: 28,546,223
Trainable params: 3,767,723
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
2 patience
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 tf.__operators__.getitem (Slic  (None, 427, 300)    0           ['label_emb[0][0]']              
 ingOpLambda)                                                                                     
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_lcm_emb (Dense)          (None, 427, 1024)    308224      ['tf.__operators__.getitem[0][0]'
                                                                 ]                                
                                                                                                  
 dot (Dot)                      (None, 427)          0           ['label_lcm_emb[0][0]',          
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['BiLSTM[0][0]']                 
                                                                                                  
 label_sim_dict (Dense)         (None, 427)          182756      ['dot[0][0]']                    
                                                                                                  
 concatenate (Concatenate)      (None, 854)          0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 29,165,303
Trainable params: 4,386,803
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
Epoch 1/150
2024-06-04 12:34:53.538963: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2024-06-04 12:34:53.574096: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8906
27/27 [==============================] - ETA: 0s - loss: 0.5003 - lcm_precision_1k: 0.1444 - lcm_precision_2k: 0.1196 - lcm_precision_3k: 0.1045 - lcm_precision_5k: 0.0904 - lcm_recall_1k: 0.0710 - lcm_recall_2k: 0.1168 - lcm_recall_3k: 0.1545 - lcm_recall_5k: 0.2251 - lcm_f1_1k: 0.0951 - lcm_f1_2k: 0.1181 - lcm_f1_3k: 0.1246 - lcm_f1_5k: 0.1290 - lcm_accuracy_1k: 0.1444 - lcm_accuracy_2k: 0.2048 - lcm_accuracy_3k: 0.2537 - lcm_accuracy_5k: 0.3329 - lcm_hamming_loss_k: 0.0061
Epoch 00001: val_loss improved from inf to 0.46037, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 12s 363ms/step - loss: 0.5003 - lcm_precision_1k: 0.1444 - lcm_precision_2k: 0.1196 - lcm_precision_3k: 0.1045 - lcm_precision_5k: 0.0904 - lcm_recall_1k: 0.0710 - lcm_recall_2k: 0.1168 - lcm_recall_3k: 0.1545 - lcm_recall_5k: 0.2251 - lcm_f1_1k: 0.0951 - lcm_f1_2k: 0.1181 - lcm_f1_3k: 0.1246 - lcm_f1_5k: 0.1290 - lcm_accuracy_1k: 0.1444 - lcm_accuracy_2k: 0.2048 - lcm_accuracy_3k: 0.2537 - lcm_accuracy_5k: 0.3329 - lcm_hamming_loss_k: 0.0061 - val_loss: 0.4604 - val_lcm_precision_1k: 0.1965 - val_lcm_precision_2k: 0.1732 - val_lcm_precision_3k: 0.1472 - val_lcm_precision_5k: 0.1223 - val_lcm_recall_1k: 0.1051 - val_lcm_recall_2k: 0.1854 - val_lcm_recall_3k: 0.2344 - val_lcm_recall_5k: 0.3187 - val_lcm_f1_1k: 0.1368 - val_lcm_f1_2k: 0.1789 - val_lcm_f1_3k: 0.1807 - val_lcm_f1_5k: 0.1767 - val_lcm_accuracy_1k: 0.1965 - val_lcm_accuracy_2k: 0.2989 - val_lcm_accuracy_3k: 0.3582 - val_lcm_accuracy_5k: 0.4414 - val_lcm_hamming_loss_k: 0.0058
Epoch 2/150
27/27 [==============================] - ETA: 0s - loss: 0.4316 - lcm_precision_1k: 0.2234 - lcm_precision_2k: 0.1873 - lcm_precision_3k: 0.1642 - lcm_precision_5k: 0.1427 - lcm_recall_1k: 0.1190 - lcm_recall_2k: 0.1990 - lcm_recall_3k: 0.2605 - lcm_recall_5k: 0.3738 - lcm_f1_1k: 0.1552 - lcm_f1_2k: 0.1929 - lcm_f1_3k: 0.2014 - lcm_f1_5k: 0.2065 - lcm_accuracy_1k: 0.2234 - lcm_accuracy_2k: 0.3211 - lcm_accuracy_3k: 0.3948 - lcm_accuracy_5k: 0.5083 - lcm_hamming_loss_k: 0.0058 ETA: 1s - loss: 0.4403 - lcm_precision_1k: 0.2097 - lcm_precision_2k: 0.1786 - lcm_precision_3k: 0.1574 - lcm_precision_5k: 0.1377 - lcm_recall_1k: 0.1096 - lcm_recall_2k: 0.1882 - lcm_recall_3k: 0.2483 - lcm_recall_5k: 0.3590 - lcm_f1_1k: 0.1438 - lcm_f1_2k: 0.1832 - lcm_f1_3k: 0.1926 - lcm_f1_5k: 0.1990 - lcm_accuracy_1k: 0.2097 - lcm_accuracy_2k: 0.3054 - lcm_accuracy_3k: 0.3781 - lcm_accuracy_5k: 0.4910 - lcm_hamming_
Epoch 00002: val_loss improved from 0.46037 to 0.39476, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 364ms/step - loss: 0.4316 - lcm_precision_1k: 0.2234 - lcm_precision_2k: 0.1873 - lcm_precision_3k: 0.1642 - lcm_precision_5k: 0.1427 - lcm_recall_1k: 0.1190 - lcm_recall_2k: 0.1990 - lcm_recall_3k: 0.2605 - lcm_recall_5k: 0.3738 - lcm_f1_1k: 0.1552 - lcm_f1_2k: 0.1929 - lcm_f1_3k: 0.2014 - lcm_f1_5k: 0.2065 - lcm_accuracy_1k: 0.2234 - lcm_accuracy_2k: 0.3211 - lcm_accuracy_3k: 0.3948 - lcm_accuracy_5k: 0.5083 - lcm_hamming_loss_k: 0.0058 - val_loss: 0.3948 - val_lcm_precision_1k: 0.2699 - val_lcm_precision_2k: 0.2217 - val_lcm_precision_3k: 0.1955 - val_lcm_precision_5k: 0.1613 - val_lcm_recall_1k: 0.1580 - val_lcm_recall_2k: 0.2532 - val_lcm_recall_3k: 0.3250 - val_lcm_recall_5k: 0.4409 - val_lcm_f1_1k: 0.1992 - val_lcm_f1_2k: 0.2361 - val_lcm_f1_3k: 0.2439 - val_lcm_f1_5k: 0.2361 - val_lcm_accuracy_1k: 0.2699 - val_lcm_accuracy_2k: 0.3915 - val_lcm_accuracy_3k: 0.4738 - val_lcm_accuracy_5k: 0.5894 - val_lcm_hamming_loss_k: 0.0055
Epoch 3/150
27/27 [==============================] - ETA: 0s - loss: 0.3746 - lcm_precision_1k: 0.2984 - lcm_precision_2k: 0.2567 - lcm_precision_3k: 0.2221 - lcm_precision_5k: 0.1817 - lcm_recall_1k: 0.1669 - lcm_recall_2k: 0.2856 - lcm_recall_3k: 0.3633 - lcm_recall_5k: 0.4845 - lcm_f1_1k: 0.2140 - lcm_f1_2k: 0.2704 - lcm_f1_3k: 0.2756 - lcm_f1_5k: 0.2643 - lcm_accuracy_1k: 0.2984 - lcm_accuracy_2k: 0.4409 - lcm_accuracy_3k: 0.5240 - lcm_accuracy_5k: 0.6319 - lcm_hamming_loss_k: 0.0054
Epoch 00003: val_loss improved from 0.39476 to 0.35839, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 365ms/step - loss: 0.3746 - lcm_precision_1k: 0.2984 - lcm_precision_2k: 0.2567 - lcm_precision_3k: 0.2221 - lcm_precision_5k: 0.1817 - lcm_recall_1k: 0.1669 - lcm_recall_2k: 0.2856 - lcm_recall_3k: 0.3633 - lcm_recall_5k: 0.4845 - lcm_f1_1k: 0.2140 - lcm_f1_2k: 0.2704 - lcm_f1_3k: 0.2756 - lcm_f1_5k: 0.2643 - lcm_accuracy_1k: 0.2984 - lcm_accuracy_2k: 0.4409 - lcm_accuracy_3k: 0.5240 - lcm_accuracy_5k: 0.6319 - lcm_hamming_loss_k: 0.0054 - val_loss: 0.3584 - val_lcm_precision_1k: 0.3225 - val_lcm_precision_2k: 0.2818 - val_lcm_precision_3k: 0.2413 - val_lcm_precision_5k: 0.1922 - val_lcm_recall_1k: 0.1860 - val_lcm_recall_2k: 0.3177 - val_lcm_recall_3k: 0.4059 - val_lcm_recall_5k: 0.5277 - val_lcm_f1_1k: 0.2358 - val_lcm_f1_2k: 0.2985 - val_lcm_f1_3k: 0.3025 - val_lcm_f1_5k: 0.2817 - val_lcm_accuracy_1k: 0.3225 - val_lcm_accuracy_2k: 0.4736 - val_lcm_accuracy_3k: 0.5741 - val_lcm_accuracy_5k: 0.6848 - val_lcm_hamming_loss_k: 0.0052
Epoch 4/150
27/27 [==============================] - ETA: 0s - loss: 0.3461 - lcm_precision_1k: 0.3548 - lcm_precision_2k: 0.3077 - lcm_precision_3k: 0.2626 - lcm_precision_5k: 0.2056 - lcm_recall_1k: 0.2035 - lcm_recall_2k: 0.3451 - lcm_recall_3k: 0.4378 - lcm_recall_5k: 0.5549 - lcm_f1_1k: 0.2585 - lcm_f1_2k: 0.3252 - lcm_f1_3k: 0.3282 - lcm_f1_5k: 0.2999 - lcm_accuracy_1k: 0.3548 - lcm_accuracy_2k: 0.5188 - lcm_accuracy_3k: 0.6102 - lcm_accuracy_5k: 0.7049 - lcm_hamming_loss_k: 0.0052 ETA: 2s - loss: 0.3486 - lcm_precision_1k: 0.3457 - lcm_precision_2k: 0.3045 - lcm_precision_3k: 0.2608 - lcm_precision_5k: 0.2058 - lcm_recall_1k: 0.1942 - lcm_recall_2k: 0.3375 - lcm_recall_3k: 0.4311 - lcm_recall_5k: 0.5511 - lcm_f1_1k: 0.2486 - lcm_f1_2k: 0.3201 - lcm_f1_3k: 0.3249 - lcm_f1_5k: 0.2997 - lcm_accuracy_1k: 0.3457 - lcm_accuracy_2k: 0.5103 - lcm_accuracy_3k: 0.6051 - lcm_accuracy_5k: 0.7016 - lcm_hamm
Epoch 00004: val_loss improved from 0.35839 to 0.33843, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 367ms/step - loss: 0.3461 - lcm_precision_1k: 0.3548 - lcm_precision_2k: 0.3077 - lcm_precision_3k: 0.2626 - lcm_precision_5k: 0.2056 - lcm_recall_1k: 0.2035 - lcm_recall_2k: 0.3451 - lcm_recall_3k: 0.4378 - lcm_recall_5k: 0.5549 - lcm_f1_1k: 0.2585 - lcm_f1_2k: 0.3252 - lcm_f1_3k: 0.3282 - lcm_f1_5k: 0.2999 - lcm_accuracy_1k: 0.3548 - lcm_accuracy_2k: 0.5188 - lcm_accuracy_3k: 0.6102 - lcm_accuracy_5k: 0.7049 - lcm_hamming_loss_k: 0.0052 - val_loss: 0.3384 - val_lcm_precision_1k: 0.3653 - val_lcm_precision_2k: 0.3113 - val_lcm_precision_3k: 0.2620 - val_lcm_precision_5k: 0.2056 - val_lcm_recall_1k: 0.2181 - val_lcm_recall_2k: 0.3605 - val_lcm_recall_3k: 0.4498 - val_lcm_recall_5k: 0.5681 - val_lcm_f1_1k: 0.2730 - val_lcm_f1_2k: 0.3339 - val_lcm_f1_3k: 0.3310 - val_lcm_f1_5k: 0.3018 - val_lcm_accuracy_1k: 0.3653 - val_lcm_accuracy_2k: 0.5330 - val_lcm_accuracy_3k: 0.6203 - val_lcm_accuracy_5k: 0.7199 - val_lcm_hamming_loss_k: 0.0050
Epoch 5/150
27/27 [==============================] - ETA: 0s - loss: 0.3250 - lcm_precision_1k: 0.3975 - lcm_precision_2k: 0.3384 - lcm_precision_3k: 0.2883 - lcm_precision_5k: 0.2221 - lcm_recall_1k: 0.2318 - lcm_recall_2k: 0.3822 - lcm_recall_3k: 0.4814 - lcm_recall_5k: 0.6015 - lcm_f1_1k: 0.2928 - lcm_f1_2k: 0.3589 - lcm_f1_3k: 0.3606 - lcm_f1_5k: 0.3244 - lcm_accuracy_1k: 0.3975 - lcm_accuracy_2k: 0.5671 - lcm_accuracy_3k: 0.6574 - lcm_accuracy_5k: 0.7510 - lcm_hamming_loss_k: 0.0050
Epoch 00005: val_loss improved from 0.33843 to 0.32282, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 370ms/step - loss: 0.3250 - lcm_precision_1k: 0.3975 - lcm_precision_2k: 0.3384 - lcm_precision_3k: 0.2883 - lcm_precision_5k: 0.2221 - lcm_recall_1k: 0.2318 - lcm_recall_2k: 0.3822 - lcm_recall_3k: 0.4814 - lcm_recall_5k: 0.6015 - lcm_f1_1k: 0.2928 - lcm_f1_2k: 0.3589 - lcm_f1_3k: 0.3606 - lcm_f1_5k: 0.3244 - lcm_accuracy_1k: 0.3975 - lcm_accuracy_2k: 0.5671 - lcm_accuracy_3k: 0.6574 - lcm_accuracy_5k: 0.7510 - lcm_hamming_loss_k: 0.0050 - val_loss: 0.3228 - val_lcm_precision_1k: 0.4168 - val_lcm_precision_2k: 0.3389 - val_lcm_precision_3k: 0.2900 - val_lcm_precision_5k: 0.2205 - val_lcm_recall_1k: 0.2544 - val_lcm_recall_2k: 0.3947 - val_lcm_recall_3k: 0.4985 - val_lcm_recall_5k: 0.6144 - val_lcm_f1_1k: 0.3158 - val_lcm_f1_2k: 0.3645 - val_lcm_f1_3k: 0.3665 - val_lcm_f1_5k: 0.3244 - val_lcm_accuracy_1k: 0.4168 - val_lcm_accuracy_2k: 0.5697 - val_lcm_accuracy_3k: 0.6686 - val_lcm_accuracy_5k: 0.7603 - val_lcm_hamming_loss_k: 0.0048
Epoch 6/150
27/27 [==============================] - ETA: 0s - loss: 0.3085 - lcm_precision_1k: 0.4470 - lcm_precision_2k: 0.3681 - lcm_precision_3k: 0.3102 - lcm_precision_5k: 0.2343 - lcm_recall_1k: 0.2651 - lcm_recall_2k: 0.4206 - lcm_recall_3k: 0.5222 - lcm_recall_5k: 0.6384 - lcm_f1_1k: 0.3328 - lcm_f1_2k: 0.3925 - lcm_f1_3k: 0.3891 - lcm_f1_5k: 0.3427 - lcm_accuracy_1k: 0.4470 - lcm_accuracy_2k: 0.6078 - lcm_accuracy_3k: 0.6989 - lcm_accuracy_5k: 0.7857 - lcm_hamming_loss_k: 0.0047
Epoch 00006: val_loss improved from 0.32282 to 0.31242, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.3085 - lcm_precision_1k: 0.4470 - lcm_precision_2k: 0.3681 - lcm_precision_3k: 0.3102 - lcm_precision_5k: 0.2343 - lcm_recall_1k: 0.2651 - lcm_recall_2k: 0.4206 - lcm_recall_3k: 0.5222 - lcm_recall_5k: 0.6384 - lcm_f1_1k: 0.3328 - lcm_f1_2k: 0.3925 - lcm_f1_3k: 0.3891 - lcm_f1_5k: 0.3427 - lcm_accuracy_1k: 0.4470 - lcm_accuracy_2k: 0.6078 - lcm_accuracy_3k: 0.6989 - lcm_accuracy_5k: 0.7857 - lcm_hamming_loss_k: 0.0047 - val_loss: 0.3124 - val_lcm_precision_1k: 0.4391 - val_lcm_precision_2k: 0.3709 - val_lcm_precision_3k: 0.3065 - val_lcm_precision_5k: 0.2262 - val_lcm_recall_1k: 0.2663 - val_lcm_recall_2k: 0.4324 - val_lcm_recall_3k: 0.5285 - val_lcm_recall_5k: 0.6351 - val_lcm_f1_1k: 0.3314 - val_lcm_f1_2k: 0.3992 - val_lcm_f1_3k: 0.3879 - val_lcm_f1_5k: 0.3334 - val_lcm_accuracy_1k: 0.4391 - val_lcm_accuracy_2k: 0.6107 - val_lcm_accuracy_3k: 0.7001 - val_lcm_accuracy_5k: 0.7821 - val_lcm_hamming_loss_k: 0.0047
Epoch 7/150
27/27 [==============================] - ETA: 0s - loss: 0.2970 - lcm_precision_1k: 0.4779 - lcm_precision_2k: 0.3900 - lcm_precision_3k: 0.3261 - lcm_precision_5k: 0.2432 - lcm_recall_1k: 0.2850 - lcm_recall_2k: 0.4462 - lcm_recall_3k: 0.5493 - lcm_recall_5k: 0.6647 - lcm_f1_1k: 0.3570 - lcm_f1_2k: 0.4161 - lcm_f1_3k: 0.4092 - lcm_f1_5k: 0.3561 - lcm_accuracy_1k: 0.4779 - lcm_accuracy_2k: 0.6343 - lcm_accuracy_3k: 0.7264 - lcm_accuracy_5k: 0.8092 - lcm_hamming_loss_k: 0.0046
Epoch 00007: val_loss improved from 0.31242 to 0.30507, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 367ms/step - loss: 0.2970 - lcm_precision_1k: 0.4779 - lcm_precision_2k: 0.3900 - lcm_precision_3k: 0.3261 - lcm_precision_5k: 0.2432 - lcm_recall_1k: 0.2850 - lcm_recall_2k: 0.4462 - lcm_recall_3k: 0.5493 - lcm_recall_5k: 0.6647 - lcm_f1_1k: 0.3570 - lcm_f1_2k: 0.4161 - lcm_f1_3k: 0.4092 - lcm_f1_5k: 0.3561 - lcm_accuracy_1k: 0.4779 - lcm_accuracy_2k: 0.6343 - lcm_accuracy_3k: 0.7264 - lcm_accuracy_5k: 0.8092 - lcm_hamming_loss_k: 0.0046 - val_loss: 0.3051 - val_lcm_precision_1k: 0.4577 - val_lcm_precision_2k: 0.3717 - val_lcm_precision_3k: 0.3126 - val_lcm_precision_5k: 0.2310 - val_lcm_recall_1k: 0.2818 - val_lcm_recall_2k: 0.4381 - val_lcm_recall_3k: 0.5396 - val_lcm_recall_5k: 0.6437 - val_lcm_f1_1k: 0.3487 - val_lcm_f1_2k: 0.4020 - val_lcm_f1_3k: 0.3957 - val_lcm_f1_5k: 0.3399 - val_lcm_accuracy_1k: 0.4577 - val_lcm_accuracy_2k: 0.6158 - val_lcm_accuracy_3k: 0.7071 - val_lcm_accuracy_5k: 0.7892 - val_lcm_hamming_loss_k: 0.0046
Epoch 8/150
27/27 [==============================] - ETA: 0s - loss: 0.2846 - lcm_precision_1k: 0.5136 - lcm_precision_2k: 0.4097 - lcm_precision_3k: 0.3381 - lcm_precision_5k: 0.2499 - lcm_recall_1k: 0.3120 - lcm_recall_2k: 0.4708 - lcm_recall_3k: 0.5717 - lcm_recall_5k: 0.6849 - lcm_f1_1k: 0.3881 - lcm_f1_2k: 0.4381 - lcm_f1_3k: 0.4248 - lcm_f1_5k: 0.3662 - lcm_accuracy_1k: 0.5136 - lcm_accuracy_2k: 0.6632 - lcm_accuracy_3k: 0.7474 - lcm_accuracy_5k: 0.8263 - lcm_hamming_loss_k: 0.0044
Epoch 00008: val_loss improved from 0.30507 to 0.29944, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 368ms/step - loss: 0.2846 - lcm_precision_1k: 0.5136 - lcm_precision_2k: 0.4097 - lcm_precision_3k: 0.3381 - lcm_precision_5k: 0.2499 - lcm_recall_1k: 0.3120 - lcm_recall_2k: 0.4708 - lcm_recall_3k: 0.5717 - lcm_recall_5k: 0.6849 - lcm_f1_1k: 0.3881 - lcm_f1_2k: 0.4381 - lcm_f1_3k: 0.4248 - lcm_f1_5k: 0.3662 - lcm_accuracy_1k: 0.5136 - lcm_accuracy_2k: 0.6632 - lcm_accuracy_3k: 0.7474 - lcm_accuracy_5k: 0.8263 - lcm_hamming_loss_k: 0.0044 - val_loss: 0.2994 - val_lcm_precision_1k: 0.4837 - val_lcm_precision_2k: 0.3881 - val_lcm_precision_3k: 0.3176 - val_lcm_precision_5k: 0.2346 - val_lcm_recall_1k: 0.3034 - val_lcm_recall_2k: 0.4602 - val_lcm_recall_3k: 0.5519 - val_lcm_recall_5k: 0.6607 - val_lcm_f1_1k: 0.3728 - val_lcm_f1_2k: 0.4210 - val_lcm_f1_3k: 0.4031 - val_lcm_f1_5k: 0.3462 - val_lcm_accuracy_1k: 0.4837 - val_lcm_accuracy_2k: 0.6389 - val_lcm_accuracy_3k: 0.7171 - val_lcm_accuracy_5k: 0.8015 - val_lcm_hamming_loss_k: 0.0045
Epoch 9/150
27/27 [==============================] - ETA: 0s - loss: 0.2800 - lcm_precision_1k: 0.5262 - lcm_precision_2k: 0.4186 - lcm_precision_3k: 0.3438 - lcm_precision_5k: 0.2539 - lcm_recall_1k: 0.3206 - lcm_recall_2k: 0.4837 - lcm_recall_3k: 0.5825 - lcm_recall_5k: 0.6962 - lcm_f1_1k: 0.3983 - lcm_f1_2k: 0.4487 - lcm_f1_3k: 0.4324 - lcm_f1_5k: 0.3720 - lcm_accuracy_1k: 0.5262 - lcm_accuracy_2k: 0.6768 - lcm_accuracy_3k: 0.7542 - lcm_accuracy_5k: 0.8358 - lcm_hamming_loss_k: 0.0044
Epoch 00009: val_loss improved from 0.29944 to 0.29822, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 367ms/step - loss: 0.2800 - lcm_precision_1k: 0.5262 - lcm_precision_2k: 0.4186 - lcm_precision_3k: 0.3438 - lcm_precision_5k: 0.2539 - lcm_recall_1k: 0.3206 - lcm_recall_2k: 0.4837 - lcm_recall_3k: 0.5825 - lcm_recall_5k: 0.6962 - lcm_f1_1k: 0.3983 - lcm_f1_2k: 0.4487 - lcm_f1_3k: 0.4324 - lcm_f1_5k: 0.3720 - lcm_accuracy_1k: 0.5262 - lcm_accuracy_2k: 0.6768 - lcm_accuracy_3k: 0.7542 - lcm_accuracy_5k: 0.8358 - lcm_hamming_loss_k: 0.0044 - val_loss: 0.2982 - val_lcm_precision_1k: 0.4928 - val_lcm_precision_2k: 0.3869 - val_lcm_precision_3k: 0.3199 - val_lcm_precision_5k: 0.2359 - val_lcm_recall_1k: 0.3085 - val_lcm_recall_2k: 0.4578 - val_lcm_recall_3k: 0.5553 - val_lcm_recall_5k: 0.6634 - val_lcm_f1_1k: 0.3793 - val_lcm_f1_2k: 0.4192 - val_lcm_f1_3k: 0.4058 - val_lcm_f1_5k: 0.3479 - val_lcm_accuracy_1k: 0.4928 - val_lcm_accuracy_2k: 0.6393 - val_lcm_accuracy_3k: 0.7277 - val_lcm_accuracy_5k: 0.8061 - val_lcm_hamming_loss_k: 0.0044
Epoch 10/150
27/27 [==============================] - ETA: 0s - loss: 0.2700 - lcm_precision_1k: 0.5521 - lcm_precision_2k: 0.4379 - lcm_precision_3k: 0.3568 - lcm_precision_5k: 0.2625 - lcm_recall_1k: 0.3384 - lcm_recall_2k: 0.5063 - lcm_recall_3k: 0.6041 - lcm_recall_5k: 0.7202 - lcm_f1_1k: 0.4195 - lcm_f1_2k: 0.4695 - lcm_f1_3k: 0.4486 - lcm_f1_5k: 0.3847 - lcm_accuracy_1k: 0.5521 - lcm_accuracy_2k: 0.7029 - lcm_accuracy_3k: 0.7788 - lcm_accuracy_5k: 0.8581 - lcm_hamming_loss_k: 0.0042
Epoch 00010: val_loss improved from 0.29822 to 0.28626, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 368ms/step - loss: 0.2700 - lcm_precision_1k: 0.5521 - lcm_precision_2k: 0.4379 - lcm_precision_3k: 0.3568 - lcm_precision_5k: 0.2625 - lcm_recall_1k: 0.3384 - lcm_recall_2k: 0.5063 - lcm_recall_3k: 0.6041 - lcm_recall_5k: 0.7202 - lcm_f1_1k: 0.4195 - lcm_f1_2k: 0.4695 - lcm_f1_3k: 0.4486 - lcm_f1_5k: 0.3847 - lcm_accuracy_1k: 0.5521 - lcm_accuracy_2k: 0.7029 - lcm_accuracy_3k: 0.7788 - lcm_accuracy_5k: 0.8581 - lcm_hamming_loss_k: 0.0042 - val_loss: 0.2863 - val_lcm_precision_1k: 0.5029 - val_lcm_precision_2k: 0.4020 - val_lcm_precision_3k: 0.3322 - val_lcm_precision_5k: 0.2428 - val_lcm_recall_1k: 0.3156 - val_lcm_recall_2k: 0.4771 - val_lcm_recall_3k: 0.5766 - val_lcm_recall_5k: 0.6826 - val_lcm_f1_1k: 0.3877 - val_lcm_f1_2k: 0.4362 - val_lcm_f1_3k: 0.4214 - val_lcm_f1_5k: 0.3581 - val_lcm_accuracy_1k: 0.5029 - val_lcm_accuracy_2k: 0.6588 - val_lcm_accuracy_3k: 0.7443 - val_lcm_accuracy_5k: 0.8252 - val_lcm_hamming_loss_k: 0.0044
Epoch 11/150
27/27 [==============================] - ETA: 0s - loss: 0.2587 - lcm_precision_1k: 0.5742 - lcm_precision_2k: 0.4526 - lcm_precision_3k: 0.3691 - lcm_precision_5k: 0.2684 - lcm_recall_1k: 0.3548 - lcm_recall_2k: 0.5266 - lcm_recall_3k: 0.6286 - lcm_recall_5k: 0.7390 - lcm_f1_1k: 0.4385 - lcm_f1_2k: 0.4867 - lcm_f1_3k: 0.4651 - lcm_f1_5k: 0.3937 - lcm_accuracy_1k: 0.5742 - lcm_accuracy_2k: 0.7259 - lcm_accuracy_3k: 0.8018 - lcm_accuracy_5k: 0.8738 - lcm_hamming_loss_k: 0.0041
Epoch 00011: val_loss improved from 0.28626 to 0.28545, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.2587 - lcm_precision_1k: 0.5742 - lcm_precision_2k: 0.4526 - lcm_precision_3k: 0.3691 - lcm_precision_5k: 0.2684 - lcm_recall_1k: 0.3548 - lcm_recall_2k: 0.5266 - lcm_recall_3k: 0.6286 - lcm_recall_5k: 0.7390 - lcm_f1_1k: 0.4385 - lcm_f1_2k: 0.4867 - lcm_f1_3k: 0.4651 - lcm_f1_5k: 0.3937 - lcm_accuracy_1k: 0.5742 - lcm_accuracy_2k: 0.7259 - lcm_accuracy_3k: 0.8018 - lcm_accuracy_5k: 0.8738 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2854 - val_lcm_precision_1k: 0.5165 - val_lcm_precision_2k: 0.4102 - val_lcm_precision_3k: 0.3324 - val_lcm_precision_5k: 0.2443 - val_lcm_recall_1k: 0.3257 - val_lcm_recall_2k: 0.4898 - val_lcm_recall_3k: 0.5808 - val_lcm_recall_5k: 0.6889 - val_lcm_f1_1k: 0.3994 - val_lcm_f1_2k: 0.4463 - val_lcm_f1_3k: 0.4227 - val_lcm_f1_5k: 0.3605 - val_lcm_accuracy_1k: 0.5165 - val_lcm_accuracy_2k: 0.6695 - val_lcm_accuracy_3k: 0.7436 - val_lcm_accuracy_5k: 0.8227 - val_lcm_hamming_loss_k: 0.0043
Epoch 12/150
27/27 [==============================] - ETA: 0s - loss: 0.2526 - lcm_precision_1k: 0.5910 - lcm_precision_2k: 0.4658 - lcm_precision_3k: 0.3777 - lcm_precision_5k: 0.2747 - lcm_recall_1k: 0.3671 - lcm_recall_2k: 0.5460 - lcm_recall_3k: 0.6443 - lcm_recall_5k: 0.7570 - lcm_f1_1k: 0.4529 - lcm_f1_2k: 0.5027 - lcm_f1_3k: 0.4762 - lcm_f1_5k: 0.4031 - lcm_accuracy_1k: 0.5910 - lcm_accuracy_2k: 0.7441 - lcm_accuracy_3k: 0.8158 - lcm_accuracy_5k: 0.8875 - lcm_hamming_loss_k: 0.0041
Epoch 00012: val_loss improved from 0.28545 to 0.27769, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.2526 - lcm_precision_1k: 0.5910 - lcm_precision_2k: 0.4658 - lcm_precision_3k: 0.3777 - lcm_precision_5k: 0.2747 - lcm_recall_1k: 0.3671 - lcm_recall_2k: 0.5460 - lcm_recall_3k: 0.6443 - lcm_recall_5k: 0.7570 - lcm_f1_1k: 0.4529 - lcm_f1_2k: 0.5027 - lcm_f1_3k: 0.4762 - lcm_f1_5k: 0.4031 - lcm_accuracy_1k: 0.5910 - lcm_accuracy_2k: 0.7441 - lcm_accuracy_3k: 0.8158 - lcm_accuracy_5k: 0.8875 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2777 - val_lcm_precision_1k: 0.5304 - val_lcm_precision_2k: 0.4179 - val_lcm_precision_3k: 0.3459 - val_lcm_precision_5k: 0.2506 - val_lcm_recall_1k: 0.3329 - val_lcm_recall_2k: 0.4994 - val_lcm_recall_3k: 0.6043 - val_lcm_recall_5k: 0.7051 - val_lcm_f1_1k: 0.4090 - val_lcm_f1_2k: 0.4549 - val_lcm_f1_3k: 0.4398 - val_lcm_f1_5k: 0.3696 - val_lcm_accuracy_1k: 0.5304 - val_lcm_accuracy_2k: 0.6861 - val_lcm_accuracy_3k: 0.7701 - val_lcm_accuracy_5k: 0.8417 - val_lcm_hamming_loss_k: 0.0043
Epoch 13/150
27/27 [==============================] - ETA: 0s - loss: 0.2435 - lcm_precision_1k: 0.6089 - lcm_precision_2k: 0.4800 - lcm_precision_3k: 0.3909 - lcm_precision_5k: 0.2813 - lcm_recall_1k: 0.3788 - lcm_recall_2k: 0.5612 - lcm_recall_3k: 0.6657 - lcm_recall_5k: 0.7728 - lcm_f1_1k: 0.4669 - lcm_f1_2k: 0.5174 - lcm_f1_3k: 0.4925 - lcm_f1_5k: 0.4124 - lcm_accuracy_1k: 0.6089 - lcm_accuracy_2k: 0.7618 - lcm_accuracy_3k: 0.8352 - lcm_accuracy_5k: 0.8992 - lcm_hamming_loss_k: 0.0040
Epoch 00013: val_loss improved from 0.27769 to 0.27344, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 368ms/step - loss: 0.2435 - lcm_precision_1k: 0.6089 - lcm_precision_2k: 0.4800 - lcm_precision_3k: 0.3909 - lcm_precision_5k: 0.2813 - lcm_recall_1k: 0.3788 - lcm_recall_2k: 0.5612 - lcm_recall_3k: 0.6657 - lcm_recall_5k: 0.7728 - lcm_f1_1k: 0.4669 - lcm_f1_2k: 0.5174 - lcm_f1_3k: 0.4925 - lcm_f1_5k: 0.4124 - lcm_accuracy_1k: 0.6089 - lcm_accuracy_2k: 0.7618 - lcm_accuracy_3k: 0.8352 - lcm_accuracy_5k: 0.8992 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2734 - val_lcm_precision_1k: 0.5386 - val_lcm_precision_2k: 0.4269 - val_lcm_precision_3k: 0.3483 - val_lcm_precision_5k: 0.2511 - val_lcm_recall_1k: 0.3389 - val_lcm_recall_2k: 0.5132 - val_lcm_recall_3k: 0.6102 - val_lcm_recall_5k: 0.7103 - val_lcm_f1_1k: 0.4159 - val_lcm_f1_2k: 0.4660 - val_lcm_f1_3k: 0.4433 - val_lcm_f1_5k: 0.3709 - val_lcm_accuracy_1k: 0.5386 - val_lcm_accuracy_2k: 0.6965 - val_lcm_accuracy_3k: 0.7752 - val_lcm_accuracy_5k: 0.8480 - val_lcm_hamming_loss_k: 0.0042
Epoch 14/150
27/27 [==============================] - ETA: 0s - loss: 0.2363 - lcm_precision_1k: 0.6291 - lcm_precision_2k: 0.4951 - lcm_precision_3k: 0.4004 - lcm_precision_5k: 0.2874 - lcm_recall_1k: 0.3920 - lcm_recall_2k: 0.5794 - lcm_recall_3k: 0.6816 - lcm_recall_5k: 0.7886 - lcm_f1_1k: 0.4829 - lcm_f1_2k: 0.5338 - lcm_f1_3k: 0.5044 - lcm_f1_5k: 0.4212 - lcm_accuracy_1k: 0.6291 - lcm_accuracy_2k: 0.7800 - lcm_accuracy_3k: 0.8477 - lcm_accuracy_5k: 0.9077 - lcm_hamming_loss_k: 0.0039 ETA: 3s - loss: 0.2363 - lcm_precision_1k: 0.6314 - lcm_precision_2k: 0.4934 - lcm_precision_3k: 0.3977 - lcm_precision_5k: 0.2843 - lcm_recall_1k: 0.3977 - lcm_recall_2k: 0.5813 - lcm_recall_3k: 0.6826 - lcm_recall_5k: 0.7854 - lcm_f1_1k: 0.4879 - lcm_f1_2k: 0.5337 - lcm_f1_3k: 0.5026 - lcm_f1_5k: 0.4175 - lcm_accuracy_1k: 0.6314 - lcm_accuracy_2k: 0.7785 - lcm_accuracy_3k: 0.8492 - lcm_accuracy_5k: 0.9062 - 
Epoch 00014: val_loss improved from 0.27344 to 0.27197, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 365ms/step - loss: 0.2363 - lcm_precision_1k: 0.6291 - lcm_precision_2k: 0.4951 - lcm_precision_3k: 0.4004 - lcm_precision_5k: 0.2874 - lcm_recall_1k: 0.3920 - lcm_recall_2k: 0.5794 - lcm_recall_3k: 0.6816 - lcm_recall_5k: 0.7886 - lcm_f1_1k: 0.4829 - lcm_f1_2k: 0.5338 - lcm_f1_3k: 0.5044 - lcm_f1_5k: 0.4212 - lcm_accuracy_1k: 0.6291 - lcm_accuracy_2k: 0.7800 - lcm_accuracy_3k: 0.8477 - lcm_accuracy_5k: 0.9077 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2720 - val_lcm_precision_1k: 0.5474 - val_lcm_precision_2k: 0.4358 - val_lcm_precision_3k: 0.3542 - val_lcm_precision_5k: 0.2552 - val_lcm_recall_1k: 0.3477 - val_lcm_recall_2k: 0.5251 - val_lcm_recall_3k: 0.6192 - val_lcm_recall_5k: 0.7185 - val_lcm_f1_1k: 0.4252 - val_lcm_f1_2k: 0.4762 - val_lcm_f1_3k: 0.4504 - val_lcm_f1_5k: 0.3765 - val_lcm_accuracy_1k: 0.5474 - val_lcm_accuracy_2k: 0.7096 - val_lcm_accuracy_3k: 0.7869 - val_lcm_accuracy_5k: 0.8569 - val_lcm_hamming_loss_k: 0.0042
Epoch 15/150
27/27 [==============================] - ETA: 0s - loss: 0.2296 - lcm_precision_1k: 0.6462 - lcm_precision_2k: 0.5060 - lcm_precision_3k: 0.4075 - lcm_precision_5k: 0.2914 - lcm_recall_1k: 0.4047 - lcm_recall_2k: 0.5948 - lcm_recall_3k: 0.6949 - lcm_recall_5k: 0.7992 - lcm_f1_1k: 0.4977 - lcm_f1_2k: 0.5468 - lcm_f1_3k: 0.5137 - lcm_f1_5k: 0.4270 - lcm_accuracy_1k: 0.6462 - lcm_accuracy_2k: 0.7962 - lcm_accuracy_3k: 0.8591 - lcm_accuracy_5k: 0.9173 - lcm_hamming_loss_k: 0.0038
Epoch 00015: val_loss improved from 0.27197 to 0.27098, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.2296 - lcm_precision_1k: 0.6462 - lcm_precision_2k: 0.5060 - lcm_precision_3k: 0.4075 - lcm_precision_5k: 0.2914 - lcm_recall_1k: 0.4047 - lcm_recall_2k: 0.5948 - lcm_recall_3k: 0.6949 - lcm_recall_5k: 0.7992 - lcm_f1_1k: 0.4977 - lcm_f1_2k: 0.5468 - lcm_f1_3k: 0.5137 - lcm_f1_5k: 0.4270 - lcm_accuracy_1k: 0.6462 - lcm_accuracy_2k: 0.7962 - lcm_accuracy_3k: 0.8591 - lcm_accuracy_5k: 0.9173 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2710 - val_lcm_precision_1k: 0.5486 - val_lcm_precision_2k: 0.4343 - val_lcm_precision_3k: 0.3544 - val_lcm_precision_5k: 0.2555 - val_lcm_recall_1k: 0.3485 - val_lcm_recall_2k: 0.5224 - val_lcm_recall_3k: 0.6201 - val_lcm_recall_5k: 0.7211 - val_lcm_f1_1k: 0.4262 - val_lcm_f1_2k: 0.4742 - val_lcm_f1_3k: 0.4509 - val_lcm_f1_5k: 0.3771 - val_lcm_accuracy_1k: 0.5486 - val_lcm_accuracy_2k: 0.7103 - val_lcm_accuracy_3k: 0.7833 - val_lcm_accuracy_5k: 0.8582 - val_lcm_hamming_loss_k: 0.0042
Epoch 16/150
27/27 [==============================] - ETA: 0s - loss: 0.2235 - lcm_precision_1k: 0.6642 - lcm_precision_2k: 0.5165 - lcm_precision_3k: 0.4161 - lcm_precision_5k: 0.2959 - lcm_recall_1k: 0.4183 - lcm_recall_2k: 0.6071 - lcm_recall_3k: 0.7075 - lcm_recall_5k: 0.8116 - lcm_f1_1k: 0.5133 - lcm_f1_2k: 0.5581 - lcm_f1_3k: 0.5240 - lcm_f1_5k: 0.4337 - lcm_accuracy_1k: 0.6642 - lcm_accuracy_2k: 0.8080 - lcm_accuracy_3k: 0.8692 - lcm_accuracy_5k: 0.9264 - lcm_hamming_loss_k: 0.0037
Epoch 00016: val_loss did not improve from 0.27098
27/27 [==============================] - 9s 336ms/step - loss: 0.2235 - lcm_precision_1k: 0.6642 - lcm_precision_2k: 0.5165 - lcm_precision_3k: 0.4161 - lcm_precision_5k: 0.2959 - lcm_recall_1k: 0.4183 - lcm_recall_2k: 0.6071 - lcm_recall_3k: 0.7075 - lcm_recall_5k: 0.8116 - lcm_f1_1k: 0.5133 - lcm_f1_2k: 0.5581 - lcm_f1_3k: 0.5240 - lcm_f1_5k: 0.4337 - lcm_accuracy_1k: 0.6642 - lcm_accuracy_2k: 0.8080 - lcm_accuracy_3k: 0.8692 - lcm_accuracy_5k: 0.9264 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2724 - val_lcm_precision_1k: 0.5538 - val_lcm_precision_2k: 0.4428 - val_lcm_precision_3k: 0.3546 - val_lcm_precision_5k: 0.2554 - val_lcm_recall_1k: 0.3504 - val_lcm_recall_2k: 0.5317 - val_lcm_recall_3k: 0.6192 - val_lcm_recall_5k: 0.7207 - val_lcm_f1_1k: 0.4291 - val_lcm_f1_2k: 0.4831 - val_lcm_f1_3k: 0.4509 - val_lcm_f1_5k: 0.3770 - val_lcm_accuracy_1k: 0.5538 - val_lcm_accuracy_2k: 0.7178 - val_lcm_accuracy_3k: 0.7823 - val_lcm_accuracy_5k: 0.8583 - val_lcm_hamming_loss_k: 0.0042
Epoch 17/150
27/27 [==============================] - ETA: 0s - loss: 0.2180 - lcm_precision_1k: 0.6800 - lcm_precision_2k: 0.5300 - lcm_precision_3k: 0.4242 - lcm_precision_5k: 0.2998 - lcm_recall_1k: 0.4274 - lcm_recall_2k: 0.6222 - lcm_recall_3k: 0.7211 - lcm_recall_5k: 0.8218 - lcm_f1_1k: 0.5248 - lcm_f1_2k: 0.5724 - lcm_f1_3k: 0.5341 - lcm_f1_5k: 0.4393 - lcm_accuracy_1k: 0.6800 - lcm_accuracy_2k: 0.8235 - lcm_accuracy_3k: 0.8813 - lcm_accuracy_5k: 0.9311 - lcm_hamming_loss_k: 0.0036
Epoch 00017: val_loss improved from 0.27098 to 0.27029, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 365ms/step - loss: 0.2180 - lcm_precision_1k: 0.6800 - lcm_precision_2k: 0.5300 - lcm_precision_3k: 0.4242 - lcm_precision_5k: 0.2998 - lcm_recall_1k: 0.4274 - lcm_recall_2k: 0.6222 - lcm_recall_3k: 0.7211 - lcm_recall_5k: 0.8218 - lcm_f1_1k: 0.5248 - lcm_f1_2k: 0.5724 - lcm_f1_3k: 0.5341 - lcm_f1_5k: 0.4393 - lcm_accuracy_1k: 0.6800 - lcm_accuracy_2k: 0.8235 - lcm_accuracy_3k: 0.8813 - lcm_accuracy_5k: 0.9311 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2703 - val_lcm_precision_1k: 0.5710 - val_lcm_precision_2k: 0.4438 - val_lcm_precision_3k: 0.3567 - val_lcm_precision_5k: 0.2574 - val_lcm_recall_1k: 0.3634 - val_lcm_recall_2k: 0.5323 - val_lcm_recall_3k: 0.6251 - val_lcm_recall_5k: 0.7277 - val_lcm_f1_1k: 0.4441 - val_lcm_f1_2k: 0.4839 - val_lcm_f1_3k: 0.4541 - val_lcm_f1_5k: 0.3802 - val_lcm_accuracy_1k: 0.5710 - val_lcm_accuracy_2k: 0.7280 - val_lcm_accuracy_3k: 0.7988 - val_lcm_accuracy_5k: 0.8658 - val_lcm_hamming_loss_k: 0.0041
Epoch 18/150
27/27 [==============================] - ETA: 0s - loss: 0.2103 - lcm_precision_1k: 0.6946 - lcm_precision_2k: 0.5417 - lcm_precision_3k: 0.4339 - lcm_precision_5k: 0.3056 - lcm_recall_1k: 0.4377 - lcm_recall_2k: 0.6367 - lcm_recall_3k: 0.7371 - lcm_recall_5k: 0.8362 - lcm_f1_1k: 0.5370 - lcm_f1_2k: 0.5853 - lcm_f1_3k: 0.5462 - lcm_f1_5k: 0.4476 - lcm_accuracy_1k: 0.6946 - lcm_accuracy_2k: 0.8409 - lcm_accuracy_3k: 0.8942 - lcm_accuracy_5k: 0.9406 - lcm_hamming_loss_k: 0.0036
Epoch 00018: val_loss improved from 0.27029 to 0.26667, saving model to logs/xyabed-lbs-0604-123450/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 366ms/step - loss: 0.2103 - lcm_precision_1k: 0.6946 - lcm_precision_2k: 0.5417 - lcm_precision_3k: 0.4339 - lcm_precision_5k: 0.3056 - lcm_recall_1k: 0.4377 - lcm_recall_2k: 0.6367 - lcm_recall_3k: 0.7371 - lcm_recall_5k: 0.8362 - lcm_f1_1k: 0.5370 - lcm_f1_2k: 0.5853 - lcm_f1_3k: 0.5462 - lcm_f1_5k: 0.4476 - lcm_accuracy_1k: 0.6946 - lcm_accuracy_2k: 0.8409 - lcm_accuracy_3k: 0.8942 - lcm_accuracy_5k: 0.9406 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2667 - val_lcm_precision_1k: 0.5755 - val_lcm_precision_2k: 0.4484 - val_lcm_precision_3k: 0.3615 - val_lcm_precision_5k: 0.2596 - val_lcm_recall_1k: 0.3638 - val_lcm_recall_2k: 0.5401 - val_lcm_recall_3k: 0.6324 - val_lcm_recall_5k: 0.7326 - val_lcm_f1_1k: 0.4457 - val_lcm_f1_2k: 0.4898 - val_lcm_f1_3k: 0.4598 - val_lcm_f1_5k: 0.3832 - val_lcm_accuracy_1k: 0.5755 - val_lcm_accuracy_2k: 0.7331 - val_lcm_accuracy_3k: 0.7990 - val_lcm_accuracy_5k: 0.8689 - val_lcm_hamming_loss_k: 0.0040
Epoch 19/150
27/27 [==============================] - ETA: 0s - loss: 0.2030 - lcm_precision_1k: 0.7112 - lcm_precision_2k: 0.5561 - lcm_precision_3k: 0.4439 - lcm_precision_5k: 0.3107 - lcm_recall_1k: 0.4483 - lcm_recall_2k: 0.6528 - lcm_recall_3k: 0.7520 - lcm_recall_5k: 0.8477 - lcm_f1_1k: 0.5499 - lcm_f1_2k: 0.6005 - lcm_f1_3k: 0.5582 - lcm_f1_5k: 0.4547 - lcm_accuracy_1k: 0.7112 - lcm_accuracy_2k: 0.8530 - lcm_accuracy_3k: 0.9061 - lcm_accuracy_5k: 0.9482 - lcm_hamming_loss_k: 0.0035
Epoch 00019: val_loss did not improve from 0.26667
27/27 [==============================] - 9s 340ms/step - loss: 0.2030 - lcm_precision_1k: 0.7112 - lcm_precision_2k: 0.5561 - lcm_precision_3k: 0.4439 - lcm_precision_5k: 0.3107 - lcm_recall_1k: 0.4483 - lcm_recall_2k: 0.6528 - lcm_recall_3k: 0.7520 - lcm_recall_5k: 0.8477 - lcm_f1_1k: 0.5499 - lcm_f1_2k: 0.6005 - lcm_f1_3k: 0.5582 - lcm_f1_5k: 0.4547 - lcm_accuracy_1k: 0.7112 - lcm_accuracy_2k: 0.8530 - lcm_accuracy_3k: 0.9061 - lcm_accuracy_5k: 0.9482 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2676 - val_lcm_precision_1k: 0.5673 - val_lcm_precision_2k: 0.4525 - val_lcm_precision_3k: 0.3617 - val_lcm_precision_5k: 0.2599 - val_lcm_recall_1k: 0.3618 - val_lcm_recall_2k: 0.5461 - val_lcm_recall_3k: 0.6345 - val_lcm_recall_5k: 0.7351 - val_lcm_f1_1k: 0.4417 - val_lcm_f1_2k: 0.4948 - val_lcm_f1_3k: 0.4606 - val_lcm_f1_5k: 0.3839 - val_lcm_accuracy_1k: 0.5673 - val_lcm_accuracy_2k: 0.7328 - val_lcm_accuracy_3k: 0.7961 - val_lcm_accuracy_5k: 0.8717 - val_lcm_hamming_loss_k: 0.0041
Epoch 20/150
27/27 [==============================] - ETA: 0s - loss: 0.1970 - lcm_precision_1k: 0.7254 - lcm_precision_2k: 0.5661 - lcm_precision_3k: 0.4528 - lcm_precision_5k: 0.3157 - lcm_recall_1k: 0.4594 - lcm_recall_2k: 0.6648 - lcm_recall_3k: 0.7665 - lcm_recall_5k: 0.8615 - lcm_f1_1k: 0.5624 - lcm_f1_2k: 0.6114 - lcm_f1_3k: 0.5692 - lcm_f1_5k: 0.4620 - lcm_accuracy_1k: 0.7254 - lcm_accuracy_2k: 0.8633 - lcm_accuracy_3k: 0.9131 - lcm_accuracy_5k: 0.9562 - lcm_hamming_loss_k: 0.0034
Epoch 00020: val_loss did not improve from 0.26667
27/27 [==============================] - 9s 335ms/step - loss: 0.1970 - lcm_precision_1k: 0.7254 - lcm_precision_2k: 0.5661 - lcm_precision_3k: 0.4528 - lcm_precision_5k: 0.3157 - lcm_recall_1k: 0.4594 - lcm_recall_2k: 0.6648 - lcm_recall_3k: 0.7665 - lcm_recall_5k: 0.8615 - lcm_f1_1k: 0.5624 - lcm_f1_2k: 0.6114 - lcm_f1_3k: 0.5692 - lcm_f1_5k: 0.4620 - lcm_accuracy_1k: 0.7254 - lcm_accuracy_2k: 0.8633 - lcm_accuracy_3k: 0.9131 - lcm_accuracy_5k: 0.9562 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2678 - val_lcm_precision_1k: 0.5751 - val_lcm_precision_2k: 0.4516 - val_lcm_precision_3k: 0.3654 - val_lcm_precision_5k: 0.2625 - val_lcm_recall_1k: 0.3649 - val_lcm_recall_2k: 0.5432 - val_lcm_recall_3k: 0.6412 - val_lcm_recall_5k: 0.7422 - val_lcm_f1_1k: 0.4464 - val_lcm_f1_2k: 0.4931 - val_lcm_f1_3k: 0.4654 - val_lcm_f1_5k: 0.3877 - val_lcm_accuracy_1k: 0.5751 - val_lcm_accuracy_2k: 0.7353 - val_lcm_accuracy_3k: 0.8103 - val_lcm_accuracy_5k: 0.8753 - val_lcm_hamming_loss_k: 0.0041
Epoch 00020: early stopping
176/176 [==============================] - 7s 38ms/step - loss: 0.2297 - lcm_precision_1k: 0.6527 - lcm_precision_2k: 0.5041 - lcm_precision_3k: 0.4049 - lcm_precision_5k: 0.2880 - lcm_recall_1k: 0.4144 - lcm_recall_2k: 0.5994 - lcm_recall_3k: 0.6959 - lcm_recall_5k: 0.7979 - lcm_f1_1k: 0.5055 - lcm_f1_2k: 0.5464 - lcm_f1_3k: 0.5109 - lcm_f1_5k: 0.4225 - lcm_accuracy_1k: 0.6527 - lcm_accuracy_2k: 0.7978 - lcm_accuracy_3k: 0.8540 - lcm_accuracy_5k: 0.9102 - lcm_hamming_loss_k: 0.0037 2s - loss: 0.2307 - lcm_precision_1k: 0.6576 - lcm_precision_2k: 0.5037 - lcm_precision_3k: 0.4025 - lcm_precision_5k: 0.2859 - lcm_recall_1k: 0.4185 - lcm_recall_2k: 0.6006 - lcm_recall_3k: 0.6945 - lcm_recall_5k: 0.7962 - lcm_f1_1k: 0.5099 - lcm_f1_2k: 0.5466 - lcm_f1_3k: 0.5086 - lcm_f1_5k: 0.4200 - lcm_accuracy_1k: 0.6576 - lcm_accuracy_2k: 0.7992 - lcm_accuracy_3
Best model result:  [0.22971901297569275, 0.6526561975479126, 0.5041267275810242, 0.40493983030319214, 0.28800174593925476, 0.4144092798233032, 0.5993703007698059, 0.6958515644073486, 0.79787278175354, 0.5055457353591919, 0.5463994741439819, 0.5109279751777649, 0.42248818278312683, 0.6526561975479126, 0.7977704405784607, 0.8540236949920654, 0.9102315306663513, 0.0037287429440766573]
13498
3375
5625
Model: "model_2"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['BiLSTM[0][0]']                 
                                                                                                  
==================================================================================================
Total params: 28,546,223
Trainable params: 3,767,723
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
2 patience
Model: "model_3"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 tf.__operators__.getitem_1 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_lcm_emb (Dense)          (None, 427, 1024)    308224      ['tf.__operators__.getitem_1[0][0
                                                                 ]']                              
                                                                                                  
 dot_1 (Dot)                    (None, 427)          0           ['label_lcm_emb[0][0]',          
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['BiLSTM[0][0]']                 
                                                                                                  
 label_sim_dict (Dense)         (None, 427)          182756      ['dot_1[0][0]']                  
                                                                                                  
 concatenate_1 (Concatenate)    (None, 854)          0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 29,165,303
Trainable params: 4,386,803
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
Epoch 1/150
/home/dzq/k12/atmk_system-master/MathByte/models/evaluation_metrics.py:260: RuntimeWarning: invalid value encountered in true_divide
  return (2 * p_k * r_k) / (p_k + r_k)
27/27 [==============================] - ETA: 0s - loss: 0.4993 - lcm_precision_1k: 0.1405 - lcm_precision_2k: 0.1241 - lcm_precision_3k: 0.1109 - lcm_precision_5k: 0.0939 - lcm_recall_1k: 0.0728 - lcm_recall_2k: 0.1286 - lcm_recall_3k: 0.1720 - lcm_recall_5k: 0.2409 - lcm_f1_1k: nan - lcm_f1_2k: 0.1262 - lcm_f1_3k: 0.1348 - lcm_f1_5k: 0.1351 - lcm_accuracy_1k: 0.1405 - lcm_accuracy_2k: 0.2123 - lcm_accuracy_3k: 0.2722 - lcm_accuracy_5k: 0.3502 - lcm_hamming_loss_k: 0.0061
Epoch 00001: val_loss improved from inf to 0.46119, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 11s 360ms/step - loss: 0.4993 - lcm_precision_1k: 0.1405 - lcm_precision_2k: 0.1241 - lcm_precision_3k: 0.1109 - lcm_precision_5k: 0.0939 - lcm_recall_1k: 0.0728 - lcm_recall_2k: 0.1286 - lcm_recall_3k: 0.1720 - lcm_recall_5k: 0.2409 - lcm_f1_1k: nan - lcm_f1_2k: 0.1262 - lcm_f1_3k: 0.1348 - lcm_f1_5k: 0.1351 - lcm_accuracy_1k: 0.1405 - lcm_accuracy_2k: 0.2123 - lcm_accuracy_3k: 0.2722 - lcm_accuracy_5k: 0.3502 - lcm_hamming_loss_k: 0.0061 - val_loss: 0.4612 - val_lcm_precision_1k: 0.2111 - val_lcm_precision_2k: 0.1704 - val_lcm_precision_3k: 0.1573 - val_lcm_precision_5k: 0.1404 - val_lcm_recall_1k: 0.1093 - val_lcm_recall_2k: 0.1757 - val_lcm_recall_3k: 0.2385 - val_lcm_recall_5k: 0.3626 - val_lcm_f1_1k: 0.1438 - val_lcm_f1_2k: 0.1728 - val_lcm_f1_3k: 0.1895 - val_lcm_f1_5k: 0.2023 - val_lcm_accuracy_1k: 0.2111 - val_lcm_accuracy_2k: 0.2891 - val_lcm_accuracy_3k: 0.3670 - val_lcm_accuracy_5k: 0.4960 - val_lcm_hamming_loss_k: 0.0058
Epoch 2/150
27/27 [==============================] - ETA: 0s - loss: 0.4242 - lcm_precision_1k: 0.2319 - lcm_precision_2k: 0.1947 - lcm_precision_3k: 0.1730 - lcm_precision_5k: 0.1463 - lcm_recall_1k: 0.1281 - lcm_recall_2k: 0.2129 - lcm_recall_3k: 0.2797 - lcm_recall_5k: 0.3884 - lcm_f1_1k: 0.1649 - lcm_f1_2k: 0.2033 - lcm_f1_3k: 0.2137 - lcm_f1_5k: 0.2125 - lcm_accuracy_1k: 0.2319 - lcm_accuracy_2k: 0.3365 - lcm_accuracy_3k: 0.4163 - lcm_accuracy_5k: 0.5195 - lcm_hamming_loss_k: 0.0057
Epoch 00002: val_loss improved from 0.46119 to 0.38498, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 366ms/step - loss: 0.4242 - lcm_precision_1k: 0.2319 - lcm_precision_2k: 0.1947 - lcm_precision_3k: 0.1730 - lcm_precision_5k: 0.1463 - lcm_recall_1k: 0.1281 - lcm_recall_2k: 0.2129 - lcm_recall_3k: 0.2797 - lcm_recall_5k: 0.3884 - lcm_f1_1k: 0.1649 - lcm_f1_2k: 0.2033 - lcm_f1_3k: 0.2137 - lcm_f1_5k: 0.2125 - lcm_accuracy_1k: 0.2319 - lcm_accuracy_2k: 0.3365 - lcm_accuracy_3k: 0.4163 - lcm_accuracy_5k: 0.5195 - lcm_hamming_loss_k: 0.0057 - val_loss: 0.3850 - val_lcm_precision_1k: 0.2989 - val_lcm_precision_2k: 0.2487 - val_lcm_precision_3k: 0.2189 - val_lcm_precision_5k: 0.1781 - val_lcm_recall_1k: 0.1675 - val_lcm_recall_2k: 0.2764 - val_lcm_recall_3k: 0.3561 - val_lcm_recall_5k: 0.4738 - val_lcm_f1_1k: 0.2145 - val_lcm_f1_2k: 0.2616 - val_lcm_f1_3k: 0.2710 - val_lcm_f1_5k: 0.2588 - val_lcm_accuracy_1k: 0.2989 - val_lcm_accuracy_2k: 0.4329 - val_lcm_accuracy_3k: 0.5207 - val_lcm_accuracy_5k: 0.6183 - val_lcm_hamming_loss_k: 0.0054
Epoch 3/150
27/27 [==============================] - ETA: 0s - loss: 0.3666 - lcm_precision_1k: 0.3165 - lcm_precision_2k: 0.2730 - lcm_precision_3k: 0.2362 - lcm_precision_5k: 0.1899 - lcm_recall_1k: 0.1807 - lcm_recall_2k: 0.3060 - lcm_recall_3k: 0.3902 - lcm_recall_5k: 0.5102 - lcm_f1_1k: 0.2300 - lcm_f1_2k: 0.2885 - lcm_f1_3k: 0.2942 - lcm_f1_5k: 0.2767 - lcm_accuracy_1k: 0.3165 - lcm_accuracy_2k: 0.4693 - lcm_accuracy_3k: 0.5558 - lcm_accuracy_5k: 0.6596 - lcm_hamming_loss_k: 0.0053
Epoch 00003: val_loss improved from 0.38498 to 0.35237, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 367ms/step - loss: 0.3666 - lcm_precision_1k: 0.3165 - lcm_precision_2k: 0.2730 - lcm_precision_3k: 0.2362 - lcm_precision_5k: 0.1899 - lcm_recall_1k: 0.1807 - lcm_recall_2k: 0.3060 - lcm_recall_3k: 0.3902 - lcm_recall_5k: 0.5102 - lcm_f1_1k: 0.2300 - lcm_f1_2k: 0.2885 - lcm_f1_3k: 0.2942 - lcm_f1_5k: 0.2767 - lcm_accuracy_1k: 0.3165 - lcm_accuracy_2k: 0.4693 - lcm_accuracy_3k: 0.5558 - lcm_accuracy_5k: 0.6596 - lcm_hamming_loss_k: 0.0053 - val_loss: 0.3524 - val_lcm_precision_1k: 0.3599 - val_lcm_precision_2k: 0.3019 - val_lcm_precision_3k: 0.2568 - val_lcm_precision_5k: 0.2037 - val_lcm_recall_1k: 0.2060 - val_lcm_recall_2k: 0.3431 - val_lcm_recall_3k: 0.4331 - val_lcm_recall_5k: 0.5537 - val_lcm_f1_1k: 0.2617 - val_lcm_f1_2k: 0.3209 - val_lcm_f1_3k: 0.3222 - val_lcm_f1_5k: 0.2977 - val_lcm_accuracy_1k: 0.3599 - val_lcm_accuracy_2k: 0.5242 - val_lcm_accuracy_3k: 0.6060 - val_lcm_accuracy_5k: 0.7007 - val_lcm_hamming_loss_k: 0.0051
Epoch 4/150
27/27 [==============================] - ETA: 0s - loss: 0.3363 - lcm_precision_1k: 0.3787 - lcm_precision_2k: 0.3217 - lcm_precision_3k: 0.2743 - lcm_precision_5k: 0.2130 - lcm_recall_1k: 0.2219 - lcm_recall_2k: 0.3657 - lcm_recall_3k: 0.4607 - lcm_recall_5k: 0.5801 - lcm_f1_1k: 0.2797 - lcm_f1_2k: 0.3422 - lcm_f1_3k: 0.3438 - lcm_f1_5k: 0.3115 - lcm_accuracy_1k: 0.3787 - lcm_accuracy_2k: 0.5427 - lcm_accuracy_3k: 0.6334 - lcm_accuracy_5k: 0.7280 - lcm_hamming_loss_k: 0.0050
Epoch 00004: val_loss improved from 0.35237 to 0.34116, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 366ms/step - loss: 0.3363 - lcm_precision_1k: 0.3787 - lcm_precision_2k: 0.3217 - lcm_precision_3k: 0.2743 - lcm_precision_5k: 0.2130 - lcm_recall_1k: 0.2219 - lcm_recall_2k: 0.3657 - lcm_recall_3k: 0.4607 - lcm_recall_5k: 0.5801 - lcm_f1_1k: 0.2797 - lcm_f1_2k: 0.3422 - lcm_f1_3k: 0.3438 - lcm_f1_5k: 0.3115 - lcm_accuracy_1k: 0.3787 - lcm_accuracy_2k: 0.5427 - lcm_accuracy_3k: 0.6334 - lcm_accuracy_5k: 0.7280 - lcm_hamming_loss_k: 0.0050 - val_loss: 0.3412 - val_lcm_precision_1k: 0.3805 - val_lcm_precision_2k: 0.3199 - val_lcm_precision_3k: 0.2717 - val_lcm_precision_5k: 0.2095 - val_lcm_recall_1k: 0.2271 - val_lcm_recall_2k: 0.3736 - val_lcm_recall_3k: 0.4633 - val_lcm_recall_5k: 0.5777 - val_lcm_f1_1k: 0.2842 - val_lcm_f1_2k: 0.3444 - val_lcm_f1_3k: 0.3424 - val_lcm_f1_5k: 0.3074 - val_lcm_accuracy_1k: 0.3805 - val_lcm_accuracy_2k: 0.5500 - val_lcm_accuracy_3k: 0.6422 - val_lcm_accuracy_5k: 0.7405 - val_lcm_hamming_loss_k: 0.0051
Epoch 5/150
27/27 [==============================] - ETA: 0s - loss: 0.3224 - lcm_precision_1k: 0.4127 - lcm_precision_2k: 0.3412 - lcm_precision_3k: 0.2898 - lcm_precision_5k: 0.2217 - lcm_recall_1k: 0.2463 - lcm_recall_2k: 0.3918 - lcm_recall_3k: 0.4903 - lcm_recall_5k: 0.6076 - lcm_f1_1k: 0.3085 - lcm_f1_2k: 0.3647 - lcm_f1_3k: 0.3643 - lcm_f1_5k: 0.3248 - lcm_accuracy_1k: 0.4127 - lcm_accuracy_2k: 0.5730 - lcm_accuracy_3k: 0.6659 - lcm_accuracy_5k: 0.7574 - lcm_hamming_loss_k: 0.0049
Epoch 00005: val_loss improved from 0.34116 to 0.32297, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.3224 - lcm_precision_1k: 0.4127 - lcm_precision_2k: 0.3412 - lcm_precision_3k: 0.2898 - lcm_precision_5k: 0.2217 - lcm_recall_1k: 0.2463 - lcm_recall_2k: 0.3918 - lcm_recall_3k: 0.4903 - lcm_recall_5k: 0.6076 - lcm_f1_1k: 0.3085 - lcm_f1_2k: 0.3647 - lcm_f1_3k: 0.3643 - lcm_f1_5k: 0.3248 - lcm_accuracy_1k: 0.4127 - lcm_accuracy_2k: 0.5730 - lcm_accuracy_3k: 0.6659 - lcm_accuracy_5k: 0.7574 - lcm_hamming_loss_k: 0.0049 - val_loss: 0.3230 - val_lcm_precision_1k: 0.4143 - val_lcm_precision_2k: 0.3520 - val_lcm_precision_3k: 0.2979 - val_lcm_precision_5k: 0.2279 - val_lcm_recall_1k: 0.2465 - val_lcm_recall_2k: 0.4034 - val_lcm_recall_3k: 0.5033 - val_lcm_recall_5k: 0.6195 - val_lcm_f1_1k: 0.3089 - val_lcm_f1_2k: 0.3758 - val_lcm_f1_3k: 0.3741 - val_lcm_f1_5k: 0.3332 - val_lcm_accuracy_1k: 0.4143 - val_lcm_accuracy_2k: 0.5889 - val_lcm_accuracy_3k: 0.6786 - val_lcm_accuracy_5k: 0.7697 - val_lcm_hamming_loss_k: 0.0049
Epoch 6/150
27/27 [==============================] - ETA: 0s - loss: 0.3091 - lcm_precision_1k: 0.4528 - lcm_precision_2k: 0.3650 - lcm_precision_3k: 0.3055 - lcm_precision_5k: 0.2308 - lcm_recall_1k: 0.2740 - lcm_recall_2k: 0.4208 - lcm_recall_3k: 0.5173 - lcm_recall_5k: 0.6333 - lcm_f1_1k: 0.3414 - lcm_f1_2k: 0.3909 - lcm_f1_3k: 0.3841 - lcm_f1_5k: 0.3383 - lcm_accuracy_1k: 0.4528 - lcm_accuracy_2k: 0.6042 - lcm_accuracy_3k: 0.6919 - lcm_accuracy_5k: 0.7815 - lcm_hamming_loss_k: 0.0047
Epoch 00006: val_loss improved from 0.32297 to 0.31244, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.3091 - lcm_precision_1k: 0.4528 - lcm_precision_2k: 0.3650 - lcm_precision_3k: 0.3055 - lcm_precision_5k: 0.2308 - lcm_recall_1k: 0.2740 - lcm_recall_2k: 0.4208 - lcm_recall_3k: 0.5173 - lcm_recall_5k: 0.6333 - lcm_f1_1k: 0.3414 - lcm_f1_2k: 0.3909 - lcm_f1_3k: 0.3841 - lcm_f1_5k: 0.3383 - lcm_accuracy_1k: 0.4528 - lcm_accuracy_2k: 0.6042 - lcm_accuracy_3k: 0.6919 - lcm_accuracy_5k: 0.7815 - lcm_hamming_loss_k: 0.0047 - val_loss: 0.3124 - val_lcm_precision_1k: 0.4442 - val_lcm_precision_2k: 0.3743 - val_lcm_precision_3k: 0.3123 - val_lcm_precision_5k: 0.2347 - val_lcm_recall_1k: 0.2651 - val_lcm_recall_2k: 0.4261 - val_lcm_recall_3k: 0.5278 - val_lcm_recall_5k: 0.6422 - val_lcm_f1_1k: 0.3319 - val_lcm_f1_2k: 0.3984 - val_lcm_f1_3k: 0.3923 - val_lcm_f1_5k: 0.3436 - val_lcm_accuracy_1k: 0.4442 - val_lcm_accuracy_2k: 0.6140 - val_lcm_accuracy_3k: 0.7070 - val_lcm_accuracy_5k: 0.7909 - val_lcm_hamming_loss_k: 0.0048
Epoch 7/150
27/27 [==============================] - ETA: 0s - loss: 0.2950 - lcm_precision_1k: 0.4854 - lcm_precision_2k: 0.3891 - lcm_precision_3k: 0.3211 - lcm_precision_5k: 0.2406 - lcm_recall_1k: 0.2951 - lcm_recall_2k: 0.4507 - lcm_recall_3k: 0.5457 - lcm_recall_5k: 0.6622 - lcm_f1_1k: 0.3669 - lcm_f1_2k: 0.4176 - lcm_f1_3k: 0.4042 - lcm_f1_5k: 0.3529 - lcm_accuracy_1k: 0.4854 - lcm_accuracy_2k: 0.6386 - lcm_accuracy_3k: 0.7204 - lcm_accuracy_5k: 0.8078 - lcm_hamming_loss_k: 0.0045 ETA: 1s - loss: 0.2948 - lcm_precision_1k: 0.4856 - lcm_precision_2k: 0.3889 - lcm_precision_3k: 0.3217 - lcm_precision_5k: 0.2416 - lcm_recall_1k: 0.2961 - lcm_recall_2k: 0.4520 - lcm_recall_3k: 0.5488 - lcm_recall_5k: 0.6660 - lcm_f1_1k: 0.3678 - lcm_f1_2k: 0.4180 - lcm_f1_3k: 0.4056 - lcm_f1_5k: 0.3545 - lcm_accuracy_1k: 0.4856 - lcm_accuracy_2k: 0.6387 - lcm_accuracy_3k: 0.7237 - lcm_accuracy_5k: 0.8112 - lcm_hamming_
Epoch 00007: val_loss improved from 0.31244 to 0.30606, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.2950 - lcm_precision_1k: 0.4854 - lcm_precision_2k: 0.3891 - lcm_precision_3k: 0.3211 - lcm_precision_5k: 0.2406 - lcm_recall_1k: 0.2951 - lcm_recall_2k: 0.4507 - lcm_recall_3k: 0.5457 - lcm_recall_5k: 0.6622 - lcm_f1_1k: 0.3669 - lcm_f1_2k: 0.4176 - lcm_f1_3k: 0.4042 - lcm_f1_5k: 0.3529 - lcm_accuracy_1k: 0.4854 - lcm_accuracy_2k: 0.6386 - lcm_accuracy_3k: 0.7204 - lcm_accuracy_5k: 0.8078 - lcm_hamming_loss_k: 0.0045 - val_loss: 0.3061 - val_lcm_precision_1k: 0.4882 - val_lcm_precision_2k: 0.3892 - val_lcm_precision_3k: 0.3214 - val_lcm_precision_5k: 0.2404 - val_lcm_recall_1k: 0.2959 - val_lcm_recall_2k: 0.4460 - val_lcm_recall_3k: 0.5426 - val_lcm_recall_5k: 0.6581 - val_lcm_f1_1k: 0.3683 - val_lcm_f1_2k: 0.4155 - val_lcm_f1_3k: 0.4036 - val_lcm_f1_5k: 0.3521 - val_lcm_accuracy_1k: 0.4882 - val_lcm_accuracy_2k: 0.6343 - val_lcm_accuracy_3k: 0.7133 - val_lcm_accuracy_5k: 0.8054 - val_lcm_hamming_loss_k: 0.0045
Epoch 8/150
27/27 [==============================] - ETA: 0s - loss: 0.2865 - lcm_precision_1k: 0.5110 - lcm_precision_2k: 0.4042 - lcm_precision_3k: 0.3354 - lcm_precision_5k: 0.2487 - lcm_recall_1k: 0.3141 - lcm_recall_2k: 0.4692 - lcm_recall_3k: 0.5718 - lcm_recall_5k: 0.6864 - lcm_f1_1k: 0.3890 - lcm_f1_2k: 0.4341 - lcm_f1_3k: 0.4227 - lcm_f1_5k: 0.3651 - lcm_accuracy_1k: 0.5110 - lcm_accuracy_2k: 0.6596 - lcm_accuracy_3k: 0.7448 - lcm_accuracy_5k: 0.8284 - lcm_hamming_loss_k: 0.0044
Epoch 00008: val_loss improved from 0.30606 to 0.30108, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 368ms/step - loss: 0.2865 - lcm_precision_1k: 0.5110 - lcm_precision_2k: 0.4042 - lcm_precision_3k: 0.3354 - lcm_precision_5k: 0.2487 - lcm_recall_1k: 0.3141 - lcm_recall_2k: 0.4692 - lcm_recall_3k: 0.5718 - lcm_recall_5k: 0.6864 - lcm_f1_1k: 0.3890 - lcm_f1_2k: 0.4341 - lcm_f1_3k: 0.4227 - lcm_f1_5k: 0.3651 - lcm_accuracy_1k: 0.5110 - lcm_accuracy_2k: 0.6596 - lcm_accuracy_3k: 0.7448 - lcm_accuracy_5k: 0.8284 - lcm_hamming_loss_k: 0.0044 - val_loss: 0.3011 - val_lcm_precision_1k: 0.4993 - val_lcm_precision_2k: 0.3988 - val_lcm_precision_3k: 0.3282 - val_lcm_precision_5k: 0.2438 - val_lcm_recall_1k: 0.3023 - val_lcm_recall_2k: 0.4602 - val_lcm_recall_3k: 0.5548 - val_lcm_recall_5k: 0.6687 - val_lcm_f1_1k: 0.3765 - val_lcm_f1_2k: 0.4272 - val_lcm_f1_3k: 0.4123 - val_lcm_f1_5k: 0.3572 - val_lcm_accuracy_1k: 0.4993 - val_lcm_accuracy_2k: 0.6473 - val_lcm_accuracy_3k: 0.7249 - val_lcm_accuracy_5k: 0.8083 - val_lcm_hamming_loss_k: 0.0045
Epoch 9/150
27/27 [==============================] - ETA: 0s - loss: 0.2799 - lcm_precision_1k: 0.5305 - lcm_precision_2k: 0.4208 - lcm_precision_3k: 0.3453 - lcm_precision_5k: 0.2540 - lcm_recall_1k: 0.3261 - lcm_recall_2k: 0.4891 - lcm_recall_3k: 0.5892 - lcm_recall_5k: 0.7004 - lcm_f1_1k: 0.4038 - lcm_f1_2k: 0.4523 - lcm_f1_3k: 0.4354 - lcm_f1_5k: 0.3727 - lcm_accuracy_1k: 0.5305 - lcm_accuracy_2k: 0.6794 - lcm_accuracy_3k: 0.7608 - lcm_accuracy_5k: 0.8391 - lcm_hamming_loss_k: 0.0043
Epoch 00009: val_loss improved from 0.30108 to 0.29200, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 367ms/step - loss: 0.2799 - lcm_precision_1k: 0.5305 - lcm_precision_2k: 0.4208 - lcm_precision_3k: 0.3453 - lcm_precision_5k: 0.2540 - lcm_recall_1k: 0.3261 - lcm_recall_2k: 0.4891 - lcm_recall_3k: 0.5892 - lcm_recall_5k: 0.7004 - lcm_f1_1k: 0.4038 - lcm_f1_2k: 0.4523 - lcm_f1_3k: 0.4354 - lcm_f1_5k: 0.3727 - lcm_accuracy_1k: 0.5305 - lcm_accuracy_2k: 0.6794 - lcm_accuracy_3k: 0.7608 - lcm_accuracy_5k: 0.8391 - lcm_hamming_loss_k: 0.0043 - val_loss: 0.2920 - val_lcm_precision_1k: 0.5279 - val_lcm_precision_2k: 0.4162 - val_lcm_precision_3k: 0.3389 - val_lcm_precision_5k: 0.2474 - val_lcm_recall_1k: 0.3237 - val_lcm_recall_2k: 0.4805 - val_lcm_recall_3k: 0.5764 - val_lcm_recall_5k: 0.6786 - val_lcm_f1_1k: 0.4012 - val_lcm_f1_2k: 0.4459 - val_lcm_f1_3k: 0.4267 - val_lcm_f1_5k: 0.3625 - val_lcm_accuracy_1k: 0.5279 - val_lcm_accuracy_2k: 0.6648 - val_lcm_accuracy_3k: 0.7452 - val_lcm_accuracy_5k: 0.8198 - val_lcm_hamming_loss_k: 0.0044
Epoch 10/150
27/27 [==============================] - ETA: 0s - loss: 0.2683 - lcm_precision_1k: 0.5530 - lcm_precision_2k: 0.4366 - lcm_precision_3k: 0.3576 - lcm_precision_5k: 0.2605 - lcm_recall_1k: 0.3430 - lcm_recall_2k: 0.5096 - lcm_recall_3k: 0.6110 - lcm_recall_5k: 0.7201 - lcm_f1_1k: 0.4233 - lcm_f1_2k: 0.4702 - lcm_f1_3k: 0.4511 - lcm_f1_5k: 0.3826 - lcm_accuracy_1k: 0.5530 - lcm_accuracy_2k: 0.7032 - lcm_accuracy_3k: 0.7830 - lcm_accuracy_5k: 0.8562 - lcm_hamming_loss_k: 0.0042
Epoch 00010: val_loss improved from 0.29200 to 0.28176, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 370ms/step - loss: 0.2683 - lcm_precision_1k: 0.5530 - lcm_precision_2k: 0.4366 - lcm_precision_3k: 0.3576 - lcm_precision_5k: 0.2605 - lcm_recall_1k: 0.3430 - lcm_recall_2k: 0.5096 - lcm_recall_3k: 0.6110 - lcm_recall_5k: 0.7201 - lcm_f1_1k: 0.4233 - lcm_f1_2k: 0.4702 - lcm_f1_3k: 0.4511 - lcm_f1_5k: 0.3826 - lcm_accuracy_1k: 0.5530 - lcm_accuracy_2k: 0.7032 - lcm_accuracy_3k: 0.7830 - lcm_accuracy_5k: 0.8562 - lcm_hamming_loss_k: 0.0042 - val_loss: 0.2818 - val_lcm_precision_1k: 0.5490 - val_lcm_precision_2k: 0.4292 - val_lcm_precision_3k: 0.3534 - val_lcm_precision_5k: 0.2554 - val_lcm_recall_1k: 0.3381 - val_lcm_recall_2k: 0.4958 - val_lcm_recall_3k: 0.6006 - val_lcm_recall_5k: 0.7014 - val_lcm_f1_1k: 0.4183 - val_lcm_f1_2k: 0.4599 - val_lcm_f1_3k: 0.4448 - val_lcm_f1_5k: 0.3744 - val_lcm_accuracy_1k: 0.5490 - val_lcm_accuracy_2k: 0.6878 - val_lcm_accuracy_3k: 0.7705 - val_lcm_accuracy_5k: 0.8381 - val_lcm_hamming_loss_k: 0.0043
Epoch 11/150
27/27 [==============================] - ETA: 0s - loss: 0.2590 - lcm_precision_1k: 0.5721 - lcm_precision_2k: 0.4505 - lcm_precision_3k: 0.3684 - lcm_precision_5k: 0.2681 - lcm_recall_1k: 0.3553 - lcm_recall_2k: 0.5278 - lcm_recall_3k: 0.6305 - lcm_recall_5k: 0.7402 - lcm_f1_1k: 0.4383 - lcm_f1_2k: 0.4861 - lcm_f1_3k: 0.4650 - lcm_f1_5k: 0.3936 - lcm_accuracy_1k: 0.5721 - lcm_accuracy_2k: 0.7218 - lcm_accuracy_3k: 0.7992 - lcm_accuracy_5k: 0.8721 - lcm_hamming_loss_k: 0.0041
Epoch 00011: val_loss did not improve from 0.28176
27/27 [==============================] - 9s 340ms/step - loss: 0.2590 - lcm_precision_1k: 0.5721 - lcm_precision_2k: 0.4505 - lcm_precision_3k: 0.3684 - lcm_precision_5k: 0.2681 - lcm_recall_1k: 0.3553 - lcm_recall_2k: 0.5278 - lcm_recall_3k: 0.6305 - lcm_recall_5k: 0.7402 - lcm_f1_1k: 0.4383 - lcm_f1_2k: 0.4861 - lcm_f1_3k: 0.4650 - lcm_f1_5k: 0.3936 - lcm_accuracy_1k: 0.5721 - lcm_accuracy_2k: 0.7218 - lcm_accuracy_3k: 0.7992 - lcm_accuracy_5k: 0.8721 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2824 - val_lcm_precision_1k: 0.5496 - val_lcm_precision_2k: 0.4254 - val_lcm_precision_3k: 0.3458 - val_lcm_precision_5k: 0.2533 - val_lcm_recall_1k: 0.3396 - val_lcm_recall_2k: 0.4963 - val_lcm_recall_3k: 0.5922 - val_lcm_recall_5k: 0.6982 - val_lcm_f1_1k: 0.4197 - val_lcm_f1_2k: 0.4580 - val_lcm_f1_3k: 0.4364 - val_lcm_f1_5k: 0.3716 - val_lcm_accuracy_1k: 0.5496 - val_lcm_accuracy_2k: 0.6915 - val_lcm_accuracy_3k: 0.7666 - val_lcm_accuracy_5k: 0.8384 - val_lcm_hamming_loss_k: 0.0043
Epoch 12/150
27/27 [==============================] - ETA: 0s - loss: 0.2532 - lcm_precision_1k: 0.5842 - lcm_precision_2k: 0.4592 - lcm_precision_3k: 0.3756 - lcm_precision_5k: 0.2720 - lcm_recall_1k: 0.3647 - lcm_recall_2k: 0.5398 - lcm_recall_3k: 0.6424 - lcm_recall_5k: 0.7525 - lcm_f1_1k: 0.4489 - lcm_f1_2k: 0.4962 - lcm_f1_3k: 0.4740 - lcm_f1_5k: 0.3996 - lcm_accuracy_1k: 0.5842 - lcm_accuracy_2k: 0.7371 - lcm_accuracy_3k: 0.8112 - lcm_accuracy_5k: 0.8821 - lcm_hamming_loss_k: 0.0041
Epoch 00012: val_loss improved from 0.28176 to 0.27389, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 368ms/step - loss: 0.2532 - lcm_precision_1k: 0.5842 - lcm_precision_2k: 0.4592 - lcm_precision_3k: 0.3756 - lcm_precision_5k: 0.2720 - lcm_recall_1k: 0.3647 - lcm_recall_2k: 0.5398 - lcm_recall_3k: 0.6424 - lcm_recall_5k: 0.7525 - lcm_f1_1k: 0.4489 - lcm_f1_2k: 0.4962 - lcm_f1_3k: 0.4740 - lcm_f1_5k: 0.3996 - lcm_accuracy_1k: 0.5842 - lcm_accuracy_2k: 0.7371 - lcm_accuracy_3k: 0.8112 - lcm_accuracy_5k: 0.8821 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2739 - val_lcm_precision_1k: 0.5633 - val_lcm_precision_2k: 0.4454 - val_lcm_precision_3k: 0.3553 - val_lcm_precision_5k: 0.2590 - val_lcm_recall_1k: 0.3482 - val_lcm_recall_2k: 0.5207 - val_lcm_recall_3k: 0.6078 - val_lcm_recall_5k: 0.7151 - val_lcm_f1_1k: 0.4302 - val_lcm_f1_2k: 0.4800 - val_lcm_f1_3k: 0.4483 - val_lcm_f1_5k: 0.3801 - val_lcm_accuracy_1k: 0.5633 - val_lcm_accuracy_2k: 0.7088 - val_lcm_accuracy_3k: 0.7710 - val_lcm_accuracy_5k: 0.8455 - val_lcm_hamming_loss_k: 0.0042
Epoch 13/150
27/27 [==============================] - ETA: 0s - loss: 0.2437 - lcm_precision_1k: 0.6061 - lcm_precision_2k: 0.4770 - lcm_precision_3k: 0.3870 - lcm_precision_5k: 0.2779 - lcm_recall_1k: 0.3795 - lcm_recall_2k: 0.5632 - lcm_recall_3k: 0.6644 - lcm_recall_5k: 0.7678 - lcm_f1_1k: 0.4667 - lcm_f1_2k: 0.5164 - lcm_f1_3k: 0.4890 - lcm_f1_5k: 0.4081 - lcm_accuracy_1k: 0.6061 - lcm_accuracy_2k: 0.7603 - lcm_accuracy_3k: 0.8323 - lcm_accuracy_5k: 0.8944 - lcm_hamming_loss_k: 0.0040 ETA: 2s - loss: 0.2429 - lcm_precision_1k: 0.6122 - lcm_precision_2k: 0.4801 - lcm_precision_3k: 0.3894 - lcm_precision_5k: 0.2795 - lcm_recall_1k: 0.3813 - lcm_recall_2k: 0.5637 - lcm_recall_3k: 0.6649 - lcm_recall_5k: 0.7690 - lcm_f1_1k: 0.4698 - lcm_f1_2k: 0.5185 - lcm_f1_3k: 0.4911 - lcm_f1_5k: 0.4100 - lcm_accuracy_1k: 0.6122 - lcm_accuracy_2k: 0.7625 - lcm_accuracy_3k: 0.8332 - lcm_accuracy_5k: 0.8957 - lcm_hammin
Epoch 00013: val_loss improved from 0.27389 to 0.27313, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 370ms/step - loss: 0.2437 - lcm_precision_1k: 0.6061 - lcm_precision_2k: 0.4770 - lcm_precision_3k: 0.3870 - lcm_precision_5k: 0.2779 - lcm_recall_1k: 0.3795 - lcm_recall_2k: 0.5632 - lcm_recall_3k: 0.6644 - lcm_recall_5k: 0.7678 - lcm_f1_1k: 0.4667 - lcm_f1_2k: 0.5164 - lcm_f1_3k: 0.4890 - lcm_f1_5k: 0.4081 - lcm_accuracy_1k: 0.6061 - lcm_accuracy_2k: 0.7603 - lcm_accuracy_3k: 0.8323 - lcm_accuracy_5k: 0.8944 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2731 - val_lcm_precision_1k: 0.5686 - val_lcm_precision_2k: 0.4504 - val_lcm_precision_3k: 0.3616 - val_lcm_precision_5k: 0.2618 - val_lcm_recall_1k: 0.3543 - val_lcm_recall_2k: 0.5310 - val_lcm_recall_3k: 0.6211 - val_lcm_recall_5k: 0.7232 - val_lcm_f1_1k: 0.4364 - val_lcm_f1_2k: 0.4872 - val_lcm_f1_3k: 0.4569 - val_lcm_f1_5k: 0.3843 - val_lcm_accuracy_1k: 0.5686 - val_lcm_accuracy_2k: 0.7219 - val_lcm_accuracy_3k: 0.7922 - val_lcm_accuracy_5k: 0.8567 - val_lcm_hamming_loss_k: 0.0042
Epoch 14/150
27/27 [==============================] - ETA: 0s - loss: 0.2367 - lcm_precision_1k: 0.6278 - lcm_precision_2k: 0.4896 - lcm_precision_3k: 0.3955 - lcm_precision_5k: 0.2834 - lcm_recall_1k: 0.3930 - lcm_recall_2k: 0.5779 - lcm_recall_3k: 0.6772 - lcm_recall_5k: 0.7831 - lcm_f1_1k: 0.4833 - lcm_f1_2k: 0.5300 - lcm_f1_3k: 0.4993 - lcm_f1_5k: 0.4161 - lcm_accuracy_1k: 0.6278 - lcm_accuracy_2k: 0.7775 - lcm_accuracy_3k: 0.8438 - lcm_accuracy_5k: 0.9039 - lcm_hamming_loss_k: 0.0039
Epoch 00014: val_loss improved from 0.27313 to 0.26829, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 371ms/step - loss: 0.2367 - lcm_precision_1k: 0.6278 - lcm_precision_2k: 0.4896 - lcm_precision_3k: 0.3955 - lcm_precision_5k: 0.2834 - lcm_recall_1k: 0.3930 - lcm_recall_2k: 0.5779 - lcm_recall_3k: 0.6772 - lcm_recall_5k: 0.7831 - lcm_f1_1k: 0.4833 - lcm_f1_2k: 0.5300 - lcm_f1_3k: 0.4993 - lcm_f1_5k: 0.4161 - lcm_accuracy_1k: 0.6278 - lcm_accuracy_2k: 0.7775 - lcm_accuracy_3k: 0.8438 - lcm_accuracy_5k: 0.9039 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2683 - val_lcm_precision_1k: 0.5644 - val_lcm_precision_2k: 0.4513 - val_lcm_precision_3k: 0.3671 - val_lcm_precision_5k: 0.2654 - val_lcm_recall_1k: 0.3513 - val_lcm_recall_2k: 0.5317 - val_lcm_recall_3k: 0.6264 - val_lcm_recall_5k: 0.7317 - val_lcm_f1_1k: 0.4329 - val_lcm_f1_2k: 0.4880 - val_lcm_f1_3k: 0.4627 - val_lcm_f1_5k: 0.3893 - val_lcm_accuracy_1k: 0.5644 - val_lcm_accuracy_2k: 0.7242 - val_lcm_accuracy_3k: 0.7943 - val_lcm_accuracy_5k: 0.8616 - val_lcm_hamming_loss_k: 0.0042
Epoch 15/150
27/27 [==============================] - ETA: 0s - loss: 0.2292 - lcm_precision_1k: 0.6404 - lcm_precision_2k: 0.5048 - lcm_precision_3k: 0.4067 - lcm_precision_5k: 0.2905 - lcm_recall_1k: 0.4026 - lcm_recall_2k: 0.5958 - lcm_recall_3k: 0.6951 - lcm_recall_5k: 0.8006 - lcm_f1_1k: 0.4943 - lcm_f1_2k: 0.5465 - lcm_f1_3k: 0.5131 - lcm_f1_5k: 0.4263 - lcm_accuracy_1k: 0.6404 - lcm_accuracy_2k: 0.7976 - lcm_accuracy_3k: 0.8618 - lcm_accuracy_5k: 0.9177 - lcm_hamming_loss_k: 0.0038 ETA: 4s - loss: 0.2293 - lcm_precision_1k: 0.6457 - lcm_precision_2k: 0.5055 - lcm_precision_3k: 0.4074 - lcm_precision_5k: 0.2907 - lcm_recall_1k: 0.4077 - lcm_recall_2k: 0.5983 - lcm_recall_3k: 0.6966 - lcm_recall_5k: 0.8008 - lcm_f1_1k: 0.4998 - lcm_f1_2k: 0.5479 - lcm_f1_3k: 0.5140 - lcm_f1_5k: 0.4265 - lcm_accuracy_1k: 0.6457 - lcm_accuracy_2k: 0.7998 - lcm_accuracy_3k: 0.8649 - lcm_accuracy_5k: 0.919
Epoch 00015: val_loss improved from 0.26829 to 0.26788, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 370ms/step - loss: 0.2292 - lcm_precision_1k: 0.6404 - lcm_precision_2k: 0.5048 - lcm_precision_3k: 0.4067 - lcm_precision_5k: 0.2905 - lcm_recall_1k: 0.4026 - lcm_recall_2k: 0.5958 - lcm_recall_3k: 0.6951 - lcm_recall_5k: 0.8006 - lcm_f1_1k: 0.4943 - lcm_f1_2k: 0.5465 - lcm_f1_3k: 0.5131 - lcm_f1_5k: 0.4263 - lcm_accuracy_1k: 0.6404 - lcm_accuracy_2k: 0.7976 - lcm_accuracy_3k: 0.8618 - lcm_accuracy_5k: 0.9177 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2679 - val_lcm_precision_1k: 0.5717 - val_lcm_precision_2k: 0.4572 - val_lcm_precision_3k: 0.3704 - val_lcm_precision_5k: 0.2653 - val_lcm_recall_1k: 0.3541 - val_lcm_recall_2k: 0.5363 - val_lcm_recall_3k: 0.6325 - val_lcm_recall_5k: 0.7319 - val_lcm_f1_1k: 0.4371 - val_lcm_f1_2k: 0.4935 - val_lcm_f1_3k: 0.4670 - val_lcm_f1_5k: 0.3893 - val_lcm_accuracy_1k: 0.5717 - val_lcm_accuracy_2k: 0.7308 - val_lcm_accuracy_3k: 0.7963 - val_lcm_accuracy_5k: 0.8590 - val_lcm_hamming_loss_k: 0.0042
Epoch 16/150
27/27 [==============================] - ETA: 0s - loss: 0.2224 - lcm_precision_1k: 0.6616 - lcm_precision_2k: 0.5146 - lcm_precision_3k: 0.4138 - lcm_precision_5k: 0.2949 - lcm_recall_1k: 0.4167 - lcm_recall_2k: 0.6061 - lcm_recall_3k: 0.7083 - lcm_recall_5k: 0.8137 - lcm_f1_1k: 0.5113 - lcm_f1_2k: 0.5565 - lcm_f1_3k: 0.5224 - lcm_f1_5k: 0.4329 - lcm_accuracy_1k: 0.6616 - lcm_accuracy_2k: 0.8084 - lcm_accuracy_3k: 0.8722 - lcm_accuracy_5k: 0.9273 - lcm_hamming_loss_k: 0.0037
Epoch 00016: val_loss improved from 0.26788 to 0.26490, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 371ms/step - loss: 0.2224 - lcm_precision_1k: 0.6616 - lcm_precision_2k: 0.5146 - lcm_precision_3k: 0.4138 - lcm_precision_5k: 0.2949 - lcm_recall_1k: 0.4167 - lcm_recall_2k: 0.6061 - lcm_recall_3k: 0.7083 - lcm_recall_5k: 0.8137 - lcm_f1_1k: 0.5113 - lcm_f1_2k: 0.5565 - lcm_f1_3k: 0.5224 - lcm_f1_5k: 0.4329 - lcm_accuracy_1k: 0.6616 - lcm_accuracy_2k: 0.8084 - lcm_accuracy_3k: 0.8722 - lcm_accuracy_5k: 0.9273 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2649 - val_lcm_precision_1k: 0.5805 - val_lcm_precision_2k: 0.4638 - val_lcm_precision_3k: 0.3744 - val_lcm_precision_5k: 0.2683 - val_lcm_recall_1k: 0.3635 - val_lcm_recall_2k: 0.5486 - val_lcm_recall_3k: 0.6406 - val_lcm_recall_5k: 0.7401 - val_lcm_f1_1k: 0.4469 - val_lcm_f1_2k: 0.5025 - val_lcm_f1_3k: 0.4725 - val_lcm_f1_5k: 0.3937 - val_lcm_accuracy_1k: 0.5805 - val_lcm_accuracy_2k: 0.7433 - val_lcm_accuracy_3k: 0.8063 - val_lcm_accuracy_5k: 0.8694 - val_lcm_hamming_loss_k: 0.0041
Epoch 17/150
27/27 [==============================] - ETA: 0s - loss: 0.2178 - lcm_precision_1k: 0.6720 - lcm_precision_2k: 0.5238 - lcm_precision_3k: 0.4225 - lcm_precision_5k: 0.3003 - lcm_recall_1k: 0.4241 - lcm_recall_2k: 0.6181 - lcm_recall_3k: 0.7221 - lcm_recall_5k: 0.8265 - lcm_f1_1k: 0.5199 - lcm_f1_2k: 0.5670 - lcm_f1_3k: 0.5330 - lcm_f1_5k: 0.4404 - lcm_accuracy_1k: 0.6720 - lcm_accuracy_2k: 0.8219 - lcm_accuracy_3k: 0.8833 - lcm_accuracy_5k: 0.9345 - lcm_hamming_loss_k: 0.0037
Epoch 00017: val_loss improved from 0.26490 to 0.26487, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 373ms/step - loss: 0.2178 - lcm_precision_1k: 0.6720 - lcm_precision_2k: 0.5238 - lcm_precision_3k: 0.4225 - lcm_precision_5k: 0.3003 - lcm_recall_1k: 0.4241 - lcm_recall_2k: 0.6181 - lcm_recall_3k: 0.7221 - lcm_recall_5k: 0.8265 - lcm_f1_1k: 0.5199 - lcm_f1_2k: 0.5670 - lcm_f1_3k: 0.5330 - lcm_f1_5k: 0.4404 - lcm_accuracy_1k: 0.6720 - lcm_accuracy_2k: 0.8219 - lcm_accuracy_3k: 0.8833 - lcm_accuracy_5k: 0.9345 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2649 - val_lcm_precision_1k: 0.5851 - val_lcm_precision_2k: 0.4644 - val_lcm_precision_3k: 0.3770 - val_lcm_precision_5k: 0.2677 - val_lcm_recall_1k: 0.3672 - val_lcm_recall_2k: 0.5489 - val_lcm_recall_3k: 0.6455 - val_lcm_recall_5k: 0.7405 - val_lcm_f1_1k: 0.4511 - val_lcm_f1_2k: 0.5030 - val_lcm_f1_3k: 0.4758 - val_lcm_f1_5k: 0.3930 - val_lcm_accuracy_1k: 0.5851 - val_lcm_accuracy_2k: 0.7431 - val_lcm_accuracy_3k: 0.8099 - val_lcm_accuracy_5k: 0.8688 - val_lcm_hamming_loss_k: 0.0041
Epoch 18/150
27/27 [==============================] - ETA: 0s - loss: 0.2105 - lcm_precision_1k: 0.6915 - lcm_precision_2k: 0.5397 - lcm_precision_3k: 0.4315 - lcm_precision_5k: 0.3042 - lcm_recall_1k: 0.4375 - lcm_recall_2k: 0.6355 - lcm_recall_3k: 0.7357 - lcm_recall_5k: 0.8358 - lcm_f1_1k: 0.5359 - lcm_f1_2k: 0.5836 - lcm_f1_3k: 0.5439 - lcm_f1_5k: 0.4460 - lcm_accuracy_1k: 0.6915 - lcm_accuracy_2k: 0.8345 - lcm_accuracy_3k: 0.8905 - lcm_accuracy_5k: 0.9393 - lcm_hamming_loss_k: 0.0036
Epoch 00018: val_loss improved from 0.26487 to 0.26235, saving model to logs/zxhvem-lbs-0604-123815/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.2105 - lcm_precision_1k: 0.6915 - lcm_precision_2k: 0.5397 - lcm_precision_3k: 0.4315 - lcm_precision_5k: 0.3042 - lcm_recall_1k: 0.4375 - lcm_recall_2k: 0.6355 - lcm_recall_3k: 0.7357 - lcm_recall_5k: 0.8358 - lcm_f1_1k: 0.5359 - lcm_f1_2k: 0.5836 - lcm_f1_3k: 0.5439 - lcm_f1_5k: 0.4460 - lcm_accuracy_1k: 0.6915 - lcm_accuracy_2k: 0.8345 - lcm_accuracy_3k: 0.8905 - lcm_accuracy_5k: 0.9393 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2624 - val_lcm_precision_1k: 0.5940 - val_lcm_precision_2k: 0.4766 - val_lcm_precision_3k: 0.3822 - val_lcm_precision_5k: 0.2708 - val_lcm_recall_1k: 0.3727 - val_lcm_recall_2k: 0.5631 - val_lcm_recall_3k: 0.6550 - val_lcm_recall_5k: 0.7471 - val_lcm_f1_1k: 0.4579 - val_lcm_f1_2k: 0.5161 - val_lcm_f1_3k: 0.4826 - val_lcm_f1_5k: 0.3973 - val_lcm_accuracy_1k: 0.5940 - val_lcm_accuracy_2k: 0.7586 - val_lcm_accuracy_3k: 0.8178 - val_lcm_accuracy_5k: 0.8744 - val_lcm_hamming_loss_k: 0.0041
Epoch 19/150
27/27 [==============================] - ETA: 0s - loss: 0.2052 - lcm_precision_1k: 0.7055 - lcm_precision_2k: 0.5477 - lcm_precision_3k: 0.4377 - lcm_precision_5k: 0.3080 - lcm_recall_1k: 0.4473 - lcm_recall_2k: 0.6466 - lcm_recall_3k: 0.7472 - lcm_recall_5k: 0.8472 - lcm_f1_1k: 0.5474 - lcm_f1_2k: 0.5929 - lcm_f1_3k: 0.5520 - lcm_f1_5k: 0.4518 - lcm_accuracy_1k: 0.7055 - lcm_accuracy_2k: 0.8471 - lcm_accuracy_3k: 0.9016 - lcm_accuracy_5k: 0.9484 - lcm_hamming_loss_k: 0.0035 ETA: 7s - loss: 0.2009 - lcm_precision_1k: 0.7178 - lcm_precision_2k: 0.5610 - lcm_precision_3k: 0.4434 - lcm_precision_5k: 0.3117 - lcm_recall_1k: 0.4568 - lcm_recall_2k: 0.6655 - lcm_recall_3k: 0.7585 - lcm_recall_5k: 0.8563 - lcm_f1_1k: 0.5583 - lcm_f1_2k: 0.6088 - lcm_f1_3k: 0.5596 - lcm_f1_5k: 0.4570 - lcm_accuracy_1k: 0.7178 - lcm_accuracy_2k: 0.8681 - lcm_accuracy_3k: 0.9111 - lcm_accuracy - ETA: 1s - loss: 0.2045 - lcm_precision_1k: 0.7078 - lcm_precision_2k: 0.5498 - lcm_precision_3k: 0.4404 - lcm_precision_5k: 0.3099 - lcm_recall_1k: 0.4473 - lcm_recall_2k: 0.6462 - lcm_recall_3k: 0.7486 - lcm_recall_5k: 0.8489 - lcm_f1_1k: 0.5481 - lcm_f1_2k: 0.5941 - lcm_f1_3k: 0.5545 - lcm_f1_5k: 0.4540 - lcm_accuracy_1k: 0.7078 - lcm_accuracy_2k: 0.8468 - lcm_accuracy_3k: 0.9028 - lcm_accuracy_5k: 0.9485 - lcm_hamming_loss
Epoch 00019: val_loss did not improve from 0.26235
27/27 [==============================] - 9s 341ms/step - loss: 0.2052 - lcm_precision_1k: 0.7055 - lcm_precision_2k: 0.5477 - lcm_precision_3k: 0.4377 - lcm_precision_5k: 0.3080 - lcm_recall_1k: 0.4473 - lcm_recall_2k: 0.6466 - lcm_recall_3k: 0.7472 - lcm_recall_5k: 0.8472 - lcm_f1_1k: 0.5474 - lcm_f1_2k: 0.5929 - lcm_f1_3k: 0.5520 - lcm_f1_5k: 0.4518 - lcm_accuracy_1k: 0.7055 - lcm_accuracy_2k: 0.8471 - lcm_accuracy_3k: 0.9016 - lcm_accuracy_5k: 0.9484 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2672 - val_lcm_precision_1k: 0.5949 - val_lcm_precision_2k: 0.4663 - val_lcm_precision_3k: 0.3791 - val_lcm_precision_5k: 0.2674 - val_lcm_recall_1k: 0.3715 - val_lcm_recall_2k: 0.5524 - val_lcm_recall_3k: 0.6498 - val_lcm_recall_5k: 0.7414 - val_lcm_f1_1k: 0.4572 - val_lcm_f1_2k: 0.5055 - val_lcm_f1_3k: 0.4786 - val_lcm_f1_5k: 0.3929 - val_lcm_accuracy_1k: 0.5949 - val_lcm_accuracy_2k: 0.7449 - val_lcm_accuracy_3k: 0.8089 - val_lcm_accuracy_5k: 0.8658 - val_lcm_hamming_loss_k: 0.0040
Epoch 20/150
27/27 [==============================] - ETA: 0s - loss: 0.1995 - lcm_precision_1k: 0.7213 - lcm_precision_2k: 0.5617 - lcm_precision_3k: 0.4478 - lcm_precision_5k: 0.3126 - lcm_recall_1k: 0.4586 - lcm_recall_2k: 0.6630 - lcm_recall_3k: 0.7625 - lcm_recall_5k: 0.8583 - lcm_f1_1k: 0.5606 - lcm_f1_2k: 0.6081 - lcm_f1_3k: 0.5641 - lcm_f1_5k: 0.4583 - lcm_accuracy_1k: 0.7213 - lcm_accuracy_2k: 0.8614 - lcm_accuracy_3k: 0.9096 - lcm_accuracy_5k: 0.9528 - lcm_hamming_loss_k: 0.0034
Epoch 00020: val_loss did not improve from 0.26235
27/27 [==============================] - 9s 341ms/step - loss: 0.1995 - lcm_precision_1k: 0.7213 - lcm_precision_2k: 0.5617 - lcm_precision_3k: 0.4478 - lcm_precision_5k: 0.3126 - lcm_recall_1k: 0.4586 - lcm_recall_2k: 0.6630 - lcm_recall_3k: 0.7625 - lcm_recall_5k: 0.8583 - lcm_f1_1k: 0.5606 - lcm_f1_2k: 0.6081 - lcm_f1_3k: 0.5641 - lcm_f1_5k: 0.4583 - lcm_accuracy_1k: 0.7213 - lcm_accuracy_2k: 0.8614 - lcm_accuracy_3k: 0.9096 - lcm_accuracy_5k: 0.9528 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2638 - val_lcm_precision_1k: 0.5947 - val_lcm_precision_2k: 0.4737 - val_lcm_precision_3k: 0.3841 - val_lcm_precision_5k: 0.2718 - val_lcm_recall_1k: 0.3723 - val_lcm_recall_2k: 0.5597 - val_lcm_recall_3k: 0.6567 - val_lcm_recall_5k: 0.7505 - val_lcm_f1_1k: 0.4578 - val_lcm_f1_2k: 0.5129 - val_lcm_f1_3k: 0.4845 - val_lcm_f1_5k: 0.3990 - val_lcm_accuracy_1k: 0.5947 - val_lcm_accuracy_2k: 0.7529 - val_lcm_accuracy_3k: 0.8158 - val_lcm_accuracy_5k: 0.8752 - val_lcm_hamming_loss_k: 0.0040
Epoch 00020: early stopping
176/176 [==============================] - 7s 36ms/step - loss: 0.2235 - lcm_precision_1k: 0.6695 - lcm_precision_2k: 0.5179 - lcm_precision_3k: 0.4145 - lcm_precision_5k: 0.2931 - lcm_recall_1k: 0.4251 - lcm_recall_2k: 0.6147 - lcm_recall_3k: 0.7125 - lcm_recall_5k: 0.8105 - lcm_f1_1k: 0.5186 - lcm_f1_2k: 0.5609 - lcm_f1_3k: 0.5231 - lcm_f1_5k: 0.4298 - lcm_accuracy_1k: 0.6695 - lcm_accuracy_2k: 0.8130 - lcm_accuracy_3k: 0.8681 - lcm_accuracy_5k: 0.9163 - lcm_hamming_loss_k: 0.0036 4s - loss: 0.2276 - lcm_precision_1k: 0.6722 - lcm_precision_2k: 0.5156 - lcm_precision_3k: 0.4119 - lcm_precision_5k: 0.2912 - lcm_recall_1k: 0.4223 - lcm_recall_2k: 0.6103 - lcm_recall_3k: 0.7091 - lcm_recall_5k: 0.8082 - lcm_f1_1k: 0.5171 - lcm_f1_2k: 0.5576 - lcm_f1_3k: 0.5202 - lcm_f1_5k: 0.4274 - lcm_ac
Best model result:  [0.22353927791118622, 0.6694719195365906, 0.5179114937782288, 0.4144670367240906, 0.29310348629951477, 0.4251295030117035, 0.6147074699401855, 0.712475061416626, 0.8105340600013733, 0.518618643283844, 0.560910701751709, 0.523081362247467, 0.42983224987983704, 0.6694719195365906, 0.8130409717559814, 0.8681333661079407, 0.9163203835487366, 0.0036499679554253817]
13498
3375
5625
Model: "model_4"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['BiLSTM[0][0]']                 
                                                                                                  
==================================================================================================
Total params: 28,546,223
Trainable params: 3,767,723
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
2 patience
Model: "model_5"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 tf.__operators__.getitem_2 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_lcm_emb (Dense)          (None, 427, 1024)    308224      ['tf.__operators__.getitem_2[0][0
                                                                 ]']                              
                                                                                                  
 dot_2 (Dot)                    (None, 427)          0           ['label_lcm_emb[0][0]',          
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['BiLSTM[0][0]']                 
                                                                                                  
 label_sim_dict (Dense)         (None, 427)          182756      ['dot_2[0][0]']                  
                                                                                                  
 concatenate_2 (Concatenate)    (None, 854)          0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 29,165,303
Trainable params: 4,386,803
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
Epoch 1/150
27/27 [==============================] - ETA: 0s - loss: 0.4983 - lcm_precision_1k: 0.1453 - lcm_precision_2k: 0.1230 - lcm_precision_3k: 0.1078 - lcm_precision_5k: 0.0903 - lcm_recall_1k: 0.0719 - lcm_recall_2k: 0.1229 - lcm_recall_3k: 0.1626 - lcm_recall_5k: 0.2273 - lcm_f1_1k: 0.0961 - lcm_f1_2k: 0.1229 - lcm_f1_3k: 0.1295 - lcm_f1_5k: 0.1292 - lcm_accuracy_1k: 0.1453 - lcm_accuracy_2k: 0.2109 - lcm_accuracy_3k: 0.2620 - lcm_accuracy_5k: 0.3366 - lcm_hamming_loss_k: 0.0061 ETA: 5s - loss: 0.5316 - lcm_precision_1k: 0.0901 - lcm_precision_2k: 0.0670 - lcm_precision_3k: 0.0544 - lcm_precision_5k: 0.0419 - lcm_recall_1k: 0.0413 - lcm_recall_2k: 0.0622 - lcm_recall_3k: 0.0754 - lcm_recall_5k: 0.1002 - lcm_f1_1k: 0.0566 - lcm_f1_2k: 0.0645 - lcm_f1_3k: 0.0632 - lcm_f1_5k: 0.0590 - lcm_accuracy_1k: 0.0901 - lcm_accuracy_2k: 0.1144 - lcm_accuracy_3k: 0.1378 - lcm_accuracy
Epoch 00001: val_loss improved from inf to 0.46910, saving model to logs/ckhnrj-lbs-0604-124140/model/checkpoint_lbs.h5
27/27 [==============================] - 11s 360ms/step - loss: 0.4983 - lcm_precision_1k: 0.1453 - lcm_precision_2k: 0.1230 - lcm_precision_3k: 0.1078 - lcm_precision_5k: 0.0903 - lcm_recall_1k: 0.0719 - lcm_recall_2k: 0.1229 - lcm_recall_3k: 0.1626 - lcm_recall_5k: 0.2273 - lcm_f1_1k: 0.0961 - lcm_f1_2k: 0.1229 - lcm_f1_3k: 0.1295 - lcm_f1_5k: 0.1292 - lcm_accuracy_1k: 0.1453 - lcm_accuracy_2k: 0.2109 - lcm_accuracy_3k: 0.2620 - lcm_accuracy_5k: 0.3366 - lcm_hamming_loss_k: 0.0061 - val_loss: 0.4691 - val_lcm_precision_1k: 0.1891 - val_lcm_precision_2k: 0.1616 - val_lcm_precision_3k: 0.1501 - val_lcm_precision_5k: 0.1310 - val_lcm_recall_1k: 0.0985 - val_lcm_recall_2k: 0.1689 - val_lcm_recall_3k: 0.2389 - val_lcm_recall_5k: 0.3392 - val_lcm_f1_1k: 0.1294 - val_lcm_f1_2k: 0.1650 - val_lcm_f1_3k: 0.1842 - val_lcm_f1_5k: 0.1888 - val_lcm_accuracy_1k: 0.1891 - val_lcm_accuracy_2k: 0.2765 - val_lcm_accuracy_3k: 0.3641 - val_lcm_accuracy_5k: 0.4628 - val_lcm_hamming_loss_k: 0.0060
Epoch 2/150
27/27 [==============================] - ETA: 0s - loss: 0.4339 - lcm_precision_1k: 0.2094 - lcm_precision_2k: 0.1770 - lcm_precision_3k: 0.1605 - lcm_precision_5k: 0.1380 - lcm_recall_1k: 0.1128 - lcm_recall_2k: 0.1890 - lcm_recall_3k: 0.2558 - lcm_recall_5k: 0.3626 - lcm_f1_1k: 0.1465 - lcm_f1_2k: 0.1827 - lcm_f1_3k: 0.1972 - lcm_f1_5k: 0.1998 - lcm_accuracy_1k: 0.2094 - lcm_accuracy_2k: 0.3069 - lcm_accuracy_3k: 0.3922 - lcm_accuracy_5k: 0.4982 - lcm_hamming_loss_k: 0.0058
Epoch 00002: val_loss improved from 0.46910 to 0.40189, saving model to logs/ckhnrj-lbs-0604-124140/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.4339 - lcm_precision_1k: 0.2094 - lcm_precision_2k: 0.1770 - lcm_precision_3k: 0.1605 - lcm_precision_5k: 0.1380 - lcm_recall_1k: 0.1128 - lcm_recall_2k: 0.1890 - lcm_recall_3k: 0.2558 - lcm_recall_5k: 0.3626 - lcm_f1_1k: 0.1465 - lcm_f1_2k: 0.1827 - lcm_f1_3k: 0.1972 - lcm_f1_5k: 0.1998 - lcm_accuracy_1k: 0.2094 - lcm_accuracy_2k: 0.3069 - lcm_accuracy_3k: 0.3922 - lcm_accuracy_5k: 0.4982 - lcm_hamming_loss_k: 0.0058 - val_loss: 0.4019 - val_lcm_precision_1k: 0.2733 - val_lcm_precision_2k: 0.2227 - val_lcm_precision_3k: 0.1949 - val_lcm_precision_5k: 0.1643 - val_lcm_recall_1k: 0.1552 - val_lcm_recall_2k: 0.2514 - val_lcm_recall_3k: 0.3230 - val_lcm_recall_5k: 0.4404 - val_lcm_f1_1k: 0.1978 - val_lcm_f1_2k: 0.2360 - val_lcm_f1_3k: 0.2429 - val_lcm_f1_5k: 0.2392 - val_lcm_accuracy_1k: 0.2733 - val_lcm_accuracy_2k: 0.3945 - val_lcm_accuracy_3k: 0.4772 - val_lcm_accuracy_5k: 0.5803 - val_lcm_hamming_loss_k: 0.0056
Epoch 3/150
27/27 [==============================] - ETA: 0s - loss: 0.3774 - lcm_precision_1k: 0.2887 - lcm_precision_2k: 0.2501 - lcm_precision_3k: 0.2168 - lcm_precision_5k: 0.1767 - lcm_recall_1k: 0.1637 - lcm_recall_2k: 0.2801 - lcm_recall_3k: 0.3574 - lcm_recall_5k: 0.4743 - lcm_f1_1k: 0.2088 - lcm_f1_2k: 0.2642 - lcm_f1_3k: 0.2698 - lcm_f1_5k: 0.2575 - lcm_accuracy_1k: 0.2887 - lcm_accuracy_2k: 0.4361 - lcm_accuracy_3k: 0.5206 - lcm_accuracy_5k: 0.6229 - lcm_hamming_loss_k: 0.0055
Epoch 00003: val_loss improved from 0.40189 to 0.36783, saving model to logs/ckhnrj-lbs-0604-124140/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.3774 - lcm_precision_1k: 0.2887 - lcm_precision_2k: 0.2501 - lcm_precision_3k: 0.2168 - lcm_precision_5k: 0.1767 - lcm_recall_1k: 0.1637 - lcm_recall_2k: 0.2801 - lcm_recall_3k: 0.3574 - lcm_recall_5k: 0.4743 - lcm_f1_1k: 0.2088 - lcm_f1_2k: 0.2642 - lcm_f1_3k: 0.2698 - lcm_f1_5k: 0.2575 - lcm_accuracy_1k: 0.2887 - lcm_accuracy_2k: 0.4361 - lcm_accuracy_3k: 0.5206 - lcm_accuracy_5k: 0.6229 - lcm_hamming_loss_k: 0.0055 - val_loss: 0.3678 - val_lcm_precision_1k: 0.3302 - val_lcm_precision_2k: 0.2860 - val_lcm_precision_3k: 0.2439 - val_lcm_precision_5k: 0.1973 - val_lcm_recall_1k: 0.1876 - val_lcm_recall_2k: 0.3203 - val_lcm_recall_3k: 0.3987 - val_lcm_recall_5k: 0.5252 - val_lcm_f1_1k: 0.2391 - val_lcm_f1_2k: 0.3020 - val_lcm_f1_3k: 0.3024 - val_lcm_f1_5k: 0.2867 - val_lcm_accuracy_1k: 0.3302 - val_lcm_accuracy_2k: 0.4867 - val_lcm_accuracy_3k: 0.5674 - val_lcm_accuracy_5k: 0.6753 - val_lcm_hamming_loss_k: 0.0053
Epoch 4/150
27/27 [==============================] - ETA: 0s - loss: 0.3475 - lcm_precision_1k: 0.3514 - lcm_precision_2k: 0.3014 - lcm_precision_3k: 0.2563 - lcm_precision_5k: 0.2031 - lcm_recall_1k: 0.2034 - lcm_recall_2k: 0.3413 - lcm_recall_3k: 0.4292 - lcm_recall_5k: 0.5513 - lcm_f1_1k: 0.2576 - lcm_f1_2k: 0.3200 - lcm_f1_3k: 0.3208 - lcm_f1_5k: 0.2968 - lcm_accuracy_1k: 0.3514 - lcm_accuracy_2k: 0.5103 - lcm_accuracy_3k: 0.6000 - lcm_accuracy_5k: 0.7040 - lcm_hamming_loss_k: 0.0052
Epoch 00004: val_loss improved from 0.36783 to 0.34131, saving model to logs/ckhnrj-lbs-0604-124140/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 367ms/step - loss: 0.3475 - lcm_precision_1k: 0.3514 - lcm_precision_2k: 0.3014 - lcm_precision_3k: 0.2563 - lcm_precision_5k: 0.2031 - lcm_recall_1k: 0.2034 - lcm_recall_2k: 0.3413 - lcm_recall_3k: 0.4292 - lcm_recall_5k: 0.5513 - lcm_f1_1k: 0.2576 - lcm_f1_2k: 0.3200 - lcm_f1_3k: 0.3208 - lcm_f1_5k: 0.2968 - lcm_accuracy_1k: 0.3514 - lcm_accuracy_2k: 0.5103 - lcm_accuracy_3k: 0.6000 - lcm_accuracy_5k: 0.7040 - lcm_hamming_loss_k: 0.0052 - val_loss: 0.3413 - val_lcm_precision_1k: 0.3717 - val_lcm_precision_2k: 0.3147 - val_lcm_precision_3k: 0.2772 - val_lcm_precision_5k: 0.2152 - val_lcm_recall_1k: 0.2147 - val_lcm_recall_2k: 0.3529 - val_lcm_recall_3k: 0.4569 - val_lcm_recall_5k: 0.5784 - val_lcm_f1_1k: 0.2720 - val_lcm_f1_2k: 0.3325 - val_lcm_f1_3k: 0.3448 - val_lcm_f1_5k: 0.3136 - val_lcm_accuracy_1k: 0.3717 - val_lcm_accuracy_2k: 0.5299 - val_lcm_accuracy_3k: 0.6312 - val_lcm_accuracy_5k: 0.7223 - val_lcm_hamming_loss_k: 0.0051
Epoch 5/150
27/27 [==============================] - ETA: 0s - loss: 0.3277 - lcm_precision_1k: 0.3959 - lcm_precision_2k: 0.3317 - lcm_precision_3k: 0.2822 - lcm_precision_5k: 0.2178 - lcm_recall_1k: 0.2339 - lcm_recall_2k: 0.3800 - lcm_recall_3k: 0.4754 - lcm_recall_5k: 0.5945 - lcm_f1_1k: 0.2940 - lcm_f1_2k: 0.3541 - lcm_f1_3k: 0.3541 - lcm_f1_5k: 0.3188 - lcm_accuracy_1k: 0.3959 - lcm_accuracy_2k: 0.5582 - lcm_accuracy_3k: 0.6496 - lcm_accuracy_5k: 0.7432 - lcm_hamming_loss_k: 0.0050
Epoch 00005: val_loss improved from 0.34131 to 0.32846, saving model to logs/ckhnrj-lbs-0604-124140/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.3277 - lcm_precision_1k: 0.3959 - lcm_precision_2k: 0.3317 - lcm_precision_3k: 0.2822 - lcm_precision_5k: 0.2178 - lcm_recall_1k: 0.2339 - lcm_recall_2k: 0.3800 - lcm_recall_3k: 0.4754 - lcm_recall_5k: 0.5945 - lcm_f1_1k: 0.2940 - lcm_f1_2k: 0.3541 - lcm_f1_3k: 0.3541 - lcm_f1_5k: 0.3188 - lcm_accuracy_1k: 0.3959 - lcm_accuracy_2k: 0.5582 - lcm_accuracy_3k: 0.6496 - lcm_accuracy_5k: 0.7432 - lcm_hamming_loss_k: 0.0050 - val_loss: 0.3285 - val_lcm_precision_1k: 0.4260 - val_lcm_precision_2k: 0.3419 - val_lcm_precision_3k: 0.2897 - val_lcm_precision_5k: 0.2242 - val_lcm_recall_1k: 0.2479 - val_lcm_recall_2k: 0.3844 - val_lcm_recall_3k: 0.4808 - val_lcm_recall_5k: 0.6026 - val_lcm_f1_1k: 0.3132 - val_lcm_f1_2k: 0.3617 - val_lcm_f1_3k: 0.3614 - val_lcm_f1_5k: 0.3266 - val_lcm_accuracy_1k: 0.4260 - val_lcm_accuracy_2k: 0.5657 - val_lcm_accuracy_3k: 0.6544 - val_lcm_accuracy_5k: 0.7488 - val_lcm_hamming_loss_k: 0.0048
Epoch 6/150
27/27 [==============================] - ETA: 0s - loss: 0.3142 - lcm_precision_1k: 0.4355 - lcm_precision_2k: 0.3582 - lcm_precision_3k: 0.3013 - lcm_precision_5k: 0.2274 - lcm_recall_1k: 0.2598 - lcm_recall_2k: 0.4125 - lcm_recall_3k: 0.5121 - lcm_recall_5k: 0.6252 - lcm_f1_1k: 0.3254 - lcm_f1_2k: 0.3834 - lcm_f1_3k: 0.3793 - lcm_f1_5k: 0.3334 - lcm_accuracy_1k: 0.4355 - lcm_accuracy_2k: 0.5937 - lcm_accuracy_3k: 0.6849 - lcm_accuracy_5k: 0.7726 - lcm_hamming_loss_k: 0.0048
Epoch 00006: val_loss improved from 0.32846 to 0.31499, saving model to logs/ckhnrj-lbs-0604-124140/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 368ms/step - loss: 0.3142 - lcm_precision_1k: 0.4355 - lcm_precision_2k: 0.3582 - lcm_precision_3k: 0.3013 - lcm_precision_5k: 0.2274 - lcm_recall_1k: 0.2598 - lcm_recall_2k: 0.4125 - lcm_recall_3k: 0.5121 - lcm_recall_5k: 0.6252 - lcm_f1_1k: 0.3254 - lcm_f1_2k: 0.3834 - lcm_f1_3k: 0.3793 - lcm_f1_5k: 0.3334 - lcm_accuracy_1k: 0.4355 - lcm_accuracy_2k: 0.5937 - lcm_accuracy_3k: 0.6849 - lcm_accuracy_5k: 0.7726 - lcm_hamming_loss_k: 0.0048 - val_loss: 0.3150 - val_lcm_precision_1k: 0.4528 - val_lcm_precision_2k: 0.3662 - val_lcm_precision_3k: 0.3123 - val_lcm_precision_5k: 0.2322 - val_lcm_recall_1k: 0.2682 - val_lcm_recall_2k: 0.4127 - val_lcm_recall_3k: 0.5176 - val_lcm_recall_5k: 0.6281 - val_lcm_f1_1k: 0.3366 - val_lcm_f1_2k: 0.3878 - val_lcm_f1_3k: 0.3893 - val_lcm_f1_5k: 0.3389 - val_lcm_accuracy_1k: 0.4528 - val_lcm_accuracy_2k: 0.6023 - val_lcm_accuracy_3k: 0.6880 - val_lcm_accuracy_5k: 0.7706 - val_lcm_hamming_loss_k: 0.0047
Epoch 7/150
27/27 [==============================] - ETA: 0s - loss: 0.3055 - lcm_precision_1k: 0.4596 - lcm_precision_2k: 0.3727 - lcm_precision_3k: 0.3127 - lcm_precision_5k: 0.2330 - lcm_recall_1k: 0.2779 - lcm_recall_2k: 0.4310 - lcm_recall_3k: 0.5301 - lcm_recall_5k: 0.6413 - lcm_f1_1k: 0.3462 - lcm_f1_2k: 0.3997 - lcm_f1_3k: 0.3933 - lcm_f1_5k: 0.3418 - lcm_accuracy_1k: 0.4596 - lcm_accuracy_2k: 0.6138 - lcm_accuracy_3k: 0.7016 - lcm_accuracy_5k: 0.7872 - lcm_hamming_loss_k: 0.0046 ETA: 5s - loss: 0.3057 - lcm_precision_1k: 0.4551 - lcm_precision_2k: 0.3706 - lcm_precision_3k: 0.3093 - lcm_precision_5k: 0.2327 - lcm_recall_1k: 0.2742 - lcm_recall_2k: 0.4279 - lcm_recall_3k: 0.5235 - lcm_recall_5k: 0.6404 - lcm_f1_1k: 0.3421 - lcm_f1_2k: 0.3971 - lcm_f1_3k: 0.3888 - lcm_f1_5k: 0.3414 - lcm_accuracy_1k: 0.4551 - lcm_accuracy_2k: 0.6062 - lcm_accuracy_3k: 0.6912 - lcm_accuracy_5
Epoch 00007: val_loss did not improve from 0.31499
27/27 [==============================] - 9s 340ms/step - loss: 0.3055 - lcm_precision_1k: 0.4596 - lcm_precision_2k: 0.3727 - lcm_precision_3k: 0.3127 - lcm_precision_5k: 0.2330 - lcm_recall_1k: 0.2779 - lcm_recall_2k: 0.4310 - lcm_recall_3k: 0.5301 - lcm_recall_5k: 0.6413 - lcm_f1_1k: 0.3462 - lcm_f1_2k: 0.3997 - lcm_f1_3k: 0.3933 - lcm_f1_5k: 0.3418 - lcm_accuracy_1k: 0.4596 - lcm_accuracy_2k: 0.6138 - lcm_accuracy_3k: 0.7016 - lcm_accuracy_5k: 0.7872 - lcm_hamming_loss_k: 0.0046 - val_loss: 0.3163 - val_lcm_precision_1k: 0.4586 - val_lcm_precision_2k: 0.3682 - val_lcm_precision_3k: 0.3110 - val_lcm_precision_5k: 0.2326 - val_lcm_recall_1k: 0.2729 - val_lcm_recall_2k: 0.4173 - val_lcm_recall_3k: 0.5178 - val_lcm_recall_5k: 0.6303 - val_lcm_f1_1k: 0.3419 - val_lcm_f1_2k: 0.3910 - val_lcm_f1_3k: 0.3884 - val_lcm_f1_5k: 0.3397 - val_lcm_accuracy_1k: 0.4586 - val_lcm_accuracy_2k: 0.6086 - val_lcm_accuracy_3k: 0.6888 - val_lcm_accuracy_5k: 0.7774 - val_lcm_hamming_loss_k: 0.0047
Epoch 8/150
27/27 [==============================] - ETA: 0s - loss: 0.2956 - lcm_precision_1k: 0.4845 - lcm_precision_2k: 0.3910 - lcm_precision_3k: 0.3242 - lcm_precision_5k: 0.2412 - lcm_recall_1k: 0.2934 - lcm_recall_2k: 0.4517 - lcm_recall_3k: 0.5514 - lcm_recall_5k: 0.6645 - lcm_f1_1k: 0.3654 - lcm_f1_2k: 0.4191 - lcm_f1_3k: 0.4083 - lcm_f1_5k: 0.3539 - lcm_accuracy_1k: 0.4845 - lcm_accuracy_2k: 0.6384 - lcm_accuracy_3k: 0.7259 - lcm_accuracy_5k: 0.8095 - lcm_hamming_loss_k: 0.0045
Epoch 00008: val_loss improved from 0.31499 to 0.30303, saving model to logs/ckhnrj-lbs-0604-124140/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 370ms/step - loss: 0.2956 - lcm_precision_1k: 0.4845 - lcm_precision_2k: 0.3910 - lcm_precision_3k: 0.3242 - lcm_precision_5k: 0.2412 - lcm_recall_1k: 0.2934 - lcm_recall_2k: 0.4517 - lcm_recall_3k: 0.5514 - lcm_recall_5k: 0.6645 - lcm_f1_1k: 0.3654 - lcm_f1_2k: 0.4191 - lcm_f1_3k: 0.4083 - lcm_f1_5k: 0.3539 - lcm_accuracy_1k: 0.4845 - lcm_accuracy_2k: 0.6384 - lcm_accuracy_3k: 0.7259 - lcm_accuracy_5k: 0.8095 - lcm_hamming_loss_k: 0.0045 - val_loss: 0.3030 - val_lcm_precision_1k: 0.4969 - val_lcm_precision_2k: 0.3912 - val_lcm_precision_3k: 0.3220 - val_lcm_precision_5k: 0.2426 - val_lcm_recall_1k: 0.2964 - val_lcm_recall_2k: 0.4455 - val_lcm_recall_3k: 0.5403 - val_lcm_recall_5k: 0.6610 - val_lcm_f1_1k: 0.3711 - val_lcm_f1_2k: 0.4164 - val_lcm_f1_3k: 0.4034 - val_lcm_f1_5k: 0.3547 - val_lcm_accuracy_1k: 0.4969 - val_lcm_accuracy_2k: 0.6400 - val_lcm_accuracy_3k: 0.7186 - val_lcm_accuracy_5k: 0.8052 - val_lcm_hamming_loss_k: 0.0045
Epoch 9/150
27/27 [==============================] - ETA: 0s - loss: 0.2800 - lcm_precision_1k: 0.5195 - lcm_precision_2k: 0.4148 - lcm_precision_3k: 0.3426 - lcm_precision_5k: 0.2522 - lcm_recall_1k: 0.3162 - lcm_recall_2k: 0.4787 - lcm_recall_3k: 0.5810 - lcm_recall_5k: 0.6942 - lcm_f1_1k: 0.3931 - lcm_f1_2k: 0.4444 - lcm_f1_3k: 0.4310 - lcm_f1_5k: 0.3699 - lcm_accuracy_1k: 0.5195 - lcm_accuracy_2k: 0.6708 - lcm_accuracy_3k: 0.7553 - lcm_accuracy_5k: 0.8341 - lcm_hamming_loss_k: 0.0044
Epoch 00009: val_loss improved from 0.30303 to 0.29373, saving model to logs/ckhnrj-lbs-0604-124140/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 368ms/step - loss: 0.2800 - lcm_precision_1k: 0.5195 - lcm_precision_2k: 0.4148 - lcm_precision_3k: 0.3426 - lcm_precision_5k: 0.2522 - lcm_recall_1k: 0.3162 - lcm_recall_2k: 0.4787 - lcm_recall_3k: 0.5810 - lcm_recall_5k: 0.6942 - lcm_f1_1k: 0.3931 - lcm_f1_2k: 0.4444 - lcm_f1_3k: 0.4310 - lcm_f1_5k: 0.3699 - lcm_accuracy_1k: 0.5195 - lcm_accuracy_2k: 0.6708 - lcm_accuracy_3k: 0.7553 - lcm_accuracy_5k: 0.8341 - lcm_hamming_loss_k: 0.0044 - val_loss: 0.2937 - val_lcm_precision_1k: 0.5174 - val_lcm_precision_2k: 0.4083 - val_lcm_precision_3k: 0.3352 - val_lcm_precision_5k: 0.2484 - val_lcm_recall_1k: 0.3123 - val_lcm_recall_2k: 0.4690 - val_lcm_recall_3k: 0.5656 - val_lcm_recall_5k: 0.6793 - val_lcm_f1_1k: 0.3891 - val_lcm_f1_2k: 0.4363 - val_lcm_f1_3k: 0.4208 - val_lcm_f1_5k: 0.3636 - val_lcm_accuracy_1k: 0.5174 - val_lcm_accuracy_2k: 0.6619 - val_lcm_accuracy_3k: 0.7389 - val_lcm_accuracy_5k: 0.8191 - val_lcm_hamming_loss_k: 0.0044
Epoch 10/150
27/27 [==============================] - ETA: 0s - loss: 0.2688 - lcm_precision_1k: 0.5485 - lcm_precision_2k: 0.4326 - lcm_precision_3k: 0.3543 - lcm_precision_5k: 0.2599 - lcm_recall_1k: 0.3380 - lcm_recall_2k: 0.5030 - lcm_recall_3k: 0.6041 - lcm_recall_5k: 0.7177 - lcm_f1_1k: 0.4182 - lcm_f1_2k: 0.4651 - lcm_f1_3k: 0.4466 - lcm_f1_5k: 0.3816 - lcm_accuracy_1k: 0.5485 - lcm_accuracy_2k: 0.6988 - lcm_accuracy_3k: 0.7764 - lcm_accuracy_5k: 0.8544 - lcm_hamming_loss_k: 0.0042
Epoch 00010: val_loss improved from 0.29373 to 0.28896, saving model to logs/ckhnrj-lbs-0604-124140/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 370ms/step - loss: 0.2688 - lcm_precision_1k: 0.5485 - lcm_precision_2k: 0.4326 - lcm_precision_3k: 0.3543 - lcm_precision_5k: 0.2599 - lcm_recall_1k: 0.3380 - lcm_recall_2k: 0.5030 - lcm_recall_3k: 0.6041 - lcm_recall_5k: 0.7177 - lcm_f1_1k: 0.4182 - lcm_f1_2k: 0.4651 - lcm_f1_3k: 0.4466 - lcm_f1_5k: 0.3816 - lcm_accuracy_1k: 0.5485 - lcm_accuracy_2k: 0.6988 - lcm_accuracy_3k: 0.7764 - lcm_accuracy_5k: 0.8544 - lcm_hamming_loss_k: 0.0042 - val_loss: 0.2890 - val_lcm_precision_1k: 0.5333 - val_lcm_precision_2k: 0.4146 - val_lcm_precision_3k: 0.3443 - val_lcm_precision_5k: 0.2518 - val_lcm_recall_1k: 0.3233 - val_lcm_recall_2k: 0.4756 - val_lcm_recall_3k: 0.5814 - val_lcm_recall_5k: 0.6920 - val_lcm_f1_1k: 0.4023 - val_lcm_f1_2k: 0.4428 - val_lcm_f1_3k: 0.4323 - val_lcm_f1_5k: 0.3690 - val_lcm_accuracy_1k: 0.5333 - val_lcm_accuracy_2k: 0.6671 - val_lcm_accuracy_3k: 0.7523 - val_lcm_accuracy_5k: 0.8355 - val_lcm_hamming_loss_k: 0.0043
Epoch 11/150
27/27 [==============================] - ETA: 0s - loss: 0.2617 - lcm_precision_1k: 0.5626 - lcm_precision_2k: 0.4484 - lcm_precision_3k: 0.3649 - lcm_precision_5k: 0.2653 - lcm_recall_1k: 0.3480 - lcm_recall_2k: 0.5247 - lcm_recall_3k: 0.6233 - lcm_recall_5k: 0.7346 - lcm_f1_1k: 0.4299 - lcm_f1_2k: 0.4835 - lcm_f1_3k: 0.4603 - lcm_f1_5k: 0.3898 - lcm_accuracy_1k: 0.5626 - lcm_accuracy_2k: 0.7164 - lcm_accuracy_3k: 0.7943 - lcm_accuracy_5k: 0.8681 - lcm_hamming_loss_k: 0.0042
Epoch 00011: val_loss improved from 0.28896 to 0.28552, saving model to logs/ckhnrj-lbs-0604-124140/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 367ms/step - loss: 0.2617 - lcm_precision_1k: 0.5626 - lcm_precision_2k: 0.4484 - lcm_precision_3k: 0.3649 - lcm_precision_5k: 0.2653 - lcm_recall_1k: 0.3480 - lcm_recall_2k: 0.5247 - lcm_recall_3k: 0.6233 - lcm_recall_5k: 0.7346 - lcm_f1_1k: 0.4299 - lcm_f1_2k: 0.4835 - lcm_f1_3k: 0.4603 - lcm_f1_5k: 0.3898 - lcm_accuracy_1k: 0.5626 - lcm_accuracy_2k: 0.7164 - lcm_accuracy_3k: 0.7943 - lcm_accuracy_5k: 0.8681 - lcm_hamming_loss_k: 0.0042 - val_loss: 0.2855 - val_lcm_precision_1k: 0.5434 - val_lcm_precision_2k: 0.4249 - val_lcm_precision_3k: 0.3461 - val_lcm_precision_5k: 0.2538 - val_lcm_recall_1k: 0.3313 - val_lcm_recall_2k: 0.4901 - val_lcm_recall_3k: 0.5835 - val_lcm_recall_5k: 0.6955 - val_lcm_f1_1k: 0.4114 - val_lcm_f1_2k: 0.4549 - val_lcm_f1_3k: 0.4343 - val_lcm_f1_5k: 0.3717 - val_lcm_accuracy_1k: 0.5434 - val_lcm_accuracy_2k: 0.6832 - val_lcm_accuracy_3k: 0.7542 - val_lcm_accuracy_5k: 0.8339 - val_lcm_hamming_loss_k: 0.0043
Epoch 12/150
27/27 [==============================] - ETA: 0s - loss: 0.2513 - lcm_precision_1k: 0.5861 - lcm_precision_2k: 0.4660 - lcm_precision_3k: 0.3788 - lcm_precision_5k: 0.2740 - lcm_recall_1k: 0.3643 - lcm_recall_2k: 0.5456 - lcm_recall_3k: 0.6478 - lcm_recall_5k: 0.7581 - lcm_f1_1k: 0.4493 - lcm_f1_2k: 0.5026 - lcm_f1_3k: 0.4780 - lcm_f1_5k: 0.4024 - lcm_accuracy_1k: 0.5861 - lcm_accuracy_2k: 0.7430 - lcm_accuracy_3k: 0.8152 - lcm_accuracy_5k: 0.8852 - lcm_hamming_loss_k: 0.0041
Epoch 00012: val_loss improved from 0.28552 to 0.28096, saving model to logs/ckhnrj-lbs-0604-124140/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 367ms/step - loss: 0.2513 - lcm_precision_1k: 0.5861 - lcm_precision_2k: 0.4660 - lcm_precision_3k: 0.3788 - lcm_precision_5k: 0.2740 - lcm_recall_1k: 0.3643 - lcm_recall_2k: 0.5456 - lcm_recall_3k: 0.6478 - lcm_recall_5k: 0.7581 - lcm_f1_1k: 0.4493 - lcm_f1_2k: 0.5026 - lcm_f1_3k: 0.4780 - lcm_f1_5k: 0.4024 - lcm_accuracy_1k: 0.5861 - lcm_accuracy_2k: 0.7430 - lcm_accuracy_3k: 0.8152 - lcm_accuracy_5k: 0.8852 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2810 - val_lcm_precision_1k: 0.5484 - val_lcm_precision_2k: 0.4308 - val_lcm_precision_3k: 0.3528 - val_lcm_precision_5k: 0.2566 - val_lcm_recall_1k: 0.3378 - val_lcm_recall_2k: 0.5019 - val_lcm_recall_3k: 0.5996 - val_lcm_recall_5k: 0.7053 - val_lcm_f1_1k: 0.4179 - val_lcm_f1_2k: 0.4634 - val_lcm_f1_3k: 0.4440 - val_lcm_f1_5k: 0.3761 - val_lcm_accuracy_1k: 0.5484 - val_lcm_accuracy_2k: 0.6925 - val_lcm_accuracy_3k: 0.7688 - val_lcm_accuracy_5k: 0.8435 - val_lcm_hamming_loss_k: 0.0043
Epoch 13/150
27/27 [==============================] - ETA: 0s - loss: 0.2431 - lcm_precision_1k: 0.6077 - lcm_precision_2k: 0.4791 - lcm_precision_3k: 0.3870 - lcm_precision_5k: 0.2787 - lcm_recall_1k: 0.3798 - lcm_recall_2k: 0.5651 - lcm_recall_3k: 0.6643 - lcm_recall_5k: 0.7700 - lcm_f1_1k: 0.4674 - lcm_f1_2k: 0.5185 - lcm_f1_3k: 0.4890 - lcm_f1_5k: 0.4092 - lcm_accuracy_1k: 0.6077 - lcm_accuracy_2k: 0.7629 - lcm_accuracy_3k: 0.8328 - lcm_accuracy_5k: 0.8947 - lcm_hamming_loss_k: 0.0040
Epoch 00013: val_loss improved from 0.28096 to 0.27750, saving model to logs/ckhnrj-lbs-0604-124140/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.2431 - lcm_precision_1k: 0.6077 - lcm_precision_2k: 0.4791 - lcm_precision_3k: 0.3870 - lcm_precision_5k: 0.2787 - lcm_recall_1k: 0.3798 - lcm_recall_2k: 0.5651 - lcm_recall_3k: 0.6643 - lcm_recall_5k: 0.7700 - lcm_f1_1k: 0.4674 - lcm_f1_2k: 0.5185 - lcm_f1_3k: 0.4890 - lcm_f1_5k: 0.4092 - lcm_accuracy_1k: 0.6077 - lcm_accuracy_2k: 0.7629 - lcm_accuracy_3k: 0.8328 - lcm_accuracy_5k: 0.8947 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2775 - val_lcm_precision_1k: 0.5558 - val_lcm_precision_2k: 0.4350 - val_lcm_precision_3k: 0.3546 - val_lcm_precision_5k: 0.2580 - val_lcm_recall_1k: 0.3462 - val_lcm_recall_2k: 0.5067 - val_lcm_recall_3k: 0.6033 - val_lcm_recall_5k: 0.7102 - val_lcm_f1_1k: 0.4264 - val_lcm_f1_2k: 0.4679 - val_lcm_f1_3k: 0.4464 - val_lcm_f1_5k: 0.3783 - val_lcm_accuracy_1k: 0.5558 - val_lcm_accuracy_2k: 0.6957 - val_lcm_accuracy_3k: 0.7722 - val_lcm_accuracy_5k: 0.8491 - val_lcm_hamming_loss_k: 0.0042
Epoch 14/150
27/27 [==============================] - ETA: 0s - loss: 0.2368 - lcm_precision_1k: 0.6210 - lcm_precision_2k: 0.4909 - lcm_precision_3k: 0.3962 - lcm_precision_5k: 0.2845 - lcm_recall_1k: 0.3875 - lcm_recall_2k: 0.5779 - lcm_recall_3k: 0.6783 - lcm_recall_5k: 0.7854 - lcm_f1_1k: 0.4771 - lcm_f1_2k: 0.5308 - lcm_f1_3k: 0.5002 - lcm_f1_5k: 0.4176 - lcm_accuracy_1k: 0.6210 - lcm_accuracy_2k: 0.7760 - lcm_accuracy_3k: 0.8438 - lcm_accuracy_5k: 0.9043 - lcm_hamming_loss_k: 0.0039
Epoch 00014: val_loss improved from 0.27750 to 0.27545, saving model to logs/ckhnrj-lbs-0604-124140/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 370ms/step - loss: 0.2368 - lcm_precision_1k: 0.6210 - lcm_precision_2k: 0.4909 - lcm_precision_3k: 0.3962 - lcm_precision_5k: 0.2845 - lcm_recall_1k: 0.3875 - lcm_recall_2k: 0.5779 - lcm_recall_3k: 0.6783 - lcm_recall_5k: 0.7854 - lcm_f1_1k: 0.4771 - lcm_f1_2k: 0.5308 - lcm_f1_3k: 0.5002 - lcm_f1_5k: 0.4176 - lcm_accuracy_1k: 0.6210 - lcm_accuracy_2k: 0.7760 - lcm_accuracy_3k: 0.8438 - lcm_accuracy_5k: 0.9043 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2754 - val_lcm_precision_1k: 0.5682 - val_lcm_precision_2k: 0.4421 - val_lcm_precision_3k: 0.3584 - val_lcm_precision_5k: 0.2607 - val_lcm_recall_1k: 0.3525 - val_lcm_recall_2k: 0.5172 - val_lcm_recall_3k: 0.6104 - val_lcm_recall_5k: 0.7188 - val_lcm_f1_1k: 0.4349 - val_lcm_f1_2k: 0.4765 - val_lcm_f1_3k: 0.4514 - val_lcm_f1_5k: 0.3825 - val_lcm_accuracy_1k: 0.5682 - val_lcm_accuracy_2k: 0.7134 - val_lcm_accuracy_3k: 0.7824 - val_lcm_accuracy_5k: 0.8559 - val_lcm_hamming_loss_k: 0.0042
Epoch 15/150
27/27 [==============================] - ETA: 0s - loss: 0.2287 - lcm_precision_1k: 0.6405 - lcm_precision_2k: 0.5078 - lcm_precision_3k: 0.4081 - lcm_precision_5k: 0.2899 - lcm_recall_1k: 0.4013 - lcm_recall_2k: 0.5988 - lcm_recall_3k: 0.6989 - lcm_recall_5k: 0.8010 - lcm_f1_1k: 0.4933 - lcm_f1_2k: 0.5495 - lcm_f1_3k: 0.5152 - lcm_f1_5k: 0.4256 - lcm_accuracy_1k: 0.6405 - lcm_accuracy_2k: 0.7982 - lcm_accuracy_3k: 0.8619 - lcm_accuracy_5k: 0.9160 - lcm_hamming_loss_k: 0.0038
Epoch 00015: val_loss did not improve from 0.27545
27/27 [==============================] - 9s 342ms/step - loss: 0.2287 - lcm_precision_1k: 0.6405 - lcm_precision_2k: 0.5078 - lcm_precision_3k: 0.4081 - lcm_precision_5k: 0.2899 - lcm_recall_1k: 0.4013 - lcm_recall_2k: 0.5988 - lcm_recall_3k: 0.6989 - lcm_recall_5k: 0.8010 - lcm_f1_1k: 0.4933 - lcm_f1_2k: 0.5495 - lcm_f1_3k: 0.5152 - lcm_f1_5k: 0.4256 - lcm_accuracy_1k: 0.6405 - lcm_accuracy_2k: 0.7982 - lcm_accuracy_3k: 0.8619 - lcm_accuracy_5k: 0.9160 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2758 - val_lcm_precision_1k: 0.5690 - val_lcm_precision_2k: 0.4410 - val_lcm_precision_3k: 0.3587 - val_lcm_precision_5k: 0.2584 - val_lcm_recall_1k: 0.3550 - val_lcm_recall_2k: 0.5171 - val_lcm_recall_3k: 0.6135 - val_lcm_recall_5k: 0.7136 - val_lcm_f1_1k: 0.4371 - val_lcm_f1_2k: 0.4758 - val_lcm_f1_3k: 0.4525 - val_lcm_f1_5k: 0.3792 - val_lcm_accuracy_1k: 0.5690 - val_lcm_accuracy_2k: 0.7106 - val_lcm_accuracy_3k: 0.7867 - val_lcm_accuracy_5k: 0.8534 - val_lcm_hamming_loss_k: 0.0042
Epoch 16/150
27/27 [==============================] - ETA: 0s - loss: 0.2229 - lcm_precision_1k: 0.6612 - lcm_precision_2k: 0.5159 - lcm_precision_3k: 0.4146 - lcm_precision_5k: 0.2946 - lcm_recall_1k: 0.4173 - lcm_recall_2k: 0.6101 - lcm_recall_3k: 0.7100 - lcm_recall_5k: 0.8130 - lcm_f1_1k: 0.5116 - lcm_f1_2k: 0.5589 - lcm_f1_3k: 0.5234 - lcm_f1_5k: 0.4324 - lcm_accuracy_1k: 0.6612 - lcm_accuracy_2k: 0.8079 - lcm_accuracy_3k: 0.8674 - lcm_accuracy_5k: 0.9236 - lcm_hamming_loss_k: 0.0037
Epoch 00016: val_loss improved from 0.27545 to 0.27155, saving model to logs/ckhnrj-lbs-0604-124140/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.2229 - lcm_precision_1k: 0.6612 - lcm_precision_2k: 0.5159 - lcm_precision_3k: 0.4146 - lcm_precision_5k: 0.2946 - lcm_recall_1k: 0.4173 - lcm_recall_2k: 0.6101 - lcm_recall_3k: 0.7100 - lcm_recall_5k: 0.8130 - lcm_f1_1k: 0.5116 - lcm_f1_2k: 0.5589 - lcm_f1_3k: 0.5234 - lcm_f1_5k: 0.4324 - lcm_accuracy_1k: 0.6612 - lcm_accuracy_2k: 0.8079 - lcm_accuracy_3k: 0.8674 - lcm_accuracy_5k: 0.9236 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2715 - val_lcm_precision_1k: 0.5724 - val_lcm_precision_2k: 0.4494 - val_lcm_precision_3k: 0.3676 - val_lcm_precision_5k: 0.2658 - val_lcm_recall_1k: 0.3551 - val_lcm_recall_2k: 0.5265 - val_lcm_recall_3k: 0.6281 - val_lcm_recall_5k: 0.7343 - val_lcm_f1_1k: 0.4381 - val_lcm_f1_2k: 0.4848 - val_lcm_f1_3k: 0.4636 - val_lcm_f1_5k: 0.3901 - val_lcm_accuracy_1k: 0.5724 - val_lcm_accuracy_2k: 0.7214 - val_lcm_accuracy_3k: 0.7990 - val_lcm_accuracy_5k: 0.8697 - val_lcm_hamming_loss_k: 0.0042
Epoch 17/150
27/27 [==============================] - ETA: 0s - loss: 0.2137 - lcm_precision_1k: 0.6832 - lcm_precision_2k: 0.5361 - lcm_precision_3k: 0.4285 - lcm_precision_5k: 0.3020 - lcm_recall_1k: 0.4297 - lcm_recall_2k: 0.6310 - lcm_recall_3k: 0.7289 - lcm_recall_5k: 0.8281 - lcm_f1_1k: 0.5276 - lcm_f1_2k: 0.5796 - lcm_f1_3k: 0.5397 - lcm_f1_5k: 0.4426 - lcm_accuracy_1k: 0.6832 - lcm_accuracy_2k: 0.8277 - lcm_accuracy_3k: 0.8831 - lcm_accuracy_5k: 0.9332 - lcm_hamming_loss_k: 0.0036
Epoch 00017: val_loss improved from 0.27155 to 0.27025, saving model to logs/ckhnrj-lbs-0604-124140/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 367ms/step - loss: 0.2137 - lcm_precision_1k: 0.6832 - lcm_precision_2k: 0.5361 - lcm_precision_3k: 0.4285 - lcm_precision_5k: 0.3020 - lcm_recall_1k: 0.4297 - lcm_recall_2k: 0.6310 - lcm_recall_3k: 0.7289 - lcm_recall_5k: 0.8281 - lcm_f1_1k: 0.5276 - lcm_f1_2k: 0.5796 - lcm_f1_3k: 0.5397 - lcm_f1_5k: 0.4426 - lcm_accuracy_1k: 0.6832 - lcm_accuracy_2k: 0.8277 - lcm_accuracy_3k: 0.8831 - lcm_accuracy_5k: 0.9332 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2702 - val_lcm_precision_1k: 0.5887 - val_lcm_precision_2k: 0.4589 - val_lcm_precision_3k: 0.3699 - val_lcm_precision_5k: 0.2656 - val_lcm_recall_1k: 0.3686 - val_lcm_recall_2k: 0.5362 - val_lcm_recall_3k: 0.6311 - val_lcm_recall_5k: 0.7306 - val_lcm_f1_1k: 0.4531 - val_lcm_f1_2k: 0.4943 - val_lcm_f1_3k: 0.4662 - val_lcm_f1_5k: 0.3894 - val_lcm_accuracy_1k: 0.5887 - val_lcm_accuracy_2k: 0.7314 - val_lcm_accuracy_3k: 0.8065 - val_lcm_accuracy_5k: 0.8670 - val_lcm_hamming_loss_k: 0.0041
Epoch 18/150
27/27 [==============================] - ETA: 0s - loss: 0.2064 - lcm_precision_1k: 0.7021 - lcm_precision_2k: 0.5464 - lcm_precision_3k: 0.4365 - lcm_precision_5k: 0.3067 - lcm_recall_1k: 0.4445 - lcm_recall_2k: 0.6446 - lcm_recall_3k: 0.7440 - lcm_recall_5k: 0.8427 - lcm_f1_1k: 0.5443 - lcm_f1_2k: 0.5914 - lcm_f1_3k: 0.5501 - lcm_f1_5k: 0.4497 - lcm_accuracy_1k: 0.7021 - lcm_accuracy_2k: 0.8430 - lcm_accuracy_3k: 0.8949 - lcm_accuracy_5k: 0.9432 - lcm_hamming_loss_k: 0.0035
Epoch 00018: val_loss did not improve from 0.27025
27/27 [==============================] - 9s 340ms/step - loss: 0.2064 - lcm_precision_1k: 0.7021 - lcm_precision_2k: 0.5464 - lcm_precision_3k: 0.4365 - lcm_precision_5k: 0.3067 - lcm_recall_1k: 0.4445 - lcm_recall_2k: 0.6446 - lcm_recall_3k: 0.7440 - lcm_recall_5k: 0.8427 - lcm_f1_1k: 0.5443 - lcm_f1_2k: 0.5914 - lcm_f1_3k: 0.5501 - lcm_f1_5k: 0.4497 - lcm_accuracy_1k: 0.7021 - lcm_accuracy_2k: 0.8430 - lcm_accuracy_3k: 0.8949 - lcm_accuracy_5k: 0.9432 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2718 - val_lcm_precision_1k: 0.5852 - val_lcm_precision_2k: 0.4564 - val_lcm_precision_3k: 0.3691 - val_lcm_precision_5k: 0.2647 - val_lcm_recall_1k: 0.3649 - val_lcm_recall_2k: 0.5349 - val_lcm_recall_3k: 0.6304 - val_lcm_recall_5k: 0.7279 - val_lcm_f1_1k: 0.4493 - val_lcm_f1_2k: 0.4923 - val_lcm_f1_3k: 0.4654 - val_lcm_f1_5k: 0.3880 - val_lcm_accuracy_1k: 0.5852 - val_lcm_accuracy_2k: 0.7250 - val_lcm_accuracy_3k: 0.7948 - val_lcm_accuracy_5k: 0.8617 - val_lcm_hamming_loss_k: 0.0041
Epoch 19/150
27/27 [==============================] - ETA: 0s - loss: 0.2003 - lcm_precision_1k: 0.7140 - lcm_precision_2k: 0.5572 - lcm_precision_3k: 0.4446 - lcm_precision_5k: 0.3108 - lcm_recall_1k: 0.4531 - lcm_recall_2k: 0.6566 - lcm_recall_3k: 0.7566 - lcm_recall_5k: 0.8520 - lcm_f1_1k: 0.5543 - lcm_f1_2k: 0.6028 - lcm_f1_3k: 0.5600 - lcm_f1_5k: 0.4554 - lcm_accuracy_1k: 0.7140 - lcm_accuracy_2k: 0.8530 - lcm_accuracy_3k: 0.9033 - lcm_accuracy_5k: 0.9483 - lcm_hamming_loss_k: 0.0035
Epoch 00019: val_loss did not improve from 0.27025
27/27 [==============================] - 9s 337ms/step - loss: 0.2003 - lcm_precision_1k: 0.7140 - lcm_precision_2k: 0.5572 - lcm_precision_3k: 0.4446 - lcm_precision_5k: 0.3108 - lcm_recall_1k: 0.4531 - lcm_recall_2k: 0.6566 - lcm_recall_3k: 0.7566 - lcm_recall_5k: 0.8520 - lcm_f1_1k: 0.5543 - lcm_f1_2k: 0.6028 - lcm_f1_3k: 0.5600 - lcm_f1_5k: 0.4554 - lcm_accuracy_1k: 0.7140 - lcm_accuracy_2k: 0.8530 - lcm_accuracy_3k: 0.9033 - lcm_accuracy_5k: 0.9483 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2727 - val_lcm_precision_1k: 0.5805 - val_lcm_precision_2k: 0.4513 - val_lcm_precision_3k: 0.3657 - val_lcm_precision_5k: 0.2640 - val_lcm_recall_1k: 0.3630 - val_lcm_recall_2k: 0.5321 - val_lcm_recall_3k: 0.6261 - val_lcm_recall_5k: 0.7276 - val_lcm_f1_1k: 0.4464 - val_lcm_f1_2k: 0.4881 - val_lcm_f1_3k: 0.4615 - val_lcm_f1_5k: 0.3872 - val_lcm_accuracy_1k: 0.5805 - val_lcm_accuracy_2k: 0.7248 - val_lcm_accuracy_3k: 0.7969 - val_lcm_accuracy_5k: 0.8658 - val_lcm_hamming_loss_k: 0.0041
Epoch 00019: early stopping
176/176 [==============================] - 7s 36ms/step - loss: 0.2237 - lcm_precision_1k: 0.6686 - lcm_precision_2k: 0.5168 - lcm_precision_3k: 0.4136 - lcm_precision_5k: 0.2926 - lcm_recall_1k: 0.4225 - lcm_recall_2k: 0.6127 - lcm_recall_3k: 0.7103 - lcm_recall_5k: 0.8077 - lcm_f1_1k: 0.5165 - lcm_f1_2k: 0.5595 - lcm_f1_3k: 0.5218 - lcm_f1_5k: 0.4289 - lcm_accuracy_1k: 0.6686 - lcm_accuracy_2k: 0.8111 - lcm_accuracy_3k: 0.8697 - lcm_accuracy_5k: 0.9161 - lcm_hamming_loss_k: 0.0037
Best model result:  [0.22365182638168335, 0.6686379909515381, 0.5167782306671143, 0.4136255085468292, 0.2926330864429474, 0.42253991961479187, 0.6127398014068604, 0.7102922797203064, 0.8077000975608826, 0.5164948105812073, 0.5594732761383057, 0.5218390226364136, 0.4289473593235016, 0.6686379909515381, 0.8111330270767212, 0.8697018027305603, 0.9160964488983154, 0.0036538944113999605]
13499
3374
5625
Model: "model_6"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['BiLSTM[0][0]']                 
                                                                                                  
==================================================================================================
Total params: 28,546,223
Trainable params: 3,767,723
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
2 patience
Model: "model_7"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 tf.__operators__.getitem_3 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_lcm_emb (Dense)          (None, 427, 1024)    308224      ['tf.__operators__.getitem_3[0][0
                                                                 ]']                              
                                                                                                  
 dot_3 (Dot)                    (None, 427)          0           ['label_lcm_emb[0][0]',          
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['BiLSTM[0][0]']                 
                                                                                                  
 label_sim_dict (Dense)         (None, 427)          182756      ['dot_3[0][0]']                  
                                                                                                  
 concatenate_3 (Concatenate)    (None, 854)          0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 29,165,303
Trainable params: 4,386,803
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
Epoch 1/150
27/27 [==============================] - ETA: 0s - loss: 0.4998 - lcm_precision_1k: 0.1449 - lcm_precision_2k: 0.1230 - lcm_precision_3k: 0.1076 - lcm_precision_5k: 0.0915 - lcm_recall_1k: 0.0724 - lcm_recall_2k: 0.1233 - lcm_recall_3k: 0.1623 - lcm_recall_5k: 0.2295 - lcm_f1_1k: nan - lcm_f1_2k: 0.1230 - lcm_f1_3k: 0.1293 - lcm_f1_5k: 0.1308 - lcm_accuracy_1k: 0.1449 - lcm_accuracy_2k: 0.2095 - lcm_accuracy_3k: 0.2614 - lcm_accuracy_5k: 0.3395 - lcm_hamming_loss_k: 0.0061
Epoch 00001: val_loss improved from inf to 0.46701, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 11s 369ms/step - loss: 0.4998 - lcm_precision_1k: 0.1449 - lcm_precision_2k: 0.1230 - lcm_precision_3k: 0.1076 - lcm_precision_5k: 0.0915 - lcm_recall_1k: 0.0724 - lcm_recall_2k: 0.1233 - lcm_recall_3k: 0.1623 - lcm_recall_5k: 0.2295 - lcm_f1_1k: nan - lcm_f1_2k: 0.1230 - lcm_f1_3k: 0.1293 - lcm_f1_5k: 0.1308 - lcm_accuracy_1k: 0.1449 - lcm_accuracy_2k: 0.2095 - lcm_accuracy_3k: 0.2614 - lcm_accuracy_5k: 0.3395 - lcm_hamming_loss_k: 0.0061 - val_loss: 0.4670 - val_lcm_precision_1k: 0.1830 - val_lcm_precision_2k: 0.1501 - val_lcm_precision_3k: 0.1346 - val_lcm_precision_5k: 0.1158 - val_lcm_recall_1k: 0.0934 - val_lcm_recall_2k: 0.1505 - val_lcm_recall_3k: 0.1990 - val_lcm_recall_5k: 0.2888 - val_lcm_f1_1k: 0.1235 - val_lcm_f1_2k: 0.1501 - val_lcm_f1_3k: 0.1604 - val_lcm_f1_5k: 0.1653 - val_lcm_accuracy_1k: 0.1830 - val_lcm_accuracy_2k: 0.2560 - val_lcm_accuracy_3k: 0.3167 - val_lcm_accuracy_5k: 0.4047 - val_lcm_hamming_loss_k: 0.0059
Epoch 2/150
27/27 [==============================] - ETA: 0s - loss: 0.4264 - lcm_precision_1k: 0.2362 - lcm_precision_2k: 0.1985 - lcm_precision_3k: 0.1744 - lcm_precision_5k: 0.1478 - lcm_recall_1k: 0.1278 - lcm_recall_2k: 0.2153 - lcm_recall_3k: 0.2818 - lcm_recall_5k: 0.3945 - lcm_f1_1k: 0.1658 - lcm_f1_2k: 0.2065 - lcm_f1_3k: 0.2154 - lcm_f1_5k: 0.2150 - lcm_accuracy_1k: 0.2362 - lcm_accuracy_2k: 0.3449 - lcm_accuracy_3k: 0.4239 - lcm_accuracy_5k: 0.5298 - lcm_hamming_loss_k: 0.0057
Epoch 00002: val_loss improved from 0.46701 to 0.39657, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 364ms/step - loss: 0.4264 - lcm_precision_1k: 0.2362 - lcm_precision_2k: 0.1985 - lcm_precision_3k: 0.1744 - lcm_precision_5k: 0.1478 - lcm_recall_1k: 0.1278 - lcm_recall_2k: 0.2153 - lcm_recall_3k: 0.2818 - lcm_recall_5k: 0.3945 - lcm_f1_1k: 0.1658 - lcm_f1_2k: 0.2065 - lcm_f1_3k: 0.2154 - lcm_f1_5k: 0.2150 - lcm_accuracy_1k: 0.2362 - lcm_accuracy_2k: 0.3449 - lcm_accuracy_3k: 0.4239 - lcm_accuracy_5k: 0.5298 - lcm_hamming_loss_k: 0.0057 - val_loss: 0.3966 - val_lcm_precision_1k: 0.2599 - val_lcm_precision_2k: 0.2285 - val_lcm_precision_3k: 0.1961 - val_lcm_precision_5k: 0.1643 - val_lcm_recall_1k: 0.1470 - val_lcm_recall_2k: 0.2525 - val_lcm_recall_3k: 0.3204 - val_lcm_recall_5k: 0.4360 - val_lcm_f1_1k: 0.1877 - val_lcm_f1_2k: 0.2397 - val_lcm_f1_3k: 0.2432 - val_lcm_f1_5k: 0.2386 - val_lcm_accuracy_1k: 0.2599 - val_lcm_accuracy_2k: 0.3859 - val_lcm_accuracy_3k: 0.4666 - val_lcm_accuracy_5k: 0.5785 - val_lcm_hamming_loss_k: 0.0056
Epoch 3/150
27/27 [==============================] - ETA: 0s - loss: 0.3708 - lcm_precision_1k: 0.3158 - lcm_precision_2k: 0.2681 - lcm_precision_3k: 0.2291 - lcm_precision_5k: 0.1839 - lcm_recall_1k: 0.1800 - lcm_recall_2k: 0.2984 - lcm_recall_3k: 0.3759 - lcm_recall_5k: 0.4934 - lcm_f1_1k: 0.2292 - lcm_f1_2k: 0.2824 - lcm_f1_3k: 0.2846 - lcm_f1_5k: 0.2679 - lcm_accuracy_1k: 0.3158 - lcm_accuracy_2k: 0.4544 - lcm_accuracy_3k: 0.5371 - lcm_accuracy_5k: 0.6399 - lcm_hamming_loss_k: 0.0053
Epoch 00003: val_loss improved from 0.39657 to 0.35954, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 371ms/step - loss: 0.3708 - lcm_precision_1k: 0.3158 - lcm_precision_2k: 0.2681 - lcm_precision_3k: 0.2291 - lcm_precision_5k: 0.1839 - lcm_recall_1k: 0.1800 - lcm_recall_2k: 0.2984 - lcm_recall_3k: 0.3759 - lcm_recall_5k: 0.4934 - lcm_f1_1k: 0.2292 - lcm_f1_2k: 0.2824 - lcm_f1_3k: 0.2846 - lcm_f1_5k: 0.2679 - lcm_accuracy_1k: 0.3158 - lcm_accuracy_2k: 0.4544 - lcm_accuracy_3k: 0.5371 - lcm_accuracy_5k: 0.6399 - lcm_hamming_loss_k: 0.0053 - val_loss: 0.3595 - val_lcm_precision_1k: 0.3367 - val_lcm_precision_2k: 0.2851 - val_lcm_precision_3k: 0.2443 - val_lcm_precision_5k: 0.1968 - val_lcm_recall_1k: 0.1932 - val_lcm_recall_2k: 0.3204 - val_lcm_recall_3k: 0.4062 - val_lcm_recall_5k: 0.5323 - val_lcm_f1_1k: 0.2453 - val_lcm_f1_2k: 0.3015 - val_lcm_f1_3k: 0.3049 - val_lcm_f1_5k: 0.2872 - val_lcm_accuracy_1k: 0.3367 - val_lcm_accuracy_2k: 0.4944 - val_lcm_accuracy_3k: 0.5765 - val_lcm_accuracy_5k: 0.6852 - val_lcm_hamming_loss_k: 0.0052
Epoch 4/150
27/27 [==============================] - ETA: 0s - loss: 0.3436 - lcm_precision_1k: 0.3634 - lcm_precision_2k: 0.3110 - lcm_precision_3k: 0.2651 - lcm_precision_5k: 0.2065 - lcm_recall_1k: 0.2105 - lcm_recall_2k: 0.3507 - lcm_recall_3k: 0.4411 - lcm_recall_5k: 0.5600 - lcm_f1_1k: 0.2664 - lcm_f1_2k: 0.3295 - lcm_f1_3k: 0.3310 - lcm_f1_5k: 0.3017 - lcm_accuracy_1k: 0.3634 - lcm_accuracy_2k: 0.5238 - lcm_accuracy_3k: 0.6142 - lcm_accuracy_5k: 0.7104 - lcm_hamming_loss_k: 0.0051
Epoch 00004: val_loss improved from 0.35954 to 0.34264, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 371ms/step - loss: 0.3436 - lcm_precision_1k: 0.3634 - lcm_precision_2k: 0.3110 - lcm_precision_3k: 0.2651 - lcm_precision_5k: 0.2065 - lcm_recall_1k: 0.2105 - lcm_recall_2k: 0.3507 - lcm_recall_3k: 0.4411 - lcm_recall_5k: 0.5600 - lcm_f1_1k: 0.2664 - lcm_f1_2k: 0.3295 - lcm_f1_3k: 0.3310 - lcm_f1_5k: 0.3017 - lcm_accuracy_1k: 0.3634 - lcm_accuracy_2k: 0.5238 - lcm_accuracy_3k: 0.6142 - lcm_accuracy_5k: 0.7104 - lcm_hamming_loss_k: 0.0051 - val_loss: 0.3426 - val_lcm_precision_1k: 0.3690 - val_lcm_precision_2k: 0.3180 - val_lcm_precision_3k: 0.2676 - val_lcm_precision_5k: 0.2084 - val_lcm_recall_1k: 0.2177 - val_lcm_recall_2k: 0.3618 - val_lcm_recall_3k: 0.4479 - val_lcm_recall_5k: 0.5650 - val_lcm_f1_1k: 0.2737 - val_lcm_f1_2k: 0.3382 - val_lcm_f1_3k: 0.3348 - val_lcm_f1_5k: 0.3044 - val_lcm_accuracy_1k: 0.3690 - val_lcm_accuracy_2k: 0.5342 - val_lcm_accuracy_3k: 0.6175 - val_lcm_accuracy_5k: 0.7193 - val_lcm_hamming_loss_k: 0.0051
Epoch 5/150
27/27 [==============================] - ETA: 0s - loss: 0.3255 - lcm_precision_1k: 0.4021 - lcm_precision_2k: 0.3365 - lcm_precision_3k: 0.2854 - lcm_precision_5k: 0.2206 - lcm_recall_1k: 0.2370 - lcm_recall_2k: 0.3843 - lcm_recall_3k: 0.4808 - lcm_recall_5k: 0.6016 - lcm_f1_1k: 0.2981 - lcm_f1_2k: 0.3587 - lcm_f1_3k: 0.3580 - lcm_f1_5k: 0.3227 - lcm_accuracy_1k: 0.4021 - lcm_accuracy_2k: 0.5635 - lcm_accuracy_3k: 0.6551 - lcm_accuracy_5k: 0.7517 - lcm_hamming_loss_k: 0.0049
Epoch 00005: val_loss improved from 0.34264 to 0.32814, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 365ms/step - loss: 0.3255 - lcm_precision_1k: 0.4021 - lcm_precision_2k: 0.3365 - lcm_precision_3k: 0.2854 - lcm_precision_5k: 0.2206 - lcm_recall_1k: 0.2370 - lcm_recall_2k: 0.3843 - lcm_recall_3k: 0.4808 - lcm_recall_5k: 0.6016 - lcm_f1_1k: 0.2981 - lcm_f1_2k: 0.3587 - lcm_f1_3k: 0.3580 - lcm_f1_5k: 0.3227 - lcm_accuracy_1k: 0.4021 - lcm_accuracy_2k: 0.5635 - lcm_accuracy_3k: 0.6551 - lcm_accuracy_5k: 0.7517 - lcm_hamming_loss_k: 0.0049 - val_loss: 0.3281 - val_lcm_precision_1k: 0.4082 - val_lcm_precision_2k: 0.3391 - val_lcm_precision_3k: 0.2864 - val_lcm_precision_5k: 0.2202 - val_lcm_recall_1k: 0.2430 - val_lcm_recall_2k: 0.3874 - val_lcm_recall_3k: 0.4786 - val_lcm_recall_5k: 0.5974 - val_lcm_f1_1k: 0.3045 - val_lcm_f1_2k: 0.3614 - val_lcm_f1_3k: 0.3581 - val_lcm_f1_5k: 0.3216 - val_lcm_accuracy_1k: 0.4082 - val_lcm_accuracy_2k: 0.5700 - val_lcm_accuracy_3k: 0.6576 - val_lcm_accuracy_5k: 0.7524 - val_lcm_hamming_loss_k: 0.0049
Epoch 6/150
27/27 [==============================] - ETA: 0s - loss: 0.3089 - lcm_precision_1k: 0.4527 - lcm_precision_2k: 0.3666 - lcm_precision_3k: 0.3086 - lcm_precision_5k: 0.2330 - lcm_recall_1k: 0.2710 - lcm_recall_2k: 0.4213 - lcm_recall_3k: 0.5213 - lcm_recall_5k: 0.6380 - lcm_f1_1k: 0.3390 - lcm_f1_2k: 0.3920 - lcm_f1_3k: 0.3877 - lcm_f1_5k: 0.3413 - lcm_accuracy_1k: 0.4527 - lcm_accuracy_2k: 0.6055 - lcm_accuracy_3k: 0.6981 - lcm_accuracy_5k: 0.7857 - lcm_hamming_loss_k: 0.0047
Epoch 00006: val_loss improved from 0.32814 to 0.31572, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 366ms/step - loss: 0.3089 - lcm_precision_1k: 0.4527 - lcm_precision_2k: 0.3666 - lcm_precision_3k: 0.3086 - lcm_precision_5k: 0.2330 - lcm_recall_1k: 0.2710 - lcm_recall_2k: 0.4213 - lcm_recall_3k: 0.5213 - lcm_recall_5k: 0.6380 - lcm_f1_1k: 0.3390 - lcm_f1_2k: 0.3920 - lcm_f1_3k: 0.3877 - lcm_f1_5k: 0.3413 - lcm_accuracy_1k: 0.4527 - lcm_accuracy_2k: 0.6055 - lcm_accuracy_3k: 0.6981 - lcm_accuracy_5k: 0.7857 - lcm_hamming_loss_k: 0.0047 - val_loss: 0.3157 - val_lcm_precision_1k: 0.4394 - val_lcm_precision_2k: 0.3562 - val_lcm_precision_3k: 0.3006 - val_lcm_precision_5k: 0.2287 - val_lcm_recall_1k: 0.2639 - val_lcm_recall_2k: 0.4095 - val_lcm_recall_3k: 0.5065 - val_lcm_recall_5k: 0.6243 - val_lcm_f1_1k: 0.3295 - val_lcm_f1_2k: 0.3807 - val_lcm_f1_3k: 0.3770 - val_lcm_f1_5k: 0.3345 - val_lcm_accuracy_1k: 0.4394 - val_lcm_accuracy_2k: 0.5901 - val_lcm_accuracy_3k: 0.6816 - val_lcm_accuracy_5k: 0.7693 - val_lcm_hamming_loss_k: 0.0047
Epoch 7/150
27/27 [==============================] - ETA: 0s - loss: 0.2990 - lcm_precision_1k: 0.4742 - lcm_precision_2k: 0.3854 - lcm_precision_3k: 0.3200 - lcm_precision_5k: 0.2398 - lcm_recall_1k: 0.2861 - lcm_recall_2k: 0.4450 - lcm_recall_3k: 0.5434 - lcm_recall_5k: 0.6583 - lcm_f1_1k: 0.3568 - lcm_f1_2k: 0.4130 - lcm_f1_3k: 0.4028 - lcm_f1_5k: 0.3515 - lcm_accuracy_1k: 0.4742 - lcm_accuracy_2k: 0.6325 - lcm_accuracy_3k: 0.7180 - lcm_accuracy_5k: 0.8028 - lcm_hamming_loss_k: 0.0046
Epoch 00007: val_loss improved from 0.31572 to 0.30623, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 367ms/step - loss: 0.2990 - lcm_precision_1k: 0.4742 - lcm_precision_2k: 0.3854 - lcm_precision_3k: 0.3200 - lcm_precision_5k: 0.2398 - lcm_recall_1k: 0.2861 - lcm_recall_2k: 0.4450 - lcm_recall_3k: 0.5434 - lcm_recall_5k: 0.6583 - lcm_f1_1k: 0.3568 - lcm_f1_2k: 0.4130 - lcm_f1_3k: 0.4028 - lcm_f1_5k: 0.3515 - lcm_accuracy_1k: 0.4742 - lcm_accuracy_2k: 0.6325 - lcm_accuracy_3k: 0.7180 - lcm_accuracy_5k: 0.8028 - lcm_hamming_loss_k: 0.0046 - val_loss: 0.3062 - val_lcm_precision_1k: 0.4618 - val_lcm_precision_2k: 0.3749 - val_lcm_precision_3k: 0.3113 - val_lcm_precision_5k: 0.2343 - val_lcm_recall_1k: 0.2823 - val_lcm_recall_2k: 0.4329 - val_lcm_recall_3k: 0.5279 - val_lcm_recall_5k: 0.6408 - val_lcm_f1_1k: 0.3502 - val_lcm_f1_2k: 0.4016 - val_lcm_f1_3k: 0.3914 - val_lcm_f1_5k: 0.3430 - val_lcm_accuracy_1k: 0.4618 - val_lcm_accuracy_2k: 0.6195 - val_lcm_accuracy_3k: 0.7037 - val_lcm_accuracy_5k: 0.7853 - val_lcm_hamming_loss_k: 0.0046
Epoch 8/150
27/27 [==============================] - ETA: 0s - loss: 0.2861 - lcm_precision_1k: 0.5077 - lcm_precision_2k: 0.4092 - lcm_precision_3k: 0.3389 - lcm_precision_5k: 0.2500 - lcm_recall_1k: 0.3084 - lcm_recall_2k: 0.4740 - lcm_recall_3k: 0.5767 - lcm_recall_5k: 0.6899 - lcm_f1_1k: 0.3837 - lcm_f1_2k: 0.4392 - lcm_f1_3k: 0.4269 - lcm_f1_5k: 0.3670 - lcm_accuracy_1k: 0.5077 - lcm_accuracy_2k: 0.6648 - lcm_accuracy_3k: 0.7503 - lcm_accuracy_5k: 0.8308 - lcm_hamming_loss_k: 0.0044
Epoch 00008: val_loss improved from 0.30623 to 0.29779, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 371ms/step - loss: 0.2861 - lcm_precision_1k: 0.5077 - lcm_precision_2k: 0.4092 - lcm_precision_3k: 0.3389 - lcm_precision_5k: 0.2500 - lcm_recall_1k: 0.3084 - lcm_recall_2k: 0.4740 - lcm_recall_3k: 0.5767 - lcm_recall_5k: 0.6899 - lcm_f1_1k: 0.3837 - lcm_f1_2k: 0.4392 - lcm_f1_3k: 0.4269 - lcm_f1_5k: 0.3670 - lcm_accuracy_1k: 0.5077 - lcm_accuracy_2k: 0.6648 - lcm_accuracy_3k: 0.7503 - lcm_accuracy_5k: 0.8308 - lcm_hamming_loss_k: 0.0044 - val_loss: 0.2978 - val_lcm_precision_1k: 0.4857 - val_lcm_precision_2k: 0.3913 - val_lcm_precision_3k: 0.3207 - val_lcm_precision_5k: 0.2416 - val_lcm_recall_1k: 0.2956 - val_lcm_recall_2k: 0.4496 - val_lcm_recall_3k: 0.5409 - val_lcm_recall_5k: 0.6607 - val_lcm_f1_1k: 0.3674 - val_lcm_f1_2k: 0.4182 - val_lcm_f1_3k: 0.4025 - val_lcm_f1_5k: 0.3536 - val_lcm_accuracy_1k: 0.4857 - val_lcm_accuracy_2k: 0.6374 - val_lcm_accuracy_3k: 0.7164 - val_lcm_accuracy_5k: 0.8050 - val_lcm_hamming_loss_k: 0.0045
Epoch 9/150
27/27 [==============================] - ETA: 0s - loss: 0.2776 - lcm_precision_1k: 0.5304 - lcm_precision_2k: 0.4229 - lcm_precision_3k: 0.3452 - lcm_precision_5k: 0.2549 - lcm_recall_1k: 0.3252 - lcm_recall_2k: 0.4921 - lcm_recall_3k: 0.5882 - lcm_recall_5k: 0.7026 - lcm_f1_1k: 0.4032 - lcm_f1_2k: 0.4548 - lcm_f1_3k: 0.4350 - lcm_f1_5k: 0.3740 - lcm_accuracy_1k: 0.5304 - lcm_accuracy_2k: 0.6840 - lcm_accuracy_3k: 0.7626 - lcm_accuracy_5k: 0.8418 - lcm_hamming_loss_k: 0.0043
Epoch 00009: val_loss improved from 0.29779 to 0.29685, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 371ms/step - loss: 0.2776 - lcm_precision_1k: 0.5304 - lcm_precision_2k: 0.4229 - lcm_precision_3k: 0.3452 - lcm_precision_5k: 0.2549 - lcm_recall_1k: 0.3252 - lcm_recall_2k: 0.4921 - lcm_recall_3k: 0.5882 - lcm_recall_5k: 0.7026 - lcm_f1_1k: 0.4032 - lcm_f1_2k: 0.4548 - lcm_f1_3k: 0.4350 - lcm_f1_5k: 0.3740 - lcm_accuracy_1k: 0.5304 - lcm_accuracy_2k: 0.6840 - lcm_accuracy_3k: 0.7626 - lcm_accuracy_5k: 0.8418 - lcm_hamming_loss_k: 0.0043 - val_loss: 0.2968 - val_lcm_precision_1k: 0.4939 - val_lcm_precision_2k: 0.3935 - val_lcm_precision_3k: 0.3275 - val_lcm_precision_5k: 0.2418 - val_lcm_recall_1k: 0.3024 - val_lcm_recall_2k: 0.4554 - val_lcm_recall_3k: 0.5573 - val_lcm_recall_5k: 0.6662 - val_lcm_f1_1k: 0.3750 - val_lcm_f1_2k: 0.4219 - val_lcm_f1_3k: 0.4123 - val_lcm_f1_5k: 0.3547 - val_lcm_accuracy_1k: 0.4939 - val_lcm_accuracy_2k: 0.6424 - val_lcm_accuracy_3k: 0.7318 - val_lcm_accuracy_5k: 0.8106 - val_lcm_hamming_loss_k: 0.0045
Epoch 10/150
27/27 [==============================] - ETA: 0s - loss: 0.2692 - lcm_precision_1k: 0.5524 - lcm_precision_2k: 0.4390 - lcm_precision_3k: 0.3586 - lcm_precision_5k: 0.2613 - lcm_recall_1k: 0.3400 - lcm_recall_2k: 0.5118 - lcm_recall_3k: 0.6120 - lcm_recall_5k: 0.7220 - lcm_f1_1k: 0.4209 - lcm_f1_2k: 0.4725 - lcm_f1_3k: 0.4522 - lcm_f1_5k: 0.3837 - lcm_accuracy_1k: 0.5524 - lcm_accuracy_2k: 0.7066 - lcm_accuracy_3k: 0.7840 - lcm_accuracy_5k: 0.8589 - lcm_hamming_loss_k: 0.0042
Epoch 00010: val_loss improved from 0.29685 to 0.29150, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.2692 - lcm_precision_1k: 0.5524 - lcm_precision_2k: 0.4390 - lcm_precision_3k: 0.3586 - lcm_precision_5k: 0.2613 - lcm_recall_1k: 0.3400 - lcm_recall_2k: 0.5118 - lcm_recall_3k: 0.6120 - lcm_recall_5k: 0.7220 - lcm_f1_1k: 0.4209 - lcm_f1_2k: 0.4725 - lcm_f1_3k: 0.4522 - lcm_f1_5k: 0.3837 - lcm_accuracy_1k: 0.5524 - lcm_accuracy_2k: 0.7066 - lcm_accuracy_3k: 0.7840 - lcm_accuracy_5k: 0.8589 - lcm_hamming_loss_k: 0.0042 - val_loss: 0.2915 - val_lcm_precision_1k: 0.5097 - val_lcm_precision_2k: 0.4075 - val_lcm_precision_3k: 0.3327 - val_lcm_precision_5k: 0.2450 - val_lcm_recall_1k: 0.3122 - val_lcm_recall_2k: 0.4709 - val_lcm_recall_3k: 0.5664 - val_lcm_recall_5k: 0.6747 - val_lcm_f1_1k: 0.3871 - val_lcm_f1_2k: 0.4367 - val_lcm_f1_3k: 0.4189 - val_lcm_f1_5k: 0.3593 - val_lcm_accuracy_1k: 0.5097 - val_lcm_accuracy_2k: 0.6608 - val_lcm_accuracy_3k: 0.7428 - val_lcm_accuracy_5k: 0.8190 - val_lcm_hamming_loss_k: 0.0044
Epoch 11/150
27/27 [==============================] - ETA: 0s - loss: 0.2629 - lcm_precision_1k: 0.5681 - lcm_precision_2k: 0.4491 - lcm_precision_3k: 0.3658 - lcm_precision_5k: 0.2654 - lcm_recall_1k: 0.3523 - lcm_recall_2k: 0.5260 - lcm_recall_3k: 0.6241 - lcm_recall_5k: 0.7335 - lcm_f1_1k: 0.4348 - lcm_f1_2k: 0.4844 - lcm_f1_3k: 0.4611 - lcm_f1_5k: 0.3897 - lcm_accuracy_1k: 0.5681 - lcm_accuracy_2k: 0.7201 - lcm_accuracy_3k: 0.7937 - lcm_accuracy_5k: 0.8686 - lcm_hamming_loss_k: 0.0041 ETA: 2s - loss: 0.2643 - lcm_precision_1k: 0.5626 - lcm_precision_2k: 0.4454 - lcm_precision_3k: 0.3634 - lcm_precision_5k: 0.2644 - lcm_recall_1k: 0.3495 - lcm_recall_2k: 0.5225 - lcm_recall_3k: 0.6206 - lcm_recall_5k: 0.7306 - lcm_f1_1k: 0.4311 - lcm_f1_2k: 0.4808 - lcm_f1_3k: 0.4583 - lcm_f1_5k: 0.3882 - lcm_accuracy_1k: 0.5626 - lcm_accuracy_2k: 0.7155 - lcm_accuracy_3k: 0.7894 - lcm_accuracy_5k: 0.8667 - lcm_hamming_loss_k:  - ETA: 1s - loss: 0.2637 - lcm_precision_1k: 0.5651 - lcm_precision_2k: 0.4473 - lcm_precision_3k: 0.3649 - lcm_precision_5k: 0.2647 - lcm_recall_1k: 0.3504 - lcm_recall_2k: 0.5232 - lcm_recall_3k: 0.6218 - lcm_recall_5k: 0.7301 - lcm_f1_1k: 0.4325 - lcm_f1_2k: 0.4822 - lcm_f1_3k: 0.4598 - lcm_f1_5k: 0.3885 - lcm_accuracy_1k: 0.5651 - lcm_accuracy_2k: 0.7180 - lcm_accuracy_3k: 0.7917 - lcm_accuracy_5k: 0.8660 - lcm_hamming_
Epoch 00011: val_loss improved from 0.29150 to 0.28476, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 372ms/step - loss: 0.2629 - lcm_precision_1k: 0.5681 - lcm_precision_2k: 0.4491 - lcm_precision_3k: 0.3658 - lcm_precision_5k: 0.2654 - lcm_recall_1k: 0.3523 - lcm_recall_2k: 0.5260 - lcm_recall_3k: 0.6241 - lcm_recall_5k: 0.7335 - lcm_f1_1k: 0.4348 - lcm_f1_2k: 0.4844 - lcm_f1_3k: 0.4611 - lcm_f1_5k: 0.3897 - lcm_accuracy_1k: 0.5681 - lcm_accuracy_2k: 0.7201 - lcm_accuracy_3k: 0.7937 - lcm_accuracy_5k: 0.8686 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2848 - val_lcm_precision_1k: 0.5283 - val_lcm_precision_2k: 0.4163 - val_lcm_precision_3k: 0.3430 - val_lcm_precision_5k: 0.2516 - val_lcm_recall_1k: 0.3268 - val_lcm_recall_2k: 0.4830 - val_lcm_recall_3k: 0.5823 - val_lcm_recall_5k: 0.6910 - val_lcm_f1_1k: 0.4036 - val_lcm_f1_2k: 0.4469 - val_lcm_f1_3k: 0.4314 - val_lcm_f1_5k: 0.3687 - val_lcm_accuracy_1k: 0.5283 - val_lcm_accuracy_2k: 0.6705 - val_lcm_accuracy_3k: 0.7535 - val_lcm_accuracy_5k: 0.8309 - val_lcm_hamming_loss_k: 0.0043
Epoch 12/150
27/27 [==============================] - ETA: 0s - loss: 0.2543 - lcm_precision_1k: 0.5859 - lcm_precision_2k: 0.4627 - lcm_precision_3k: 0.3748 - lcm_precision_5k: 0.2722 - lcm_recall_1k: 0.3639 - lcm_recall_2k: 0.5417 - lcm_recall_3k: 0.6393 - lcm_recall_5k: 0.7510 - lcm_f1_1k: 0.4488 - lcm_f1_2k: 0.4990 - lcm_f1_3k: 0.4725 - lcm_f1_5k: 0.3995 - lcm_accuracy_1k: 0.5859 - lcm_accuracy_2k: 0.7385 - lcm_accuracy_3k: 0.8109 - lcm_accuracy_5k: 0.8837 - lcm_hamming_loss_k: 0.0041
Epoch 00012: val_loss improved from 0.28476 to 0.27963, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 367ms/step - loss: 0.2543 - lcm_precision_1k: 0.5859 - lcm_precision_2k: 0.4627 - lcm_precision_3k: 0.3748 - lcm_precision_5k: 0.2722 - lcm_recall_1k: 0.3639 - lcm_recall_2k: 0.5417 - lcm_recall_3k: 0.6393 - lcm_recall_5k: 0.7510 - lcm_f1_1k: 0.4488 - lcm_f1_2k: 0.4990 - lcm_f1_3k: 0.4725 - lcm_f1_5k: 0.3995 - lcm_accuracy_1k: 0.5859 - lcm_accuracy_2k: 0.7385 - lcm_accuracy_3k: 0.8109 - lcm_accuracy_5k: 0.8837 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2796 - val_lcm_precision_1k: 0.5460 - val_lcm_precision_2k: 0.4283 - val_lcm_precision_3k: 0.3452 - val_lcm_precision_5k: 0.2526 - val_lcm_recall_1k: 0.3394 - val_lcm_recall_2k: 0.5004 - val_lcm_recall_3k: 0.5895 - val_lcm_recall_5k: 0.6958 - val_lcm_f1_1k: 0.4184 - val_lcm_f1_2k: 0.4613 - val_lcm_f1_3k: 0.4352 - val_lcm_f1_5k: 0.3704 - val_lcm_accuracy_1k: 0.5460 - val_lcm_accuracy_2k: 0.6933 - val_lcm_accuracy_3k: 0.7672 - val_lcm_accuracy_5k: 0.8355 - val_lcm_hamming_loss_k: 0.0042
Epoch 13/150
27/27 [==============================] - ETA: 0s - loss: 0.2471 - lcm_precision_1k: 0.6008 - lcm_precision_2k: 0.4748 - lcm_precision_3k: 0.3839 - lcm_precision_5k: 0.2756 - lcm_recall_1k: 0.3756 - lcm_recall_2k: 0.5588 - lcm_recall_3k: 0.6569 - lcm_recall_5k: 0.7614 - lcm_f1_1k: 0.4622 - lcm_f1_2k: 0.5134 - lcm_f1_3k: 0.4846 - lcm_f1_5k: 0.4047 - lcm_accuracy_1k: 0.6008 - lcm_accuracy_2k: 0.7572 - lcm_accuracy_3k: 0.8272 - lcm_accuracy_5k: 0.8914 - lcm_hamming_loss_k: 0.0040
Epoch 00013: val_loss improved from 0.27963 to 0.27677, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 366ms/step - loss: 0.2471 - lcm_precision_1k: 0.6008 - lcm_precision_2k: 0.4748 - lcm_precision_3k: 0.3839 - lcm_precision_5k: 0.2756 - lcm_recall_1k: 0.3756 - lcm_recall_2k: 0.5588 - lcm_recall_3k: 0.6569 - lcm_recall_5k: 0.7614 - lcm_f1_1k: 0.4622 - lcm_f1_2k: 0.5134 - lcm_f1_3k: 0.4846 - lcm_f1_5k: 0.4047 - lcm_accuracy_1k: 0.6008 - lcm_accuracy_2k: 0.7572 - lcm_accuracy_3k: 0.8272 - lcm_accuracy_5k: 0.8914 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2768 - val_lcm_precision_1k: 0.5490 - val_lcm_precision_2k: 0.4318 - val_lcm_precision_3k: 0.3523 - val_lcm_precision_5k: 0.2558 - val_lcm_recall_1k: 0.3404 - val_lcm_recall_2k: 0.5085 - val_lcm_recall_3k: 0.6032 - val_lcm_recall_5k: 0.7060 - val_lcm_f1_1k: 0.4200 - val_lcm_f1_2k: 0.4667 - val_lcm_f1_3k: 0.4446 - val_lcm_f1_5k: 0.3754 - val_lcm_accuracy_1k: 0.5490 - val_lcm_accuracy_2k: 0.7033 - val_lcm_accuracy_3k: 0.7762 - val_lcm_accuracy_5k: 0.8456 - val_lcm_hamming_loss_k: 0.0042
Epoch 14/150
27/27 [==============================] - ETA: 0s - loss: 0.2389 - lcm_precision_1k: 0.6249 - lcm_precision_2k: 0.4899 - lcm_precision_3k: 0.3963 - lcm_precision_5k: 0.2830 - lcm_recall_1k: 0.3900 - lcm_recall_2k: 0.5765 - lcm_recall_3k: 0.6772 - lcm_recall_5k: 0.7807 - lcm_f1_1k: 0.4802 - lcm_f1_2k: 0.5296 - lcm_f1_3k: 0.5000 - lcm_f1_5k: 0.4154 - lcm_accuracy_1k: 0.6249 - lcm_accuracy_2k: 0.7768 - lcm_accuracy_3k: 0.8445 - lcm_accuracy_5k: 0.9057 - lcm_hamming_loss_k: 0.0039
Epoch 00014: val_loss improved from 0.27677 to 0.27352, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 368ms/step - loss: 0.2389 - lcm_precision_1k: 0.6249 - lcm_precision_2k: 0.4899 - lcm_precision_3k: 0.3963 - lcm_precision_5k: 0.2830 - lcm_recall_1k: 0.3900 - lcm_recall_2k: 0.5765 - lcm_recall_3k: 0.6772 - lcm_recall_5k: 0.7807 - lcm_f1_1k: 0.4802 - lcm_f1_2k: 0.5296 - lcm_f1_3k: 0.5000 - lcm_f1_5k: 0.4154 - lcm_accuracy_1k: 0.6249 - lcm_accuracy_2k: 0.7768 - lcm_accuracy_3k: 0.8445 - lcm_accuracy_5k: 0.9057 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2735 - val_lcm_precision_1k: 0.5564 - val_lcm_precision_2k: 0.4370 - val_lcm_precision_3k: 0.3564 - val_lcm_precision_5k: 0.2593 - val_lcm_recall_1k: 0.3494 - val_lcm_recall_2k: 0.5143 - val_lcm_recall_3k: 0.6094 - val_lcm_recall_5k: 0.7167 - val_lcm_f1_1k: 0.4290 - val_lcm_f1_2k: 0.4722 - val_lcm_f1_3k: 0.4495 - val_lcm_f1_5k: 0.3807 - val_lcm_accuracy_1k: 0.5564 - val_lcm_accuracy_2k: 0.7100 - val_lcm_accuracy_3k: 0.7833 - val_lcm_accuracy_5k: 0.8573 - val_lcm_hamming_loss_k: 0.0042
Epoch 15/150
27/27 [==============================] - ETA: 0s - loss: 0.2336 - lcm_precision_1k: 0.6346 - lcm_precision_2k: 0.4995 - lcm_precision_3k: 0.4039 - lcm_precision_5k: 0.2874 - lcm_recall_1k: 0.3975 - lcm_recall_2k: 0.5888 - lcm_recall_3k: 0.6911 - lcm_recall_5k: 0.7939 - lcm_f1_1k: 0.4888 - lcm_f1_2k: 0.5404 - lcm_f1_3k: 0.5098 - lcm_f1_5k: 0.4220 - lcm_accuracy_1k: 0.6346 - lcm_accuracy_2k: 0.7871 - lcm_accuracy_3k: 0.8563 - lcm_accuracy_5k: 0.9138 - lcm_hamming_loss_k: 0.0038
Epoch 00015: val_loss improved from 0.27352 to 0.27100, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 372ms/step - loss: 0.2336 - lcm_precision_1k: 0.6346 - lcm_precision_2k: 0.4995 - lcm_precision_3k: 0.4039 - lcm_precision_5k: 0.2874 - lcm_recall_1k: 0.3975 - lcm_recall_2k: 0.5888 - lcm_recall_3k: 0.6911 - lcm_recall_5k: 0.7939 - lcm_f1_1k: 0.4888 - lcm_f1_2k: 0.5404 - lcm_f1_3k: 0.5098 - lcm_f1_5k: 0.4220 - lcm_accuracy_1k: 0.6346 - lcm_accuracy_2k: 0.7871 - lcm_accuracy_3k: 0.8563 - lcm_accuracy_5k: 0.9138 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2710 - val_lcm_precision_1k: 0.5646 - val_lcm_precision_2k: 0.4410 - val_lcm_precision_3k: 0.3605 - val_lcm_precision_5k: 0.2616 - val_lcm_recall_1k: 0.3537 - val_lcm_recall_2k: 0.5182 - val_lcm_recall_3k: 0.6154 - val_lcm_recall_5k: 0.7217 - val_lcm_f1_1k: 0.4347 - val_lcm_f1_2k: 0.4762 - val_lcm_f1_3k: 0.4545 - val_lcm_f1_5k: 0.3838 - val_lcm_accuracy_1k: 0.5646 - val_lcm_accuracy_2k: 0.7126 - val_lcm_accuracy_3k: 0.7872 - val_lcm_accuracy_5k: 0.8573 - val_lcm_hamming_loss_k: 0.0042
Epoch 16/150
27/27 [==============================] - ETA: 0s - loss: 0.2262 - lcm_precision_1k: 0.6519 - lcm_precision_2k: 0.5114 - lcm_precision_3k: 0.4118 - lcm_precision_5k: 0.2927 - lcm_recall_1k: 0.4101 - lcm_recall_2k: 0.6034 - lcm_recall_3k: 0.7045 - lcm_recall_5k: 0.8057 - lcm_f1_1k: 0.5034 - lcm_f1_2k: 0.5536 - lcm_f1_3k: 0.5197 - lcm_f1_5k: 0.4293 - lcm_accuracy_1k: 0.6519 - lcm_accuracy_2k: 0.8038 - lcm_accuracy_3k: 0.8685 - lcm_accuracy_5k: 0.9231 - lcm_hamming_loss_k: 0.0038 ETA: 3s - loss: 0.2257 - lcm_precision_1k: 0.6531 - lcm_precision_2k: 0.5129 - lcm_precision_3k: 0.4117 - lcm_precision_5k: 0.2926 - lcm_recall_1k: 0.4116 - lcm_recall_2k: 0.6068 - lcm_recall_3k: 0.7070 - lcm_recall_5k: 0.8090 - lcm_f1_1k: 0.5048 - lcm_f1_2k: 0.5558 - lcm_f1_3k: 0.5204 - lcm_f1_5k: 0.4297 - lcm_accuracy_1k: 0.6531 - lcm_accuracy_2k: 0.8058 - lcm_accuracy_3k: 0.8702 - lcm_accuracy_5k: 0.9264 - lcm_
Epoch 00016: val_loss improved from 0.27100 to 0.26997, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.2262 - lcm_precision_1k: 0.6519 - lcm_precision_2k: 0.5114 - lcm_precision_3k: 0.4118 - lcm_precision_5k: 0.2927 - lcm_recall_1k: 0.4101 - lcm_recall_2k: 0.6034 - lcm_recall_3k: 0.7045 - lcm_recall_5k: 0.8057 - lcm_f1_1k: 0.5034 - lcm_f1_2k: 0.5536 - lcm_f1_3k: 0.5197 - lcm_f1_5k: 0.4293 - lcm_accuracy_1k: 0.6519 - lcm_accuracy_2k: 0.8038 - lcm_accuracy_3k: 0.8685 - lcm_accuracy_5k: 0.9231 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2700 - val_lcm_precision_1k: 0.5789 - val_lcm_precision_2k: 0.4413 - val_lcm_precision_3k: 0.3605 - val_lcm_precision_5k: 0.2616 - val_lcm_recall_1k: 0.3629 - val_lcm_recall_2k: 0.5216 - val_lcm_recall_3k: 0.6183 - val_lcm_recall_5k: 0.7231 - val_lcm_f1_1k: 0.4459 - val_lcm_f1_2k: 0.4778 - val_lcm_f1_3k: 0.4553 - val_lcm_f1_5k: 0.3841 - val_lcm_accuracy_1k: 0.5789 - val_lcm_accuracy_2k: 0.7199 - val_lcm_accuracy_3k: 0.7921 - val_lcm_accuracy_5k: 0.8566 - val_lcm_hamming_loss_k: 0.0041
Epoch 17/150
27/27 [==============================] - ETA: 0s - loss: 0.2198 - lcm_precision_1k: 0.6669 - lcm_precision_2k: 0.5266 - lcm_precision_3k: 0.4226 - lcm_precision_5k: 0.2978 - lcm_recall_1k: 0.4178 - lcm_recall_2k: 0.6203 - lcm_recall_3k: 0.7207 - lcm_recall_5k: 0.8189 - lcm_f1_1k: 0.5136 - lcm_f1_2k: 0.5696 - lcm_f1_3k: 0.5327 - lcm_f1_5k: 0.4367 - lcm_accuracy_1k: 0.6669 - lcm_accuracy_2k: 0.8229 - lcm_accuracy_3k: 0.8819 - lcm_accuracy_5k: 0.9313 - lcm_hamming_loss_k: 0.0037
Epoch 00017: val_loss improved from 0.26997 to 0.26972, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 366ms/step - loss: 0.2198 - lcm_precision_1k: 0.6669 - lcm_precision_2k: 0.5266 - lcm_precision_3k: 0.4226 - lcm_precision_5k: 0.2978 - lcm_recall_1k: 0.4178 - lcm_recall_2k: 0.6203 - lcm_recall_3k: 0.7207 - lcm_recall_5k: 0.8189 - lcm_f1_1k: 0.5136 - lcm_f1_2k: 0.5696 - lcm_f1_3k: 0.5327 - lcm_f1_5k: 0.4367 - lcm_accuracy_1k: 0.6669 - lcm_accuracy_2k: 0.8229 - lcm_accuracy_3k: 0.8819 - lcm_accuracy_5k: 0.9313 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2697 - val_lcm_precision_1k: 0.5730 - val_lcm_precision_2k: 0.4422 - val_lcm_precision_3k: 0.3623 - val_lcm_precision_5k: 0.2632 - val_lcm_recall_1k: 0.3570 - val_lcm_recall_2k: 0.5207 - val_lcm_recall_3k: 0.6197 - val_lcm_recall_5k: 0.7264 - val_lcm_f1_1k: 0.4397 - val_lcm_f1_2k: 0.4780 - val_lcm_f1_3k: 0.4570 - val_lcm_f1_5k: 0.3862 - val_lcm_accuracy_1k: 0.5730 - val_lcm_accuracy_2k: 0.7156 - val_lcm_accuracy_3k: 0.7879 - val_lcm_accuracy_5k: 0.8625 - val_lcm_hamming_loss_k: 0.0041
Epoch 18/150
27/27 [==============================] - ETA: 0s - loss: 0.2144 - lcm_precision_1k: 0.6783 - lcm_precision_2k: 0.5321 - lcm_precision_3k: 0.4289 - lcm_precision_5k: 0.3012 - lcm_recall_1k: 0.4284 - lcm_recall_2k: 0.6278 - lcm_recall_3k: 0.7327 - lcm_recall_5k: 0.8304 - lcm_f1_1k: 0.5250 - lcm_f1_2k: 0.5759 - lcm_f1_3k: 0.5410 - lcm_f1_5k: 0.4420 - lcm_accuracy_1k: 0.6783 - lcm_accuracy_2k: 0.8277 - lcm_accuracy_3k: 0.8882 - lcm_accuracy_5k: 0.9384 - lcm_hamming_loss_k: 0.0036 ETA: 2s - loss: 0.2142 - lcm_precision_1k: 0.6837 - lcm_precision_2k: 0.5339 - lcm_precision_3k: 0.4304 - lcm_precision_5k: 0.3032 - lcm_recall_1k: 0.4326 - lcm_recall_2k: 0.6290 - lcm_recall_3k: 0.7330 - lcm_recall_5k: 0.8323 - lcm_f1_1k: 0.5298 - lcm_f1_2k: 0.5775 - lcm_f1_3k: 0.5423 - lcm_f1_5k: 0.4444 - lcm_accuracy_1k: 0.6837 - lcm_accuracy_2k: 0.8295 - lcm_accuracy_3k: 0.8890 - lcm_accuracy_5k: 0.9391 - lcm_hammin
Epoch 00018: val_loss improved from 0.26972 to 0.26862, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.2144 - lcm_precision_1k: 0.6783 - lcm_precision_2k: 0.5321 - lcm_precision_3k: 0.4289 - lcm_precision_5k: 0.3012 - lcm_recall_1k: 0.4284 - lcm_recall_2k: 0.6278 - lcm_recall_3k: 0.7327 - lcm_recall_5k: 0.8304 - lcm_f1_1k: 0.5250 - lcm_f1_2k: 0.5759 - lcm_f1_3k: 0.5410 - lcm_f1_5k: 0.4420 - lcm_accuracy_1k: 0.6783 - lcm_accuracy_2k: 0.8277 - lcm_accuracy_3k: 0.8882 - lcm_accuracy_5k: 0.9384 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2686 - val_lcm_precision_1k: 0.5863 - val_lcm_precision_2k: 0.4512 - val_lcm_precision_3k: 0.3641 - val_lcm_precision_5k: 0.2647 - val_lcm_recall_1k: 0.3685 - val_lcm_recall_2k: 0.5323 - val_lcm_recall_3k: 0.6237 - val_lcm_recall_5k: 0.7295 - val_lcm_f1_1k: 0.4522 - val_lcm_f1_2k: 0.4881 - val_lcm_f1_3k: 0.4596 - val_lcm_f1_5k: 0.3883 - val_lcm_accuracy_1k: 0.5863 - val_lcm_accuracy_2k: 0.7310 - val_lcm_accuracy_3k: 0.7971 - val_lcm_accuracy_5k: 0.8627 - val_lcm_hamming_loss_k: 0.0041
Epoch 19/150
27/27 [==============================] - ETA: 0s - loss: 0.2054 - lcm_precision_1k: 0.7067 - lcm_precision_2k: 0.5511 - lcm_precision_3k: 0.4406 - lcm_precision_5k: 0.3077 - lcm_recall_1k: 0.4476 - lcm_recall_2k: 0.6499 - lcm_recall_3k: 0.7508 - lcm_recall_5k: 0.8445 - lcm_f1_1k: 0.5480 - lcm_f1_2k: 0.5964 - lcm_f1_3k: 0.5552 - lcm_f1_5k: 0.4510 - lcm_accuracy_1k: 0.7067 - lcm_accuracy_2k: 0.8510 - lcm_accuracy_3k: 0.9047 - lcm_accuracy_5k: 0.9463 - lcm_hamming_loss_k: 0.00 - ETA: 0s - loss: 0.2057 - lcm_precision_1k: 0.7049 - lcm_precision_2k: 0.5506 - lcm_precision_3k: 0.4400 - lcm_precision_5k: 0.3078 - lcm_recall_1k: 0.4462 - lcm_recall_2k: 0.6492 - lcm_recall_3k: 0.7498 - lcm_recall_5k: 0.8437 - lcm_f1_1k: 0.5464 - lcm_f1_2k: 0.5958 - lcm_f1_3k: 0.5545 - lcm_f1_5k: 0.4510 - lcm_accuracy_1k: 0.7049 - lcm_accuracy_2k: 0.8510 - lcm_accuracy_3k: 0.9043 - lcm_accuracy_5k: 0.9459 - lcm_hamming_loss_k: 0.0035
Epoch 00019: val_loss did not improve from 0.26862
27/27 [==============================] - 9s 341ms/step - loss: 0.2057 - lcm_precision_1k: 0.7049 - lcm_precision_2k: 0.5506 - lcm_precision_3k: 0.4400 - lcm_precision_5k: 0.3078 - lcm_recall_1k: 0.4462 - lcm_recall_2k: 0.6492 - lcm_recall_3k: 0.7498 - lcm_recall_5k: 0.8437 - lcm_f1_1k: 0.5464 - lcm_f1_2k: 0.5958 - lcm_f1_3k: 0.5545 - lcm_f1_5k: 0.4510 - lcm_accuracy_1k: 0.7049 - lcm_accuracy_2k: 0.8510 - lcm_accuracy_3k: 0.9043 - lcm_accuracy_5k: 0.9459 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2697 - val_lcm_precision_1k: 0.5807 - val_lcm_precision_2k: 0.4501 - val_lcm_precision_3k: 0.3625 - val_lcm_precision_5k: 0.2624 - val_lcm_recall_1k: 0.3653 - val_lcm_recall_2k: 0.5288 - val_lcm_recall_3k: 0.6187 - val_lcm_recall_5k: 0.7244 - val_lcm_f1_1k: 0.4483 - val_lcm_f1_2k: 0.4860 - val_lcm_f1_3k: 0.4569 - val_lcm_f1_5k: 0.3851 - val_lcm_accuracy_1k: 0.5807 - val_lcm_accuracy_2k: 0.7254 - val_lcm_accuracy_3k: 0.7883 - val_lcm_accuracy_5k: 0.8577 - val_lcm_hamming_loss_k: 0.0041
Epoch 20/150
27/27 [==============================] - ETA: 0s - loss: 0.2014 - lcm_precision_1k: 0.7161 - lcm_precision_2k: 0.5581 - lcm_precision_3k: 0.4468 - lcm_precision_5k: 0.3116 - lcm_recall_1k: 0.4532 - lcm_recall_2k: 0.6570 - lcm_recall_3k: 0.7591 - lcm_recall_5k: 0.8544 - lcm_f1_1k: 0.5550 - lcm_f1_2k: 0.6034 - lcm_f1_3k: 0.5624 - lcm_f1_5k: 0.4566 - lcm_accuracy_1k: 0.7161 - lcm_accuracy_2k: 0.8558 - lcm_accuracy_3k: 0.9080 - lcm_accuracy_5k: 0.9524 - lcm_hamming_loss_k: 0.0035 ETA: 1s - loss: 0.2013 - lcm_precision_1k: 0.7160 - lcm_precision_2k: 0.5600 - lcm_precision_3k: 0.4479 - lcm_precision_5k: 0.3129 - lcm_recall_1k: 0.4528 - lcm_recall_2k: 0.6588 - lcm_recall_3k: 0.7599 - lcm_recall_5k: 0.8563 - lcm_f1_1k: 0.5547 - lcm_f1_2k: 0.6053 - lcm_f1_3k: 0.5635 - lcm_f1_5k: 0.4583 - lcm_accuracy_1k: 0.7160 - lcm_accuracy_2k: 0.8590 - lcm_accuracy_3k: 0.9092 - lcm_accuracy_5k: 0.9533 - lcm_hamming_
Epoch 00020: val_loss improved from 0.26862 to 0.26579, saving model to logs/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 370ms/step - loss: 0.2014 - lcm_precision_1k: 0.7161 - lcm_precision_2k: 0.5581 - lcm_precision_3k: 0.4468 - lcm_precision_5k: 0.3116 - lcm_recall_1k: 0.4532 - lcm_recall_2k: 0.6570 - lcm_recall_3k: 0.7591 - lcm_recall_5k: 0.8544 - lcm_f1_1k: 0.5550 - lcm_f1_2k: 0.6034 - lcm_f1_3k: 0.5624 - lcm_f1_5k: 0.4566 - lcm_accuracy_1k: 0.7161 - lcm_accuracy_2k: 0.8558 - lcm_accuracy_3k: 0.9080 - lcm_accuracy_5k: 0.9524 - lcm_hamming_loss_k: 0.0035 - val_loss: 0.2658 - val_lcm_precision_1k: 0.5978 - val_lcm_precision_2k: 0.4565 - val_lcm_precision_3k: 0.3706 - val_lcm_precision_5k: 0.2673 - val_lcm_recall_1k: 0.3749 - val_lcm_recall_2k: 0.5391 - val_lcm_recall_3k: 0.6342 - val_lcm_recall_5k: 0.7383 - val_lcm_f1_1k: 0.4605 - val_lcm_f1_2k: 0.4941 - val_lcm_f1_3k: 0.4676 - val_lcm_f1_5k: 0.3924 - val_lcm_accuracy_1k: 0.5978 - val_lcm_accuracy_2k: 0.7351 - val_lcm_accuracy_3k: 0.8017 - val_lcm_accuracy_5k: 0.8704 - val_lcm_hamming_loss_k: 0.0040
Epoch 21/150
27/27 [==============================] - ETA: 0s - loss: 0.1945 - lcm_precision_1k: 0.7305 - lcm_precision_2k: 0.5703 - lcm_precision_3k: 0.4553 - lcm_precision_5k: 0.3164 - lcm_recall_1k: 0.4649 - lcm_recall_2k: 0.6722 - lcm_recall_3k: 0.7748 - lcm_recall_5k: 0.8658 - lcm_f1_1k: 0.5681 - lcm_f1_2k: 0.6170 - lcm_f1_3k: 0.5735 - lcm_f1_5k: 0.4634 - lcm_accuracy_1k: 0.7305 - lcm_accuracy_2k: 0.8710 - lcm_accuracy_3k: 0.9203 - lcm_accuracy_5k: 0.9571 - lcm_hamming_loss_k: 0.0034
Epoch 00021: val_loss did not improve from 0.26579
27/27 [==============================] - 9s 338ms/step - loss: 0.1945 - lcm_precision_1k: 0.7305 - lcm_precision_2k: 0.5703 - lcm_precision_3k: 0.4553 - lcm_precision_5k: 0.3164 - lcm_recall_1k: 0.4649 - lcm_recall_2k: 0.6722 - lcm_recall_3k: 0.7748 - lcm_recall_5k: 0.8658 - lcm_f1_1k: 0.5681 - lcm_f1_2k: 0.6170 - lcm_f1_3k: 0.5735 - lcm_f1_5k: 0.4634 - lcm_accuracy_1k: 0.7305 - lcm_accuracy_2k: 0.8710 - lcm_accuracy_3k: 0.9203 - lcm_accuracy_5k: 0.9571 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2712 - val_lcm_precision_1k: 0.5867 - val_lcm_precision_2k: 0.4557 - val_lcm_precision_3k: 0.3673 - val_lcm_precision_5k: 0.2633 - val_lcm_recall_1k: 0.3681 - val_lcm_recall_2k: 0.5376 - val_lcm_recall_3k: 0.6286 - val_lcm_recall_5k: 0.7288 - val_lcm_f1_1k: 0.4521 - val_lcm_f1_2k: 0.4931 - val_lcm_f1_3k: 0.4635 - val_lcm_f1_5k: 0.3867 - val_lcm_accuracy_1k: 0.5867 - val_lcm_accuracy_2k: 0.7312 - val_lcm_accuracy_3k: 0.7953 - val_lcm_accuracy_5k: 0.8660 - val_lcm_hamming_loss_k: 0.0041
Epoch 22/150
27/27 [==============================] - ETA: 0s - loss: 0.1929 - lcm_precision_1k: 0.7389 - lcm_precision_2k: 0.5747 - lcm_precision_3k: 0.4576 - lcm_precision_5k: 0.3180 - lcm_recall_1k: 0.4694 - lcm_recall_2k: 0.6749 - lcm_recall_3k: 0.7758 - lcm_recall_5k: 0.8678 - lcm_f1_1k: 0.5740 - lcm_f1_2k: 0.6206 - lcm_f1_3k: 0.5755 - lcm_f1_5k: 0.4654 - lcm_accuracy_1k: 0.7389 - lcm_accuracy_2k: 0.8708 - lcm_accuracy_3k: 0.9197 - lcm_accuracy_5k: 0.9594 - lcm_hamming_loss_k: 0.0034
Epoch 00022: val_loss did not improve from 0.26579
27/27 [==============================] - 9s 339ms/step - loss: 0.1929 - lcm_precision_1k: 0.7389 - lcm_precision_2k: 0.5747 - lcm_precision_3k: 0.4576 - lcm_precision_5k: 0.3180 - lcm_recall_1k: 0.4694 - lcm_recall_2k: 0.6749 - lcm_recall_3k: 0.7758 - lcm_recall_5k: 0.8678 - lcm_f1_1k: 0.5740 - lcm_f1_2k: 0.6206 - lcm_f1_3k: 0.5755 - lcm_f1_5k: 0.4654 - lcm_accuracy_1k: 0.7389 - lcm_accuracy_2k: 0.8708 - lcm_accuracy_3k: 0.9197 - lcm_accuracy_5k: 0.9594 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2685 - val_lcm_precision_1k: 0.5929 - val_lcm_precision_2k: 0.4574 - val_lcm_precision_3k: 0.3683 - val_lcm_precision_5k: 0.2658 - val_lcm_recall_1k: 0.3741 - val_lcm_recall_2k: 0.5405 - val_lcm_recall_3k: 0.6335 - val_lcm_recall_5k: 0.7371 - val_lcm_f1_1k: 0.4585 - val_lcm_f1_2k: 0.4952 - val_lcm_f1_3k: 0.4656 - val_lcm_f1_5k: 0.3905 - val_lcm_accuracy_1k: 0.5929 - val_lcm_accuracy_2k: 0.7341 - val_lcm_accuracy_3k: 0.8029 - val_lcm_accuracy_5k: 0.8699 - val_lcm_hamming_loss_k: 0.0040
Epoch 00022: early stopping
176/176 [==============================] - 7s 37ms/step - loss: 0.2141 - lcm_precision_1k: 0.6935 - lcm_precision_2k: 0.5333 - lcm_precision_3k: 0.4267 - lcm_precision_5k: 0.3009 - lcm_recall_1k: 0.4422 - lcm_recall_2k: 0.6305 - lcm_recall_3k: 0.7290 - lcm_recall_5k: 0.8292 - lcm_f1_1k: 0.5387 - lcm_f1_2k: 0.5767 - lcm_f1_3k: 0.5373 - lcm_f1_5k: 0.4408 - lcm_accuracy_1k: 0.6935 - lcm_accuracy_2k: 0.8281 - lcm_accuracy_3k: 0.8818 - lcm_accuracy_5k: 0.9297 - lcm_hamming_loss_k: 0.0035
Best model result:  [0.21413291990756989, 0.6934518218040466, 0.5333287119865417, 0.42674490809440613, 0.3008676767349243, 0.44218742847442627, 0.6305114030838013, 0.728987455368042, 0.8292034268379211, 0.5386955738067627, 0.5767128467559814, 0.5373210310935974, 0.4407860040664673, 0.6934518218040466, 0.8280807137489319, 0.881849467754364, 0.9297210574150085, 0.003537696786224842]
13499
3374
5625
Model: "model_8"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['BiLSTM[0][0]']                 
                                                                                                  
==================================================================================================
Total params: 28,546,223
Trainable params: 3,767,723
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
2 patience
Model: "model_9"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 442)]        0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 150)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 442, 300)     128100      ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 150, 300)     24778500    ['text_input[0][0]']             
                                                                                                  
 tf.__operators__.getitem_4 (Sl  (None, 427, 300)    0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_lcm_emb (Dense)          (None, 427, 1024)    308224      ['tf.__operators__.getitem_4[0][0
                                                                 ]']                              
                                                                                                  
 dot_4 (Dot)                    (None, 427)          0           ['label_lcm_emb[0][0]',          
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 pred_probs (Dense)             (None, 427)          437675      ['BiLSTM[0][0]']                 
                                                                                                  
 label_sim_dict (Dense)         (None, 427)          182756      ['dot_4[0][0]']                  
                                                                                                  
 concatenate_4 (Concatenate)    (None, 854)          0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 29,165,303
Trainable params: 4,386,803
Non-trainable params: 24,778,500
__________________________________________________________________________________________________
None
Epoch 1/150
27/27 [==============================] - ETA: 0s - loss: 0.4992 - lcm_precision_1k: 0.1386 - lcm_precision_2k: 0.1239 - lcm_precision_3k: 0.1084 - lcm_precision_5k: 0.0909 - lcm_recall_1k: 0.0693 - lcm_recall_2k: 0.1252 - lcm_recall_3k: 0.1641 - lcm_recall_5k: 0.2295 - lcm_f1_1k: 0.0923 - lcm_f1_2k: 0.1244 - lcm_f1_3k: 0.1304 - lcm_f1_5k: 0.1301 - lcm_accuracy_1k: 0.1386 - lcm_accuracy_2k: 0.2228 - lcm_accuracy_3k: 0.2709 - lcm_accuracy_5k: 0.3404 - lcm_hamming_loss_k: 0.0062
Epoch 00001: val_loss improved from inf to 0.45987, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 11s 360ms/step - loss: 0.4992 - lcm_precision_1k: 0.1386 - lcm_precision_2k: 0.1239 - lcm_precision_3k: 0.1084 - lcm_precision_5k: 0.0909 - lcm_recall_1k: 0.0693 - lcm_recall_2k: 0.1252 - lcm_recall_3k: 0.1641 - lcm_recall_5k: 0.2295 - lcm_f1_1k: 0.0923 - lcm_f1_2k: 0.1244 - lcm_f1_3k: 0.1304 - lcm_f1_5k: 0.1301 - lcm_accuracy_1k: 0.1386 - lcm_accuracy_2k: 0.2228 - lcm_accuracy_3k: 0.2709 - lcm_accuracy_5k: 0.3404 - lcm_hamming_loss_k: 0.0062 - val_loss: 0.4599 - val_lcm_precision_1k: 0.1929 - val_lcm_precision_2k: 0.1716 - val_lcm_precision_3k: 0.1543 - val_lcm_precision_5k: 0.1284 - val_lcm_recall_1k: 0.1034 - val_lcm_recall_2k: 0.1843 - val_lcm_recall_3k: 0.2444 - val_lcm_recall_5k: 0.3343 - val_lcm_f1_1k: 0.1346 - val_lcm_f1_2k: 0.1776 - val_lcm_f1_3k: 0.1891 - val_lcm_f1_5k: 0.1855 - val_lcm_accuracy_1k: 0.1929 - val_lcm_accuracy_2k: 0.2947 - val_lcm_accuracy_3k: 0.3684 - val_lcm_accuracy_5k: 0.4598 - val_lcm_hamming_loss_k: 0.0058
Epoch 2/150
27/27 [==============================] - ETA: 0s - loss: 0.4340 - lcm_precision_1k: 0.2172 - lcm_precision_2k: 0.1848 - lcm_precision_3k: 0.1653 - lcm_precision_5k: 0.1390 - lcm_recall_1k: 0.1173 - lcm_recall_2k: 0.2023 - lcm_recall_3k: 0.2673 - lcm_recall_5k: 0.3673 - lcm_f1_1k: 0.1523 - lcm_f1_2k: 0.1931 - lcm_f1_3k: 0.2042 - lcm_f1_5k: 0.2016 - lcm_accuracy_1k: 0.2172 - lcm_accuracy_2k: 0.3227 - lcm_accuracy_3k: 0.3994 - lcm_accuracy_5k: 0.4988 - lcm_hamming_loss_k: 0.0058
Epoch 00002: val_loss improved from 0.45987 to 0.40028, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 370ms/step - loss: 0.4340 - lcm_precision_1k: 0.2172 - lcm_precision_2k: 0.1848 - lcm_precision_3k: 0.1653 - lcm_precision_5k: 0.1390 - lcm_recall_1k: 0.1173 - lcm_recall_2k: 0.2023 - lcm_recall_3k: 0.2673 - lcm_recall_5k: 0.3673 - lcm_f1_1k: 0.1523 - lcm_f1_2k: 0.1931 - lcm_f1_3k: 0.2042 - lcm_f1_5k: 0.2016 - lcm_accuracy_1k: 0.2172 - lcm_accuracy_2k: 0.3227 - lcm_accuracy_3k: 0.3994 - lcm_accuracy_5k: 0.4988 - lcm_hamming_loss_k: 0.0058 - val_loss: 0.4003 - val_lcm_precision_1k: 0.2411 - val_lcm_precision_2k: 0.2066 - val_lcm_precision_3k: 0.1837 - val_lcm_precision_5k: 0.1505 - val_lcm_recall_1k: 0.1337 - val_lcm_recall_2k: 0.2280 - val_lcm_recall_3k: 0.2966 - val_lcm_recall_5k: 0.4043 - val_lcm_f1_1k: 0.1719 - val_lcm_f1_2k: 0.2167 - val_lcm_f1_3k: 0.2268 - val_lcm_f1_5k: 0.2193 - val_lcm_accuracy_1k: 0.2411 - val_lcm_accuracy_2k: 0.3613 - val_lcm_accuracy_3k: 0.4440 - val_lcm_accuracy_5k: 0.5424 - val_lcm_hamming_loss_k: 0.0056
Epoch 3/150
27/27 [==============================] - ETA: 0s - loss: 0.3772 - lcm_precision_1k: 0.2865 - lcm_precision_2k: 0.2442 - lcm_precision_3k: 0.2132 - lcm_precision_5k: 0.1760 - lcm_recall_1k: 0.1621 - lcm_recall_2k: 0.2727 - lcm_recall_3k: 0.3500 - lcm_recall_5k: 0.4701 - lcm_f1_1k: 0.2070 - lcm_f1_2k: 0.2576 - lcm_f1_3k: 0.2649 - lcm_f1_5k: 0.2561 - lcm_accuracy_1k: 0.2865 - lcm_accuracy_2k: 0.4232 - lcm_accuracy_3k: 0.5092 - lcm_accuracy_5k: 0.6170 - lcm_hamming_loss_k: 0.0055
Epoch 00003: val_loss improved from 0.40028 to 0.36689, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 366ms/step - loss: 0.3772 - lcm_precision_1k: 0.2865 - lcm_precision_2k: 0.2442 - lcm_precision_3k: 0.2132 - lcm_precision_5k: 0.1760 - lcm_recall_1k: 0.1621 - lcm_recall_2k: 0.2727 - lcm_recall_3k: 0.3500 - lcm_recall_5k: 0.4701 - lcm_f1_1k: 0.2070 - lcm_f1_2k: 0.2576 - lcm_f1_3k: 0.2649 - lcm_f1_5k: 0.2561 - lcm_accuracy_1k: 0.2865 - lcm_accuracy_2k: 0.4232 - lcm_accuracy_3k: 0.5092 - lcm_accuracy_5k: 0.6170 - lcm_hamming_loss_k: 0.0055 - val_loss: 0.3669 - val_lcm_precision_1k: 0.3000 - val_lcm_precision_2k: 0.2691 - val_lcm_precision_3k: 0.2306 - val_lcm_precision_5k: 0.1842 - val_lcm_recall_1k: 0.1683 - val_lcm_recall_2k: 0.3027 - val_lcm_recall_3k: 0.3831 - val_lcm_recall_5k: 0.5020 - val_lcm_f1_1k: 0.2156 - val_lcm_f1_2k: 0.2848 - val_lcm_f1_3k: 0.2877 - val_lcm_f1_5k: 0.2694 - val_lcm_accuracy_1k: 0.3000 - val_lcm_accuracy_2k: 0.4616 - val_lcm_accuracy_3k: 0.5437 - val_lcm_accuracy_5k: 0.6457 - val_lcm_hamming_loss_k: 0.0053
Epoch 4/150
27/27 [==============================] - ETA: 0s - loss: 0.3497 - lcm_precision_1k: 0.3478 - lcm_precision_2k: 0.2996 - lcm_precision_3k: 0.2568 - lcm_precision_5k: 0.2015 - lcm_recall_1k: 0.1982 - lcm_recall_2k: 0.3364 - lcm_recall_3k: 0.4270 - lcm_recall_5k: 0.5447 - lcm_f1_1k: 0.2524 - lcm_f1_2k: 0.3168 - lcm_f1_3k: 0.3207 - lcm_f1_5k: 0.2941 - lcm_accuracy_1k: 0.3478 - lcm_accuracy_2k: 0.5065 - lcm_accuracy_3k: 0.5982 - lcm_accuracy_5k: 0.7000 - lcm_hamming_loss_k: 0.0052
Epoch 00004: val_loss improved from 0.36689 to 0.34034, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 370ms/step - loss: 0.3497 - lcm_precision_1k: 0.3478 - lcm_precision_2k: 0.2996 - lcm_precision_3k: 0.2568 - lcm_precision_5k: 0.2015 - lcm_recall_1k: 0.1982 - lcm_recall_2k: 0.3364 - lcm_recall_3k: 0.4270 - lcm_recall_5k: 0.5447 - lcm_f1_1k: 0.2524 - lcm_f1_2k: 0.3168 - lcm_f1_3k: 0.3207 - lcm_f1_5k: 0.2941 - lcm_accuracy_1k: 0.3478 - lcm_accuracy_2k: 0.5065 - lcm_accuracy_3k: 0.5982 - lcm_accuracy_5k: 0.7000 - lcm_hamming_loss_k: 0.0052 - val_loss: 0.3403 - val_lcm_precision_1k: 0.3693 - val_lcm_precision_2k: 0.3128 - val_lcm_precision_3k: 0.2605 - val_lcm_precision_5k: 0.2037 - val_lcm_recall_1k: 0.2173 - val_lcm_recall_2k: 0.3591 - val_lcm_recall_3k: 0.4434 - val_lcm_recall_5k: 0.5649 - val_lcm_f1_1k: 0.2735 - val_lcm_f1_2k: 0.3341 - val_lcm_f1_3k: 0.3280 - val_lcm_f1_5k: 0.2993 - val_lcm_accuracy_1k: 0.3693 - val_lcm_accuracy_2k: 0.5302 - val_lcm_accuracy_3k: 0.6116 - val_lcm_accuracy_5k: 0.7044 - val_lcm_hamming_loss_k: 0.0050
Epoch 5/150
27/27 [==============================] - ETA: 0s - loss: 0.3297 - lcm_precision_1k: 0.3976 - lcm_precision_2k: 0.3313 - lcm_precision_3k: 0.2829 - lcm_precision_5k: 0.2188 - lcm_recall_1k: 0.2340 - lcm_recall_2k: 0.3772 - lcm_recall_3k: 0.4739 - lcm_recall_5k: 0.5960 - lcm_f1_1k: 0.2945 - lcm_f1_2k: 0.3527 - lcm_f1_3k: 0.3542 - lcm_f1_5k: 0.3200 - lcm_accuracy_1k: 0.3976 - lcm_accuracy_2k: 0.5574 - lcm_accuracy_3k: 0.6503 - lcm_accuracy_5k: 0.7478 - lcm_hamming_loss_k: 0.0050
Epoch 00005: val_loss improved from 0.34034 to 0.32632, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 367ms/step - loss: 0.3297 - lcm_precision_1k: 0.3976 - lcm_precision_2k: 0.3313 - lcm_precision_3k: 0.2829 - lcm_precision_5k: 0.2188 - lcm_recall_1k: 0.2340 - lcm_recall_2k: 0.3772 - lcm_recall_3k: 0.4739 - lcm_recall_5k: 0.5960 - lcm_f1_1k: 0.2945 - lcm_f1_2k: 0.3527 - lcm_f1_3k: 0.3542 - lcm_f1_5k: 0.3200 - lcm_accuracy_1k: 0.3976 - lcm_accuracy_2k: 0.5574 - lcm_accuracy_3k: 0.6503 - lcm_accuracy_5k: 0.7478 - lcm_hamming_loss_k: 0.0050 - val_loss: 0.3263 - val_lcm_precision_1k: 0.4110 - val_lcm_precision_2k: 0.3425 - val_lcm_precision_3k: 0.2857 - val_lcm_precision_5k: 0.2166 - val_lcm_recall_1k: 0.2482 - val_lcm_recall_2k: 0.3946 - val_lcm_recall_3k: 0.4887 - val_lcm_recall_5k: 0.5997 - val_lcm_f1_1k: 0.3093 - val_lcm_f1_2k: 0.3665 - val_lcm_f1_3k: 0.3604 - val_lcm_f1_5k: 0.3181 - val_lcm_accuracy_1k: 0.4110 - val_lcm_accuracy_2k: 0.5671 - val_lcm_accuracy_3k: 0.6548 - val_lcm_accuracy_5k: 0.7445 - val_lcm_hamming_loss_k: 0.0048
Epoch 6/150
27/27 [==============================] - ETA: 0s - loss: 0.3141 - lcm_precision_1k: 0.4296 - lcm_precision_2k: 0.3552 - lcm_precision_3k: 0.3020 - lcm_precision_5k: 0.2294 - lcm_recall_1k: 0.2557 - lcm_recall_2k: 0.4071 - lcm_recall_3k: 0.5087 - lcm_recall_5k: 0.6256 - lcm_f1_1k: 0.3205 - lcm_f1_2k: 0.3793 - lcm_f1_3k: 0.3790 - lcm_f1_5k: 0.3357 - lcm_accuracy_1k: 0.4296 - lcm_accuracy_2k: 0.5918 - lcm_accuracy_3k: 0.6836 - lcm_accuracy_5k: 0.7763 - lcm_hamming_loss_k: 0.0048
Epoch 00006: val_loss improved from 0.32632 to 0.31896, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 373ms/step - loss: 0.3141 - lcm_precision_1k: 0.4296 - lcm_precision_2k: 0.3552 - lcm_precision_3k: 0.3020 - lcm_precision_5k: 0.2294 - lcm_recall_1k: 0.2557 - lcm_recall_2k: 0.4071 - lcm_recall_3k: 0.5087 - lcm_recall_5k: 0.6256 - lcm_f1_1k: 0.3205 - lcm_f1_2k: 0.3793 - lcm_f1_3k: 0.3790 - lcm_f1_5k: 0.3357 - lcm_accuracy_1k: 0.4296 - lcm_accuracy_2k: 0.5918 - lcm_accuracy_3k: 0.6836 - lcm_accuracy_5k: 0.7763 - lcm_hamming_loss_k: 0.0048 - val_loss: 0.3190 - val_lcm_precision_1k: 0.4277 - val_lcm_precision_2k: 0.3492 - val_lcm_precision_3k: 0.2942 - val_lcm_precision_5k: 0.2212 - val_lcm_recall_1k: 0.2591 - val_lcm_recall_2k: 0.4025 - val_lcm_recall_3k: 0.5029 - val_lcm_recall_5k: 0.6136 - val_lcm_f1_1k: 0.3226 - val_lcm_f1_2k: 0.3737 - val_lcm_f1_3k: 0.3710 - val_lcm_f1_5k: 0.3251 - val_lcm_accuracy_1k: 0.4277 - val_lcm_accuracy_2k: 0.5802 - val_lcm_accuracy_3k: 0.6660 - val_lcm_accuracy_5k: 0.7574 - val_lcm_hamming_loss_k: 0.0047
Epoch 7/150
27/27 [==============================] - ETA: 0s - loss: 0.3025 - lcm_precision_1k: 0.4673 - lcm_precision_2k: 0.3793 - lcm_precision_3k: 0.3169 - lcm_precision_5k: 0.2370 - lcm_recall_1k: 0.2805 - lcm_recall_2k: 0.4357 - lcm_recall_3k: 0.5341 - lcm_recall_5k: 0.6486 - lcm_f1_1k: 0.3505 - lcm_f1_2k: 0.4055 - lcm_f1_3k: 0.3977 - lcm_f1_5k: 0.3471 - lcm_accuracy_1k: 0.4673 - lcm_accuracy_2k: 0.6251 - lcm_accuracy_3k: 0.7091 - lcm_accuracy_5k: 0.7971 - lcm_hamming_loss_k: 0.0046
Epoch 00007: val_loss improved from 0.31896 to 0.30345, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 367ms/step - loss: 0.3025 - lcm_precision_1k: 0.4673 - lcm_precision_2k: 0.3793 - lcm_precision_3k: 0.3169 - lcm_precision_5k: 0.2370 - lcm_recall_1k: 0.2805 - lcm_recall_2k: 0.4357 - lcm_recall_3k: 0.5341 - lcm_recall_5k: 0.6486 - lcm_f1_1k: 0.3505 - lcm_f1_2k: 0.4055 - lcm_f1_3k: 0.3977 - lcm_f1_5k: 0.3471 - lcm_accuracy_1k: 0.4673 - lcm_accuracy_2k: 0.6251 - lcm_accuracy_3k: 0.7091 - lcm_accuracy_5k: 0.7971 - lcm_hamming_loss_k: 0.0046 - val_loss: 0.3034 - val_lcm_precision_1k: 0.4893 - val_lcm_precision_2k: 0.3827 - val_lcm_precision_3k: 0.3119 - val_lcm_precision_5k: 0.2328 - val_lcm_recall_1k: 0.2963 - val_lcm_recall_2k: 0.4449 - val_lcm_recall_3k: 0.5347 - val_lcm_recall_5k: 0.6484 - val_lcm_f1_1k: 0.3689 - val_lcm_f1_2k: 0.4112 - val_lcm_f1_3k: 0.3938 - val_lcm_f1_5k: 0.3424 - val_lcm_accuracy_1k: 0.4893 - val_lcm_accuracy_2k: 0.6286 - val_lcm_accuracy_3k: 0.7079 - val_lcm_accuracy_5k: 0.7880 - val_lcm_hamming_loss_k: 0.0045
Epoch 8/150
27/27 [==============================] - ETA: 0s - loss: 0.2883 - lcm_precision_1k: 0.5006 - lcm_precision_2k: 0.4017 - lcm_precision_3k: 0.3344 - lcm_precision_5k: 0.2482 - lcm_recall_1k: 0.3026 - lcm_recall_2k: 0.4634 - lcm_recall_3k: 0.5650 - lcm_recall_5k: 0.6796 - lcm_f1_1k: 0.3771 - lcm_f1_2k: 0.4303 - lcm_f1_3k: 0.4201 - lcm_f1_5k: 0.3636 - lcm_accuracy_1k: 0.5006 - lcm_accuracy_2k: 0.6548 - lcm_accuracy_3k: 0.7404 - lcm_accuracy_5k: 0.8240 - lcm_hamming_loss_k: 0.0045
Epoch 00008: val_loss improved from 0.30345 to 0.29327, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 368ms/step - loss: 0.2883 - lcm_precision_1k: 0.5006 - lcm_precision_2k: 0.4017 - lcm_precision_3k: 0.3344 - lcm_precision_5k: 0.2482 - lcm_recall_1k: 0.3026 - lcm_recall_2k: 0.4634 - lcm_recall_3k: 0.5650 - lcm_recall_5k: 0.6796 - lcm_f1_1k: 0.3771 - lcm_f1_2k: 0.4303 - lcm_f1_3k: 0.4201 - lcm_f1_5k: 0.3636 - lcm_accuracy_1k: 0.5006 - lcm_accuracy_2k: 0.6548 - lcm_accuracy_3k: 0.7404 - lcm_accuracy_5k: 0.8240 - lcm_hamming_loss_k: 0.0045 - val_loss: 0.2933 - val_lcm_precision_1k: 0.5052 - val_lcm_precision_2k: 0.3962 - val_lcm_precision_3k: 0.3213 - val_lcm_precision_5k: 0.2362 - val_lcm_recall_1k: 0.3085 - val_lcm_recall_2k: 0.4619 - val_lcm_recall_3k: 0.5550 - val_lcm_recall_5k: 0.6580 - val_lcm_f1_1k: 0.3829 - val_lcm_f1_2k: 0.4263 - val_lcm_f1_3k: 0.4068 - val_lcm_f1_5k: 0.3475 - val_lcm_accuracy_1k: 0.5052 - val_lcm_accuracy_2k: 0.6464 - val_lcm_accuracy_3k: 0.7200 - val_lcm_accuracy_5k: 0.7938 - val_lcm_hamming_loss_k: 0.0044
Epoch 9/150
27/27 [==============================] - ETA: 0s - loss: 0.2786 - lcm_precision_1k: 0.5298 - lcm_precision_2k: 0.4206 - lcm_precision_3k: 0.3451 - lcm_precision_5k: 0.2547 - lcm_recall_1k: 0.3239 - lcm_recall_2k: 0.4865 - lcm_recall_3k: 0.5842 - lcm_recall_5k: 0.6989 - lcm_f1_1k: 0.4020 - lcm_f1_2k: 0.4511 - lcm_f1_3k: 0.4339 - lcm_f1_5k: 0.3733 - lcm_accuracy_1k: 0.5298 - lcm_accuracy_2k: 0.6805 - lcm_accuracy_3k: 0.7611 - lcm_accuracy_5k: 0.8411 - lcm_hamming_loss_k: 0.0043
Epoch 00009: val_loss improved from 0.29327 to 0.28700, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 369ms/step - loss: 0.2786 - lcm_precision_1k: 0.5298 - lcm_precision_2k: 0.4206 - lcm_precision_3k: 0.3451 - lcm_precision_5k: 0.2547 - lcm_recall_1k: 0.3239 - lcm_recall_2k: 0.4865 - lcm_recall_3k: 0.5842 - lcm_recall_5k: 0.6989 - lcm_f1_1k: 0.4020 - lcm_f1_2k: 0.4511 - lcm_f1_3k: 0.4339 - lcm_f1_5k: 0.3733 - lcm_accuracy_1k: 0.5298 - lcm_accuracy_2k: 0.6805 - lcm_accuracy_3k: 0.7611 - lcm_accuracy_5k: 0.8411 - lcm_hamming_loss_k: 0.0043 - val_loss: 0.2870 - val_lcm_precision_1k: 0.5154 - val_lcm_precision_2k: 0.4062 - val_lcm_precision_3k: 0.3310 - val_lcm_precision_5k: 0.2442 - val_lcm_recall_1k: 0.3179 - val_lcm_recall_2k: 0.4766 - val_lcm_recall_3k: 0.5702 - val_lcm_recall_5k: 0.6848 - val_lcm_f1_1k: 0.3930 - val_lcm_f1_2k: 0.4384 - val_lcm_f1_3k: 0.4186 - val_lcm_f1_5k: 0.3598 - val_lcm_accuracy_1k: 0.5154 - val_lcm_accuracy_2k: 0.6607 - val_lcm_accuracy_3k: 0.7367 - val_lcm_accuracy_5k: 0.8213 - val_lcm_hamming_loss_k: 0.0043
Epoch 10/150
27/27 [==============================] - ETA: 0s - loss: 0.2688 - lcm_precision_1k: 0.5540 - lcm_precision_2k: 0.4383 - lcm_precision_3k: 0.3578 - lcm_precision_5k: 0.2625 - lcm_recall_1k: 0.3407 - lcm_recall_2k: 0.5089 - lcm_recall_3k: 0.6076 - lcm_recall_5k: 0.7214 - lcm_f1_1k: 0.4218 - lcm_f1_2k: 0.4710 - lcm_f1_3k: 0.4503 - lcm_f1_5k: 0.3849 - lcm_accuracy_1k: 0.5540 - lcm_accuracy_2k: 0.7051 - lcm_accuracy_3k: 0.7826 - lcm_accuracy_5k: 0.8574 - lcm_hamming_loss_k: 0.0042
Epoch 00010: val_loss improved from 0.28700 to 0.28224, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 372ms/step - loss: 0.2688 - lcm_precision_1k: 0.5540 - lcm_precision_2k: 0.4383 - lcm_precision_3k: 0.3578 - lcm_precision_5k: 0.2625 - lcm_recall_1k: 0.3407 - lcm_recall_2k: 0.5089 - lcm_recall_3k: 0.6076 - lcm_recall_5k: 0.7214 - lcm_f1_1k: 0.4218 - lcm_f1_2k: 0.4710 - lcm_f1_3k: 0.4503 - lcm_f1_5k: 0.3849 - lcm_accuracy_1k: 0.5540 - lcm_accuracy_2k: 0.7051 - lcm_accuracy_3k: 0.7826 - lcm_accuracy_5k: 0.8574 - lcm_hamming_loss_k: 0.0042 - val_loss: 0.2822 - val_lcm_precision_1k: 0.5320 - val_lcm_precision_2k: 0.4154 - val_lcm_precision_3k: 0.3369 - val_lcm_precision_5k: 0.2475 - val_lcm_recall_1k: 0.3293 - val_lcm_recall_2k: 0.4851 - val_lcm_recall_3k: 0.5807 - val_lcm_recall_5k: 0.6929 - val_lcm_f1_1k: 0.4066 - val_lcm_f1_2k: 0.4473 - val_lcm_f1_3k: 0.4262 - val_lcm_f1_5k: 0.3646 - val_lcm_accuracy_1k: 0.5320 - val_lcm_accuracy_2k: 0.6708 - val_lcm_accuracy_3k: 0.7448 - val_lcm_accuracy_5k: 0.8279 - val_lcm_hamming_loss_k: 0.0043
Epoch 11/150
27/27 [==============================] - ETA: 0s - loss: 0.2608 - lcm_precision_1k: 0.5707 - lcm_precision_2k: 0.4529 - lcm_precision_3k: 0.3698 - lcm_precision_5k: 0.2689 - lcm_recall_1k: 0.3512 - lcm_recall_2k: 0.5261 - lcm_recall_3k: 0.6281 - lcm_recall_5k: 0.7389 - lcm_f1_1k: 0.4348 - lcm_f1_2k: 0.4867 - lcm_f1_3k: 0.4655 - lcm_f1_5k: 0.3943 - lcm_accuracy_1k: 0.5707 - lcm_accuracy_2k: 0.7245 - lcm_accuracy_3k: 0.8005 - lcm_accuracy_5k: 0.8725 - lcm_hamming_loss_k: 0.0041
Epoch 00011: val_loss improved from 0.28224 to 0.28145, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 370ms/step - loss: 0.2608 - lcm_precision_1k: 0.5707 - lcm_precision_2k: 0.4529 - lcm_precision_3k: 0.3698 - lcm_precision_5k: 0.2689 - lcm_recall_1k: 0.3512 - lcm_recall_2k: 0.5261 - lcm_recall_3k: 0.6281 - lcm_recall_5k: 0.7389 - lcm_f1_1k: 0.4348 - lcm_f1_2k: 0.4867 - lcm_f1_3k: 0.4655 - lcm_f1_5k: 0.3943 - lcm_accuracy_1k: 0.5707 - lcm_accuracy_2k: 0.7245 - lcm_accuracy_3k: 0.8005 - lcm_accuracy_5k: 0.8725 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2815 - val_lcm_precision_1k: 0.5307 - val_lcm_precision_2k: 0.4212 - val_lcm_precision_3k: 0.3436 - val_lcm_precision_5k: 0.2484 - val_lcm_recall_1k: 0.3290 - val_lcm_recall_2k: 0.4964 - val_lcm_recall_3k: 0.5920 - val_lcm_recall_5k: 0.6967 - val_lcm_f1_1k: 0.4060 - val_lcm_f1_2k: 0.4555 - val_lcm_f1_3k: 0.4346 - val_lcm_f1_5k: 0.3660 - val_lcm_accuracy_1k: 0.5307 - val_lcm_accuracy_2k: 0.6828 - val_lcm_accuracy_3k: 0.7578 - val_lcm_accuracy_5k: 0.8306 - val_lcm_hamming_loss_k: 0.0043
Epoch 12/150
27/27 [==============================] - ETA: 0s - loss: 0.2524 - lcm_precision_1k: 0.5912 - lcm_precision_2k: 0.4648 - lcm_precision_3k: 0.3780 - lcm_precision_5k: 0.2738 - lcm_recall_1k: 0.3667 - lcm_recall_2k: 0.5420 - lcm_recall_3k: 0.6448 - lcm_recall_5k: 0.7537 - lcm_f1_1k: 0.4525 - lcm_f1_2k: 0.5003 - lcm_f1_3k: 0.4765 - lcm_f1_5k: 0.4017 - lcm_accuracy_1k: 0.5912 - lcm_accuracy_2k: 0.7420 - lcm_accuracy_3k: 0.8169 - lcm_accuracy_5k: 0.8836 - lcm_hamming_loss_k: 0.0041
Epoch 00012: val_loss improved from 0.28145 to 0.27472, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 371ms/step - loss: 0.2524 - lcm_precision_1k: 0.5912 - lcm_precision_2k: 0.4648 - lcm_precision_3k: 0.3780 - lcm_precision_5k: 0.2738 - lcm_recall_1k: 0.3667 - lcm_recall_2k: 0.5420 - lcm_recall_3k: 0.6448 - lcm_recall_5k: 0.7537 - lcm_f1_1k: 0.4525 - lcm_f1_2k: 0.5003 - lcm_f1_3k: 0.4765 - lcm_f1_5k: 0.4017 - lcm_accuracy_1k: 0.5912 - lcm_accuracy_2k: 0.7420 - lcm_accuracy_3k: 0.8169 - lcm_accuracy_5k: 0.8836 - lcm_hamming_loss_k: 0.0041 - val_loss: 0.2747 - val_lcm_precision_1k: 0.5492 - val_lcm_precision_2k: 0.4326 - val_lcm_precision_3k: 0.3476 - val_lcm_precision_5k: 0.2537 - val_lcm_recall_1k: 0.3421 - val_lcm_recall_2k: 0.5137 - val_lcm_recall_3k: 0.6035 - val_lcm_recall_5k: 0.7126 - val_lcm_f1_1k: 0.4215 - val_lcm_f1_2k: 0.4694 - val_lcm_f1_3k: 0.4409 - val_lcm_f1_5k: 0.3741 - val_lcm_accuracy_1k: 0.5492 - val_lcm_accuracy_2k: 0.7041 - val_lcm_accuracy_3k: 0.7684 - val_lcm_accuracy_5k: 0.8437 - val_lcm_hamming_loss_k: 0.0042
Epoch 13/150
27/27 [==============================] - ETA: 0s - loss: 0.2456 - lcm_precision_1k: 0.6069 - lcm_precision_2k: 0.4790 - lcm_precision_3k: 0.3884 - lcm_precision_5k: 0.2793 - lcm_recall_1k: 0.3772 - lcm_recall_2k: 0.5590 - lcm_recall_3k: 0.6597 - lcm_recall_5k: 0.7667 - lcm_f1_1k: 0.4652 - lcm_f1_2k: 0.5158 - lcm_f1_3k: 0.4889 - lcm_f1_5k: 0.4094 - lcm_accuracy_1k: 0.6069 - lcm_accuracy_2k: 0.7575 - lcm_accuracy_3k: 0.8274 - lcm_accuracy_5k: 0.8943 - lcm_hamming_loss_k: 0.0040 ETA: 2s - loss: 0.2464 - lcm_precision_1k: 0.6012 - lcm_precision_2k: 0.4777 - lcm_precision_3k: 0.3889 - lcm_precision_5k: 0.2800 - lcm_recall_1k: 0.3717 - lcm_recall_2k: 0.5549 - lcm_recall_3k: 0.6586 - lcm_recall_5k: 0.7671 - lcm_f1_1k: 0.4593 - lcm_f1_2k: 0.5134 - lcm_f1_3k: 0.4890 - lcm_f1_5k: 0.4102 - lcm_accuracy_1k: 0.6012 - lcm_accuracy_2k: 0.7544 - lcm_accuracy_3k: 0.8266 - lcm_accuracy_5k: 0.8938 - lcm_hamm
Epoch 00013: val_loss improved from 0.27472 to 0.27169, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 368ms/step - loss: 0.2456 - lcm_precision_1k: 0.6069 - lcm_precision_2k: 0.4790 - lcm_precision_3k: 0.3884 - lcm_precision_5k: 0.2793 - lcm_recall_1k: 0.3772 - lcm_recall_2k: 0.5590 - lcm_recall_3k: 0.6597 - lcm_recall_5k: 0.7667 - lcm_f1_1k: 0.4652 - lcm_f1_2k: 0.5158 - lcm_f1_3k: 0.4889 - lcm_f1_5k: 0.4094 - lcm_accuracy_1k: 0.6069 - lcm_accuracy_2k: 0.7575 - lcm_accuracy_3k: 0.8274 - lcm_accuracy_5k: 0.8943 - lcm_hamming_loss_k: 0.0040 - val_loss: 0.2717 - val_lcm_precision_1k: 0.5584 - val_lcm_precision_2k: 0.4397 - val_lcm_precision_3k: 0.3549 - val_lcm_precision_5k: 0.2551 - val_lcm_recall_1k: 0.3480 - val_lcm_recall_2k: 0.5208 - val_lcm_recall_3k: 0.6166 - val_lcm_recall_5k: 0.7178 - val_lcm_f1_1k: 0.4286 - val_lcm_f1_2k: 0.4766 - val_lcm_f1_3k: 0.4503 - val_lcm_f1_5k: 0.3763 - val_lcm_accuracy_1k: 0.5584 - val_lcm_accuracy_2k: 0.7108 - val_lcm_accuracy_3k: 0.7787 - val_lcm_accuracy_5k: 0.8454 - val_lcm_hamming_loss_k: 0.0041
Epoch 14/150
27/27 [==============================] - ETA: 0s - loss: 0.2368 - lcm_precision_1k: 0.6240 - lcm_precision_2k: 0.4942 - lcm_precision_3k: 0.3980 - lcm_precision_5k: 0.2857 - lcm_recall_1k: 0.3894 - lcm_recall_2k: 0.5795 - lcm_recall_3k: 0.6780 - lcm_recall_5k: 0.7852 - lcm_f1_1k: 0.4795 - lcm_f1_2k: 0.5334 - lcm_f1_3k: 0.5015 - lcm_f1_5k: 0.4189 - lcm_accuracy_1k: 0.6240 - lcm_accuracy_2k: 0.7792 - lcm_accuracy_3k: 0.8459 - lcm_accuracy_5k: 0.9078 - lcm_hamming_loss_k: 0.0039
Epoch 00014: val_loss improved from 0.27169 to 0.26893, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 368ms/step - loss: 0.2368 - lcm_precision_1k: 0.6240 - lcm_precision_2k: 0.4942 - lcm_precision_3k: 0.3980 - lcm_precision_5k: 0.2857 - lcm_recall_1k: 0.3894 - lcm_recall_2k: 0.5795 - lcm_recall_3k: 0.6780 - lcm_recall_5k: 0.7852 - lcm_f1_1k: 0.4795 - lcm_f1_2k: 0.5334 - lcm_f1_3k: 0.5015 - lcm_f1_5k: 0.4189 - lcm_accuracy_1k: 0.6240 - lcm_accuracy_2k: 0.7792 - lcm_accuracy_3k: 0.8459 - lcm_accuracy_5k: 0.9078 - lcm_hamming_loss_k: 0.0039 - val_loss: 0.2689 - val_lcm_precision_1k: 0.5563 - val_lcm_precision_2k: 0.4389 - val_lcm_precision_3k: 0.3586 - val_lcm_precision_5k: 0.2578 - val_lcm_recall_1k: 0.3463 - val_lcm_recall_2k: 0.5219 - val_lcm_recall_3k: 0.6198 - val_lcm_recall_5k: 0.7198 - val_lcm_f1_1k: 0.4267 - val_lcm_f1_2k: 0.4765 - val_lcm_f1_3k: 0.4541 - val_lcm_f1_5k: 0.3795 - val_lcm_accuracy_1k: 0.5563 - val_lcm_accuracy_2k: 0.7119 - val_lcm_accuracy_3k: 0.7812 - val_lcm_accuracy_5k: 0.8464 - val_lcm_hamming_loss_k: 0.0041
Epoch 15/150
27/27 [==============================] - ETA: 0s - loss: 0.2306 - lcm_precision_1k: 0.6408 - lcm_precision_2k: 0.5067 - lcm_precision_3k: 0.4069 - lcm_precision_5k: 0.2914 - lcm_recall_1k: 0.3999 - lcm_recall_2k: 0.5942 - lcm_recall_3k: 0.6910 - lcm_recall_5k: 0.7988 - lcm_f1_1k: 0.4924 - lcm_f1_2k: 0.5469 - lcm_f1_3k: 0.5121 - lcm_f1_5k: 0.4270 - lcm_accuracy_1k: 0.6408 - lcm_accuracy_2k: 0.7949 - lcm_accuracy_3k: 0.8573 - lcm_accuracy_5k: 0.9173 - lcm_hamming_loss_k: 0.0038
Epoch 00015: val_loss improved from 0.26893 to 0.26745, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 370ms/step - loss: 0.2306 - lcm_precision_1k: 0.6408 - lcm_precision_2k: 0.5067 - lcm_precision_3k: 0.4069 - lcm_precision_5k: 0.2914 - lcm_recall_1k: 0.3999 - lcm_recall_2k: 0.5942 - lcm_recall_3k: 0.6910 - lcm_recall_5k: 0.7988 - lcm_f1_1k: 0.4924 - lcm_f1_2k: 0.5469 - lcm_f1_3k: 0.5121 - lcm_f1_5k: 0.4270 - lcm_accuracy_1k: 0.6408 - lcm_accuracy_2k: 0.7949 - lcm_accuracy_3k: 0.8573 - lcm_accuracy_5k: 0.9173 - lcm_hamming_loss_k: 0.0038 - val_loss: 0.2674 - val_lcm_precision_1k: 0.5699 - val_lcm_precision_2k: 0.4478 - val_lcm_precision_3k: 0.3620 - val_lcm_precision_5k: 0.2595 - val_lcm_recall_1k: 0.3577 - val_lcm_recall_2k: 0.5320 - val_lcm_recall_3k: 0.6261 - val_lcm_recall_5k: 0.7247 - val_lcm_f1_1k: 0.4394 - val_lcm_f1_2k: 0.4861 - val_lcm_f1_3k: 0.4586 - val_lcm_f1_5k: 0.3821 - val_lcm_accuracy_1k: 0.5699 - val_lcm_accuracy_2k: 0.7211 - val_lcm_accuracy_3k: 0.7845 - val_lcm_accuracy_5k: 0.8494 - val_lcm_hamming_loss_k: 0.0041
Epoch 16/150
27/27 [==============================] - ETA: 0s - loss: 0.2220 - lcm_precision_1k: 0.6612 - lcm_precision_2k: 0.5221 - lcm_precision_3k: 0.4185 - lcm_precision_5k: 0.2968 - lcm_recall_1k: 0.4155 - lcm_recall_2k: 0.6137 - lcm_recall_3k: 0.7122 - lcm_recall_5k: 0.8137 - lcm_f1_1k: 0.5102 - lcm_f1_2k: 0.5641 - lcm_f1_3k: 0.5271 - lcm_f1_5k: 0.4348 - lcm_accuracy_1k: 0.6612 - lcm_accuracy_2k: 0.8158 - lcm_accuracy_3k: 0.8742 - lcm_accuracy_5k: 0.9275 - lcm_hamming_loss_k: 0.0037
Epoch 00016: val_loss improved from 0.26745 to 0.26671, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 370ms/step - loss: 0.2220 - lcm_precision_1k: 0.6612 - lcm_precision_2k: 0.5221 - lcm_precision_3k: 0.4185 - lcm_precision_5k: 0.2968 - lcm_recall_1k: 0.4155 - lcm_recall_2k: 0.6137 - lcm_recall_3k: 0.7122 - lcm_recall_5k: 0.8137 - lcm_f1_1k: 0.5102 - lcm_f1_2k: 0.5641 - lcm_f1_3k: 0.5271 - lcm_f1_5k: 0.4348 - lcm_accuracy_1k: 0.6612 - lcm_accuracy_2k: 0.8158 - lcm_accuracy_3k: 0.8742 - lcm_accuracy_5k: 0.9275 - lcm_hamming_loss_k: 0.0037 - val_loss: 0.2667 - val_lcm_precision_1k: 0.5764 - val_lcm_precision_2k: 0.4478 - val_lcm_precision_3k: 0.3632 - val_lcm_precision_5k: 0.2615 - val_lcm_recall_1k: 0.3610 - val_lcm_recall_2k: 0.5320 - val_lcm_recall_3k: 0.6285 - val_lcm_recall_5k: 0.7326 - val_lcm_f1_1k: 0.4439 - val_lcm_f1_2k: 0.4860 - val_lcm_f1_3k: 0.4602 - val_lcm_f1_5k: 0.3853 - val_lcm_accuracy_1k: 0.5764 - val_lcm_accuracy_2k: 0.7196 - val_lcm_accuracy_3k: 0.7880 - val_lcm_accuracy_5k: 0.8555 - val_lcm_hamming_loss_k: 0.0041
Epoch 17/150
27/27 [==============================] - ETA: 0s - loss: 0.2156 - lcm_precision_1k: 0.6792 - lcm_precision_2k: 0.5340 - lcm_precision_3k: 0.4286 - lcm_precision_5k: 0.3032 - lcm_recall_1k: 0.4257 - lcm_recall_2k: 0.6255 - lcm_recall_3k: 0.7263 - lcm_recall_5k: 0.8278 - lcm_f1_1k: 0.5232 - lcm_f1_2k: 0.5760 - lcm_f1_3k: 0.5390 - lcm_f1_5k: 0.4438 - lcm_accuracy_1k: 0.6792 - lcm_accuracy_2k: 0.8269 - lcm_accuracy_3k: 0.8847 - lcm_accuracy_5k: 0.9371 - lcm_hamming_loss_k: 0.0036
Epoch 00017: val_loss improved from 0.26671 to 0.26589, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 372ms/step - loss: 0.2156 - lcm_precision_1k: 0.6792 - lcm_precision_2k: 0.5340 - lcm_precision_3k: 0.4286 - lcm_precision_5k: 0.3032 - lcm_recall_1k: 0.4257 - lcm_recall_2k: 0.6255 - lcm_recall_3k: 0.7263 - lcm_recall_5k: 0.8278 - lcm_f1_1k: 0.5232 - lcm_f1_2k: 0.5760 - lcm_f1_3k: 0.5390 - lcm_f1_5k: 0.4438 - lcm_accuracy_1k: 0.6792 - lcm_accuracy_2k: 0.8269 - lcm_accuracy_3k: 0.8847 - lcm_accuracy_5k: 0.9371 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2659 - val_lcm_precision_1k: 0.5729 - val_lcm_precision_2k: 0.4497 - val_lcm_precision_3k: 0.3636 - val_lcm_precision_5k: 0.2595 - val_lcm_recall_1k: 0.3607 - val_lcm_recall_2k: 0.5365 - val_lcm_recall_3k: 0.6328 - val_lcm_recall_5k: 0.7281 - val_lcm_f1_1k: 0.4425 - val_lcm_f1_2k: 0.4890 - val_lcm_f1_3k: 0.4616 - val_lcm_f1_5k: 0.3824 - val_lcm_accuracy_1k: 0.5729 - val_lcm_accuracy_2k: 0.7302 - val_lcm_accuracy_3k: 0.7921 - val_lcm_accuracy_5k: 0.8508 - val_lcm_hamming_loss_k: 0.0041
Epoch 18/150
27/27 [==============================] - ETA: 0s - loss: 0.2084 - lcm_precision_1k: 0.6971 - lcm_precision_2k: 0.5466 - lcm_precision_3k: 0.4385 - lcm_precision_5k: 0.3084 - lcm_recall_1k: 0.4386 - lcm_recall_2k: 0.6411 - lcm_recall_3k: 0.7433 - lcm_recall_5k: 0.8422 - lcm_f1_1k: 0.5384 - lcm_f1_2k: 0.5900 - lcm_f1_3k: 0.5515 - lcm_f1_5k: 0.4514 - lcm_accuracy_1k: 0.6971 - lcm_accuracy_2k: 0.8423 - lcm_accuracy_3k: 0.8978 - lcm_accuracy_5k: 0.9450 - lcm_hamming_loss_k: 0.0036
Epoch 00018: val_loss improved from 0.26589 to 0.26534, saving model to logs/xvtmmy-lbs-0604-124839/model/checkpoint_lbs.h5
27/27 [==============================] - 10s 372ms/step - loss: 0.2084 - lcm_precision_1k: 0.6971 - lcm_precision_2k: 0.5466 - lcm_precision_3k: 0.4385 - lcm_precision_5k: 0.3084 - lcm_recall_1k: 0.4386 - lcm_recall_2k: 0.6411 - lcm_recall_3k: 0.7433 - lcm_recall_5k: 0.8422 - lcm_f1_1k: 0.5384 - lcm_f1_2k: 0.5900 - lcm_f1_3k: 0.5515 - lcm_f1_5k: 0.4514 - lcm_accuracy_1k: 0.6971 - lcm_accuracy_2k: 0.8423 - lcm_accuracy_3k: 0.8978 - lcm_accuracy_5k: 0.9450 - lcm_hamming_loss_k: 0.0036 - val_loss: 0.2653 - val_lcm_precision_1k: 0.5853 - val_lcm_precision_2k: 0.4538 - val_lcm_precision_3k: 0.3674 - val_lcm_precision_5k: 0.2620 - val_lcm_recall_1k: 0.3688 - val_lcm_recall_2k: 0.5398 - val_lcm_recall_3k: 0.6357 - val_lcm_recall_5k: 0.7322 - val_lcm_f1_1k: 0.4524 - val_lcm_f1_2k: 0.4929 - val_lcm_f1_3k: 0.4656 - val_lcm_f1_5k: 0.3858 - val_lcm_accuracy_1k: 0.5853 - val_lcm_accuracy_2k: 0.7334 - val_lcm_accuracy_3k: 0.7937 - val_lcm_accuracy_5k: 0.8522 - val_lcm_hamming_loss_k: 0.0040
Epoch 19/150
27/27 [==============================] - ETA: 0s - loss: 0.2014 - lcm_precision_1k: 0.7214 - lcm_precision_2k: 0.5586 - lcm_precision_3k: 0.4462 - lcm_precision_5k: 0.3123 - lcm_recall_1k: 0.4553 - lcm_recall_2k: 0.6553 - lcm_recall_3k: 0.7556 - lcm_recall_5k: 0.8530 - lcm_f1_1k: 0.5582 - lcm_f1_2k: 0.6030 - lcm_f1_3k: 0.5610 - lcm_f1_5k: 0.4572 - lcm_accuracy_1k: 0.7214 - lcm_accuracy_2k: 0.8550 - lcm_accuracy_3k: 0.9077 - lcm_accuracy_5k: 0.9526 - lcm_hamming_loss_k: 0.0034
Epoch 00019: val_loss did not improve from 0.26534
27/27 [==============================] - 9s 344ms/step - loss: 0.2014 - lcm_precision_1k: 0.7214 - lcm_precision_2k: 0.5586 - lcm_precision_3k: 0.4462 - lcm_precision_5k: 0.3123 - lcm_recall_1k: 0.4553 - lcm_recall_2k: 0.6553 - lcm_recall_3k: 0.7556 - lcm_recall_5k: 0.8530 - lcm_f1_1k: 0.5582 - lcm_f1_2k: 0.6030 - lcm_f1_3k: 0.5610 - lcm_f1_5k: 0.4572 - lcm_accuracy_1k: 0.7214 - lcm_accuracy_2k: 0.8550 - lcm_accuracy_3k: 0.9077 - lcm_accuracy_5k: 0.9526 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2660 - val_lcm_precision_1k: 0.5824 - val_lcm_precision_2k: 0.4554 - val_lcm_precision_3k: 0.3691 - val_lcm_precision_5k: 0.2626 - val_lcm_recall_1k: 0.3665 - val_lcm_recall_2k: 0.5436 - val_lcm_recall_3k: 0.6412 - val_lcm_recall_5k: 0.7384 - val_lcm_f1_1k: 0.4498 - val_lcm_f1_2k: 0.4954 - val_lcm_f1_3k: 0.4684 - val_lcm_f1_5k: 0.3873 - val_lcm_accuracy_1k: 0.5824 - val_lcm_accuracy_2k: 0.7369 - val_lcm_accuracy_3k: 0.8016 - val_lcm_accuracy_5k: 0.8625 - val_lcm_hamming_loss_k: 0.0040
Epoch 20/150
27/27 [==============================] - ETA: 0s - loss: 0.1961 - lcm_precision_1k: 0.7282 - lcm_precision_2k: 0.5678 - lcm_precision_3k: 0.4542 - lcm_precision_5k: 0.3164 - lcm_recall_1k: 0.4612 - lcm_recall_2k: 0.6657 - lcm_recall_3k: 0.7683 - lcm_recall_5k: 0.8616 - lcm_f1_1k: 0.5647 - lcm_f1_2k: 0.6128 - lcm_f1_3k: 0.5708 - lcm_f1_5k: 0.4628 - lcm_accuracy_1k: 0.7282 - lcm_accuracy_2k: 0.8645 - lcm_accuracy_3k: 0.9165 - lcm_accuracy_5k: 0.9553 - lcm_hamming_loss_k: 0.0034
Epoch 00020: val_loss did not improve from 0.26534
27/27 [==============================] - 9s 344ms/step - loss: 0.1961 - lcm_precision_1k: 0.7282 - lcm_precision_2k: 0.5678 - lcm_precision_3k: 0.4542 - lcm_precision_5k: 0.3164 - lcm_recall_1k: 0.4612 - lcm_recall_2k: 0.6657 - lcm_recall_3k: 0.7683 - lcm_recall_5k: 0.8616 - lcm_f1_1k: 0.5647 - lcm_f1_2k: 0.6128 - lcm_f1_3k: 0.5708 - lcm_f1_5k: 0.4628 - lcm_accuracy_1k: 0.7282 - lcm_accuracy_2k: 0.8645 - lcm_accuracy_3k: 0.9165 - lcm_accuracy_5k: 0.9553 - lcm_hamming_loss_k: 0.0034 - val_loss: 0.2659 - val_lcm_precision_1k: 0.5871 - val_lcm_precision_2k: 0.4536 - val_lcm_precision_3k: 0.3644 - val_lcm_precision_5k: 0.2634 - val_lcm_recall_1k: 0.3690 - val_lcm_recall_2k: 0.5418 - val_lcm_recall_3k: 0.6357 - val_lcm_recall_5k: 0.7394 - val_lcm_f1_1k: 0.4531 - val_lcm_f1_2k: 0.4936 - val_lcm_f1_3k: 0.4631 - val_lcm_f1_5k: 0.3883 - val_lcm_accuracy_1k: 0.5871 - val_lcm_accuracy_2k: 0.7333 - val_lcm_accuracy_3k: 0.7987 - val_lcm_accuracy_5k: 0.8627 - val_lcm_hamming_loss_k: 0.0040
Epoch 00020: early stopping
176/176 [==============================] - 7s 36ms/step - loss: 0.2159 - lcm_precision_1k: 0.6816 - lcm_precision_2k: 0.5291 - lcm_precision_3k: 0.4269 - lcm_precision_5k: 0.3000 - lcm_recall_1k: 0.4316 - lcm_recall_2k: 0.6240 - lcm_recall_3k: 0.7267 - lcm_recall_5k: 0.8240 - lcm_f1_1k: 0.5272 - lcm_f1_2k: 0.5714 - lcm_f1_3k: 0.5368 - lcm_f1_5k: 0.4392 - lcm_accuracy_1k: 0.6816 - lcm_accuracy_2k: 0.8201 - lcm_accuracy_3k: 0.8760 - lcm_accuracy_5k: 0.9235 - lcm_hamming_loss_k: 0.0036 1s - loss: 0.2163 - lcm_precision_1k: 0.6801 - lcm_precision_2k: 0.5289 - lcm_precision_3k: 0.4257 - lcm_precision_5k: 0.2983 - lcm_recall_1k: 0.4322 - lcm_recall_2k: 0.6246 - lcm_recall_3k: 0.7273 - lcm_recall_5k: 0.8223 - lcm_f1_1k: 0.5272 - lcm_f1_2k: 0.5715 - lcm_f1_3k: 0.5361 - lcm_f1_5k: 0.4371 - lcm_accuracy_1k: 0.6801 - lcm_accuracy_2k: 0.8199 - lcm_accuracy_3k: 0.8767 - lcm_accuracy_5k: 0.9230 
Best model result:  [0.21592846512794495, 0.6816455721855164, 0.5291357636451721, 0.4269404411315918, 0.30004438757896423, 0.43163231015205383, 0.6239737868309021, 0.7266546487808228, 0.8240258693695068, 0.5272342562675476, 0.571440577507019, 0.5368217825889587, 0.43919479846954346, 0.6816455721855164, 0.8201373815536499, 0.8760429620742798, 0.9234768152236938, 0.00359295099042356]
fold_result:  [[0.22971901297569275, 0.6526561975479126, 0.5041267275810242, 0.40493983030319214, 0.28800174593925476, 0.4144092798233032, 0.5993703007698059, 0.6958515644073486, 0.79787278175354, 0.5055457353591919, 0.5463994741439819, 0.5109279751777649, 0.42248818278312683, 0.6526561975479126, 0.7977704405784607, 0.8540236949920654, 0.9102315306663513, 0.0037287429440766573], [0.22353927791118622, 0.6694719195365906, 0.5179114937782288, 0.4144670367240906, 0.29310348629951477, 0.4251295030117035, 0.6147074699401855, 0.712475061416626, 0.8105340600013733, 0.518618643283844, 0.560910701751709, 0.523081362247467, 0.42983224987983704, 0.6694719195365906, 0.8130409717559814, 0.8681333661079407, 0.9163203835487366, 0.0036499679554253817], [0.22365182638168335, 0.6686379909515381, 0.5167782306671143, 0.4136255085468292, 0.2926330864429474, 0.42253991961479187, 0.6127398014068604, 0.7102922797203064, 0.8077000975608826, 0.5164948105812073, 0.5594732761383057, 0.5218390226364136, 0.4289473593235016, 0.6686379909515381, 0.8111330270767212, 0.8697018027305603, 0.9160964488983154, 0.0036538944113999605], [0.21413291990756989, 0.6934518218040466, 0.5333287119865417, 0.42674490809440613, 0.3008676767349243, 0.44218742847442627, 0.6305114030838013, 0.728987455368042, 0.8292034268379211, 0.5386955738067627, 0.5767128467559814, 0.5373210310935974, 0.4407860040664673, 0.6934518218040466, 0.8280807137489319, 0.881849467754364, 0.9297210574150085, 0.003537696786224842], [0.21592846512794495, 0.6816455721855164, 0.5291357636451721, 0.4269404411315918, 0.30004438757896423, 0.43163231015205383, 0.6239737868309021, 0.7266546487808228, 0.8240258693695068, 0.5272342562675476, 0.571440577507019, 0.5368217825889587, 0.43919479846954346, 0.6816455721855164, 0.8201373815536499, 0.8760429620742798, 0.9234768152236938, 0.00359295099042356]]
average_result:  [0.22139430046081543, 0.6731727004051209, 0.5202561855316162, 0.41734354496002196, 0.29493007659912107, 0.42717968821525576, 0.6162605524063111, 0.7148522019386292, 0.8138672471046448, 0.5213178038597107, 0.5629873752593995, 0.5259982347488403, 0.43224971890449526, 0.6731727004051209, 0.814032506942749, 0.8699502587318421, 0.9191692471504211, 0.0036326506175100803]
2024-06-04 12:52:05,002 : INFO : =======End=======
