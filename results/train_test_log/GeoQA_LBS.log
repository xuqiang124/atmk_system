/home/dzq/anaconda3/envs/k121/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
/home/dzq/anaconda3/envs/k121/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). 
 The versions of TensorFlow you are currently using is 2.7.0 and is not supported. 
Some things might work, some things might not.
If you were to encounter a bug, do not file an issue.
If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. 
You can find the compatibility matrix in TensorFlow Addon's readme:
https://github.com/tensorflow/addons
  warnings.warn(
2024-06-04 11:41:44,947 : INFO : Loading config...
2024-06-04 11:41:44,948 : INFO : {'cache_file_h5py': '../file_data/a7/math_data.h5', 'cache_file_pickle': '../file_data/a7/vocab_label.pkl', 'embeddings': '../file_data/a7/embeddings.pkl', 'maxlen': 120, 'emb_size': 300, 'epochs': 100, 'batch_size': 256, 'alpha': 4, 'hidden_size': 512, 'num_classes_list': [49], 'l_patience': 2, 'b_patience': 3}
2024-06-04 11:41:44,948 : INFO : Loading data...
2024-06-04 11:41:44,952 : INFO : Loading embeddings...
2024-06-04 11:41:44,955 : INFO : model name lbs
TOTAL: 4950 TRAIN: [[3325 1645 3528 ...    0    0    0]
 [3325 1645 2529 ...    0    0    0]
 [1732 1399  586 ...    0    0    0]
 ...
 [ 607 2529  281 ...    0    0    0]
 [3325 1645  607 ...    0    0    0]
 [2899 1645  924 ...    0    0    0]] 3712 TEST: [[3325 1645 1109 ...    0    0    0]
 [2899 1645  607 ...    0    0    0]
 [3325 1645  554 ...    0    0    0]
 ...
 [1109 1645 3325 ...    0    0    0]
 [3325 1645 2529 ...    0    0    0]
 [3325 1645  607 ...    0    0    0]] 1238
2024-06-04 11:41:44,958 : INFO : =====Start final=====
2969
743
1238
2024-06-04 11:41:44.994562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 11:41:45.016596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 11:41:45.016698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 11:41:45.016908: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-04 11:41:45.018675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 11:41:45.018768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 11:41:45.018825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 11:41:45.347363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 11:41:45.347490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 11:41:45.347556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-06-04 11:41:45.347626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22102 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 text_input (InputLayer)        [(None, 120)]        0           []                               
                                                                                                  
 text_emb (Embedding)           (None, 120, 300)     1064400     ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_input (InputLayer)       [(None, 49)]         0           []                               
                                                                                                  
 pred_probs (Dense)             (None, 49)           50225       ['BiLSTM[0][0]']                 
                                                                                                  
==================================================================================================
Total params: 4,444,673
Trainable params: 3,380,273
Non-trainable params: 1,064,400
__________________________________________________________________________________________________
None
2 patience
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 49)]         0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 120)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 49, 300)      14700       ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 120, 300)     1064400     ['text_input[0][0]']             
                                                                                                  
 tf.__operators__.getitem (Slic  (None, 49, 300)     0           ['label_emb[0][0]']              
 ingOpLambda)                                                                                     
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_lcm_emb (Dense)          (None, 49, 1024)     308224      ['tf.__operators__.getitem[0][0]'
                                                                 ]                                
                                                                                                  
 dot (Dot)                      (None, 49)           0           ['label_lcm_emb[0][0]',          
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 pred_probs (Dense)             (None, 49)           50225       ['BiLSTM[0][0]']                 
                                                                                                  
 label_sim_dict (Dense)         (None, 49)           2450        ['dot[0][0]']                    
                                                                                                  
 concatenate (Concatenate)      (None, 98)           0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 4,770,047
Trainable params: 3,705,647
Non-trainable params: 1,064,400
__________________________________________________________________________________________________
None
Epoch 1/100
2024-06-04 11:41:48.277632: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2024-06-04 11:41:48.314368: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8906
12/12 [==============================] - ETA: 0s - loss: 1.3596 - lcm_precision_1k: 0.2736 - lcm_precision_2k: 0.2231 - lcm_precision_3k: 0.1898 - lcm_precision_5k: 0.1595 - lcm_recall_1k: 0.1361 - lcm_recall_2k: 0.2272 - lcm_recall_3k: 0.3118 - lcm_recall_5k: 0.4151 - lcm_f1_1k: 0.1818 - lcm_f1_2k: 0.2251 - lcm_f1_3k: 0.2359 - lcm_f1_5k: 0.2304 - lcm_accuracy_1k: 0.2736 - lcm_accuracy_2k: 0.4398 - lcm_accuracy_3k: 0.5419 - lcm_accuracy_5k: 0.6767 - lcm_hamming_loss_k: 0.0518
Epoch 00001: val_loss improved from inf to 1.28199, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 4s 104ms/step - loss: 1.3596 - lcm_precision_1k: 0.2736 - lcm_precision_2k: 0.2231 - lcm_precision_3k: 0.1898 - lcm_precision_5k: 0.1595 - lcm_recall_1k: 0.1361 - lcm_recall_2k: 0.2272 - lcm_recall_3k: 0.3118 - lcm_recall_5k: 0.4151 - lcm_f1_1k: 0.1818 - lcm_f1_2k: 0.2251 - lcm_f1_3k: 0.2359 - lcm_f1_5k: 0.2304 - lcm_accuracy_1k: 0.2736 - lcm_accuracy_2k: 0.4398 - lcm_accuracy_3k: 0.5419 - lcm_accuracy_5k: 0.6767 - lcm_hamming_loss_k: 0.0518 - val_loss: 1.2820 - val_lcm_precision_1k: 0.2976 - val_lcm_precision_2k: 0.2430 - val_lcm_precision_3k: 0.2010 - val_lcm_precision_5k: 0.1762 - val_lcm_recall_1k: 0.1514 - val_lcm_recall_2k: 0.2462 - val_lcm_recall_3k: 0.3336 - val_lcm_recall_5k: 0.4547 - val_lcm_f1_1k: 0.2000 - val_lcm_f1_2k: 0.2434 - val_lcm_f1_3k: 0.2506 - val_lcm_f1_5k: 0.2538 - val_lcm_accuracy_1k: 0.2976 - val_lcm_accuracy_2k: 0.4809 - val_lcm_accuracy_3k: 0.5794 - val_lcm_accuracy_5k: 0.7337 - val_lcm_hamming_loss_k: 0.0515
Epoch 2/100
12/12 [==============================] - ETA: 0s - loss: 1.2755 - lcm_precision_1k: 0.2797 - lcm_precision_2k: 0.2310 - lcm_precision_3k: 0.1910 - lcm_precision_5k: 0.1698 - lcm_recall_1k: 0.1397 - lcm_recall_2k: 0.2336 - lcm_recall_3k: 0.3151 - lcm_recall_5k: 0.4394 - lcm_f1_1k: 0.1863 - lcm_f1_2k: 0.2322 - lcm_f1_3k: 0.2378 - lcm_f1_5k: 0.2449 - lcm_accuracy_1k: 0.2797 - lcm_accuracy_2k: 0.4544 - lcm_accuracy_3k: 0.5499 - lcm_accuracy_5k: 0.7080 - lcm_hamming_loss_k: 0.0515
Epoch 00002: val_loss improved from 1.28199 to 1.25522, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 74ms/step - loss: 1.2755 - lcm_precision_1k: 0.2797 - lcm_precision_2k: 0.2310 - lcm_precision_3k: 0.1910 - lcm_precision_5k: 0.1698 - lcm_recall_1k: 0.1397 - lcm_recall_2k: 0.2336 - lcm_recall_3k: 0.3151 - lcm_recall_5k: 0.4394 - lcm_f1_1k: 0.1863 - lcm_f1_2k: 0.2322 - lcm_f1_3k: 0.2378 - lcm_f1_5k: 0.2449 - lcm_accuracy_1k: 0.2797 - lcm_accuracy_2k: 0.4544 - lcm_accuracy_3k: 0.5499 - lcm_accuracy_5k: 0.7080 - lcm_hamming_loss_k: 0.0515 - val_loss: 1.2552 - val_lcm_precision_1k: 0.3045 - val_lcm_precision_2k: 0.2430 - val_lcm_precision_3k: 0.2010 - val_lcm_precision_5k: 0.1780 - val_lcm_recall_1k: 0.1561 - val_lcm_recall_2k: 0.2462 - val_lcm_recall_3k: 0.3336 - val_lcm_recall_5k: 0.4455 - val_lcm_f1_1k: 0.2057 - val_lcm_f1_2k: 0.2434 - val_lcm_f1_3k: 0.2506 - val_lcm_f1_5k: 0.2541 - val_lcm_accuracy_1k: 0.3045 - val_lcm_accuracy_2k: 0.4809 - val_lcm_accuracy_3k: 0.5794 - val_lcm_accuracy_5k: 0.7419 - val_lcm_hamming_loss_k: 0.0512
Epoch 3/100
12/12 [==============================] - ETA: 0s - loss: 1.2332 - lcm_precision_1k: 0.3063 - lcm_precision_2k: 0.2305 - lcm_precision_3k: 0.2164 - lcm_precision_5k: 0.1897 - lcm_recall_1k: 0.1543 - lcm_recall_2k: 0.2326 - lcm_recall_3k: 0.3444 - lcm_recall_5k: 0.4859 - lcm_f1_1k: 0.2052 - lcm_f1_2k: 0.2315 - lcm_f1_3k: 0.2656 - lcm_f1_5k: 0.2727 - lcm_accuracy_1k: 0.3063 - lcm_accuracy_2k: 0.4535 - lcm_accuracy_3k: 0.5741 - lcm_accuracy_5k: 0.7183 - lcm_hamming_loss_k: 0.0504
Epoch 00003: val_loss improved from 1.25522 to 1.18195, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 78ms/step - loss: 1.2332 - lcm_precision_1k: 0.3063 - lcm_precision_2k: 0.2305 - lcm_precision_3k: 0.2164 - lcm_precision_5k: 0.1897 - lcm_recall_1k: 0.1543 - lcm_recall_2k: 0.2326 - lcm_recall_3k: 0.3444 - lcm_recall_5k: 0.4859 - lcm_f1_1k: 0.2052 - lcm_f1_2k: 0.2315 - lcm_f1_3k: 0.2656 - lcm_f1_5k: 0.2727 - lcm_accuracy_1k: 0.3063 - lcm_accuracy_2k: 0.4535 - lcm_accuracy_3k: 0.5741 - lcm_accuracy_5k: 0.7183 - lcm_hamming_loss_k: 0.0504 - val_loss: 1.1819 - val_lcm_precision_1k: 0.2976 - val_lcm_precision_2k: 0.2437 - val_lcm_precision_3k: 0.2491 - val_lcm_precision_5k: 0.2221 - val_lcm_recall_1k: 0.1514 - val_lcm_recall_2k: 0.2476 - val_lcm_recall_3k: 0.3657 - val_lcm_recall_5k: 0.5568 - val_lcm_f1_1k: 0.2000 - val_lcm_f1_2k: 0.2446 - val_lcm_f1_3k: 0.2955 - val_lcm_f1_5k: 0.3173 - val_lcm_accuracy_1k: 0.2976 - val_lcm_accuracy_2k: 0.4824 - val_lcm_accuracy_3k: 0.6153 - val_lcm_accuracy_5k: 0.7778 - val_lcm_hamming_loss_k: 0.0515
Epoch 4/100
11/12 [==========================>...] - ETA: 0s - loss: 1.1229 - lcm_precision_1k: 0.2773 - lcm_precision_2k: 0.2745 - lcm_precision_3k: 0.2707 - lcm_precision_5k: 0.2256 - lcm_recall_1k: 0.1371 - lcm_recall_2k: 0.2814 - lcm_recall_3k: 0.4178 - lcm_recall_5k: 0.5811 - lcm_f1_1k: 0.1833 - lcm_f1_2k: 0.2776 - lcm_f1_3k: 0.3283 - lcm_f1_5k: 0.3249 - lcm_accuracy_1k: 0.2773 - lcm_accuracy_2k: 0.5103 - lcm_accuracy_3k: 0.6502 - lcm_accuracy_5k: 0.7894 - lcm_hamming_loss_k: 0.0519
Epoch 00004: val_loss improved from 1.18195 to 1.07700, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 78ms/step - loss: 1.1195 - lcm_precision_1k: 0.2727 - lcm_precision_2k: 0.2767 - lcm_precision_3k: 0.2710 - lcm_precision_5k: 0.2260 - lcm_recall_1k: 0.1368 - lcm_recall_2k: 0.2900 - lcm_recall_3k: 0.4251 - lcm_recall_5k: 0.5875 - lcm_f1_1k: 0.1820 - lcm_f1_2k: 0.2827 - lcm_f1_3k: 0.3306 - lcm_f1_5k: 0.3263 - lcm_accuracy_1k: 0.2727 - lcm_accuracy_2k: 0.5163 - lcm_accuracy_3k: 0.6543 - lcm_accuracy_5k: 0.7917 - lcm_hamming_loss_k: 0.0517 - val_loss: 1.0770 - val_lcm_precision_1k: 0.2989 - val_lcm_precision_2k: 0.3356 - val_lcm_precision_3k: 0.2970 - val_lcm_precision_5k: 0.2322 - val_lcm_recall_1k: 0.1518 - val_lcm_recall_2k: 0.3559 - val_lcm_recall_3k: 0.4742 - val_lcm_recall_5k: 0.6000 - val_lcm_f1_1k: 0.2007 - val_lcm_f1_2k: 0.3448 - val_lcm_f1_3k: 0.3650 - val_lcm_f1_5k: 0.3346 - val_lcm_accuracy_1k: 0.2989 - val_lcm_accuracy_2k: 0.5919 - val_lcm_accuracy_3k: 0.6874 - val_lcm_accuracy_5k: 0.7984 - val_lcm_hamming_loss_k: 0.0514
Epoch 5/100
11/12 [==========================>...] - ETA: 0s - loss: 1.0435 - lcm_precision_1k: 0.3494 - lcm_precision_2k: 0.3375 - lcm_precision_3k: 0.3030 - lcm_precision_5k: 0.2450 - lcm_recall_1k: 0.1823 - lcm_recall_2k: 0.3712 - lcm_recall_3k: 0.4877 - lcm_recall_5k: 0.6297 - lcm_f1_1k: 0.2394 - lcm_f1_2k: 0.3534 - lcm_f1_3k: 0.3737 - lcm_f1_5k: 0.3526 - lcm_accuracy_1k: 0.3494 - lcm_accuracy_2k: 0.5881 - lcm_accuracy_3k: 0.7024 - lcm_accuracy_5k: 0.8189 - lcm_hamming_loss_k: 0.0486
Epoch 00005: val_loss improved from 1.07700 to 0.96210, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 75ms/step - loss: 1.0397 - lcm_precision_1k: 0.3639 - lcm_precision_2k: 0.3448 - lcm_precision_3k: 0.3075 - lcm_precision_5k: 0.2459 - lcm_recall_1k: 0.1903 - lcm_recall_2k: 0.3755 - lcm_recall_3k: 0.4913 - lcm_recall_5k: 0.6280 - lcm_f1_1k: 0.2497 - lcm_f1_2k: 0.3593 - lcm_f1_3k: 0.3781 - lcm_f1_5k: 0.3533 - lcm_accuracy_1k: 0.3639 - lcm_accuracy_2k: 0.5941 - lcm_accuracy_3k: 0.7071 - lcm_accuracy_5k: 0.8176 - lcm_hamming_loss_k: 0.0482 - val_loss: 0.9621 - val_lcm_precision_1k: 0.5315 - val_lcm_precision_2k: 0.4538 - val_lcm_precision_3k: 0.3730 - val_lcm_precision_5k: 0.2776 - val_lcm_recall_1k: 0.2816 - val_lcm_recall_2k: 0.4886 - val_lcm_recall_3k: 0.5870 - val_lcm_recall_5k: 0.7005 - val_lcm_f1_1k: 0.3669 - val_lcm_f1_2k: 0.4703 - val_lcm_f1_3k: 0.4557 - val_lcm_f1_5k: 0.3972 - val_lcm_accuracy_1k: 0.5315 - val_lcm_accuracy_2k: 0.7059 - val_lcm_accuracy_3k: 0.7983 - val_lcm_accuracy_5k: 0.8828 - val_lcm_hamming_loss_k: 0.0419
Epoch 6/100
11/12 [==========================>...] - ETA: 0s - loss: 0.9112 - lcm_precision_1k: 0.5387 - lcm_precision_2k: 0.4490 - lcm_precision_3k: 0.3699 - lcm_precision_5k: 0.2780 - lcm_recall_1k: 0.3016 - lcm_recall_2k: 0.4871 - lcm_recall_3k: 0.5851 - lcm_recall_5k: 0.7022 - lcm_f1_1k: 0.3864 - lcm_f1_2k: 0.4671 - lcm_f1_3k: 0.4532 - lcm_f1_5k: 0.3982 - lcm_accuracy_1k: 0.5387 - lcm_accuracy_2k: 0.7184 - lcm_accuracy_3k: 0.7944 - lcm_accuracy_5k: 0.8693 - lcm_hamming_loss_k: 0.0410
Epoch 00006: val_loss did not improve from 0.96210
12/12 [==============================] - 1s 62ms/step - loss: 0.9113 - lcm_precision_1k: 0.5412 - lcm_precision_2k: 0.4470 - lcm_precision_3k: 0.3681 - lcm_precision_5k: 0.2774 - lcm_recall_1k: 0.3046 - lcm_recall_2k: 0.4858 - lcm_recall_3k: 0.5832 - lcm_recall_5k: 0.7016 - lcm_f1_1k: 0.3895 - lcm_f1_2k: 0.4654 - lcm_f1_3k: 0.4513 - lcm_f1_5k: 0.3975 - lcm_accuracy_1k: 0.5412 - lcm_accuracy_2k: 0.7157 - lcm_accuracy_3k: 0.7914 - lcm_accuracy_5k: 0.8682 - lcm_hamming_loss_k: 0.0409 - val_loss: 1.0082 - val_lcm_precision_1k: 0.5143 - val_lcm_precision_2k: 0.4190 - val_lcm_precision_3k: 0.3282 - val_lcm_precision_5k: 0.2499 - val_lcm_recall_1k: 0.2904 - val_lcm_recall_2k: 0.4445 - val_lcm_recall_3k: 0.5082 - val_lcm_recall_5k: 0.6305 - val_lcm_f1_1k: 0.3708 - val_lcm_f1_2k: 0.4310 - val_lcm_f1_3k: 0.3985 - val_lcm_f1_5k: 0.3578 - val_lcm_accuracy_1k: 0.5143 - val_lcm_accuracy_2k: 0.6664 - val_lcm_accuracy_3k: 0.7286 - val_lcm_accuracy_5k: 0.8176 - val_lcm_hamming_loss_k: 0.0426
Epoch 7/100
11/12 [==========================>...] - ETA: 0s - loss: 0.8420 - lcm_precision_1k: 0.6119 - lcm_precision_2k: 0.4897 - lcm_precision_3k: 0.3980 - lcm_precision_5k: 0.2873 - lcm_recall_1k: 0.3492 - lcm_recall_2k: 0.5306 - lcm_recall_3k: 0.6242 - lcm_recall_5k: 0.7242 - lcm_f1_1k: 0.4444 - lcm_f1_2k: 0.5093 - lcm_f1_3k: 0.4860 - lcm_f1_5k: 0.4113 - lcm_accuracy_1k: 0.6119 - lcm_accuracy_2k: 0.7614 - lcm_accuracy_3k: 0.8260 - lcm_accuracy_5k: 0.8821 - lcm_hamming_loss_k: 0.0378
Epoch 00007: val_loss improved from 0.96210 to 0.81534, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 74ms/step - loss: 0.8401 - lcm_precision_1k: 0.6153 - lcm_precision_2k: 0.4919 - lcm_precision_3k: 0.4000 - lcm_precision_5k: 0.2901 - lcm_recall_1k: 0.3494 - lcm_recall_2k: 0.5294 - lcm_recall_3k: 0.6237 - lcm_recall_5k: 0.7265 - lcm_f1_1k: 0.4455 - lcm_f1_2k: 0.5098 - lcm_f1_3k: 0.4873 - lcm_f1_5k: 0.4146 - lcm_accuracy_1k: 0.6153 - lcm_accuracy_2k: 0.7616 - lcm_accuracy_3k: 0.8280 - lcm_accuracy_5k: 0.8854 - lcm_hamming_loss_k: 0.0379 - val_loss: 0.8153 - val_lcm_precision_1k: 0.6412 - val_lcm_precision_2k: 0.5171 - val_lcm_precision_3k: 0.4108 - val_lcm_precision_5k: 0.3028 - val_lcm_recall_1k: 0.3728 - val_lcm_recall_2k: 0.5547 - val_lcm_recall_3k: 0.6416 - val_lcm_recall_5k: 0.7613 - val_lcm_f1_1k: 0.4713 - val_lcm_f1_2k: 0.5350 - val_lcm_f1_3k: 0.5004 - val_lcm_f1_5k: 0.4328 - val_lcm_accuracy_1k: 0.6412 - val_lcm_accuracy_2k: 0.7975 - val_lcm_accuracy_3k: 0.8576 - val_lcm_accuracy_5k: 0.9208 - val_lcm_hamming_loss_k: 0.0375
Epoch 8/100
11/12 [==========================>...] - ETA: 0s - loss: 0.7628 - lcm_precision_1k: 0.6602 - lcm_precision_2k: 0.5256 - lcm_precision_3k: 0.4202 - lcm_precision_5k: 0.3094 - lcm_recall_1k: 0.3779 - lcm_recall_2k: 0.5610 - lcm_recall_3k: 0.6533 - lcm_recall_5k: 0.7713 - lcm_f1_1k: 0.4805 - lcm_f1_2k: 0.5426 - lcm_f1_3k: 0.5114 - lcm_f1_5k: 0.4416 - lcm_accuracy_1k: 0.6602 - lcm_accuracy_2k: 0.7919 - lcm_accuracy_3k: 0.8516 - lcm_accuracy_5k: 0.9105 - lcm_hamming_loss_k: 0.0362
Epoch 00008: val_loss improved from 0.81534 to 0.72264, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 73ms/step - loss: 0.7618 - lcm_precision_1k: 0.6612 - lcm_precision_2k: 0.5270 - lcm_precision_3k: 0.4192 - lcm_precision_5k: 0.3066 - lcm_recall_1k: 0.3814 - lcm_recall_2k: 0.5663 - lcm_recall_3k: 0.6560 - lcm_recall_5k: 0.7696 - lcm_f1_1k: 0.4836 - lcm_f1_2k: 0.5458 - lcm_f1_3k: 0.5114 - lcm_f1_5k: 0.4385 - lcm_accuracy_1k: 0.6612 - lcm_accuracy_2k: 0.7929 - lcm_accuracy_3k: 0.8514 - lcm_accuracy_5k: 0.9071 - lcm_hamming_loss_k: 0.0358 - val_loss: 0.7226 - val_lcm_precision_1k: 0.6928 - val_lcm_precision_2k: 0.5498 - val_lcm_precision_3k: 0.4430 - val_lcm_precision_5k: 0.3213 - val_lcm_recall_1k: 0.3910 - val_lcm_recall_2k: 0.5791 - val_lcm_recall_3k: 0.6785 - val_lcm_recall_5k: 0.7891 - val_lcm_f1_1k: 0.4994 - val_lcm_f1_2k: 0.5634 - val_lcm_f1_3k: 0.5353 - val_lcm_f1_5k: 0.4561 - val_lcm_accuracy_1k: 0.6928 - val_lcm_accuracy_2k: 0.8185 - val_lcm_accuracy_3k: 0.8749 - val_lcm_accuracy_5k: 0.9260 - val_lcm_hamming_loss_k: 0.0353
Epoch 9/100
11/12 [==========================>...] - ETA: 0s - loss: 0.7034 - lcm_precision_1k: 0.6992 - lcm_precision_2k: 0.5487 - lcm_precision_3k: 0.4390 - lcm_precision_5k: 0.3198 - lcm_recall_1k: 0.4035 - lcm_recall_2k: 0.5873 - lcm_recall_3k: 0.6832 - lcm_recall_5k: 0.8024 - lcm_f1_1k: 0.5115 - lcm_f1_2k: 0.5672 - lcm_f1_3k: 0.5345 - lcm_f1_5k: 0.4572 - lcm_accuracy_1k: 0.6992 - lcm_accuracy_2k: 0.8171 - lcm_accuracy_3k: 0.8690 - lcm_accuracy_5k: 0.9272 - lcm_hamming_loss_k: 0.0343
Epoch 00009: val_loss improved from 0.72264 to 0.68861, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 84ms/step - loss: 0.7005 - lcm_precision_1k: 0.7063 - lcm_precision_2k: 0.5544 - lcm_precision_3k: 0.4435 - lcm_precision_5k: 0.3214 - lcm_recall_1k: 0.4066 - lcm_recall_2k: 0.5917 - lcm_recall_3k: 0.6885 - lcm_recall_5k: 0.8043 - lcm_f1_1k: 0.5159 - lcm_f1_2k: 0.5723 - lcm_f1_3k: 0.5394 - lcm_f1_5k: 0.4592 - lcm_accuracy_1k: 0.7063 - lcm_accuracy_2k: 0.8225 - lcm_accuracy_3k: 0.8755 - lcm_accuracy_5k: 0.9316 - lcm_hamming_loss_k: 0.0342 - val_loss: 0.6886 - val_lcm_precision_1k: 0.6975 - val_lcm_precision_2k: 0.5659 - val_lcm_precision_3k: 0.4554 - val_lcm_precision_5k: 0.3252 - val_lcm_recall_1k: 0.4015 - val_lcm_recall_2k: 0.5996 - val_lcm_recall_3k: 0.6993 - val_lcm_recall_5k: 0.8043 - val_lcm_f1_1k: 0.5095 - val_lcm_f1_2k: 0.5815 - val_lcm_f1_3k: 0.5508 - val_lcm_f1_5k: 0.4625 - val_lcm_accuracy_1k: 0.6975 - val_lcm_accuracy_2k: 0.8302 - val_lcm_accuracy_3k: 0.8828 - val_lcm_accuracy_5k: 0.9303 - val_lcm_hamming_loss_k: 0.0352
Epoch 10/100
11/12 [==========================>...] - ETA: 0s - loss: 0.6493 - lcm_precision_1k: 0.7351 - lcm_precision_2k: 0.5847 - lcm_precision_3k: 0.4689 - lcm_precision_5k: 0.3308 - lcm_recall_1k: 0.4228 - lcm_recall_2k: 0.6193 - lcm_recall_3k: 0.7250 - lcm_recall_5k: 0.8292 - lcm_f1_1k: 0.5366 - lcm_f1_2k: 0.6013 - lcm_f1_3k: 0.5693 - lcm_f1_5k: 0.4728 - lcm_accuracy_1k: 0.7351 - lcm_accuracy_2k: 0.8480 - lcm_accuracy_3k: 0.8992 - lcm_accuracy_5k: 0.9474 - lcm_hamming_loss_k: 0.0329
Epoch 00010: val_loss improved from 0.68861 to 0.64804, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 75ms/step - loss: 0.6469 - lcm_precision_1k: 0.7403 - lcm_precision_2k: 0.5885 - lcm_precision_3k: 0.4714 - lcm_precision_5k: 0.3318 - lcm_recall_1k: 0.4255 - lcm_recall_2k: 0.6237 - lcm_recall_3k: 0.7280 - lcm_recall_5k: 0.8299 - lcm_f1_1k: 0.5402 - lcm_f1_2k: 0.6054 - lcm_f1_3k: 0.5720 - lcm_f1_5k: 0.4739 - lcm_accuracy_1k: 0.7403 - lcm_accuracy_2k: 0.8514 - lcm_accuracy_3k: 0.9010 - lcm_accuracy_5k: 0.9475 - lcm_hamming_loss_k: 0.0328 - val_loss: 0.6480 - val_lcm_precision_1k: 0.7458 - val_lcm_precision_2k: 0.5764 - val_lcm_precision_3k: 0.4657 - val_lcm_precision_5k: 0.3384 - val_lcm_recall_1k: 0.4316 - val_lcm_recall_2k: 0.6091 - val_lcm_recall_3k: 0.7067 - val_lcm_recall_5k: 0.8365 - val_lcm_f1_1k: 0.5465 - val_lcm_f1_2k: 0.5917 - val_lcm_f1_3k: 0.5608 - val_lcm_f1_5k: 0.4814 - val_lcm_accuracy_1k: 0.7458 - val_lcm_accuracy_2k: 0.8589 - val_lcm_accuracy_3k: 0.8959 - val_lcm_accuracy_5k: 0.9580 - val_lcm_hamming_loss_k: 0.0332
Epoch 11/100
11/12 [==========================>...] - ETA: 0s - loss: 0.6112 - lcm_precision_1k: 0.7603 - lcm_precision_2k: 0.5999 - lcm_precision_3k: 0.4807 - lcm_precision_5k: 0.3394 - lcm_recall_1k: 0.4401 - lcm_recall_2k: 0.6373 - lcm_recall_3k: 0.7427 - lcm_recall_5k: 0.8491 - lcm_f1_1k: 0.5575 - lcm_f1_2k: 0.6180 - lcm_f1_3k: 0.5836 - lcm_f1_5k: 0.4849 - lcm_accuracy_1k: 0.7603 - lcm_accuracy_2k: 0.8665 - lcm_accuracy_3k: 0.9151 - lcm_accuracy_5k: 0.9581 - lcm_hamming_loss_k: 0.0319
Epoch 00011: val_loss improved from 0.64804 to 0.63958, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 79ms/step - loss: 0.6102 - lcm_precision_1k: 0.7656 - lcm_precision_2k: 0.6028 - lcm_precision_3k: 0.4832 - lcm_precision_5k: 0.3402 - lcm_recall_1k: 0.4405 - lcm_recall_2k: 0.6377 - lcm_recall_3k: 0.7444 - lcm_recall_5k: 0.8498 - lcm_f1_1k: 0.5591 - lcm_f1_2k: 0.6197 - lcm_f1_3k: 0.5859 - lcm_f1_5k: 0.4858 - lcm_accuracy_1k: 0.7656 - lcm_accuracy_2k: 0.8673 - lcm_accuracy_3k: 0.9157 - lcm_accuracy_5k: 0.9572 - lcm_hamming_loss_k: 0.0317 - val_loss: 0.6396 - val_lcm_precision_1k: 0.7497 - val_lcm_precision_2k: 0.5985 - val_lcm_precision_3k: 0.4762 - val_lcm_precision_5k: 0.3418 - val_lcm_recall_1k: 0.4217 - val_lcm_recall_2k: 0.6209 - val_lcm_recall_3k: 0.7270 - val_lcm_recall_5k: 0.8422 - val_lcm_f1_1k: 0.5392 - val_lcm_f1_2k: 0.6086 - val_lcm_f1_3k: 0.5749 - val_lcm_f1_5k: 0.4857 - val_lcm_accuracy_1k: 0.7497 - val_lcm_accuracy_2k: 0.8447 - val_lcm_accuracy_3k: 0.9016 - val_lcm_accuracy_5k: 0.9552 - val_lcm_hamming_loss_k: 0.0330
Epoch 12/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5867 - lcm_precision_1k: 0.7709 - lcm_precision_2k: 0.6144 - lcm_precision_3k: 0.4909 - lcm_precision_5k: 0.3439 - lcm_recall_1k: 0.4438 - lcm_recall_2k: 0.6535 - lcm_recall_3k: 0.7614 - lcm_recall_5k: 0.8620 - lcm_f1_1k: 0.5632 - lcm_f1_2k: 0.6333 - lcm_f1_3k: 0.5969 - lcm_f1_5k: 0.4916 - lcm_accuracy_1k: 0.7709 - lcm_accuracy_2k: 0.8800 - lcm_accuracy_3k: 0.9251 - lcm_accuracy_5k: 0.9652 - lcm_hamming_loss_k: 0.0314
Epoch 00012: val_loss improved from 0.63958 to 0.61740, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 82ms/step - loss: 0.5890 - lcm_precision_1k: 0.7710 - lcm_precision_2k: 0.6119 - lcm_precision_3k: 0.4912 - lcm_precision_5k: 0.3444 - lcm_recall_1k: 0.4435 - lcm_recall_2k: 0.6504 - lcm_recall_3k: 0.7603 - lcm_recall_5k: 0.8617 - lcm_f1_1k: 0.5630 - lcm_f1_2k: 0.6305 - lcm_f1_3k: 0.5967 - lcm_f1_5k: 0.4921 - lcm_accuracy_1k: 0.7710 - lcm_accuracy_2k: 0.8807 - lcm_accuracy_3k: 0.9264 - lcm_accuracy_5k: 0.9665 - lcm_hamming_loss_k: 0.0315 - val_loss: 0.6174 - val_lcm_precision_1k: 0.7655 - val_lcm_precision_2k: 0.6029 - val_lcm_precision_3k: 0.4848 - val_lcm_precision_5k: 0.3393 - val_lcm_recall_1k: 0.4371 - val_lcm_recall_2k: 0.6291 - val_lcm_recall_3k: 0.7368 - val_lcm_recall_5k: 0.8353 - val_lcm_f1_1k: 0.5561 - val_lcm_f1_2k: 0.6148 - val_lcm_f1_3k: 0.5840 - val_lcm_f1_5k: 0.4820 - val_lcm_accuracy_1k: 0.7655 - val_lcm_accuracy_2k: 0.8711 - val_lcm_accuracy_3k: 0.9189 - val_lcm_accuracy_5k: 0.9513 - val_lcm_hamming_loss_k: 0.0324
Epoch 13/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5746 - lcm_precision_1k: 0.7852 - lcm_precision_2k: 0.6238 - lcm_precision_3k: 0.4963 - lcm_precision_5k: 0.3473 - lcm_recall_1k: 0.4531 - lcm_recall_2k: 0.6649 - lcm_recall_3k: 0.7695 - lcm_recall_5k: 0.8699 - lcm_f1_1k: 0.5744 - lcm_f1_2k: 0.6435 - lcm_f1_3k: 0.6033 - lcm_f1_5k: 0.4963 - lcm_accuracy_1k: 0.7852 - lcm_accuracy_2k: 0.8874 - lcm_accuracy_3k: 0.9336 - lcm_accuracy_5k: 0.9702 - lcm_hamming_loss_k: 0.0309
Epoch 00013: val_loss improved from 0.61740 to 0.60922, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 81ms/step - loss: 0.5745 - lcm_precision_1k: 0.7856 - lcm_precision_2k: 0.6238 - lcm_precision_3k: 0.4971 - lcm_precision_5k: 0.3470 - lcm_recall_1k: 0.4547 - lcm_recall_2k: 0.6654 - lcm_recall_3k: 0.7704 - lcm_recall_5k: 0.8688 - lcm_f1_1k: 0.5758 - lcm_f1_2k: 0.6437 - lcm_f1_3k: 0.6041 - lcm_f1_5k: 0.4958 - lcm_accuracy_1k: 0.7856 - lcm_accuracy_2k: 0.8887 - lcm_accuracy_3k: 0.9337 - lcm_accuracy_5k: 0.9688 - lcm_hamming_loss_k: 0.0309 - val_loss: 0.6092 - val_lcm_precision_1k: 0.7678 - val_lcm_precision_2k: 0.6124 - val_lcm_precision_3k: 0.4896 - val_lcm_precision_5k: 0.3458 - val_lcm_recall_1k: 0.4348 - val_lcm_recall_2k: 0.6360 - val_lcm_recall_3k: 0.7346 - val_lcm_recall_5k: 0.8479 - val_lcm_f1_1k: 0.5549 - val_lcm_f1_2k: 0.6232 - val_lcm_f1_3k: 0.5869 - val_lcm_f1_5k: 0.4907 - val_lcm_accuracy_1k: 0.7678 - val_lcm_accuracy_2k: 0.8724 - val_lcm_accuracy_3k: 0.9014 - val_lcm_accuracy_5k: 0.9541 - val_lcm_hamming_loss_k: 0.0323
Epoch 14/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5483 - lcm_precision_1k: 0.8072 - lcm_precision_2k: 0.6360 - lcm_precision_3k: 0.5048 - lcm_precision_5k: 0.3512 - lcm_recall_1k: 0.4638 - lcm_recall_2k: 0.6743 - lcm_recall_3k: 0.7797 - lcm_recall_5k: 0.8777 - lcm_f1_1k: 0.5890 - lcm_f1_2k: 0.6545 - lcm_f1_3k: 0.6128 - lcm_f1_5k: 0.5017 - lcm_accuracy_1k: 0.8072 - lcm_accuracy_2k: 0.8942 - lcm_accuracy_3k: 0.9386 - lcm_accuracy_5k: 0.9713 - lcm_hamming_loss_k: 0.0300
Epoch 00014: val_loss improved from 0.60922 to 0.58202, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 76ms/step - loss: 0.5469 - lcm_precision_1k: 0.8069 - lcm_precision_2k: 0.6367 - lcm_precision_3k: 0.5053 - lcm_precision_5k: 0.3515 - lcm_recall_1k: 0.4651 - lcm_recall_2k: 0.6768 - lcm_recall_3k: 0.7818 - lcm_recall_5k: 0.8797 - lcm_f1_1k: 0.5900 - lcm_f1_2k: 0.6560 - lcm_f1_3k: 0.6137 - lcm_f1_5k: 0.5022 - lcm_accuracy_1k: 0.8069 - lcm_accuracy_2k: 0.8965 - lcm_accuracy_3k: 0.9399 - lcm_accuracy_5k: 0.9731 - lcm_hamming_loss_k: 0.0300 - val_loss: 0.5820 - val_lcm_precision_1k: 0.7838 - val_lcm_precision_2k: 0.6219 - val_lcm_precision_3k: 0.5046 - val_lcm_precision_5k: 0.3510 - val_lcm_recall_1k: 0.4444 - val_lcm_recall_2k: 0.6518 - val_lcm_recall_3k: 0.7603 - val_lcm_recall_5k: 0.8579 - val_lcm_f1_1k: 0.5668 - val_lcm_f1_2k: 0.6357 - val_lcm_f1_3k: 0.6059 - val_lcm_f1_5k: 0.4976 - val_lcm_accuracy_1k: 0.7838 - val_lcm_accuracy_2k: 0.8782 - val_lcm_accuracy_3k: 0.9244 - val_lcm_accuracy_5k: 0.9556 - val_lcm_hamming_loss_k: 0.0316
Epoch 15/100
12/12 [==============================] - ETA: 0s - loss: 0.5160 - lcm_precision_1k: 0.8296 - lcm_precision_2k: 0.6548 - lcm_precision_3k: 0.5211 - lcm_precision_5k: 0.3589 - lcm_recall_1k: 0.4814 - lcm_recall_2k: 0.7010 - lcm_recall_3k: 0.8061 - lcm_recall_5k: 0.8982 - lcm_f1_1k: 0.6092 - lcm_f1_2k: 0.6770 - lcm_f1_3k: 0.6329 - lcm_f1_5k: 0.5128 - lcm_accuracy_1k: 0.8296 - lcm_accuracy_2k: 0.9192 - lcm_accuracy_3k: 0.9527 - lcm_accuracy_5k: 0.9845 - lcm_hamming_loss_k: 0.0291
Epoch 00015: val_loss improved from 0.58202 to 0.56719, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 85ms/step - loss: 0.5160 - lcm_precision_1k: 0.8296 - lcm_precision_2k: 0.6548 - lcm_precision_3k: 0.5211 - lcm_precision_5k: 0.3589 - lcm_recall_1k: 0.4814 - lcm_recall_2k: 0.7010 - lcm_recall_3k: 0.8061 - lcm_recall_5k: 0.8982 - lcm_f1_1k: 0.6092 - lcm_f1_2k: 0.6770 - lcm_f1_3k: 0.6329 - lcm_f1_5k: 0.5128 - lcm_accuracy_1k: 0.8296 - lcm_accuracy_2k: 0.9192 - lcm_accuracy_3k: 0.9527 - lcm_accuracy_5k: 0.9845 - lcm_hamming_loss_k: 0.0291 - val_loss: 0.5672 - val_lcm_precision_1k: 0.8055 - val_lcm_precision_2k: 0.6381 - val_lcm_precision_3k: 0.5093 - val_lcm_precision_5k: 0.3515 - val_lcm_recall_1k: 0.4561 - val_lcm_recall_2k: 0.6595 - val_lcm_recall_3k: 0.7646 - val_lcm_recall_5k: 0.8570 - val_lcm_f1_1k: 0.5819 - val_lcm_f1_2k: 0.6477 - val_lcm_f1_3k: 0.6106 - val_lcm_f1_5k: 0.4979 - val_lcm_accuracy_1k: 0.8055 - val_lcm_accuracy_2k: 0.8871 - val_lcm_accuracy_3k: 0.9297 - val_lcm_accuracy_5k: 0.9580 - val_lcm_hamming_loss_k: 0.0307
Epoch 16/100
11/12 [==========================>...] - ETA: 0s - loss: 0.4876 - lcm_precision_1k: 0.8576 - lcm_precision_2k: 0.6697 - lcm_precision_3k: 0.5323 - lcm_precision_5k: 0.3631 - lcm_recall_1k: 0.4997 - lcm_recall_2k: 0.7157 - lcm_recall_3k: 0.8225 - lcm_recall_5k: 0.9067 - lcm_f1_1k: 0.6314 - lcm_f1_2k: 0.6919 - lcm_f1_3k: 0.6463 - lcm_f1_5k: 0.5185 - lcm_accuracy_1k: 0.8576 - lcm_accuracy_2k: 0.9290 - lcm_accuracy_3k: 0.9624 - lcm_accuracy_5k: 0.9837 - lcm_hamming_loss_k: 0.0279
Epoch 00016: val_loss improved from 0.56719 to 0.55110, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 82ms/step - loss: 0.4873 - lcm_precision_1k: 0.8597 - lcm_precision_2k: 0.6730 - lcm_precision_3k: 0.5343 - lcm_precision_5k: 0.3647 - lcm_recall_1k: 0.4985 - lcm_recall_2k: 0.7160 - lcm_recall_3k: 0.8221 - lcm_recall_5k: 0.9069 - lcm_f1_1k: 0.6310 - lcm_f1_2k: 0.6938 - lcm_f1_3k: 0.6475 - lcm_f1_5k: 0.5201 - lcm_accuracy_1k: 0.8597 - lcm_accuracy_2k: 0.9289 - lcm_accuracy_3k: 0.9622 - lcm_accuracy_5k: 0.9840 - lcm_hamming_loss_k: 0.0279 - val_loss: 0.5511 - val_lcm_precision_1k: 0.8213 - val_lcm_precision_2k: 0.6444 - val_lcm_precision_3k: 0.5146 - val_lcm_precision_5k: 0.3574 - val_lcm_recall_1k: 0.4714 - val_lcm_recall_2k: 0.6771 - val_lcm_recall_3k: 0.7770 - val_lcm_recall_5k: 0.8716 - val_lcm_f1_1k: 0.5988 - val_lcm_f1_2k: 0.6596 - val_lcm_f1_3k: 0.6185 - val_lcm_f1_5k: 0.5064 - val_lcm_accuracy_1k: 0.8213 - val_lcm_accuracy_2k: 0.9052 - val_lcm_accuracy_3k: 0.9337 - val_lcm_accuracy_5k: 0.9580 - val_lcm_hamming_loss_k: 0.0301
Epoch 17/100
12/12 [==============================] - ETA: 0s - loss: 0.4699 - lcm_precision_1k: 0.8549 - lcm_precision_2k: 0.6758 - lcm_precision_3k: 0.5368 - lcm_precision_5k: 0.3686 - lcm_recall_1k: 0.4985 - lcm_recall_2k: 0.7205 - lcm_recall_3k: 0.8272 - lcm_recall_5k: 0.9165 - lcm_f1_1k: 0.6297 - lcm_f1_2k: 0.6974 - lcm_f1_3k: 0.6511 - lcm_f1_5k: 0.5258 - lcm_accuracy_1k: 0.8549 - lcm_accuracy_2k: 0.9323 - lcm_accuracy_3k: 0.9639 - lcm_accuracy_5k: 0.9870 - lcm_hamming_loss_k: 0.0280
Epoch 00017: val_loss improved from 0.55110 to 0.53420, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 75ms/step - loss: 0.4699 - lcm_precision_1k: 0.8549 - lcm_precision_2k: 0.6758 - lcm_precision_3k: 0.5368 - lcm_precision_5k: 0.3686 - lcm_recall_1k: 0.4985 - lcm_recall_2k: 0.7205 - lcm_recall_3k: 0.8272 - lcm_recall_5k: 0.9165 - lcm_f1_1k: 0.6297 - lcm_f1_2k: 0.6974 - lcm_f1_3k: 0.6511 - lcm_f1_5k: 0.5258 - lcm_accuracy_1k: 0.8549 - lcm_accuracy_2k: 0.9323 - lcm_accuracy_3k: 0.9639 - lcm_accuracy_5k: 0.9870 - lcm_hamming_loss_k: 0.0280 - val_loss: 0.5342 - val_lcm_precision_1k: 0.8191 - val_lcm_precision_2k: 0.6500 - val_lcm_precision_3k: 0.5222 - val_lcm_precision_5k: 0.3591 - val_lcm_recall_1k: 0.4667 - val_lcm_recall_2k: 0.6751 - val_lcm_recall_3k: 0.7868 - val_lcm_recall_5k: 0.8772 - val_lcm_f1_1k: 0.5941 - val_lcm_f1_2k: 0.6615 - val_lcm_f1_3k: 0.6270 - val_lcm_f1_5k: 0.5090 - val_lcm_accuracy_1k: 0.8191 - val_lcm_accuracy_2k: 0.8983 - val_lcm_accuracy_3k: 0.9351 - val_lcm_accuracy_5k: 0.9621 - val_lcm_hamming_loss_k: 0.0302
Epoch 18/100
11/12 [==========================>...] - ETA: 0s - loss: 0.4477 - lcm_precision_1k: 0.8711 - lcm_precision_2k: 0.6909 - lcm_precision_3k: 0.5460 - lcm_precision_5k: 0.3712 - lcm_recall_1k: 0.5087 - lcm_recall_2k: 0.7388 - lcm_recall_3k: 0.8431 - lcm_recall_5k: 0.9221 - lcm_f1_1k: 0.6422 - lcm_f1_2k: 0.7140 - lcm_f1_3k: 0.6627 - lcm_f1_5k: 0.5293 - lcm_accuracy_1k: 0.8711 - lcm_accuracy_2k: 0.9439 - lcm_accuracy_3k: 0.9727 - lcm_accuracy_5k: 0.9890 - lcm_hamming_loss_k: 0.0274
Epoch 00018: val_loss improved from 0.53420 to 0.53111, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 80ms/step - loss: 0.4487 - lcm_precision_1k: 0.8682 - lcm_precision_2k: 0.6916 - lcm_precision_3k: 0.5457 - lcm_precision_5k: 0.3707 - lcm_recall_1k: 0.5056 - lcm_recall_2k: 0.7380 - lcm_recall_3k: 0.8417 - lcm_recall_5k: 0.9192 - lcm_f1_1k: 0.6389 - lcm_f1_2k: 0.7140 - lcm_f1_3k: 0.6621 - lcm_f1_5k: 0.5283 - lcm_accuracy_1k: 0.8682 - lcm_accuracy_2k: 0.9442 - lcm_accuracy_3k: 0.9728 - lcm_accuracy_5k: 0.9888 - lcm_hamming_loss_k: 0.0276 - val_loss: 0.5311 - val_lcm_precision_1k: 0.8192 - val_lcm_precision_2k: 0.6556 - val_lcm_precision_3k: 0.5260 - val_lcm_precision_5k: 0.3610 - val_lcm_recall_1k: 0.4655 - val_lcm_recall_2k: 0.6796 - val_lcm_recall_3k: 0.7915 - val_lcm_recall_5k: 0.8812 - val_lcm_f1_1k: 0.5933 - val_lcm_f1_2k: 0.6666 - val_lcm_f1_3k: 0.6312 - val_lcm_f1_5k: 0.5116 - val_lcm_accuracy_1k: 0.8192 - val_lcm_accuracy_2k: 0.9039 - val_lcm_accuracy_3k: 0.9449 - val_lcm_accuracy_5k: 0.9675 - val_lcm_hamming_loss_k: 0.0302
Epoch 19/100
12/12 [==============================] - ETA: 0s - loss: 0.4410 - lcm_precision_1k: 0.8712 - lcm_precision_2k: 0.6931 - lcm_precision_3k: 0.5478 - lcm_precision_5k: 0.3708 - lcm_recall_1k: 0.5091 - lcm_recall_2k: 0.7399 - lcm_recall_3k: 0.8441 - lcm_recall_5k: 0.9219 - lcm_f1_1k: 0.6424 - lcm_f1_2k: 0.7156 - lcm_f1_3k: 0.6642 - lcm_f1_5k: 0.5288 - lcm_accuracy_1k: 0.8712 - lcm_accuracy_2k: 0.9473 - lcm_accuracy_3k: 0.9739 - lcm_accuracy_5k: 0.9877 - lcm_hamming_loss_k: 0.0273 ETA: 0s - loss: 0.4265 - lcm_precision_1k: 0.8730 - lcm_precision_2k: 0.6855 - lcm_precision_3k: 0.5437 - lcm_precision_5k: 0.3665 - lcm_recall_1k: 0.5215 - lcm_recall_2k: 0.7428 - lcm_recall_3k: 0.8525 - lcm_recall_5k: 0.9260 - lcm_f1_1k: 0.6529 - lcm_f1_2k: 0.7129 - lcm_f1_3k: 0.6639 - lcm_f1_5k: 0.5251 - lcm_accuracy_1k: 0.8730 - lcm_accuracy_2k: 0.9433 - lcm_accuracy_3k: 0.9785 - lcm_accuracy_5k: 0.9902 - lcm_hamming_
Epoch 00019: val_loss did not improve from 0.53111
12/12 [==============================] - 1s 66ms/step - loss: 0.4410 - lcm_precision_1k: 0.8712 - lcm_precision_2k: 0.6931 - lcm_precision_3k: 0.5478 - lcm_precision_5k: 0.3708 - lcm_recall_1k: 0.5091 - lcm_recall_2k: 0.7399 - lcm_recall_3k: 0.8441 - lcm_recall_5k: 0.9219 - lcm_f1_1k: 0.6424 - lcm_f1_2k: 0.7156 - lcm_f1_3k: 0.6642 - lcm_f1_5k: 0.5288 - lcm_accuracy_1k: 0.8712 - lcm_accuracy_2k: 0.9473 - lcm_accuracy_3k: 0.9739 - lcm_accuracy_5k: 0.9877 - lcm_hamming_loss_k: 0.0273 - val_loss: 0.5338 - val_lcm_precision_1k: 0.8083 - val_lcm_precision_2k: 0.6441 - val_lcm_precision_3k: 0.5204 - val_lcm_precision_5k: 0.3597 - val_lcm_recall_1k: 0.4633 - val_lcm_recall_2k: 0.6757 - val_lcm_recall_3k: 0.7866 - val_lcm_recall_5k: 0.8806 - val_lcm_f1_1k: 0.5885 - val_lcm_f1_2k: 0.6586 - val_lcm_f1_3k: 0.6257 - val_lcm_f1_5k: 0.5102 - val_lcm_accuracy_1k: 0.8083 - val_lcm_accuracy_2k: 0.8988 - val_lcm_accuracy_3k: 0.9368 - val_lcm_accuracy_5k: 0.9650 - val_lcm_hamming_loss_k: 0.0306
Epoch 20/100
11/12 [==========================>...] - ETA: 0s - loss: 0.4166 - lcm_precision_1k: 0.8895 - lcm_precision_2k: 0.7113 - lcm_precision_3k: 0.5595 - lcm_precision_5k: 0.3773 - lcm_recall_1k: 0.5196 - lcm_recall_2k: 0.7561 - lcm_recall_3k: 0.8591 - lcm_recall_5k: 0.9314 - lcm_f1_1k: 0.6560 - lcm_f1_2k: 0.7329 - lcm_f1_3k: 0.6776 - lcm_f1_5k: 0.5369 - lcm_accuracy_1k: 0.8895 - lcm_accuracy_2k: 0.9570 - lcm_accuracy_3k: 0.9801 - lcm_accuracy_5k: 0.9901 - lcm_hamming_loss_k: 0.0268
Epoch 00020: val_loss improved from 0.53111 to 0.51828, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 87ms/step - loss: 0.4168 - lcm_precision_1k: 0.8884 - lcm_precision_2k: 0.7078 - lcm_precision_3k: 0.5565 - lcm_precision_5k: 0.3771 - lcm_recall_1k: 0.5223 - lcm_recall_2k: 0.7556 - lcm_recall_3k: 0.8574 - lcm_recall_5k: 0.9341 - lcm_f1_1k: 0.6577 - lcm_f1_2k: 0.7308 - lcm_f1_3k: 0.6748 - lcm_f1_5k: 0.5372 - lcm_accuracy_1k: 0.8884 - lcm_accuracy_2k: 0.9568 - lcm_accuracy_3k: 0.9791 - lcm_accuracy_5k: 0.9909 - lcm_hamming_loss_k: 0.0266 - val_loss: 0.5183 - val_lcm_precision_1k: 0.8441 - val_lcm_precision_2k: 0.6691 - val_lcm_precision_3k: 0.5396 - val_lcm_precision_5k: 0.3667 - val_lcm_recall_1k: 0.4827 - val_lcm_recall_2k: 0.6969 - val_lcm_recall_3k: 0.8105 - val_lcm_recall_5k: 0.8925 - val_lcm_f1_1k: 0.6137 - val_lcm_f1_2k: 0.6821 - val_lcm_f1_3k: 0.6472 - val_lcm_f1_5k: 0.5192 - val_lcm_accuracy_1k: 0.8441 - val_lcm_accuracy_2k: 0.9153 - val_lcm_accuracy_3k: 0.9477 - val_lcm_accuracy_5k: 0.9731 - val_lcm_hamming_loss_k: 0.0292
Epoch 21/100
12/12 [==============================] - ETA: 0s - loss: 0.3968 - lcm_precision_1k: 0.8981 - lcm_precision_2k: 0.7157 - lcm_precision_3k: 0.5630 - lcm_precision_5k: 0.3811 - lcm_recall_1k: 0.5302 - lcm_recall_2k: 0.7650 - lcm_recall_3k: 0.8659 - lcm_recall_5k: 0.9409 - lcm_f1_1k: 0.6667 - lcm_f1_2k: 0.7394 - lcm_f1_3k: 0.6822 - lcm_f1_5k: 0.5424 - lcm_accuracy_1k: 0.8981 - lcm_accuracy_2k: 0.9639 - lcm_accuracy_3k: 0.9830 - lcm_accuracy_5k: 0.9934 - lcm_hamming_loss_k: 0.0263
Epoch 00021: val_loss improved from 0.51828 to 0.51626, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 80ms/step - loss: 0.3968 - lcm_precision_1k: 0.8981 - lcm_precision_2k: 0.7157 - lcm_precision_3k: 0.5630 - lcm_precision_5k: 0.3811 - lcm_recall_1k: 0.5302 - lcm_recall_2k: 0.7650 - lcm_recall_3k: 0.8659 - lcm_recall_5k: 0.9409 - lcm_f1_1k: 0.6667 - lcm_f1_2k: 0.7394 - lcm_f1_3k: 0.6822 - lcm_f1_5k: 0.5424 - lcm_accuracy_1k: 0.8981 - lcm_accuracy_2k: 0.9639 - lcm_accuracy_3k: 0.9830 - lcm_accuracy_5k: 0.9934 - lcm_hamming_loss_k: 0.0263 - val_loss: 0.5163 - val_lcm_precision_1k: 0.8471 - val_lcm_precision_2k: 0.6625 - val_lcm_precision_3k: 0.5308 - val_lcm_precision_5k: 0.3686 - val_lcm_recall_1k: 0.4841 - val_lcm_recall_2k: 0.6883 - val_lcm_recall_3k: 0.7934 - val_lcm_recall_5k: 0.8937 - val_lcm_f1_1k: 0.6156 - val_lcm_f1_2k: 0.6743 - val_lcm_f1_3k: 0.6354 - val_lcm_f1_5k: 0.5213 - val_lcm_accuracy_1k: 0.8471 - val_lcm_accuracy_2k: 0.9081 - val_lcm_accuracy_3k: 0.9371 - val_lcm_accuracy_5k: 0.9704 - val_lcm_hamming_loss_k: 0.0291
Epoch 22/100
12/12 [==============================] - ETA: 0s - loss: 0.3851 - lcm_precision_1k: 0.9046 - lcm_precision_2k: 0.7215 - lcm_precision_3k: 0.5685 - lcm_precision_5k: 0.3815 - lcm_recall_1k: 0.5297 - lcm_recall_2k: 0.7684 - lcm_recall_3k: 0.8728 - lcm_recall_5k: 0.9430 - lcm_f1_1k: 0.6681 - lcm_f1_2k: 0.7442 - lcm_f1_3k: 0.6885 - lcm_f1_5k: 0.5432 - lcm_accuracy_1k: 0.9046 - lcm_accuracy_2k: 0.9632 - lcm_accuracy_3k: 0.9855 - lcm_accuracy_5k: 0.9936 - lcm_hamming_loss_k: 0.0261
Epoch 00022: val_loss improved from 0.51626 to 0.50916, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 78ms/step - loss: 0.3851 - lcm_precision_1k: 0.9046 - lcm_precision_2k: 0.7215 - lcm_precision_3k: 0.5685 - lcm_precision_5k: 0.3815 - lcm_recall_1k: 0.5297 - lcm_recall_2k: 0.7684 - lcm_recall_3k: 0.8728 - lcm_recall_5k: 0.9430 - lcm_f1_1k: 0.6681 - lcm_f1_2k: 0.7442 - lcm_f1_3k: 0.6885 - lcm_f1_5k: 0.5432 - lcm_accuracy_1k: 0.9046 - lcm_accuracy_2k: 0.9632 - lcm_accuracy_3k: 0.9855 - lcm_accuracy_5k: 0.9936 - lcm_hamming_loss_k: 0.0261 - val_loss: 0.5092 - val_lcm_precision_1k: 0.8354 - val_lcm_precision_2k: 0.6735 - val_lcm_precision_3k: 0.5328 - val_lcm_precision_5k: 0.3631 - val_lcm_recall_1k: 0.4775 - val_lcm_recall_2k: 0.7054 - val_lcm_recall_3k: 0.8048 - val_lcm_recall_5k: 0.8919 - val_lcm_f1_1k: 0.6074 - val_lcm_f1_2k: 0.6884 - val_lcm_f1_3k: 0.6403 - val_lcm_f1_5k: 0.5155 - val_lcm_accuracy_1k: 0.8354 - val_lcm_accuracy_2k: 0.9245 - val_lcm_accuracy_3k: 0.9501 - val_lcm_accuracy_5k: 0.9783 - val_lcm_hamming_loss_k: 0.0295
Epoch 23/100
11/12 [==========================>...] - ETA: 0s - loss: 0.3657 - lcm_precision_1k: 0.9201 - lcm_precision_2k: 0.7337 - lcm_precision_3k: 0.5731 - lcm_precision_5k: 0.3861 - lcm_recall_1k: 0.5457 - lcm_recall_2k: 0.7816 - lcm_recall_3k: 0.8789 - lcm_recall_5k: 0.9508 - lcm_f1_1k: 0.6850 - lcm_f1_2k: 0.7568 - lcm_f1_3k: 0.6938 - lcm_f1_5k: 0.5491 - lcm_accuracy_1k: 0.9201 - lcm_accuracy_2k: 0.9709 - lcm_accuracy_3k: 0.9897 - lcm_accuracy_5k: 0.9968 - lcm_hamming_loss_k: 0.0255
Epoch 00023: val_loss improved from 0.50916 to 0.50379, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 84ms/step - loss: 0.3644 - lcm_precision_1k: 0.9186 - lcm_precision_2k: 0.7335 - lcm_precision_3k: 0.5746 - lcm_precision_5k: 0.3859 - lcm_recall_1k: 0.5445 - lcm_recall_2k: 0.7814 - lcm_recall_3k: 0.8812 - lcm_recall_5k: 0.9516 - lcm_f1_1k: 0.6836 - lcm_f1_2k: 0.7567 - lcm_f1_3k: 0.6955 - lcm_f1_5k: 0.5491 - lcm_accuracy_1k: 0.9186 - lcm_accuracy_2k: 0.9695 - lcm_accuracy_3k: 0.9889 - lcm_accuracy_5k: 0.9960 - lcm_hamming_loss_k: 0.0254 - val_loss: 0.5038 - val_lcm_precision_1k: 0.8435 - val_lcm_precision_2k: 0.6694 - val_lcm_precision_3k: 0.5373 - val_lcm_precision_5k: 0.3655 - val_lcm_recall_1k: 0.4869 - val_lcm_recall_2k: 0.7016 - val_lcm_recall_3k: 0.8130 - val_lcm_recall_5k: 0.8920 - val_lcm_f1_1k: 0.6167 - val_lcm_f1_2k: 0.6842 - val_lcm_f1_3k: 0.6461 - val_lcm_f1_5k: 0.5179 - val_lcm_accuracy_1k: 0.8435 - val_lcm_accuracy_2k: 0.9308 - val_lcm_accuracy_3k: 0.9542 - val_lcm_accuracy_5k: 0.9744 - val_lcm_hamming_loss_k: 0.0292
Epoch 24/100
11/12 [==========================>...] - ETA: 0s - loss: 0.3533 - lcm_precision_1k: 0.9293 - lcm_precision_2k: 0.7386 - lcm_precision_3k: 0.5808 - lcm_precision_5k: 0.3879 - lcm_recall_1k: 0.5469 - lcm_recall_2k: 0.7840 - lcm_recall_3k: 0.8863 - lcm_recall_5k: 0.9545 - lcm_f1_1k: 0.6884 - lcm_f1_2k: 0.7604 - lcm_f1_3k: 0.7016 - lcm_f1_5k: 0.5516 - lcm_accuracy_1k: 0.9293 - lcm_accuracy_2k: 0.9737 - lcm_accuracy_3k: 0.9894 - lcm_accuracy_5k: 0.9972 - lcm_hamming_loss_k: 0.0251
Epoch 00024: val_loss improved from 0.50379 to 0.49336, saving model to logs/qmaqkq-lbs-0604-114144/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 74ms/step - loss: 0.3533 - lcm_precision_1k: 0.9287 - lcm_precision_2k: 0.7356 - lcm_precision_3k: 0.5795 - lcm_precision_5k: 0.3868 - lcm_recall_1k: 0.5485 - lcm_recall_2k: 0.7832 - lcm_recall_3k: 0.8865 - lcm_recall_5k: 0.9535 - lcm_f1_1k: 0.6895 - lcm_f1_2k: 0.7585 - lcm_f1_3k: 0.7007 - lcm_f1_5k: 0.5502 - lcm_accuracy_1k: 0.9287 - lcm_accuracy_2k: 0.9737 - lcm_accuracy_3k: 0.9897 - lcm_accuracy_5k: 0.9974 - lcm_hamming_loss_k: 0.0250 - val_loss: 0.4934 - val_lcm_precision_1k: 0.8488 - val_lcm_precision_2k: 0.6815 - val_lcm_precision_3k: 0.5476 - val_lcm_precision_5k: 0.3686 - val_lcm_recall_1k: 0.4889 - val_lcm_recall_2k: 0.7148 - val_lcm_recall_3k: 0.8258 - val_lcm_recall_5k: 0.9039 - val_lcm_f1_1k: 0.6201 - val_lcm_f1_2k: 0.6970 - val_lcm_f1_3k: 0.6577 - val_lcm_f1_5k: 0.5230 - val_lcm_accuracy_1k: 0.8488 - val_lcm_accuracy_2k: 0.9409 - val_lcm_accuracy_3k: 0.9516 - val_lcm_accuracy_5k: 0.9770 - val_lcm_hamming_loss_k: 0.0290
Epoch 25/100
11/12 [==========================>...] - ETA: 0s - loss: 0.3289 - lcm_precision_1k: 0.9322 - lcm_precision_2k: 0.7468 - lcm_precision_3k: 0.5870 - lcm_precision_5k: 0.3908 - lcm_recall_1k: 0.5523 - lcm_recall_2k: 0.7963 - lcm_recall_3k: 0.8961 - lcm_recall_5k: 0.9598 - lcm_f1_1k: 0.6935 - lcm_f1_2k: 0.7707 - lcm_f1_3k: 0.7092 - lcm_f1_5k: 0.5554 - lcm_accuracy_1k: 0.9322 - lcm_accuracy_2k: 0.9809 - lcm_accuracy_3k: 0.9926 - lcm_accuracy_5k: 0.9972 - lcm_hamming_loss_k: 0.0249
Epoch 00025: val_loss did not improve from 0.49336
12/12 [==============================] - 1s 61ms/step - loss: 0.3286 - lcm_precision_1k: 0.9318 - lcm_precision_2k: 0.7461 - lcm_precision_3k: 0.5864 - lcm_precision_5k: 0.3903 - lcm_recall_1k: 0.5527 - lcm_recall_2k: 0.7965 - lcm_recall_3k: 0.8961 - lcm_recall_5k: 0.9598 - lcm_f1_1k: 0.6937 - lcm_f1_2k: 0.7704 - lcm_f1_3k: 0.7088 - lcm_f1_5k: 0.5549 - lcm_accuracy_1k: 0.9318 - lcm_accuracy_2k: 0.9808 - lcm_accuracy_3k: 0.9932 - lcm_accuracy_5k: 0.9974 - lcm_hamming_loss_k: 0.0249 - val_loss: 0.5070 - val_lcm_precision_1k: 0.8367 - val_lcm_precision_2k: 0.6719 - val_lcm_precision_3k: 0.5375 - val_lcm_precision_5k: 0.3643 - val_lcm_recall_1k: 0.4871 - val_lcm_recall_2k: 0.7063 - val_lcm_recall_3k: 0.8158 - val_lcm_recall_5k: 0.8918 - val_lcm_f1_1k: 0.6154 - val_lcm_f1_2k: 0.6881 - val_lcm_f1_3k: 0.6471 - val_lcm_f1_5k: 0.5166 - val_lcm_accuracy_1k: 0.8367 - val_lcm_accuracy_2k: 0.9300 - val_lcm_accuracy_3k: 0.9553 - val_lcm_accuracy_5k: 0.9744 - val_lcm_hamming_loss_k: 0.0295
Epoch 26/100
11/12 [==========================>...] - ETA: 0s - loss: 0.3189 - lcm_precision_1k: 0.9386 - lcm_precision_2k: 0.7537 - lcm_precision_3k: 0.5947 - lcm_precision_5k: 0.3923 - lcm_recall_1k: 0.5557 - lcm_recall_2k: 0.8018 - lcm_recall_3k: 0.9042 - lcm_recall_5k: 0.9618 - lcm_f1_1k: 0.6980 - lcm_f1_2k: 0.7769 - lcm_f1_3k: 0.7174 - lcm_f1_5k: 0.5572 - lcm_accuracy_1k: 0.9386 - lcm_accuracy_2k: 0.9823 - lcm_accuracy_3k: 0.9943 - lcm_accuracy_5k: 0.9989 - lcm_hamming_loss_k: 0.0247
Epoch 00026: val_loss did not improve from 0.49336
12/12 [==============================] - 1s 57ms/step - loss: 0.3187 - lcm_precision_1k: 0.9377 - lcm_precision_2k: 0.7530 - lcm_precision_3k: 0.5933 - lcm_precision_5k: 0.3918 - lcm_recall_1k: 0.5561 - lcm_recall_2k: 0.8025 - lcm_recall_3k: 0.9045 - lcm_recall_5k: 0.9626 - lcm_f1_1k: 0.6980 - lcm_f1_2k: 0.7769 - lcm_f1_3k: 0.7164 - lcm_f1_5k: 0.5569 - lcm_accuracy_1k: 0.9377 - lcm_accuracy_2k: 0.9805 - lcm_accuracy_3k: 0.9943 - lcm_accuracy_5k: 0.9985 - lcm_hamming_loss_k: 0.0246 - val_loss: 0.4985 - val_lcm_precision_1k: 0.8549 - val_lcm_precision_2k: 0.6746 - val_lcm_precision_3k: 0.5357 - val_lcm_precision_5k: 0.3656 - val_lcm_recall_1k: 0.4922 - val_lcm_recall_2k: 0.7024 - val_lcm_recall_3k: 0.8093 - val_lcm_recall_5k: 0.8932 - val_lcm_f1_1k: 0.6241 - val_lcm_f1_2k: 0.6874 - val_lcm_f1_3k: 0.6439 - val_lcm_f1_5k: 0.5182 - val_lcm_accuracy_1k: 0.8549 - val_lcm_accuracy_2k: 0.9269 - val_lcm_accuracy_3k: 0.9570 - val_lcm_accuracy_5k: 0.9770 - val_lcm_hamming_loss_k: 0.0287
Epoch 00026: early stopping
39/39 [==============================] - 1s 21ms/step - loss: 0.4183 - lcm_precision_1k: 0.8952 - lcm_precision_2k: 0.7153 - lcm_precision_3k: 0.5653 - lcm_precision_5k: 0.3805 - lcm_recall_1k: 0.5162 - lcm_recall_2k: 0.7496 - lcm_recall_3k: 0.8528 - lcm_recall_5k: 0.9244 - lcm_f1_1k: 0.6538 - lcm_f1_2k: 0.7309 - lcm_f1_3k: 0.6789 - lcm_f1_5k: 0.5384 - lcm_accuracy_1k: 0.8952 - lcm_accuracy_2k: 0.9648 - lcm_accuracy_3k: 0.9788 - lcm_accuracy_5k: 0.9884 - lcm_hamming_loss_k: 0.0273
Best model result:  [0.41830337047576904, 0.8951692581176758, 0.7152538299560547, 0.5653231143951416, 0.3805307447910309, 0.5162205100059509, 0.7495743632316589, 0.8528359532356262, 0.9243797063827515, 0.6537653803825378, 0.7309410572052002, 0.6789171099662781, 0.5384482741355896, 0.8951692581176758, 0.9648255705833435, 0.9788126945495605, 0.9884229898452759, 0.027337245643138885]
2969
743
1238
Model: "model_2"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 text_input (InputLayer)        [(None, 120)]        0           []                               
                                                                                                  
 text_emb (Embedding)           (None, 120, 300)     1064400     ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_input (InputLayer)       [(None, 49)]         0           []                               
                                                                                                  
 pred_probs (Dense)             (None, 49)           50225       ['BiLSTM[0][0]']                 
                                                                                                  
==================================================================================================
Total params: 4,444,673
Trainable params: 3,380,273
Non-trainable params: 1,064,400
__________________________________________________________________________________________________
None
2 patience
Model: "model_3"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 49)]         0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 120)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 49, 300)      14700       ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 120, 300)     1064400     ['text_input[0][0]']             
                                                                                                  
 tf.__operators__.getitem_1 (Sl  (None, 49, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_lcm_emb (Dense)          (None, 49, 1024)     308224      ['tf.__operators__.getitem_1[0][0
                                                                 ]']                              
                                                                                                  
 dot_1 (Dot)                    (None, 49)           0           ['label_lcm_emb[0][0]',          
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 pred_probs (Dense)             (None, 49)           50225       ['BiLSTM[0][0]']                 
                                                                                                  
 label_sim_dict (Dense)         (None, 49)           2450        ['dot_1[0][0]']                  
                                                                                                  
 concatenate_1 (Concatenate)    (None, 98)           0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 4,770,047
Trainable params: 3,705,647
Non-trainable params: 1,064,400
__________________________________________________________________________________________________
None
Epoch 1/100
11/12 [==========================>...] - ETA: 0s - loss: 1.3590 - lcm_precision_1k: 0.2578 - lcm_precision_2k: 0.2172 - lcm_precision_3k: 0.1771 - lcm_precision_5k: 0.1545 - lcm_recall_1k: 0.1298 - lcm_recall_2k: 0.2200 - lcm_recall_3k: 0.2891 - lcm_recall_5k: 0.3997 - lcm_f1_1k: 0.1725 - lcm_f1_2k: 0.2183 - lcm_f1_3k: 0.2194 - lcm_f1_5k: 0.2227 - lcm_accuracy_1k: 0.2578 - lcm_accuracy_2k: 0.4261 - lcm_accuracy_3k: 0.5074 - lcm_accuracy_5k: 0.6296 - lcm_hamming_loss_k: 0.0526
Epoch 00001: val_loss improved from inf to 1.27597, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 3s 109ms/step - loss: 1.3559 - lcm_precision_1k: 0.2587 - lcm_precision_2k: 0.2173 - lcm_precision_3k: 0.1774 - lcm_precision_5k: 0.1550 - lcm_recall_1k: 0.1299 - lcm_recall_2k: 0.2200 - lcm_recall_3k: 0.2903 - lcm_recall_5k: 0.4030 - lcm_f1_1k: 0.1728 - lcm_f1_2k: 0.2184 - lcm_f1_3k: 0.2200 - lcm_f1_5k: 0.2238 - lcm_accuracy_1k: 0.2587 - lcm_accuracy_2k: 0.4271 - lcm_accuracy_3k: 0.5104 - lcm_accuracy_5k: 0.6354 - lcm_hamming_loss_k: 0.0524 - val_loss: 1.2760 - val_lcm_precision_1k: 0.2834 - val_lcm_precision_2k: 0.2357 - val_lcm_precision_3k: 0.1939 - val_lcm_precision_5k: 0.1710 - val_lcm_recall_1k: 0.1341 - val_lcm_recall_2k: 0.2359 - val_lcm_recall_3k: 0.3163 - val_lcm_recall_5k: 0.4376 - val_lcm_f1_1k: 0.1820 - val_lcm_f1_2k: 0.2352 - val_lcm_f1_3k: 0.2402 - val_lcm_f1_5k: 0.2457 - val_lcm_accuracy_1k: 0.2834 - val_lcm_accuracy_2k: 0.4663 - val_lcm_accuracy_3k: 0.5608 - val_lcm_accuracy_5k: 0.7174 - val_lcm_hamming_loss_k: 0.0517
Epoch 2/100
11/12 [==========================>...] - ETA: 0s - loss: 1.2630 - lcm_precision_1k: 0.2798 - lcm_precision_2k: 0.2333 - lcm_precision_3k: 0.1925 - lcm_precision_5k: 0.1740 - lcm_recall_1k: 0.1421 - lcm_recall_2k: 0.2365 - lcm_recall_3k: 0.3169 - lcm_recall_5k: 0.4510 - lcm_f1_1k: 0.1884 - lcm_f1_2k: 0.2348 - lcm_f1_3k: 0.2394 - lcm_f1_5k: 0.2511 - lcm_accuracy_1k: 0.2798 - lcm_accuracy_2k: 0.4588 - lcm_accuracy_3k: 0.5526 - lcm_accuracy_5k: 0.7162 - lcm_hamming_loss_k: 0.0517
Epoch 00002: val_loss improved from 1.27597 to 1.22874, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 84ms/step - loss: 1.2608 - lcm_precision_1k: 0.2767 - lcm_precision_2k: 0.2318 - lcm_precision_3k: 0.1924 - lcm_precision_5k: 0.1750 - lcm_recall_1k: 0.1403 - lcm_recall_2k: 0.2350 - lcm_recall_3k: 0.3188 - lcm_recall_5k: 0.4548 - lcm_f1_1k: 0.1861 - lcm_f1_2k: 0.2333 - lcm_f1_3k: 0.2399 - lcm_f1_5k: 0.2527 - lcm_accuracy_1k: 0.2767 - lcm_accuracy_2k: 0.4560 - lcm_accuracy_3k: 0.5528 - lcm_accuracy_5k: 0.7192 - lcm_hamming_loss_k: 0.0517 - val_loss: 1.2287 - val_lcm_precision_1k: 0.2847 - val_lcm_precision_2k: 0.2357 - val_lcm_precision_3k: 0.1939 - val_lcm_precision_5k: 0.1906 - val_lcm_recall_1k: 0.1354 - val_lcm_recall_2k: 0.2359 - val_lcm_recall_3k: 0.3163 - val_lcm_recall_5k: 0.4808 - val_lcm_f1_1k: 0.1834 - val_lcm_f1_2k: 0.2352 - val_lcm_f1_3k: 0.2402 - val_lcm_f1_5k: 0.2728 - val_lcm_accuracy_1k: 0.2847 - val_lcm_accuracy_2k: 0.4663 - val_lcm_accuracy_3k: 0.5608 - val_lcm_accuracy_5k: 0.7267 - val_lcm_hamming_loss_k: 0.0517
Epoch 3/100
11/12 [==========================>...] - ETA: 0s - loss: 1.2044 - lcm_precision_1k: 0.2802 - lcm_precision_2k: 0.2308 - lcm_precision_3k: 0.2257 - lcm_precision_5k: 0.1964 - lcm_recall_1k: 0.1428 - lcm_recall_2k: 0.2345 - lcm_recall_3k: 0.3640 - lcm_recall_5k: 0.5027 - lcm_f1_1k: 0.1891 - lcm_f1_2k: 0.2326 - lcm_f1_3k: 0.2786 - lcm_f1_5k: 0.2824 - lcm_accuracy_1k: 0.2802 - lcm_accuracy_2k: 0.4538 - lcm_accuracy_3k: 0.5888 - lcm_accuracy_5k: 0.7280 - lcm_hamming_loss_k: 0.0516
Epoch 00003: val_loss improved from 1.22874 to 1.15477, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 81ms/step - loss: 1.2031 - lcm_precision_1k: 0.2781 - lcm_precision_2k: 0.2334 - lcm_precision_3k: 0.2262 - lcm_precision_5k: 0.1969 - lcm_recall_1k: 0.1418 - lcm_recall_2k: 0.2362 - lcm_recall_3k: 0.3647 - lcm_recall_5k: 0.5040 - lcm_f1_1k: 0.1878 - lcm_f1_2k: 0.2347 - lcm_f1_3k: 0.2791 - lcm_f1_5k: 0.2832 - lcm_accuracy_1k: 0.2781 - lcm_accuracy_2k: 0.4590 - lcm_accuracy_3k: 0.5936 - lcm_accuracy_5k: 0.7321 - lcm_hamming_loss_k: 0.0517 - val_loss: 1.1548 - val_lcm_precision_1k: 0.2834 - val_lcm_precision_2k: 0.2357 - val_lcm_precision_3k: 0.2667 - val_lcm_precision_5k: 0.2188 - val_lcm_recall_1k: 0.1341 - val_lcm_recall_2k: 0.2359 - val_lcm_recall_3k: 0.4219 - val_lcm_recall_5k: 0.5593 - val_lcm_f1_1k: 0.1820 - val_lcm_f1_2k: 0.2352 - val_lcm_f1_3k: 0.3266 - val_lcm_f1_5k: 0.3144 - val_lcm_accuracy_1k: 0.2834 - val_lcm_accuracy_2k: 0.4663 - val_lcm_accuracy_3k: 0.6571 - val_lcm_accuracy_5k: 0.7795 - val_lcm_hamming_loss_k: 0.0517
Epoch 4/100
11/12 [==========================>...] - ETA: 0s - loss: 1.1282 - lcm_precision_1k: 0.2948 - lcm_precision_2k: 0.2429 - lcm_precision_3k: 0.2528 - lcm_precision_5k: 0.2229 - lcm_recall_1k: 0.1501 - lcm_recall_2k: 0.2488 - lcm_recall_3k: 0.4046 - lcm_recall_5k: 0.5753 - lcm_f1_1k: 0.1988 - lcm_f1_2k: 0.2456 - lcm_f1_3k: 0.3111 - lcm_f1_5k: 0.3212 - lcm_accuracy_1k: 0.2948 - lcm_accuracy_2k: 0.4719 - lcm_accuracy_3k: 0.6481 - lcm_accuracy_5k: 0.7937 - lcm_hamming_loss_k: 0.0510
Epoch 00004: val_loss improved from 1.15477 to 1.07347, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 88ms/step - loss: 1.1292 - lcm_precision_1k: 0.2893 - lcm_precision_2k: 0.2455 - lcm_precision_3k: 0.2505 - lcm_precision_5k: 0.2214 - lcm_recall_1k: 0.1487 - lcm_recall_2k: 0.2529 - lcm_recall_3k: 0.4002 - lcm_recall_5k: 0.5729 - lcm_f1_1k: 0.1963 - lcm_f1_2k: 0.2490 - lcm_f1_3k: 0.3080 - lcm_f1_5k: 0.3193 - lcm_accuracy_1k: 0.2893 - lcm_accuracy_2k: 0.4751 - lcm_accuracy_3k: 0.6425 - lcm_accuracy_5k: 0.7923 - lcm_hamming_loss_k: 0.0513 - val_loss: 1.0735 - val_lcm_precision_1k: 0.3069 - val_lcm_precision_2k: 0.3198 - val_lcm_precision_3k: 0.2846 - val_lcm_precision_5k: 0.2334 - val_lcm_recall_1k: 0.1527 - val_lcm_recall_2k: 0.3352 - val_lcm_recall_3k: 0.4462 - val_lcm_recall_5k: 0.5940 - val_lcm_f1_1k: 0.2038 - val_lcm_f1_2k: 0.3265 - val_lcm_f1_3k: 0.3473 - val_lcm_f1_5k: 0.3350 - val_lcm_accuracy_1k: 0.3069 - val_lcm_accuracy_2k: 0.5789 - val_lcm_accuracy_3k: 0.6736 - val_lcm_accuracy_5k: 0.8078 - val_lcm_hamming_loss_k: 0.0507
Epoch 5/100
12/12 [==============================] - ETA: 0s - loss: 1.0242 - lcm_precision_1k: 0.3706 - lcm_precision_2k: 0.3699 - lcm_precision_3k: 0.3114 - lcm_precision_5k: 0.2481 - lcm_recall_1k: 0.2078 - lcm_recall_2k: 0.4055 - lcm_recall_3k: 0.4987 - lcm_recall_5k: 0.6377 - lcm_f1_1k: 0.2660 - lcm_f1_2k: 0.3867 - lcm_f1_3k: 0.3832 - lcm_f1_5k: 0.3571 - lcm_accuracy_1k: 0.3706 - lcm_accuracy_2k: 0.6322 - lcm_accuracy_3k: 0.7175 - lcm_accuracy_5k: 0.8299 - lcm_hamming_loss_k: 0.0479
Epoch 00005: val_loss improved from 1.07347 to 0.94723, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 81ms/step - loss: 1.0242 - lcm_precision_1k: 0.3706 - lcm_precision_2k: 0.3699 - lcm_precision_3k: 0.3114 - lcm_precision_5k: 0.2481 - lcm_recall_1k: 0.2078 - lcm_recall_2k: 0.4055 - lcm_recall_3k: 0.4987 - lcm_recall_5k: 0.6377 - lcm_f1_1k: 0.2660 - lcm_f1_2k: 0.3867 - lcm_f1_3k: 0.3832 - lcm_f1_5k: 0.3571 - lcm_accuracy_1k: 0.3706 - lcm_accuracy_2k: 0.6322 - lcm_accuracy_3k: 0.7175 - lcm_accuracy_5k: 0.8299 - lcm_hamming_loss_k: 0.0479 - val_loss: 0.9472 - val_lcm_precision_1k: 0.4756 - val_lcm_precision_2k: 0.4500 - val_lcm_precision_3k: 0.3683 - val_lcm_precision_5k: 0.2791 - val_lcm_recall_1k: 0.2584 - val_lcm_recall_2k: 0.4782 - val_lcm_recall_3k: 0.5746 - val_lcm_recall_5k: 0.7013 - val_lcm_f1_1k: 0.3348 - val_lcm_f1_2k: 0.4635 - val_lcm_f1_3k: 0.4487 - val_lcm_f1_5k: 0.3991 - val_lcm_accuracy_1k: 0.4756 - val_lcm_accuracy_2k: 0.7225 - val_lcm_accuracy_3k: 0.7899 - val_lcm_accuracy_5k: 0.8750 - val_lcm_hamming_loss_k: 0.0439
Epoch 6/100
12/12 [==============================] - ETA: 0s - loss: 0.8833 - lcm_precision_1k: 0.5585 - lcm_precision_2k: 0.4664 - lcm_precision_3k: 0.3840 - lcm_precision_5k: 0.2877 - lcm_recall_1k: 0.3195 - lcm_recall_2k: 0.5062 - lcm_recall_3k: 0.6055 - lcm_recall_5k: 0.7282 - lcm_f1_1k: 0.4063 - lcm_f1_2k: 0.4853 - lcm_f1_3k: 0.4698 - lcm_f1_5k: 0.4123 - lcm_accuracy_1k: 0.5585 - lcm_accuracy_2k: 0.7465 - lcm_accuracy_3k: 0.8135 - lcm_accuracy_5k: 0.8830 - lcm_hamming_loss_k: 0.0404 ETA: 0s - loss: 0.9121 - lcm_precision_1k: 0.5000 - lcm_precision_2k: 0.4466 - lcm_precision_3k: 0.3663 - lcm_precision_5k: 0.2779 - lcm_recall_1k: 0.2880 - lcm_recall_2k: 0.4897 - lcm_recall_3k: 0.5877 - lcm_recall_5k: 0.7167 - lcm_f1_1k: 0.3654 - lcm_f1_2k: 0.4672 - lcm_f1_3k: 0.4513 - lcm_f1_5k: 0.4004 - lcm_accuracy_1k: 0.5000 - lcm_accuracy_2k: 0.7226 - lcm_accuracy_3k: 0.7916 - lcm_accuracy_5k: 0.8763 - lcm_hamming_lo
Epoch 00006: val_loss improved from 0.94723 to 0.84996, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 83ms/step - loss: 0.8833 - lcm_precision_1k: 0.5585 - lcm_precision_2k: 0.4664 - lcm_precision_3k: 0.3840 - lcm_precision_5k: 0.2877 - lcm_recall_1k: 0.3195 - lcm_recall_2k: 0.5062 - lcm_recall_3k: 0.6055 - lcm_recall_5k: 0.7282 - lcm_f1_1k: 0.4063 - lcm_f1_2k: 0.4853 - lcm_f1_3k: 0.4698 - lcm_f1_5k: 0.4123 - lcm_accuracy_1k: 0.5585 - lcm_accuracy_2k: 0.7465 - lcm_accuracy_3k: 0.8135 - lcm_accuracy_5k: 0.8830 - lcm_hamming_loss_k: 0.0404 - val_loss: 0.8500 - val_lcm_precision_1k: 0.6137 - val_lcm_precision_2k: 0.5253 - val_lcm_precision_3k: 0.4027 - val_lcm_precision_5k: 0.2946 - val_lcm_recall_1k: 0.3325 - val_lcm_recall_2k: 0.5470 - val_lcm_recall_3k: 0.6175 - val_lcm_recall_5k: 0.7283 - val_lcm_f1_1k: 0.4310 - val_lcm_f1_2k: 0.5354 - val_lcm_f1_3k: 0.4870 - val_lcm_f1_5k: 0.4192 - val_lcm_accuracy_1k: 0.6137 - val_lcm_accuracy_2k: 0.7724 - val_lcm_accuracy_3k: 0.8342 - val_lcm_accuracy_5k: 0.8873 - val_lcm_hamming_loss_k: 0.0382
Epoch 7/100
11/12 [==========================>...] - ETA: 0s - loss: 0.8095 - lcm_precision_1k: 0.6229 - lcm_precision_2k: 0.5067 - lcm_precision_3k: 0.4091 - lcm_precision_5k: 0.3046 - lcm_recall_1k: 0.3575 - lcm_recall_2k: 0.5472 - lcm_recall_3k: 0.6389 - lcm_recall_5k: 0.7632 - lcm_f1_1k: 0.4540 - lcm_f1_2k: 0.5261 - lcm_f1_3k: 0.4987 - lcm_f1_5k: 0.4354 - lcm_accuracy_1k: 0.6229 - lcm_accuracy_2k: 0.7830 - lcm_accuracy_3k: 0.8359 - lcm_accuracy_5k: 0.9023 - lcm_hamming_loss_k: 0.0377
Epoch 00007: val_loss improved from 0.84996 to 0.83950, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 78ms/step - loss: 0.8072 - lcm_precision_1k: 0.6254 - lcm_precision_2k: 0.5094 - lcm_precision_3k: 0.4099 - lcm_precision_5k: 0.3040 - lcm_recall_1k: 0.3596 - lcm_recall_2k: 0.5501 - lcm_recall_3k: 0.6413 - lcm_recall_5k: 0.7655 - lcm_f1_1k: 0.4565 - lcm_f1_2k: 0.5289 - lcm_f1_3k: 0.5000 - lcm_f1_5k: 0.4351 - lcm_accuracy_1k: 0.6254 - lcm_accuracy_2k: 0.7815 - lcm_accuracy_3k: 0.8360 - lcm_accuracy_5k: 0.9040 - lcm_hamming_loss_k: 0.0375 - val_loss: 0.8395 - val_lcm_precision_1k: 0.6246 - val_lcm_precision_2k: 0.4977 - val_lcm_precision_3k: 0.4072 - val_lcm_precision_5k: 0.2972 - val_lcm_recall_1k: 0.3440 - val_lcm_recall_2k: 0.5216 - val_lcm_recall_3k: 0.6250 - val_lcm_recall_5k: 0.7398 - val_lcm_f1_1k: 0.4433 - val_lcm_f1_2k: 0.5090 - val_lcm_f1_3k: 0.4928 - val_lcm_f1_5k: 0.4237 - val_lcm_accuracy_1k: 0.6246 - val_lcm_accuracy_2k: 0.7437 - val_lcm_accuracy_3k: 0.8239 - val_lcm_accuracy_5k: 0.8933 - val_lcm_hamming_loss_k: 0.0378
Epoch 8/100
12/12 [==============================] - ETA: 0s - loss: 0.7620 - lcm_precision_1k: 0.6544 - lcm_precision_2k: 0.5210 - lcm_precision_3k: 0.4232 - lcm_precision_5k: 0.3069 - lcm_recall_1k: 0.3818 - lcm_recall_2k: 0.5634 - lcm_recall_3k: 0.6619 - lcm_recall_5k: 0.7727 - lcm_f1_1k: 0.4821 - lcm_f1_2k: 0.5412 - lcm_f1_3k: 0.5162 - lcm_f1_5k: 0.4392 - lcm_accuracy_1k: 0.6544 - lcm_accuracy_2k: 0.7896 - lcm_accuracy_3k: 0.8536 - lcm_accuracy_5k: 0.9118 - lcm_hamming_loss_k: 0.0363
Epoch 00008: val_loss improved from 0.83950 to 0.77498, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 82ms/step - loss: 0.7620 - lcm_precision_1k: 0.6544 - lcm_precision_2k: 0.5210 - lcm_precision_3k: 0.4232 - lcm_precision_5k: 0.3069 - lcm_recall_1k: 0.3818 - lcm_recall_2k: 0.5634 - lcm_recall_3k: 0.6619 - lcm_recall_5k: 0.7727 - lcm_f1_1k: 0.4821 - lcm_f1_2k: 0.5412 - lcm_f1_3k: 0.5162 - lcm_f1_5k: 0.4392 - lcm_accuracy_1k: 0.6544 - lcm_accuracy_2k: 0.7896 - lcm_accuracy_3k: 0.8536 - lcm_accuracy_5k: 0.9118 - lcm_hamming_loss_k: 0.0363 - val_loss: 0.7750 - val_lcm_precision_1k: 0.6619 - val_lcm_precision_2k: 0.5497 - val_lcm_precision_3k: 0.4351 - val_lcm_precision_5k: 0.3078 - val_lcm_recall_1k: 0.3691 - val_lcm_recall_2k: 0.5727 - val_lcm_recall_3k: 0.6655 - val_lcm_recall_5k: 0.7656 - val_lcm_f1_1k: 0.4737 - val_lcm_f1_2k: 0.5605 - val_lcm_f1_3k: 0.5257 - val_lcm_f1_5k: 0.4388 - val_lcm_accuracy_1k: 0.6619 - val_lcm_accuracy_2k: 0.7974 - val_lcm_accuracy_3k: 0.8562 - val_lcm_accuracy_5k: 0.9038 - val_lcm_hamming_loss_k: 0.0363
Epoch 9/100
12/12 [==============================] - ETA: 0s - loss: 0.7095 - lcm_precision_1k: 0.6742 - lcm_precision_2k: 0.5540 - lcm_precision_3k: 0.4449 - lcm_precision_5k: 0.3223 - lcm_recall_1k: 0.3946 - lcm_recall_2k: 0.5964 - lcm_recall_3k: 0.6941 - lcm_recall_5k: 0.8083 - lcm_f1_1k: 0.4977 - lcm_f1_2k: 0.5743 - lcm_f1_3k: 0.5421 - lcm_f1_5k: 0.4608 - lcm_accuracy_1k: 0.6742 - lcm_accuracy_2k: 0.8263 - lcm_accuracy_3k: 0.8743 - lcm_accuracy_5k: 0.9322 - lcm_hamming_loss_k: 0.0355
Epoch 00009: val_loss improved from 0.77498 to 0.69151, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 80ms/step - loss: 0.7095 - lcm_precision_1k: 0.6742 - lcm_precision_2k: 0.5540 - lcm_precision_3k: 0.4449 - lcm_precision_5k: 0.3223 - lcm_recall_1k: 0.3946 - lcm_recall_2k: 0.5964 - lcm_recall_3k: 0.6941 - lcm_recall_5k: 0.8083 - lcm_f1_1k: 0.4977 - lcm_f1_2k: 0.5743 - lcm_f1_3k: 0.5421 - lcm_f1_5k: 0.4608 - lcm_accuracy_1k: 0.6742 - lcm_accuracy_2k: 0.8263 - lcm_accuracy_3k: 0.8743 - lcm_accuracy_5k: 0.9322 - lcm_hamming_loss_k: 0.0355 - val_loss: 0.6915 - val_lcm_precision_1k: 0.7424 - val_lcm_precision_2k: 0.5915 - val_lcm_precision_3k: 0.4645 - val_lcm_precision_5k: 0.3210 - val_lcm_recall_1k: 0.4179 - val_lcm_recall_2k: 0.6118 - val_lcm_recall_3k: 0.7038 - val_lcm_recall_5k: 0.7953 - val_lcm_f1_1k: 0.5344 - val_lcm_f1_2k: 0.6010 - val_lcm_f1_3k: 0.5592 - val_lcm_f1_5k: 0.4571 - val_lcm_accuracy_1k: 0.7424 - val_lcm_accuracy_2k: 0.8466 - val_lcm_accuracy_3k: 0.8835 - val_lcm_accuracy_5k: 0.9211 - val_lcm_hamming_loss_k: 0.0330
Epoch 10/100
12/12 [==============================] - ETA: 0s - loss: 0.6459 - lcm_precision_1k: 0.7380 - lcm_precision_2k: 0.5820 - lcm_precision_3k: 0.4682 - lcm_precision_5k: 0.3321 - lcm_recall_1k: 0.4281 - lcm_recall_2k: 0.6210 - lcm_recall_3k: 0.7245 - lcm_recall_5k: 0.8336 - lcm_f1_1k: 0.5418 - lcm_f1_2k: 0.6008 - lcm_f1_3k: 0.5687 - lcm_f1_5k: 0.4749 - lcm_accuracy_1k: 0.7380 - lcm_accuracy_2k: 0.8483 - lcm_accuracy_3k: 0.8984 - lcm_accuracy_5k: 0.9482 - lcm_hamming_loss_k: 0.0328
Epoch 00010: val_loss improved from 0.69151 to 0.66156, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 79ms/step - loss: 0.6459 - lcm_precision_1k: 0.7380 - lcm_precision_2k: 0.5820 - lcm_precision_3k: 0.4682 - lcm_precision_5k: 0.3321 - lcm_recall_1k: 0.4281 - lcm_recall_2k: 0.6210 - lcm_recall_3k: 0.7245 - lcm_recall_5k: 0.8336 - lcm_f1_1k: 0.5418 - lcm_f1_2k: 0.6008 - lcm_f1_3k: 0.5687 - lcm_f1_5k: 0.4749 - lcm_accuracy_1k: 0.7380 - lcm_accuracy_2k: 0.8483 - lcm_accuracy_3k: 0.8984 - lcm_accuracy_5k: 0.9482 - lcm_hamming_loss_k: 0.0328 - val_loss: 0.6616 - val_lcm_precision_1k: 0.7445 - val_lcm_precision_2k: 0.5936 - val_lcm_precision_3k: 0.4748 - val_lcm_precision_5k: 0.3333 - val_lcm_recall_1k: 0.4122 - val_lcm_recall_2k: 0.6152 - val_lcm_recall_3k: 0.7163 - val_lcm_recall_5k: 0.8212 - val_lcm_f1_1k: 0.5303 - val_lcm_f1_2k: 0.6039 - val_lcm_f1_3k: 0.5708 - val_lcm_f1_5k: 0.4739 - val_lcm_accuracy_1k: 0.7445 - val_lcm_accuracy_2k: 0.8567 - val_lcm_accuracy_3k: 0.8949 - val_lcm_accuracy_5k: 0.9338 - val_lcm_hamming_loss_k: 0.0329
Epoch 11/100
11/12 [==========================>...] - ETA: 0s - loss: 0.6134 - lcm_precision_1k: 0.7617 - lcm_precision_2k: 0.6071 - lcm_precision_3k: 0.4872 - lcm_precision_5k: 0.3391 - lcm_recall_1k: 0.4441 - lcm_recall_2k: 0.6482 - lcm_recall_3k: 0.7528 - lcm_recall_5k: 0.8488 - lcm_f1_1k: 0.5610 - lcm_f1_2k: 0.6268 - lcm_f1_3k: 0.5915 - lcm_f1_5k: 0.4846 - lcm_accuracy_1k: 0.7617 - lcm_accuracy_2k: 0.8754 - lcm_accuracy_3k: 0.9201 - lcm_accuracy_5k: 0.9570 - lcm_hamming_loss_k: 0.0320
Epoch 00011: val_loss improved from 0.66156 to 0.64658, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 74ms/step - loss: 0.6158 - lcm_precision_1k: 0.7582 - lcm_precision_2k: 0.6049 - lcm_precision_3k: 0.4851 - lcm_precision_5k: 0.3376 - lcm_recall_1k: 0.4412 - lcm_recall_2k: 0.6461 - lcm_recall_3k: 0.7509 - lcm_recall_5k: 0.8484 - lcm_f1_1k: 0.5577 - lcm_f1_2k: 0.6247 - lcm_f1_3k: 0.5893 - lcm_f1_5k: 0.4829 - lcm_accuracy_1k: 0.7582 - lcm_accuracy_2k: 0.8705 - lcm_accuracy_3k: 0.9181 - lcm_accuracy_5k: 0.9584 - lcm_hamming_loss_k: 0.0320 - val_loss: 0.6466 - val_lcm_precision_1k: 0.7406 - val_lcm_precision_2k: 0.6050 - val_lcm_precision_3k: 0.4865 - val_lcm_precision_5k: 0.3375 - val_lcm_recall_1k: 0.4053 - val_lcm_recall_2k: 0.6228 - val_lcm_recall_3k: 0.7305 - val_lcm_recall_5k: 0.8290 - val_lcm_f1_1k: 0.5235 - val_lcm_f1_2k: 0.6132 - val_lcm_f1_3k: 0.5837 - val_lcm_f1_5k: 0.4794 - val_lcm_accuracy_1k: 0.7406 - val_lcm_accuracy_2k: 0.8534 - val_lcm_accuracy_3k: 0.8935 - val_lcm_accuracy_5k: 0.9381 - val_lcm_hamming_loss_k: 0.0330
Epoch 12/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5917 - lcm_precision_1k: 0.7685 - lcm_precision_2k: 0.6113 - lcm_precision_3k: 0.4889 - lcm_precision_5k: 0.3437 - lcm_recall_1k: 0.4476 - lcm_recall_2k: 0.6560 - lcm_recall_3k: 0.7610 - lcm_recall_5k: 0.8611 - lcm_f1_1k: 0.5655 - lcm_f1_2k: 0.6327 - lcm_f1_3k: 0.5952 - lcm_f1_5k: 0.4913 - lcm_accuracy_1k: 0.7685 - lcm_accuracy_2k: 0.8810 - lcm_accuracy_3k: 0.9272 - lcm_accuracy_5k: 0.9631 - lcm_hamming_loss_k: 0.0316
Epoch 00012: val_loss improved from 0.64658 to 0.63367, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 77ms/step - loss: 0.5898 - lcm_precision_1k: 0.7703 - lcm_precision_2k: 0.6127 - lcm_precision_3k: 0.4913 - lcm_precision_5k: 0.3452 - lcm_recall_1k: 0.4488 - lcm_recall_2k: 0.6570 - lcm_recall_3k: 0.7638 - lcm_recall_5k: 0.8624 - lcm_f1_1k: 0.5670 - lcm_f1_2k: 0.6339 - lcm_f1_3k: 0.5979 - lcm_f1_5k: 0.4929 - lcm_accuracy_1k: 0.7703 - lcm_accuracy_2k: 0.8839 - lcm_accuracy_3k: 0.9295 - lcm_accuracy_5k: 0.9645 - lcm_hamming_loss_k: 0.0317 - val_loss: 0.6337 - val_lcm_precision_1k: 0.7584 - val_lcm_precision_2k: 0.6066 - val_lcm_precision_3k: 0.4862 - val_lcm_precision_5k: 0.3371 - val_lcm_recall_1k: 0.4264 - val_lcm_recall_2k: 0.6334 - val_lcm_recall_3k: 0.7375 - val_lcm_recall_5k: 0.8328 - val_lcm_f1_1k: 0.5457 - val_lcm_f1_2k: 0.6193 - val_lcm_f1_3k: 0.5857 - val_lcm_f1_5k: 0.4796 - val_lcm_accuracy_1k: 0.7584 - val_lcm_accuracy_2k: 0.8689 - val_lcm_accuracy_3k: 0.9042 - val_lcm_accuracy_5k: 0.9445 - val_lcm_hamming_loss_k: 0.0323
Epoch 13/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5639 - lcm_precision_1k: 0.7962 - lcm_precision_2k: 0.6259 - lcm_precision_3k: 0.4983 - lcm_precision_5k: 0.3500 - lcm_recall_1k: 0.4638 - lcm_recall_2k: 0.6717 - lcm_recall_3k: 0.7745 - lcm_recall_5k: 0.8737 - lcm_f1_1k: 0.5860 - lcm_f1_2k: 0.6478 - lcm_f1_3k: 0.6063 - lcm_f1_5k: 0.4997 - lcm_accuracy_1k: 0.7962 - lcm_accuracy_2k: 0.8974 - lcm_accuracy_3k: 0.9332 - lcm_accuracy_5k: 0.9684 - lcm_hamming_loss_k: 0.0305
Epoch 00013: val_loss improved from 0.63367 to 0.62499, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 84ms/step - loss: 0.5633 - lcm_precision_1k: 0.7952 - lcm_precision_2k: 0.6255 - lcm_precision_3k: 0.4993 - lcm_precision_5k: 0.3504 - lcm_recall_1k: 0.4638 - lcm_recall_2k: 0.6706 - lcm_recall_3k: 0.7739 - lcm_recall_5k: 0.8721 - lcm_f1_1k: 0.5857 - lcm_f1_2k: 0.6470 - lcm_f1_3k: 0.6068 - lcm_f1_5k: 0.4998 - lcm_accuracy_1k: 0.7952 - lcm_accuracy_2k: 0.8978 - lcm_accuracy_3k: 0.9344 - lcm_accuracy_5k: 0.9678 - lcm_hamming_loss_k: 0.0306 - val_loss: 0.6250 - val_lcm_precision_1k: 0.7645 - val_lcm_precision_2k: 0.6052 - val_lcm_precision_3k: 0.4866 - val_lcm_precision_5k: 0.3383 - val_lcm_recall_1k: 0.4268 - val_lcm_recall_2k: 0.6278 - val_lcm_recall_3k: 0.7375 - val_lcm_recall_5k: 0.8341 - val_lcm_f1_1k: 0.5474 - val_lcm_f1_2k: 0.6158 - val_lcm_f1_3k: 0.5858 - val_lcm_f1_5k: 0.4810 - val_lcm_accuracy_1k: 0.7645 - val_lcm_accuracy_2k: 0.8563 - val_lcm_accuracy_3k: 0.9081 - val_lcm_accuracy_5k: 0.9456 - val_lcm_hamming_loss_k: 0.0321
Epoch 14/100
12/12 [==============================] - ETA: 0s - loss: 0.5405 - lcm_precision_1k: 0.8029 - lcm_precision_2k: 0.6330 - lcm_precision_3k: 0.5089 - lcm_precision_5k: 0.3564 - lcm_recall_1k: 0.4673 - lcm_recall_2k: 0.6772 - lcm_recall_3k: 0.7876 - lcm_recall_5k: 0.8878 - lcm_f1_1k: 0.5906 - lcm_f1_2k: 0.6543 - lcm_f1_3k: 0.6182 - lcm_f1_5k: 0.5086 - lcm_accuracy_1k: 0.8029 - lcm_accuracy_2k: 0.9025 - lcm_accuracy_3k: 0.9452 - lcm_accuracy_5k: 0.9740 - lcm_hamming_loss_k: 0.0303
Epoch 00014: val_loss did not improve from 0.62499
12/12 [==============================] - 1s 65ms/step - loss: 0.5405 - lcm_precision_1k: 0.8029 - lcm_precision_2k: 0.6330 - lcm_precision_3k: 0.5089 - lcm_precision_5k: 0.3564 - lcm_recall_1k: 0.4673 - lcm_recall_2k: 0.6772 - lcm_recall_3k: 0.7876 - lcm_recall_5k: 0.8878 - lcm_f1_1k: 0.5906 - lcm_f1_2k: 0.6543 - lcm_f1_3k: 0.6182 - lcm_f1_5k: 0.5086 - lcm_accuracy_1k: 0.8029 - lcm_accuracy_2k: 0.9025 - lcm_accuracy_3k: 0.9452 - lcm_accuracy_5k: 0.9740 - lcm_hamming_loss_k: 0.0303 - val_loss: 0.6587 - val_lcm_precision_1k: 0.7302 - val_lcm_precision_2k: 0.5919 - val_lcm_precision_3k: 0.4722 - val_lcm_precision_5k: 0.3377 - val_lcm_recall_1k: 0.4117 - val_lcm_recall_2k: 0.6117 - val_lcm_recall_3k: 0.7173 - val_lcm_recall_5k: 0.8285 - val_lcm_f1_1k: 0.5262 - val_lcm_f1_2k: 0.6012 - val_lcm_f1_3k: 0.5691 - val_lcm_f1_5k: 0.4796 - val_lcm_accuracy_1k: 0.7302 - val_lcm_accuracy_2k: 0.8537 - val_lcm_accuracy_3k: 0.8959 - val_lcm_accuracy_5k: 0.9393 - val_lcm_hamming_loss_k: 0.0335
Epoch 15/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5439 - lcm_precision_1k: 0.7944 - lcm_precision_2k: 0.6307 - lcm_precision_3k: 0.5136 - lcm_precision_5k: 0.3580 - lcm_recall_1k: 0.4634 - lcm_recall_2k: 0.6723 - lcm_recall_3k: 0.7930 - lcm_recall_5k: 0.8891 - lcm_f1_1k: 0.5852 - lcm_f1_2k: 0.6507 - lcm_f1_3k: 0.6234 - lcm_f1_5k: 0.5104 - lcm_accuracy_1k: 0.7944 - lcm_accuracy_2k: 0.8974 - lcm_accuracy_3k: 0.9425 - lcm_accuracy_5k: 0.9720 - lcm_hamming_loss_k: 0.0307
Epoch 00015: val_loss improved from 0.62499 to 0.61863, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 81ms/step - loss: 0.5438 - lcm_precision_1k: 0.7935 - lcm_precision_2k: 0.6282 - lcm_precision_3k: 0.5124 - lcm_precision_5k: 0.3572 - lcm_recall_1k: 0.4635 - lcm_recall_2k: 0.6704 - lcm_recall_3k: 0.7928 - lcm_recall_5k: 0.8889 - lcm_f1_1k: 0.5851 - lcm_f1_2k: 0.6486 - lcm_f1_3k: 0.6224 - lcm_f1_5k: 0.5095 - lcm_accuracy_1k: 0.7935 - lcm_accuracy_2k: 0.8956 - lcm_accuracy_3k: 0.9418 - lcm_accuracy_5k: 0.9721 - lcm_hamming_loss_k: 0.0306 - val_loss: 0.6186 - val_lcm_precision_1k: 0.7633 - val_lcm_precision_2k: 0.6115 - val_lcm_precision_3k: 0.4901 - val_lcm_precision_5k: 0.3407 - val_lcm_recall_1k: 0.4269 - val_lcm_recall_2k: 0.6382 - val_lcm_recall_3k: 0.7379 - val_lcm_recall_5k: 0.8384 - val_lcm_f1_1k: 0.5471 - val_lcm_f1_2k: 0.6240 - val_lcm_f1_3k: 0.5886 - val_lcm_f1_5k: 0.4843 - val_lcm_accuracy_1k: 0.7633 - val_lcm_accuracy_2k: 0.8779 - val_lcm_accuracy_3k: 0.9137 - val_lcm_accuracy_5k: 0.9529 - val_lcm_hamming_loss_k: 0.0321
Epoch 16/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5108 - lcm_precision_1k: 0.8295 - lcm_precision_2k: 0.6465 - lcm_precision_3k: 0.5250 - lcm_precision_5k: 0.3596 - lcm_recall_1k: 0.4888 - lcm_recall_2k: 0.6938 - lcm_recall_3k: 0.8110 - lcm_recall_5k: 0.8960 - lcm_f1_1k: 0.6150 - lcm_f1_2k: 0.6692 - lcm_f1_3k: 0.6372 - lcm_f1_5k: 0.5131 - lcm_accuracy_1k: 0.8295 - lcm_accuracy_2k: 0.9166 - lcm_accuracy_3k: 0.9553 - lcm_accuracy_5k: 0.9773 - lcm_hamming_loss_k: 0.0291
Epoch 00016: val_loss improved from 0.61863 to 0.59392, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 87ms/step - loss: 0.5106 - lcm_precision_1k: 0.8290 - lcm_precision_2k: 0.6482 - lcm_precision_3k: 0.5271 - lcm_precision_5k: 0.3606 - lcm_recall_1k: 0.4859 - lcm_recall_2k: 0.6933 - lcm_recall_3k: 0.8117 - lcm_recall_5k: 0.8954 - lcm_f1_1k: 0.6126 - lcm_f1_2k: 0.6698 - lcm_f1_3k: 0.6391 - lcm_f1_5k: 0.5140 - lcm_accuracy_1k: 0.8290 - lcm_accuracy_2k: 0.9175 - lcm_accuracy_3k: 0.9568 - lcm_accuracy_5k: 0.9781 - lcm_hamming_loss_k: 0.0293 - val_loss: 0.5939 - val_lcm_precision_1k: 0.7926 - val_lcm_precision_2k: 0.6250 - val_lcm_precision_3k: 0.5009 - val_lcm_precision_5k: 0.3468 - val_lcm_recall_1k: 0.4430 - val_lcm_recall_2k: 0.6519 - val_lcm_recall_3k: 0.7588 - val_lcm_recall_5k: 0.8571 - val_lcm_f1_1k: 0.5677 - val_lcm_f1_2k: 0.6375 - val_lcm_f1_3k: 0.6028 - val_lcm_f1_5k: 0.4934 - val_lcm_accuracy_1k: 0.7926 - val_lcm_accuracy_2k: 0.8806 - val_lcm_accuracy_3k: 0.9191 - val_lcm_accuracy_5k: 0.9568 - val_lcm_hamming_loss_k: 0.0309
Epoch 17/100
11/12 [==========================>...] - ETA: 0s - loss: 0.4862 - lcm_precision_1k: 0.8466 - lcm_precision_2k: 0.6673 - lcm_precision_3k: 0.5304 - lcm_precision_5k: 0.3665 - lcm_recall_1k: 0.4925 - lcm_recall_2k: 0.7095 - lcm_recall_3k: 0.8159 - lcm_recall_5k: 0.9090 - lcm_f1_1k: 0.6226 - lcm_f1_2k: 0.6876 - lcm_f1_3k: 0.6428 - lcm_f1_5k: 0.5223 - lcm_accuracy_1k: 0.8466 - lcm_accuracy_2k: 0.9226 - lcm_accuracy_3k: 0.9567 - lcm_accuracy_5k: 0.9830 - lcm_hamming_loss_k: 0.0285
Epoch 00017: val_loss improved from 0.59392 to 0.58218, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 92ms/step - loss: 0.4862 - lcm_precision_1k: 0.8447 - lcm_precision_2k: 0.6661 - lcm_precision_3k: 0.5301 - lcm_precision_5k: 0.3662 - lcm_recall_1k: 0.4934 - lcm_recall_2k: 0.7098 - lcm_recall_3k: 0.8174 - lcm_recall_5k: 0.9094 - lcm_f1_1k: 0.6228 - lcm_f1_2k: 0.6872 - lcm_f1_3k: 0.6430 - lcm_f1_5k: 0.5221 - lcm_accuracy_1k: 0.8447 - lcm_accuracy_2k: 0.9241 - lcm_accuracy_3k: 0.9581 - lcm_accuracy_5k: 0.9839 - lcm_hamming_loss_k: 0.0286 - val_loss: 0.5822 - val_lcm_precision_1k: 0.7935 - val_lcm_precision_2k: 0.6397 - val_lcm_precision_3k: 0.5058 - val_lcm_precision_5k: 0.3503 - val_lcm_recall_1k: 0.4456 - val_lcm_recall_2k: 0.6644 - val_lcm_recall_3k: 0.7689 - val_lcm_recall_5k: 0.8647 - val_lcm_f1_1k: 0.5703 - val_lcm_f1_2k: 0.6513 - val_lcm_f1_3k: 0.6096 - val_lcm_f1_5k: 0.4983 - val_lcm_accuracy_1k: 0.7935 - val_lcm_accuracy_2k: 0.8907 - val_lcm_accuracy_3k: 0.9316 - val_lcm_accuracy_5k: 0.9582 - val_lcm_hamming_loss_k: 0.0309
Epoch 18/100
11/12 [==========================>...] - ETA: 0s - loss: 0.4737 - lcm_precision_1k: 0.8505 - lcm_precision_2k: 0.6790 - lcm_precision_3k: 0.5416 - lcm_precision_5k: 0.3704 - lcm_recall_1k: 0.4970 - lcm_recall_2k: 0.7235 - lcm_recall_3k: 0.8327 - lcm_recall_5k: 0.9152 - lcm_f1_1k: 0.6273 - lcm_f1_2k: 0.7004 - lcm_f1_3k: 0.6562 - lcm_f1_5k: 0.5273 - lcm_accuracy_1k: 0.8505 - lcm_accuracy_2k: 0.9364 - lcm_accuracy_3k: 0.9698 - lcm_accuracy_5k: 0.9865 - lcm_hamming_loss_k: 0.0285
Epoch 00018: val_loss improved from 0.58218 to 0.57438, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 93ms/step - loss: 0.4701 - lcm_precision_1k: 0.8564 - lcm_precision_2k: 0.6809 - lcm_precision_3k: 0.5407 - lcm_precision_5k: 0.3687 - lcm_recall_1k: 0.5048 - lcm_recall_2k: 0.7307 - lcm_recall_3k: 0.8373 - lcm_recall_5k: 0.9176 - lcm_f1_1k: 0.6350 - lcm_f1_2k: 0.7048 - lcm_f1_3k: 0.6570 - lcm_f1_5k: 0.5259 - lcm_accuracy_1k: 0.8564 - lcm_accuracy_2k: 0.9390 - lcm_accuracy_3k: 0.9713 - lcm_accuracy_5k: 0.9871 - lcm_hamming_loss_k: 0.0280 - val_loss: 0.5744 - val_lcm_precision_1k: 0.7931 - val_lcm_precision_2k: 0.6429 - val_lcm_precision_3k: 0.5092 - val_lcm_precision_5k: 0.3537 - val_lcm_recall_1k: 0.4438 - val_lcm_recall_2k: 0.6702 - val_lcm_recall_3k: 0.7714 - val_lcm_recall_5k: 0.8691 - val_lcm_f1_1k: 0.5687 - val_lcm_f1_2k: 0.6557 - val_lcm_f1_3k: 0.6128 - val_lcm_f1_5k: 0.5024 - val_lcm_accuracy_1k: 0.7931 - val_lcm_accuracy_2k: 0.8971 - val_lcm_accuracy_3k: 0.9270 - val_lcm_accuracy_5k: 0.9597 - val_lcm_hamming_loss_k: 0.0309
Epoch 19/100
12/12 [==============================] - ETA: 0s - loss: 0.4408 - lcm_precision_1k: 0.8756 - lcm_precision_2k: 0.6917 - lcm_precision_3k: 0.5519 - lcm_precision_5k: 0.3728 - lcm_recall_1k: 0.5154 - lcm_recall_2k: 0.7373 - lcm_recall_3k: 0.8484 - lcm_recall_5k: 0.9247 - lcm_f1_1k: 0.6487 - lcm_f1_2k: 0.7136 - lcm_f1_3k: 0.6686 - lcm_f1_5k: 0.5313 - lcm_accuracy_1k: 0.8756 - lcm_accuracy_2k: 0.9428 - lcm_accuracy_3k: 0.9703 - lcm_accuracy_5k: 0.9882 - lcm_hamming_loss_k: 0.0273
Epoch 00019: val_loss improved from 0.57438 to 0.56371, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 89ms/step - loss: 0.4408 - lcm_precision_1k: 0.8756 - lcm_precision_2k: 0.6917 - lcm_precision_3k: 0.5519 - lcm_precision_5k: 0.3728 - lcm_recall_1k: 0.5154 - lcm_recall_2k: 0.7373 - lcm_recall_3k: 0.8484 - lcm_recall_5k: 0.9247 - lcm_f1_1k: 0.6487 - lcm_f1_2k: 0.7136 - lcm_f1_3k: 0.6686 - lcm_f1_5k: 0.5313 - lcm_accuracy_1k: 0.8756 - lcm_accuracy_2k: 0.9428 - lcm_accuracy_3k: 0.9703 - lcm_accuracy_5k: 0.9882 - lcm_hamming_loss_k: 0.0273 - val_loss: 0.5637 - val_lcm_precision_1k: 0.8084 - val_lcm_precision_2k: 0.6469 - val_lcm_precision_3k: 0.5121 - val_lcm_precision_5k: 0.3524 - val_lcm_recall_1k: 0.4526 - val_lcm_recall_2k: 0.6733 - val_lcm_recall_3k: 0.7749 - val_lcm_recall_5k: 0.8660 - val_lcm_f1_1k: 0.5797 - val_lcm_f1_2k: 0.6590 - val_lcm_f1_3k: 0.6161 - val_lcm_f1_5k: 0.5006 - val_lcm_accuracy_1k: 0.8084 - val_lcm_accuracy_2k: 0.9046 - val_lcm_accuracy_3k: 0.9309 - val_lcm_accuracy_5k: 0.9598 - val_lcm_hamming_loss_k: 0.0303
Epoch 20/100
11/12 [==========================>...] - ETA: 0s - loss: 0.4328 - lcm_precision_1k: 0.8803 - lcm_precision_2k: 0.6966 - lcm_precision_3k: 0.5497 - lcm_precision_5k: 0.3748 - lcm_recall_1k: 0.5177 - lcm_recall_2k: 0.7435 - lcm_recall_3k: 0.8493 - lcm_recall_5k: 0.9286 - lcm_f1_1k: 0.6518 - lcm_f1_2k: 0.7191 - lcm_f1_3k: 0.6673 - lcm_f1_5k: 0.5340 - lcm_accuracy_1k: 0.8803 - lcm_accuracy_2k: 0.9460 - lcm_accuracy_3k: 0.9752 - lcm_accuracy_5k: 0.9876 - lcm_hamming_loss_k: 0.0270
Epoch 00020: val_loss improved from 0.56371 to 0.55462, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 97ms/step - loss: 0.4344 - lcm_precision_1k: 0.8821 - lcm_precision_2k: 0.6965 - lcm_precision_3k: 0.5502 - lcm_precision_5k: 0.3759 - lcm_recall_1k: 0.5168 - lcm_recall_2k: 0.7407 - lcm_recall_3k: 0.8464 - lcm_recall_5k: 0.9272 - lcm_f1_1k: 0.6516 - lcm_f1_2k: 0.7178 - lcm_f1_3k: 0.6668 - lcm_f1_5k: 0.5348 - lcm_accuracy_1k: 0.8821 - lcm_accuracy_2k: 0.9467 - lcm_accuracy_3k: 0.9745 - lcm_accuracy_5k: 0.9875 - lcm_hamming_loss_k: 0.0271 - val_loss: 0.5546 - val_lcm_precision_1k: 0.8087 - val_lcm_precision_2k: 0.6516 - val_lcm_precision_3k: 0.5132 - val_lcm_precision_5k: 0.3562 - val_lcm_recall_1k: 0.4492 - val_lcm_recall_2k: 0.6754 - val_lcm_recall_3k: 0.7765 - val_lcm_recall_5k: 0.8752 - val_lcm_f1_1k: 0.5769 - val_lcm_f1_2k: 0.6625 - val_lcm_f1_3k: 0.6173 - val_lcm_f1_5k: 0.5060 - val_lcm_accuracy_1k: 0.8087 - val_lcm_accuracy_2k: 0.8937 - val_lcm_accuracy_3k: 0.9269 - val_lcm_accuracy_5k: 0.9640 - val_lcm_hamming_loss_k: 0.0303
Epoch 21/100
12/12 [==============================] - ETA: 0s - loss: 0.4055 - lcm_precision_1k: 0.8973 - lcm_precision_2k: 0.7090 - lcm_precision_3k: 0.5626 - lcm_precision_5k: 0.3805 - lcm_recall_1k: 0.5286 - lcm_recall_2k: 0.7564 - lcm_recall_3k: 0.8643 - lcm_recall_5k: 0.9392 - lcm_f1_1k: 0.6651 - lcm_f1_2k: 0.7318 - lcm_f1_3k: 0.6814 - lcm_f1_5k: 0.5415 - lcm_accuracy_1k: 0.8973 - lcm_accuracy_2k: 0.9565 - lcm_accuracy_3k: 0.9828 - lcm_accuracy_5k: 0.9938 - lcm_hamming_loss_k: 0.0264
Epoch 00021: val_loss improved from 0.55462 to 0.53560, saving model to logs/mmgqkj-lbs-0604-114213/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 91ms/step - loss: 0.4055 - lcm_precision_1k: 0.8973 - lcm_precision_2k: 0.7090 - lcm_precision_3k: 0.5626 - lcm_precision_5k: 0.3805 - lcm_recall_1k: 0.5286 - lcm_recall_2k: 0.7564 - lcm_recall_3k: 0.8643 - lcm_recall_5k: 0.9392 - lcm_f1_1k: 0.6651 - lcm_f1_2k: 0.7318 - lcm_f1_3k: 0.6814 - lcm_f1_5k: 0.5415 - lcm_accuracy_1k: 0.8973 - lcm_accuracy_2k: 0.9565 - lcm_accuracy_3k: 0.9828 - lcm_accuracy_5k: 0.9938 - lcm_hamming_loss_k: 0.0264 - val_loss: 0.5356 - val_lcm_precision_1k: 0.8117 - val_lcm_precision_2k: 0.6669 - val_lcm_precision_3k: 0.5236 - val_lcm_precision_5k: 0.3578 - val_lcm_recall_1k: 0.4591 - val_lcm_recall_2k: 0.6946 - val_lcm_recall_3k: 0.7947 - val_lcm_recall_5k: 0.8795 - val_lcm_f1_1k: 0.5860 - val_lcm_f1_2k: 0.6799 - val_lcm_f1_3k: 0.6306 - val_lcm_f1_5k: 0.5083 - val_lcm_accuracy_1k: 0.8117 - val_lcm_accuracy_2k: 0.9165 - val_lcm_accuracy_3k: 0.9406 - val_lcm_accuracy_5k: 0.9663 - val_lcm_hamming_loss_k: 0.0301
Epoch 22/100
12/12 [==============================] - ETA: 0s - loss: 0.3871 - lcm_precision_1k: 0.9018 - lcm_precision_2k: 0.7188 - lcm_precision_3k: 0.5683 - lcm_precision_5k: 0.3835 - lcm_recall_1k: 0.5329 - lcm_recall_2k: 0.7690 - lcm_recall_3k: 0.8734 - lcm_recall_5k: 0.9458 - lcm_f1_1k: 0.6698 - lcm_f1_2k: 0.7430 - lcm_f1_3k: 0.6886 - lcm_f1_5k: 0.5456 - lcm_accuracy_1k: 0.9018 - lcm_accuracy_2k: 0.9631 - lcm_accuracy_3k: 0.9861 - lcm_accuracy_5k: 0.9946 - lcm_hamming_loss_k: 0.0262
Epoch 00022: val_loss did not improve from 0.53560
12/12 [==============================] - 1s 62ms/step - loss: 0.3871 - lcm_precision_1k: 0.9018 - lcm_precision_2k: 0.7188 - lcm_precision_3k: 0.5683 - lcm_precision_5k: 0.3835 - lcm_recall_1k: 0.5329 - lcm_recall_2k: 0.7690 - lcm_recall_3k: 0.8734 - lcm_recall_5k: 0.9458 - lcm_f1_1k: 0.6698 - lcm_f1_2k: 0.7430 - lcm_f1_3k: 0.6886 - lcm_f1_5k: 0.5456 - lcm_accuracy_1k: 0.9018 - lcm_accuracy_2k: 0.9631 - lcm_accuracy_3k: 0.9861 - lcm_accuracy_5k: 0.9946 - lcm_hamming_loss_k: 0.0262 - val_loss: 0.5404 - val_lcm_precision_1k: 0.8244 - val_lcm_precision_2k: 0.6622 - val_lcm_precision_3k: 0.5231 - val_lcm_precision_5k: 0.3574 - val_lcm_recall_1k: 0.4644 - val_lcm_recall_2k: 0.6925 - val_lcm_recall_3k: 0.7917 - val_lcm_recall_5k: 0.8790 - val_lcm_f1_1k: 0.5936 - val_lcm_f1_2k: 0.6763 - val_lcm_f1_3k: 0.6293 - val_lcm_f1_5k: 0.5078 - val_lcm_accuracy_1k: 0.8244 - val_lcm_accuracy_2k: 0.9137 - val_lcm_accuracy_3k: 0.9422 - val_lcm_accuracy_5k: 0.9663 - val_lcm_hamming_loss_k: 0.0296
Epoch 23/100
11/12 [==========================>...] - ETA: 0s - loss: 0.3755 - lcm_precision_1k: 0.9162 - lcm_precision_2k: 0.7271 - lcm_precision_3k: 0.5746 - lcm_precision_5k: 0.3854 - lcm_recall_1k: 0.5417 - lcm_recall_2k: 0.7767 - lcm_recall_3k: 0.8790 - lcm_recall_5k: 0.9493 - lcm_f1_1k: 0.6808 - lcm_f1_2k: 0.7510 - lcm_f1_3k: 0.6948 - lcm_f1_5k: 0.5482 - lcm_accuracy_1k: 0.9162 - lcm_accuracy_2k: 0.9705 - lcm_accuracy_3k: 0.9876 - lcm_accuracy_5k: 0.9965 - lcm_hamming_loss_k: 0.0257
Epoch 00023: val_loss did not improve from 0.53560
12/12 [==============================] - 1s 63ms/step - loss: 0.3746 - lcm_precision_1k: 0.9166 - lcm_precision_2k: 0.7267 - lcm_precision_3k: 0.5744 - lcm_precision_5k: 0.3849 - lcm_recall_1k: 0.5431 - lcm_recall_2k: 0.7774 - lcm_recall_3k: 0.8797 - lcm_recall_5k: 0.9491 - lcm_f1_1k: 0.6820 - lcm_f1_2k: 0.7511 - lcm_f1_3k: 0.6949 - lcm_f1_5k: 0.5476 - lcm_accuracy_1k: 0.9166 - lcm_accuracy_2k: 0.9714 - lcm_accuracy_3k: 0.9881 - lcm_accuracy_5k: 0.9962 - lcm_hamming_loss_k: 0.0256 - val_loss: 0.5412 - val_lcm_precision_1k: 0.8211 - val_lcm_precision_2k: 0.6642 - val_lcm_precision_3k: 0.5228 - val_lcm_precision_5k: 0.3540 - val_lcm_recall_1k: 0.4633 - val_lcm_recall_2k: 0.6945 - val_lcm_recall_3k: 0.7929 - val_lcm_recall_5k: 0.8710 - val_lcm_f1_1k: 0.5917 - val_lcm_f1_2k: 0.6781 - val_lcm_f1_3k: 0.6295 - val_lcm_f1_5k: 0.5030 - val_lcm_accuracy_1k: 0.8211 - val_lcm_accuracy_2k: 0.9064 - val_lcm_accuracy_3k: 0.9383 - val_lcm_accuracy_5k: 0.9650 - val_lcm_hamming_loss_k: 0.0298
Epoch 00023: early stopping
39/39 [==============================] - 1s 19ms/step - loss: 0.4589 - lcm_precision_1k: 0.8619 - lcm_precision_2k: 0.6978 - lcm_precision_3k: 0.5535 - lcm_precision_5k: 0.3770 - lcm_recall_1k: 0.4930 - lcm_recall_2k: 0.7306 - lcm_recall_3k: 0.8354 - lcm_recall_5k: 0.9162 - lcm_f1_1k: 0.6261 - lcm_f1_2k: 0.7128 - lcm_f1_3k: 0.6649 - lcm_f1_5k: 0.5334 - lcm_accuracy_1k: 0.8619 - lcm_accuracy_2k: 0.9468 - lcm_accuracy_3k: 0.9732 - lcm_accuracy_5k: 0.9880 - lcm_hamming_loss_k: 0.0287 0s - loss: 0.4678 - lcm_precision_1k: 0.8576 - lcm_precision_2k: 0.6927 - lcm_precision_3k: 0.5515 - lcm_precision_5k: 0.3736 - lcm_recall_1k: 0.4901 - lcm_recall_2k: 0.7233 - lcm_recall_3k: 0.8305 - lcm_recall_5k: 0.9051 - lcm_f1_1k: 0.6227 - lcm_f1_2k: 0.7067 - lcm_f1_3k: 0.6617 - lcm_f1_5k: 0.5280 - lcm_accuracy_1k: 0.8576 - lcm_accuracy_2k: 0.9445 - lcm_accuracy_3k: 0.9740 - lcm_accuracy_5k: 0.9879 - lcm_hamming_
Best model result:  [0.45892876386642456, 0.8618846535682678, 0.6977666616439819, 0.5535179376602173, 0.3769744336605072, 0.4929641783237457, 0.7306179404258728, 0.8354102969169617, 0.9161770343780518, 0.62613445520401, 0.7127858400344849, 0.6648779511451721, 0.5334470868110657, 0.8618846535682678, 0.9467639327049255, 0.9732100367546082, 0.9879922270774841, 0.028696002438664436]
2970
742
1238
Model: "model_4"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 text_input (InputLayer)        [(None, 120)]        0           []                               
                                                                                                  
 text_emb (Embedding)           (None, 120, 300)     1064400     ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_input (InputLayer)       [(None, 49)]         0           []                               
                                                                                                  
 pred_probs (Dense)             (None, 49)           50225       ['BiLSTM[0][0]']                 
                                                                                                  
==================================================================================================
Total params: 4,444,673
Trainable params: 3,380,273
Non-trainable params: 1,064,400
__________________________________________________________________________________________________
None
2 patience
Model: "model_5"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 49)]         0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 120)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 49, 300)      14700       ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 120, 300)     1064400     ['text_input[0][0]']             
                                                                                                  
 tf.__operators__.getitem_2 (Sl  (None, 49, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_lcm_emb (Dense)          (None, 49, 1024)     308224      ['tf.__operators__.getitem_2[0][0
                                                                 ]']                              
                                                                                                  
 dot_2 (Dot)                    (None, 49)           0           ['label_lcm_emb[0][0]',          
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 pred_probs (Dense)             (None, 49)           50225       ['BiLSTM[0][0]']                 
                                                                                                  
 label_sim_dict (Dense)         (None, 49)           2450        ['dot_2[0][0]']                  
                                                                                                  
 concatenate_2 (Concatenate)    (None, 98)           0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 4,770,047
Trainable params: 3,705,647
Non-trainable params: 1,064,400
__________________________________________________________________________________________________
None
Epoch 1/100
11/12 [==========================>...] - ETA: 0s - loss: 1.3564 - lcm_precision_1k: 0.2631 - lcm_precision_2k: 0.2191 - lcm_precision_3k: 0.1816 - lcm_precision_5k: 0.1585 - lcm_recall_1k: 0.1323 - lcm_recall_2k: 0.2234 - lcm_recall_3k: 0.2987 - lcm_recall_5k: 0.4103 - lcm_f1_1k: 0.1759 - lcm_f1_2k: 0.2210 - lcm_f1_3k: 0.2256 - lcm_f1_5k: 0.2286 - lcm_accuracy_1k: 0.2631 - lcm_accuracy_2k: 0.4311 - lcm_accuracy_3k: 0.5210 - lcm_accuracy_5k: 0.6666 - lcm_hamming_loss_k: 0.0523
Epoch 00001: val_loss improved from inf to 1.28757, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 3s 95ms/step - loss: 1.3538 - lcm_precision_1k: 0.2596 - lcm_precision_2k: 0.2155 - lcm_precision_3k: 0.1791 - lcm_precision_5k: 0.1591 - lcm_recall_1k: 0.1303 - lcm_recall_2k: 0.2196 - lcm_recall_3k: 0.2950 - lcm_recall_5k: 0.4108 - lcm_f1_1k: 0.1733 - lcm_f1_2k: 0.2173 - lcm_f1_3k: 0.2226 - lcm_f1_5k: 0.2292 - lcm_accuracy_1k: 0.2596 - lcm_accuracy_2k: 0.4244 - lcm_accuracy_3k: 0.5143 - lcm_accuracy_5k: 0.6662 - lcm_hamming_loss_k: 0.0525 - val_loss: 1.2876 - val_lcm_precision_1k: 0.2821 - val_lcm_precision_2k: 0.2413 - val_lcm_precision_3k: 0.1995 - val_lcm_precision_5k: 0.1729 - val_lcm_recall_1k: 0.1388 - val_lcm_recall_2k: 0.2349 - val_lcm_recall_3k: 0.3215 - val_lcm_recall_5k: 0.4306 - val_lcm_f1_1k: 0.1850 - val_lcm_f1_2k: 0.2371 - val_lcm_f1_3k: 0.2461 - val_lcm_f1_5k: 0.2465 - val_lcm_accuracy_1k: 0.2821 - val_lcm_accuracy_2k: 0.4721 - val_lcm_accuracy_3k: 0.5724 - val_lcm_accuracy_5k: 0.6906 - val_lcm_hamming_loss_k: 0.0517
Epoch 2/100
11/12 [==========================>...] - ETA: 0s - loss: 1.2722 - lcm_precision_1k: 0.2759 - lcm_precision_2k: 0.2315 - lcm_precision_3k: 0.1951 - lcm_precision_5k: 0.1718 - lcm_recall_1k: 0.1384 - lcm_recall_2k: 0.2374 - lcm_recall_3k: 0.3135 - lcm_recall_5k: 0.4402 - lcm_f1_1k: 0.1843 - lcm_f1_2k: 0.2344 - lcm_f1_3k: 0.2402 - lcm_f1_5k: 0.2471 - lcm_accuracy_1k: 0.2759 - lcm_accuracy_2k: 0.4563 - lcm_accuracy_3k: 0.5586 - lcm_accuracy_5k: 0.6950 - lcm_hamming_loss_k: 0.0517
Epoch 00002: val_loss improved from 1.28757 to 1.24849, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 84ms/step - loss: 1.2718 - lcm_precision_1k: 0.2789 - lcm_precision_2k: 0.2325 - lcm_precision_3k: 0.1945 - lcm_precision_5k: 0.1717 - lcm_recall_1k: 0.1403 - lcm_recall_2k: 0.2378 - lcm_recall_3k: 0.3122 - lcm_recall_5k: 0.4391 - lcm_f1_1k: 0.1866 - lcm_f1_2k: 0.2351 - lcm_f1_3k: 0.2394 - lcm_f1_5k: 0.2468 - lcm_accuracy_1k: 0.2789 - lcm_accuracy_2k: 0.4589 - lcm_accuracy_3k: 0.5580 - lcm_accuracy_5k: 0.6971 - lcm_hamming_loss_k: 0.0517 - val_loss: 1.2485 - val_lcm_precision_1k: 0.2821 - val_lcm_precision_2k: 0.2400 - val_lcm_precision_3k: 0.2087 - val_lcm_precision_5k: 0.1749 - val_lcm_recall_1k: 0.1388 - val_lcm_recall_2k: 0.2330 - val_lcm_recall_3k: 0.3385 - val_lcm_recall_5k: 0.4475 - val_lcm_f1_1k: 0.1850 - val_lcm_f1_2k: 0.2355 - val_lcm_f1_3k: 0.2582 - val_lcm_f1_5k: 0.2512 - val_lcm_accuracy_1k: 0.2821 - val_lcm_accuracy_2k: 0.4695 - val_lcm_accuracy_3k: 0.5881 - val_lcm_accuracy_5k: 0.7203 - val_lcm_hamming_loss_k: 0.0517
Epoch 3/100
11/12 [==========================>...] - ETA: 0s - loss: 1.2322 - lcm_precision_1k: 0.2766 - lcm_precision_2k: 0.2296 - lcm_precision_3k: 0.2198 - lcm_precision_5k: 0.1863 - lcm_recall_1k: 0.1384 - lcm_recall_2k: 0.2351 - lcm_recall_3k: 0.3537 - lcm_recall_5k: 0.4792 - lcm_f1_1k: 0.1844 - lcm_f1_2k: 0.2321 - lcm_f1_3k: 0.2710 - lcm_f1_5k: 0.2682 - lcm_accuracy_1k: 0.2766 - lcm_accuracy_2k: 0.4531 - lcm_accuracy_3k: 0.5820 - lcm_accuracy_5k: 0.7219 - lcm_hamming_loss_k: 0.0518
Epoch 00003: val_loss improved from 1.24849 to 1.19446, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 94ms/step - loss: 1.2290 - lcm_precision_1k: 0.2779 - lcm_precision_2k: 0.2326 - lcm_precision_3k: 0.2248 - lcm_precision_5k: 0.1876 - lcm_recall_1k: 0.1400 - lcm_recall_2k: 0.2375 - lcm_recall_3k: 0.3593 - lcm_recall_5k: 0.4820 - lcm_f1_1k: 0.1861 - lcm_f1_2k: 0.2349 - lcm_f1_3k: 0.2764 - lcm_f1_5k: 0.2700 - lcm_accuracy_1k: 0.2779 - lcm_accuracy_2k: 0.4587 - lcm_accuracy_3k: 0.5882 - lcm_accuracy_5k: 0.7224 - lcm_hamming_loss_k: 0.0517 - val_loss: 1.1945 - val_lcm_precision_1k: 0.2821 - val_lcm_precision_2k: 0.2400 - val_lcm_precision_3k: 0.2580 - val_lcm_precision_5k: 0.2153 - val_lcm_recall_1k: 0.1388 - val_lcm_recall_2k: 0.2330 - val_lcm_recall_3k: 0.3982 - val_lcm_recall_5k: 0.5526 - val_lcm_f1_1k: 0.1850 - val_lcm_f1_2k: 0.2355 - val_lcm_f1_3k: 0.3129 - val_lcm_f1_5k: 0.3098 - val_lcm_accuracy_1k: 0.2821 - val_lcm_accuracy_2k: 0.4695 - val_lcm_accuracy_3k: 0.6484 - val_lcm_accuracy_5k: 0.7852 - val_lcm_hamming_loss_k: 0.0517
Epoch 4/100
11/12 [==========================>...] - ETA: 0s - loss: 1.1520 - lcm_precision_1k: 0.2752 - lcm_precision_2k: 0.2548 - lcm_precision_3k: 0.2557 - lcm_precision_5k: 0.2205 - lcm_recall_1k: 0.1388 - lcm_recall_2k: 0.2694 - lcm_recall_3k: 0.4098 - lcm_recall_5k: 0.5665 - lcm_f1_1k: 0.1844 - lcm_f1_2k: 0.2618 - lcm_f1_3k: 0.3149 - lcm_f1_5k: 0.3174 - lcm_accuracy_1k: 0.2752 - lcm_accuracy_2k: 0.4908 - lcm_accuracy_3k: 0.6534 - lcm_accuracy_5k: 0.7830 - lcm_hamming_loss_k: 0.0519
Epoch 00004: val_loss improved from 1.19446 to 1.08724, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 92ms/step - loss: 1.1468 - lcm_precision_1k: 0.2793 - lcm_precision_2k: 0.2614 - lcm_precision_3k: 0.2584 - lcm_precision_5k: 0.2213 - lcm_recall_1k: 0.1403 - lcm_recall_2k: 0.2788 - lcm_recall_3k: 0.4164 - lcm_recall_5k: 0.5716 - lcm_f1_1k: 0.1867 - lcm_f1_2k: 0.2697 - lcm_f1_3k: 0.3188 - lcm_f1_5k: 0.3190 - lcm_accuracy_1k: 0.2793 - lcm_accuracy_2k: 0.5018 - lcm_accuracy_3k: 0.6590 - lcm_accuracy_5k: 0.7870 - lcm_hamming_loss_k: 0.0516 - val_loss: 1.0872 - val_lcm_precision_1k: 0.2821 - val_lcm_precision_2k: 0.3362 - val_lcm_precision_3k: 0.2899 - val_lcm_precision_5k: 0.2324 - val_lcm_recall_1k: 0.1388 - val_lcm_recall_2k: 0.3608 - val_lcm_recall_3k: 0.4522 - val_lcm_recall_5k: 0.6036 - val_lcm_f1_1k: 0.1850 - val_lcm_f1_2k: 0.3480 - val_lcm_f1_3k: 0.3531 - val_lcm_f1_5k: 0.3355 - val_lcm_accuracy_1k: 0.2821 - val_lcm_accuracy_2k: 0.5608 - val_lcm_accuracy_3k: 0.6977 - val_lcm_accuracy_5k: 0.8111 - val_lcm_hamming_loss_k: 0.0517
Epoch 5/100
12/12 [==============================] - ETA: 0s - loss: 1.0429 - lcm_precision_1k: 0.2948 - lcm_precision_2k: 0.3326 - lcm_precision_3k: 0.2982 - lcm_precision_5k: 0.2494 - lcm_recall_1k: 0.1511 - lcm_recall_2k: 0.3593 - lcm_recall_3k: 0.4757 - lcm_recall_5k: 0.6399 - lcm_f1_1k: 0.1996 - lcm_f1_2k: 0.3453 - lcm_f1_3k: 0.3664 - lcm_f1_5k: 0.3589 - lcm_accuracy_1k: 0.2948 - lcm_accuracy_2k: 0.5659 - lcm_accuracy_3k: 0.7034 - lcm_accuracy_5k: 0.8287 - lcm_hamming_loss_k: 0.0510
Epoch 00005: val_loss improved from 1.08724 to 1.00284, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 94ms/step - loss: 1.0429 - lcm_precision_1k: 0.2948 - lcm_precision_2k: 0.3326 - lcm_precision_3k: 0.2982 - lcm_precision_5k: 0.2494 - lcm_recall_1k: 0.1511 - lcm_recall_2k: 0.3593 - lcm_recall_3k: 0.4757 - lcm_recall_5k: 0.6399 - lcm_f1_1k: 0.1996 - lcm_f1_2k: 0.3453 - lcm_f1_3k: 0.3664 - lcm_f1_5k: 0.3589 - lcm_accuracy_1k: 0.2948 - lcm_accuracy_2k: 0.5659 - lcm_accuracy_3k: 0.7034 - lcm_accuracy_5k: 0.8287 - lcm_hamming_loss_k: 0.0510 - val_loss: 1.0028 - val_lcm_precision_1k: 0.4106 - val_lcm_precision_2k: 0.3351 - val_lcm_precision_3k: 0.3085 - val_lcm_precision_5k: 0.2560 - val_lcm_recall_1k: 0.2210 - val_lcm_recall_2k: 0.3536 - val_lcm_recall_3k: 0.4937 - val_lcm_recall_5k: 0.6499 - val_lcm_f1_1k: 0.2869 - val_lcm_f1_2k: 0.3439 - val_lcm_f1_3k: 0.3797 - val_lcm_f1_5k: 0.3672 - val_lcm_accuracy_1k: 0.4106 - val_lcm_accuracy_2k: 0.5727 - val_lcm_accuracy_3k: 0.7230 - val_lcm_accuracy_5k: 0.8424 - val_lcm_hamming_loss_k: 0.0465
Epoch 6/100
11/12 [==========================>...] - ETA: 0s - loss: 0.9446 - lcm_precision_1k: 0.4950 - lcm_precision_2k: 0.4196 - lcm_precision_3k: 0.3518 - lcm_precision_5k: 0.2720 - lcm_recall_1k: 0.2751 - lcm_recall_2k: 0.4541 - lcm_recall_3k: 0.5574 - lcm_recall_5k: 0.6916 - lcm_f1_1k: 0.3535 - lcm_f1_2k: 0.4360 - lcm_f1_3k: 0.4312 - lcm_f1_5k: 0.3903 - lcm_accuracy_1k: 0.4950 - lcm_accuracy_2k: 0.6971 - lcm_accuracy_3k: 0.7766 - lcm_accuracy_5k: 0.8658 - lcm_hamming_loss_k: 0.0429
Epoch 00006: val_loss improved from 1.00284 to 0.88840, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 93ms/step - loss: 0.9414 - lcm_precision_1k: 0.5003 - lcm_precision_2k: 0.4217 - lcm_precision_3k: 0.3530 - lcm_precision_5k: 0.2732 - lcm_recall_1k: 0.2771 - lcm_recall_2k: 0.4550 - lcm_recall_3k: 0.5575 - lcm_recall_5k: 0.6947 - lcm_f1_1k: 0.3565 - lcm_f1_2k: 0.4376 - lcm_f1_3k: 0.4321 - lcm_f1_5k: 0.3921 - lcm_accuracy_1k: 0.5003 - lcm_accuracy_2k: 0.6996 - lcm_accuracy_3k: 0.7769 - lcm_accuracy_5k: 0.8672 - lcm_hamming_loss_k: 0.0426 - val_loss: 0.8884 - val_lcm_precision_1k: 0.5635 - val_lcm_precision_2k: 0.4492 - val_lcm_precision_3k: 0.3868 - val_lcm_precision_5k: 0.2890 - val_lcm_recall_1k: 0.3044 - val_lcm_recall_2k: 0.4690 - val_lcm_recall_3k: 0.6025 - val_lcm_recall_5k: 0.7177 - val_lcm_f1_1k: 0.3951 - val_lcm_f1_2k: 0.4588 - val_lcm_f1_3k: 0.4710 - val_lcm_f1_5k: 0.4118 - val_lcm_accuracy_1k: 0.5635 - val_lcm_accuracy_2k: 0.7210 - val_lcm_accuracy_3k: 0.8113 - val_lcm_accuracy_5k: 0.8701 - val_lcm_hamming_loss_k: 0.0402
Epoch 7/100
11/12 [==========================>...] - ETA: 0s - loss: 0.8572 - lcm_precision_1k: 0.5810 - lcm_precision_2k: 0.4698 - lcm_precision_3k: 0.3910 - lcm_precision_5k: 0.2928 - lcm_recall_1k: 0.3305 - lcm_recall_2k: 0.5108 - lcm_recall_3k: 0.6128 - lcm_recall_5k: 0.7362 - lcm_f1_1k: 0.4212 - lcm_f1_2k: 0.4893 - lcm_f1_3k: 0.4773 - lcm_f1_5k: 0.4189 - lcm_accuracy_1k: 0.5810 - lcm_accuracy_2k: 0.7521 - lcm_accuracy_3k: 0.8168 - lcm_accuracy_5k: 0.8885 - lcm_hamming_loss_k: 0.0393
Epoch 00007: val_loss improved from 0.88840 to 0.86842, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 90ms/step - loss: 0.8590 - lcm_precision_1k: 0.5796 - lcm_precision_2k: 0.4705 - lcm_precision_3k: 0.3894 - lcm_precision_5k: 0.2926 - lcm_recall_1k: 0.3289 - lcm_recall_2k: 0.5093 - lcm_recall_3k: 0.6086 - lcm_recall_5k: 0.7341 - lcm_f1_1k: 0.4195 - lcm_f1_2k: 0.4890 - lcm_f1_3k: 0.4749 - lcm_f1_5k: 0.4183 - lcm_accuracy_1k: 0.5796 - lcm_accuracy_2k: 0.7506 - lcm_accuracy_3k: 0.8142 - lcm_accuracy_5k: 0.8875 - lcm_hamming_loss_k: 0.0394 - val_loss: 0.8684 - val_lcm_precision_1k: 0.5685 - val_lcm_precision_2k: 0.4629 - val_lcm_precision_3k: 0.3863 - val_lcm_precision_5k: 0.2853 - val_lcm_recall_1k: 0.3230 - val_lcm_recall_2k: 0.5010 - val_lcm_recall_3k: 0.6070 - val_lcm_recall_5k: 0.7170 - val_lcm_f1_1k: 0.4119 - val_lcm_f1_2k: 0.4811 - val_lcm_f1_3k: 0.4720 - val_lcm_f1_5k: 0.4080 - val_lcm_accuracy_1k: 0.5685 - val_lcm_accuracy_2k: 0.7466 - val_lcm_accuracy_3k: 0.8245 - val_lcm_accuracy_5k: 0.8749 - val_lcm_hamming_loss_k: 0.0400
Epoch 8/100
12/12 [==============================] - ETA: 0s - loss: 0.7976 - lcm_precision_1k: 0.6190 - lcm_precision_2k: 0.5049 - lcm_precision_3k: 0.4143 - lcm_precision_5k: 0.3059 - lcm_recall_1k: 0.3540 - lcm_recall_2k: 0.5430 - lcm_recall_3k: 0.6471 - lcm_recall_5k: 0.7655 - lcm_f1_1k: 0.4502 - lcm_f1_2k: 0.5231 - lcm_f1_3k: 0.5051 - lcm_f1_5k: 0.4371 - lcm_accuracy_1k: 0.6190 - lcm_accuracy_2k: 0.7786 - lcm_accuracy_3k: 0.8486 - lcm_accuracy_5k: 0.9083 - lcm_hamming_loss_k: 0.0379
Epoch 00008: val_loss improved from 0.86842 to 0.78715, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 89ms/step - loss: 0.7976 - lcm_precision_1k: 0.6190 - lcm_precision_2k: 0.5049 - lcm_precision_3k: 0.4143 - lcm_precision_5k: 0.3059 - lcm_recall_1k: 0.3540 - lcm_recall_2k: 0.5430 - lcm_recall_3k: 0.6471 - lcm_recall_5k: 0.7655 - lcm_f1_1k: 0.4502 - lcm_f1_2k: 0.5231 - lcm_f1_3k: 0.5051 - lcm_f1_5k: 0.4371 - lcm_accuracy_1k: 0.6190 - lcm_accuracy_2k: 0.7786 - lcm_accuracy_3k: 0.8486 - lcm_accuracy_5k: 0.9083 - lcm_hamming_loss_k: 0.0379 - val_loss: 0.7872 - val_lcm_precision_1k: 0.6369 - val_lcm_precision_2k: 0.5106 - val_lcm_precision_3k: 0.4182 - val_lcm_precision_5k: 0.3030 - val_lcm_recall_1k: 0.3593 - val_lcm_recall_2k: 0.5464 - val_lcm_recall_3k: 0.6522 - val_lcm_recall_5k: 0.7618 - val_lcm_f1_1k: 0.4592 - val_lcm_f1_2k: 0.5278 - val_lcm_f1_3k: 0.5094 - val_lcm_f1_5k: 0.4334 - val_lcm_accuracy_1k: 0.6369 - val_lcm_accuracy_2k: 0.7853 - val_lcm_accuracy_3k: 0.8496 - val_lcm_accuracy_5k: 0.9085 - val_lcm_hamming_loss_k: 0.0372
Epoch 9/100
11/12 [==========================>...] - ETA: 0s - loss: 0.7309 - lcm_precision_1k: 0.6744 - lcm_precision_2k: 0.5373 - lcm_precision_3k: 0.4363 - lcm_precision_5k: 0.3173 - lcm_recall_1k: 0.3882 - lcm_recall_2k: 0.5752 - lcm_recall_3k: 0.6760 - lcm_recall_5k: 0.7924 - lcm_f1_1k: 0.4926 - lcm_f1_2k: 0.5555 - lcm_f1_3k: 0.5303 - lcm_f1_5k: 0.4531 - lcm_accuracy_1k: 0.6744 - lcm_accuracy_2k: 0.8118 - lcm_accuracy_3k: 0.8665 - lcm_accuracy_5k: 0.9233 - lcm_hamming_loss_k: 0.0356
Epoch 00009: val_loss improved from 0.78715 to 0.72473, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 89ms/step - loss: 0.7290 - lcm_precision_1k: 0.6734 - lcm_precision_2k: 0.5380 - lcm_precision_3k: 0.4368 - lcm_precision_5k: 0.3171 - lcm_recall_1k: 0.3880 - lcm_recall_2k: 0.5759 - lcm_recall_3k: 0.6778 - lcm_recall_5k: 0.7940 - lcm_f1_1k: 0.4922 - lcm_f1_2k: 0.5562 - lcm_f1_3k: 0.5312 - lcm_f1_5k: 0.4532 - lcm_accuracy_1k: 0.6734 - lcm_accuracy_2k: 0.8112 - lcm_accuracy_3k: 0.8662 - lcm_accuracy_5k: 0.9227 - lcm_hamming_loss_k: 0.0356 - val_loss: 0.7247 - val_lcm_precision_1k: 0.6897 - val_lcm_precision_2k: 0.5557 - val_lcm_precision_3k: 0.4509 - val_lcm_precision_5k: 0.3155 - val_lcm_recall_1k: 0.3912 - val_lcm_recall_2k: 0.5896 - val_lcm_recall_3k: 0.6922 - val_lcm_recall_5k: 0.7812 - val_lcm_f1_1k: 0.4992 - val_lcm_f1_2k: 0.5720 - val_lcm_f1_3k: 0.5459 - val_lcm_f1_5k: 0.4493 - val_lcm_accuracy_1k: 0.6897 - val_lcm_accuracy_2k: 0.8258 - val_lcm_accuracy_3k: 0.8675 - val_lcm_accuracy_5k: 0.9133 - val_lcm_hamming_loss_k: 0.0351
Epoch 10/100
12/12 [==============================] - ETA: 0s - loss: 0.6692 - lcm_precision_1k: 0.7163 - lcm_precision_2k: 0.5809 - lcm_precision_3k: 0.4646 - lcm_precision_5k: 0.3285 - lcm_recall_1k: 0.4149 - lcm_recall_2k: 0.6183 - lcm_recall_3k: 0.7170 - lcm_recall_5k: 0.8233 - lcm_f1_1k: 0.5253 - lcm_f1_2k: 0.5988 - lcm_f1_3k: 0.5637 - lcm_f1_5k: 0.4696 - lcm_accuracy_1k: 0.7163 - lcm_accuracy_2k: 0.8446 - lcm_accuracy_3k: 0.8902 - lcm_accuracy_5k: 0.9404 - lcm_hamming_loss_k: 0.0338
Epoch 00010: val_loss improved from 0.72473 to 0.68804, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 83ms/step - loss: 0.6692 - lcm_precision_1k: 0.7163 - lcm_precision_2k: 0.5809 - lcm_precision_3k: 0.4646 - lcm_precision_5k: 0.3285 - lcm_recall_1k: 0.4149 - lcm_recall_2k: 0.6183 - lcm_recall_3k: 0.7170 - lcm_recall_5k: 0.8233 - lcm_f1_1k: 0.5253 - lcm_f1_2k: 0.5988 - lcm_f1_3k: 0.5637 - lcm_f1_5k: 0.4696 - lcm_accuracy_1k: 0.7163 - lcm_accuracy_2k: 0.8446 - lcm_accuracy_3k: 0.8902 - lcm_accuracy_5k: 0.9404 - lcm_hamming_loss_k: 0.0338 - val_loss: 0.6880 - val_lcm_precision_1k: 0.6882 - val_lcm_precision_2k: 0.5596 - val_lcm_precision_3k: 0.4575 - val_lcm_precision_5k: 0.3200 - val_lcm_recall_1k: 0.4028 - val_lcm_recall_2k: 0.5978 - val_lcm_recall_3k: 0.7027 - val_lcm_recall_5k: 0.7967 - val_lcm_f1_1k: 0.5081 - val_lcm_f1_2k: 0.5780 - val_lcm_f1_3k: 0.5541 - val_lcm_f1_5k: 0.4564 - val_lcm_accuracy_1k: 0.6882 - val_lcm_accuracy_2k: 0.8419 - val_lcm_accuracy_3k: 0.8806 - val_lcm_accuracy_5k: 0.9277 - val_lcm_hamming_loss_k: 0.0351
Epoch 11/100
11/12 [==========================>...] - ETA: 0s - loss: 0.6343 - lcm_precision_1k: 0.7376 - lcm_precision_2k: 0.5824 - lcm_precision_3k: 0.4768 - lcm_precision_5k: 0.3364 - lcm_recall_1k: 0.4293 - lcm_recall_2k: 0.6232 - lcm_recall_3k: 0.7381 - lcm_recall_5k: 0.8407 - lcm_f1_1k: 0.5426 - lcm_f1_2k: 0.6020 - lcm_f1_3k: 0.5793 - lcm_f1_5k: 0.4805 - lcm_accuracy_1k: 0.7376 - lcm_accuracy_2k: 0.8537 - lcm_accuracy_3k: 0.9070 - lcm_accuracy_5k: 0.9506 - lcm_hamming_loss_k: 0.0328
Epoch 00011: val_loss did not improve from 0.68804
12/12 [==============================] - 1s 57ms/step - loss: 0.6343 - lcm_precision_1k: 0.7356 - lcm_precision_2k: 0.5839 - lcm_precision_3k: 0.4773 - lcm_precision_5k: 0.3376 - lcm_recall_1k: 0.4282 - lcm_recall_2k: 0.6229 - lcm_recall_3k: 0.7361 - lcm_recall_5k: 0.8406 - lcm_f1_1k: 0.5412 - lcm_f1_2k: 0.6027 - lcm_f1_3k: 0.5790 - lcm_f1_5k: 0.4817 - lcm_accuracy_1k: 0.7356 - lcm_accuracy_2k: 0.8540 - lcm_accuracy_3k: 0.9061 - lcm_accuracy_5k: 0.9515 - lcm_hamming_loss_k: 0.0331 - val_loss: 0.6886 - val_lcm_precision_1k: 0.6951 - val_lcm_precision_2k: 0.5700 - val_lcm_precision_3k: 0.4578 - val_lcm_precision_5k: 0.3219 - val_lcm_recall_1k: 0.3928 - val_lcm_recall_2k: 0.6015 - val_lcm_recall_3k: 0.6997 - val_lcm_recall_5k: 0.7986 - val_lcm_f1_1k: 0.5018 - val_lcm_f1_2k: 0.5850 - val_lcm_f1_3k: 0.5533 - val_lcm_f1_5k: 0.4587 - val_lcm_accuracy_1k: 0.6951 - val_lcm_accuracy_2k: 0.8283 - val_lcm_accuracy_3k: 0.8719 - val_lcm_accuracy_5k: 0.9238 - val_lcm_hamming_loss_k: 0.0348
Epoch 12/100
11/12 [==========================>...] - ETA: 0s - loss: 0.6249 - lcm_precision_1k: 0.7578 - lcm_precision_2k: 0.5955 - lcm_precision_3k: 0.4800 - lcm_precision_5k: 0.3384 - lcm_recall_1k: 0.4374 - lcm_recall_2k: 0.6345 - lcm_recall_3k: 0.7391 - lcm_recall_5k: 0.8418 - lcm_f1_1k: 0.5545 - lcm_f1_2k: 0.6143 - lcm_f1_3k: 0.5819 - lcm_f1_5k: 0.4827 - lcm_accuracy_1k: 0.7578 - lcm_accuracy_2k: 0.8679 - lcm_accuracy_3k: 0.9119 - lcm_accuracy_5k: 0.9489 - lcm_hamming_loss_k: 0.0321
Epoch 00012: val_loss improved from 0.68804 to 0.67570, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 86ms/step - loss: 0.6244 - lcm_precision_1k: 0.7574 - lcm_precision_2k: 0.5965 - lcm_precision_3k: 0.4806 - lcm_precision_5k: 0.3394 - lcm_recall_1k: 0.4370 - lcm_recall_2k: 0.6357 - lcm_recall_3k: 0.7395 - lcm_recall_5k: 0.8434 - lcm_f1_1k: 0.5541 - lcm_f1_2k: 0.6154 - lcm_f1_3k: 0.5825 - lcm_f1_5k: 0.4840 - lcm_accuracy_1k: 0.7574 - lcm_accuracy_2k: 0.8676 - lcm_accuracy_3k: 0.9112 - lcm_accuracy_5k: 0.9510 - lcm_hamming_loss_k: 0.0322 - val_loss: 0.6757 - val_lcm_precision_1k: 0.7075 - val_lcm_precision_2k: 0.5650 - val_lcm_precision_3k: 0.4574 - val_lcm_precision_5k: 0.3191 - val_lcm_recall_1k: 0.4117 - val_lcm_recall_2k: 0.6042 - val_lcm_recall_3k: 0.7044 - val_lcm_recall_5k: 0.7922 - val_lcm_f1_1k: 0.5205 - val_lcm_f1_2k: 0.5839 - val_lcm_f1_3k: 0.5545 - val_lcm_f1_5k: 0.4548 - val_lcm_accuracy_1k: 0.7075 - val_lcm_accuracy_2k: 0.8315 - val_lcm_accuracy_3k: 0.8748 - val_lcm_accuracy_5k: 0.9205 - val_lcm_hamming_loss_k: 0.0343
Epoch 13/100
11/12 [==========================>...] - ETA: 0s - loss: 0.6008 - lcm_precision_1k: 0.7635 - lcm_precision_2k: 0.6060 - lcm_precision_3k: 0.4874 - lcm_precision_5k: 0.3417 - lcm_recall_1k: 0.4417 - lcm_recall_2k: 0.6452 - lcm_recall_3k: 0.7523 - lcm_recall_5k: 0.8504 - lcm_f1_1k: 0.5595 - lcm_f1_2k: 0.6248 - lcm_f1_3k: 0.5914 - lcm_f1_5k: 0.4874 - lcm_accuracy_1k: 0.7635 - lcm_accuracy_2k: 0.8711 - lcm_accuracy_3k: 0.9141 - lcm_accuracy_5k: 0.9542 - lcm_hamming_loss_k: 0.0319
Epoch 00013: val_loss improved from 0.67570 to 0.65477, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 90ms/step - loss: 0.6005 - lcm_precision_1k: 0.7621 - lcm_precision_2k: 0.6050 - lcm_precision_3k: 0.4866 - lcm_precision_5k: 0.3420 - lcm_recall_1k: 0.4411 - lcm_recall_2k: 0.6444 - lcm_recall_3k: 0.7509 - lcm_recall_5k: 0.8518 - lcm_f1_1k: 0.5586 - lcm_f1_2k: 0.6240 - lcm_f1_3k: 0.5905 - lcm_f1_5k: 0.4880 - lcm_accuracy_1k: 0.7621 - lcm_accuracy_2k: 0.8716 - lcm_accuracy_3k: 0.9131 - lcm_accuracy_5k: 0.9548 - lcm_hamming_loss_k: 0.0319 - val_loss: 0.6548 - val_lcm_precision_1k: 0.7243 - val_lcm_precision_2k: 0.5862 - val_lcm_precision_3k: 0.4691 - val_lcm_precision_5k: 0.3269 - val_lcm_recall_1k: 0.4124 - val_lcm_recall_2k: 0.6205 - val_lcm_recall_3k: 0.7175 - val_lcm_recall_5k: 0.8097 - val_lcm_f1_1k: 0.5255 - val_lcm_f1_2k: 0.6027 - val_lcm_f1_3k: 0.5670 - val_lcm_f1_5k: 0.4656 - val_lcm_accuracy_1k: 0.7243 - val_lcm_accuracy_2k: 0.8481 - val_lcm_accuracy_3k: 0.8771 - val_lcm_accuracy_5k: 0.9301 - val_lcm_hamming_loss_k: 0.0337
Epoch 14/100
12/12 [==============================] - ETA: 0s - loss: 0.5709 - lcm_precision_1k: 0.7876 - lcm_precision_2k: 0.6262 - lcm_precision_3k: 0.5044 - lcm_precision_5k: 0.3506 - lcm_recall_1k: 0.4553 - lcm_recall_2k: 0.6652 - lcm_recall_3k: 0.7763 - lcm_recall_5k: 0.8706 - lcm_f1_1k: 0.5769 - lcm_f1_2k: 0.6450 - lcm_f1_3k: 0.6114 - lcm_f1_5k: 0.4998 - lcm_accuracy_1k: 0.7876 - lcm_accuracy_2k: 0.8918 - lcm_accuracy_3k: 0.9313 - lcm_accuracy_5k: 0.9645 - lcm_hamming_loss_k: 0.0309
Epoch 00014: val_loss improved from 0.65477 to 0.63224, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 86ms/step - loss: 0.5709 - lcm_precision_1k: 0.7876 - lcm_precision_2k: 0.6262 - lcm_precision_3k: 0.5044 - lcm_precision_5k: 0.3506 - lcm_recall_1k: 0.4553 - lcm_recall_2k: 0.6652 - lcm_recall_3k: 0.7763 - lcm_recall_5k: 0.8706 - lcm_f1_1k: 0.5769 - lcm_f1_2k: 0.6450 - lcm_f1_3k: 0.6114 - lcm_f1_5k: 0.4998 - lcm_accuracy_1k: 0.7876 - lcm_accuracy_2k: 0.8918 - lcm_accuracy_3k: 0.9313 - lcm_accuracy_5k: 0.9645 - lcm_hamming_loss_k: 0.0309 - val_loss: 0.6322 - val_lcm_precision_1k: 0.7287 - val_lcm_precision_2k: 0.6000 - val_lcm_precision_3k: 0.4764 - val_lcm_precision_5k: 0.3334 - val_lcm_recall_1k: 0.4157 - val_lcm_recall_2k: 0.6266 - val_lcm_recall_3k: 0.7264 - val_lcm_recall_5k: 0.8237 - val_lcm_f1_1k: 0.5293 - val_lcm_f1_2k: 0.6127 - val_lcm_f1_3k: 0.5752 - val_lcm_f1_5k: 0.4744 - val_lcm_accuracy_1k: 0.7287 - val_lcm_accuracy_2k: 0.8516 - val_lcm_accuracy_3k: 0.8920 - val_lcm_accuracy_5k: 0.9389 - val_lcm_hamming_loss_k: 0.0335
Epoch 15/100
12/12 [==============================] - ETA: 0s - loss: 0.5539 - lcm_precision_1k: 0.8005 - lcm_precision_2k: 0.6351 - lcm_precision_3k: 0.5101 - lcm_precision_5k: 0.3528 - lcm_recall_1k: 0.4605 - lcm_recall_2k: 0.6728 - lcm_recall_3k: 0.7839 - lcm_recall_5k: 0.8752 - lcm_f1_1k: 0.5844 - lcm_f1_2k: 0.6532 - lcm_f1_3k: 0.6179 - lcm_f1_5k: 0.5028 - lcm_accuracy_1k: 0.8005 - lcm_accuracy_2k: 0.8907 - lcm_accuracy_3k: 0.9353 - lcm_accuracy_5k: 0.9680 - lcm_hamming_loss_k: 0.0304
Epoch 00015: val_loss did not improve from 0.63224
12/12 [==============================] - 1s 63ms/step - loss: 0.5539 - lcm_precision_1k: 0.8005 - lcm_precision_2k: 0.6351 - lcm_precision_3k: 0.5101 - lcm_precision_5k: 0.3528 - lcm_recall_1k: 0.4605 - lcm_recall_2k: 0.6728 - lcm_recall_3k: 0.7839 - lcm_recall_5k: 0.8752 - lcm_f1_1k: 0.5844 - lcm_f1_2k: 0.6532 - lcm_f1_3k: 0.6179 - lcm_f1_5k: 0.5028 - lcm_accuracy_1k: 0.8005 - lcm_accuracy_2k: 0.8907 - lcm_accuracy_3k: 0.9353 - lcm_accuracy_5k: 0.9680 - lcm_hamming_loss_k: 0.0304 - val_loss: 0.6420 - val_lcm_precision_1k: 0.7318 - val_lcm_precision_2k: 0.5918 - val_lcm_precision_3k: 0.4720 - val_lcm_precision_5k: 0.3316 - val_lcm_recall_1k: 0.4143 - val_lcm_recall_2k: 0.6155 - val_lcm_recall_3k: 0.7145 - val_lcm_recall_5k: 0.8148 - val_lcm_f1_1k: 0.5289 - val_lcm_f1_2k: 0.6030 - val_lcm_f1_3k: 0.5681 - val_lcm_f1_5k: 0.4710 - val_lcm_accuracy_1k: 0.7318 - val_lcm_accuracy_2k: 0.8390 - val_lcm_accuracy_3k: 0.8842 - val_lcm_accuracy_5k: 0.9304 - val_lcm_hamming_loss_k: 0.0333
Epoch 16/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5376 - lcm_precision_1k: 0.8026 - lcm_precision_2k: 0.6424 - lcm_precision_3k: 0.5143 - lcm_precision_5k: 0.3578 - lcm_recall_1k: 0.4643 - lcm_recall_2k: 0.6835 - lcm_recall_3k: 0.7869 - lcm_recall_5k: 0.8859 - lcm_f1_1k: 0.5882 - lcm_f1_2k: 0.6622 - lcm_f1_3k: 0.6219 - lcm_f1_5k: 0.5097 - lcm_accuracy_1k: 0.8026 - lcm_accuracy_2k: 0.9034 - lcm_accuracy_3k: 0.9375 - lcm_accuracy_5k: 0.9720 - lcm_hamming_loss_k: 0.0304
Epoch 00016: val_loss improved from 0.63224 to 0.59491, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 86ms/step - loss: 0.5368 - lcm_precision_1k: 0.8049 - lcm_precision_2k: 0.6433 - lcm_precision_3k: 0.5139 - lcm_precision_5k: 0.3572 - lcm_recall_1k: 0.4668 - lcm_recall_2k: 0.6860 - lcm_recall_3k: 0.7894 - lcm_recall_5k: 0.8872 - lcm_f1_1k: 0.5908 - lcm_f1_2k: 0.6638 - lcm_f1_3k: 0.6224 - lcm_f1_5k: 0.5093 - lcm_accuracy_1k: 0.8049 - lcm_accuracy_2k: 0.9044 - lcm_accuracy_3k: 0.9384 - lcm_accuracy_5k: 0.9727 - lcm_hamming_loss_k: 0.0302 - val_loss: 0.5949 - val_lcm_precision_1k: 0.7595 - val_lcm_precision_2k: 0.6109 - val_lcm_precision_3k: 0.4926 - val_lcm_precision_5k: 0.3441 - val_lcm_recall_1k: 0.4335 - val_lcm_recall_2k: 0.6386 - val_lcm_recall_3k: 0.7524 - val_lcm_recall_5k: 0.8502 - val_lcm_f1_1k: 0.5519 - val_lcm_f1_2k: 0.6242 - val_lcm_f1_3k: 0.5951 - val_lcm_f1_5k: 0.4897 - val_lcm_accuracy_1k: 0.7595 - val_lcm_accuracy_2k: 0.8638 - val_lcm_accuracy_3k: 0.9085 - val_lcm_accuracy_5k: 0.9566 - val_lcm_hamming_loss_k: 0.0322
Epoch 17/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5106 - lcm_precision_1k: 0.8263 - lcm_precision_2k: 0.6591 - lcm_precision_3k: 0.5291 - lcm_precision_5k: 0.3626 - lcm_recall_1k: 0.4777 - lcm_recall_2k: 0.7021 - lcm_recall_3k: 0.8095 - lcm_recall_5k: 0.8980 - lcm_f1_1k: 0.6052 - lcm_f1_2k: 0.6798 - lcm_f1_3k: 0.6398 - lcm_f1_5k: 0.5166 - lcm_accuracy_1k: 0.8263 - lcm_accuracy_2k: 0.9208 - lcm_accuracy_3k: 0.9496 - lcm_accuracy_5k: 0.9773 - lcm_hamming_loss_k: 0.0294
Epoch 00017: val_loss improved from 0.59491 to 0.57457, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 89ms/step - loss: 0.5091 - lcm_precision_1k: 0.8278 - lcm_precision_2k: 0.6596 - lcm_precision_3k: 0.5298 - lcm_precision_5k: 0.3623 - lcm_recall_1k: 0.4789 - lcm_recall_2k: 0.7026 - lcm_recall_3k: 0.8114 - lcm_recall_5k: 0.8987 - lcm_f1_1k: 0.6067 - lcm_f1_2k: 0.6803 - lcm_f1_3k: 0.6409 - lcm_f1_5k: 0.5163 - lcm_accuracy_1k: 0.8278 - lcm_accuracy_2k: 0.9215 - lcm_accuracy_3k: 0.9505 - lcm_accuracy_5k: 0.9770 - lcm_hamming_loss_k: 0.0292 - val_loss: 0.5746 - val_lcm_precision_1k: 0.8031 - val_lcm_precision_2k: 0.6227 - val_lcm_precision_3k: 0.4941 - val_lcm_precision_5k: 0.3436 - val_lcm_recall_1k: 0.4550 - val_lcm_recall_2k: 0.6549 - val_lcm_recall_3k: 0.7568 - val_lcm_recall_5k: 0.8550 - val_lcm_f1_1k: 0.5808 - val_lcm_f1_2k: 0.6381 - val_lcm_f1_3k: 0.5975 - val_lcm_f1_5k: 0.4900 - val_lcm_accuracy_1k: 0.8031 - val_lcm_accuracy_2k: 0.8782 - val_lcm_accuracy_3k: 0.9182 - val_lcm_accuracy_5k: 0.9603 - val_lcm_hamming_loss_k: 0.0304
Epoch 18/100
11/12 [==========================>...] - ETA: 0s - loss: 0.4867 - lcm_precision_1k: 0.8413 - lcm_precision_2k: 0.6674 - lcm_precision_3k: 0.5334 - lcm_precision_5k: 0.3655 - lcm_recall_1k: 0.4887 - lcm_recall_2k: 0.7118 - lcm_recall_3k: 0.8199 - lcm_recall_5k: 0.9066 - lcm_f1_1k: 0.6180 - lcm_f1_2k: 0.6887 - lcm_f1_3k: 0.6462 - lcm_f1_5k: 0.5209 - lcm_accuracy_1k: 0.8413 - lcm_accuracy_2k: 0.9265 - lcm_accuracy_3k: 0.9549 - lcm_accuracy_5k: 0.9801 - lcm_hamming_loss_k: 0.0286
Epoch 00018: val_loss improved from 0.57457 to 0.56838, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 90ms/step - loss: 0.4852 - lcm_precision_1k: 0.8448 - lcm_precision_2k: 0.6708 - lcm_precision_3k: 0.5365 - lcm_precision_5k: 0.3675 - lcm_recall_1k: 0.4898 - lcm_recall_2k: 0.7124 - lcm_recall_3k: 0.8207 - lcm_recall_5k: 0.9076 - lcm_f1_1k: 0.6199 - lcm_f1_2k: 0.6908 - lcm_f1_3k: 0.6487 - lcm_f1_5k: 0.5231 - lcm_accuracy_1k: 0.8448 - lcm_accuracy_2k: 0.9272 - lcm_accuracy_3k: 0.9559 - lcm_accuracy_5k: 0.9807 - lcm_hamming_loss_k: 0.0286 - val_loss: 0.5684 - val_lcm_precision_1k: 0.7860 - val_lcm_precision_2k: 0.6311 - val_lcm_precision_3k: 0.5024 - val_lcm_precision_5k: 0.3451 - val_lcm_recall_1k: 0.4581 - val_lcm_recall_2k: 0.6706 - val_lcm_recall_3k: 0.7746 - val_lcm_recall_5k: 0.8561 - val_lcm_f1_1k: 0.5788 - val_lcm_f1_2k: 0.6499 - val_lcm_f1_3k: 0.6092 - val_lcm_f1_5k: 0.4917 - val_lcm_accuracy_1k: 0.7860 - val_lcm_accuracy_2k: 0.8936 - val_lcm_accuracy_3k: 0.9416 - val_lcm_accuracy_5k: 0.9606 - val_lcm_hamming_loss_k: 0.0311
Epoch 19/100
11/12 [==========================>...] - ETA: 0s - loss: 0.4660 - lcm_precision_1k: 0.8537 - lcm_precision_2k: 0.6836 - lcm_precision_3k: 0.5422 - lcm_precision_5k: 0.3714 - lcm_recall_1k: 0.4983 - lcm_recall_2k: 0.7276 - lcm_recall_3k: 0.8308 - lcm_recall_5k: 0.9177 - lcm_f1_1k: 0.6291 - lcm_f1_2k: 0.7047 - lcm_f1_3k: 0.6560 - lcm_f1_5k: 0.5287 - lcm_accuracy_1k: 0.8537 - lcm_accuracy_2k: 0.9414 - lcm_accuracy_3k: 0.9649 - lcm_accuracy_5k: 0.9848 - lcm_hamming_loss_k: 0.0282
Epoch 00019: val_loss improved from 0.56838 to 0.56578, saving model to logs/qcjpgj-lbs-0604-114239/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 81ms/step - loss: 0.4677 - lcm_precision_1k: 0.8502 - lcm_precision_2k: 0.6813 - lcm_precision_3k: 0.5413 - lcm_precision_5k: 0.3707 - lcm_recall_1k: 0.4956 - lcm_recall_2k: 0.7243 - lcm_recall_3k: 0.8304 - lcm_recall_5k: 0.9167 - lcm_f1_1k: 0.6260 - lcm_f1_2k: 0.7020 - lcm_f1_3k: 0.6553 - lcm_f1_5k: 0.5278 - lcm_accuracy_1k: 0.8502 - lcm_accuracy_2k: 0.9387 - lcm_accuracy_3k: 0.9651 - lcm_accuracy_5k: 0.9844 - lcm_hamming_loss_k: 0.0284 - val_loss: 0.5658 - val_lcm_precision_1k: 0.8015 - val_lcm_precision_2k: 0.6309 - val_lcm_precision_3k: 0.4993 - val_lcm_precision_5k: 0.3426 - val_lcm_recall_1k: 0.4548 - val_lcm_recall_2k: 0.6579 - val_lcm_recall_3k: 0.7622 - val_lcm_recall_5k: 0.8503 - val_lcm_f1_1k: 0.5801 - val_lcm_f1_2k: 0.6438 - val_lcm_f1_3k: 0.6030 - val_lcm_f1_5k: 0.4881 - val_lcm_accuracy_1k: 0.8015 - val_lcm_accuracy_2k: 0.8727 - val_lcm_accuracy_3k: 0.9193 - val_lcm_accuracy_5k: 0.9532 - val_lcm_hamming_loss_k: 0.0305
Epoch 20/100
11/12 [==========================>...] - ETA: 0s - loss: 0.4584 - lcm_precision_1k: 0.8572 - lcm_precision_2k: 0.6827 - lcm_precision_3k: 0.5461 - lcm_precision_5k: 0.3727 - lcm_recall_1k: 0.4992 - lcm_recall_2k: 0.7256 - lcm_recall_3k: 0.8369 - lcm_recall_5k: 0.9222 - lcm_f1_1k: 0.6309 - lcm_f1_2k: 0.7034 - lcm_f1_3k: 0.6608 - lcm_f1_5k: 0.5307 - lcm_accuracy_1k: 0.8572 - lcm_accuracy_2k: 0.9400 - lcm_accuracy_3k: 0.9666 - lcm_accuracy_5k: 0.9883 - lcm_hamming_loss_k: 0.0280
Epoch 00020: val_loss did not improve from 0.56578
12/12 [==============================] - 1s 66ms/step - loss: 0.4586 - lcm_precision_1k: 0.8556 - lcm_precision_2k: 0.6813 - lcm_precision_3k: 0.5462 - lcm_precision_5k: 0.3731 - lcm_recall_1k: 0.4980 - lcm_recall_2k: 0.7243 - lcm_recall_3k: 0.8362 - lcm_recall_5k: 0.9215 - lcm_f1_1k: 0.6294 - lcm_f1_2k: 0.7020 - lcm_f1_3k: 0.6607 - lcm_f1_5k: 0.5311 - lcm_accuracy_1k: 0.8556 - lcm_accuracy_2k: 0.9385 - lcm_accuracy_3k: 0.9656 - lcm_accuracy_5k: 0.9871 - lcm_hamming_loss_k: 0.0282 - val_loss: 0.5897 - val_lcm_precision_1k: 0.7783 - val_lcm_precision_2k: 0.6234 - val_lcm_precision_3k: 0.4928 - val_lcm_precision_5k: 0.3452 - val_lcm_recall_1k: 0.4426 - val_lcm_recall_2k: 0.6554 - val_lcm_recall_3k: 0.7510 - val_lcm_recall_5k: 0.8501 - val_lcm_f1_1k: 0.5641 - val_lcm_f1_2k: 0.6386 - val_lcm_f1_3k: 0.5948 - val_lcm_f1_5k: 0.4907 - val_lcm_accuracy_1k: 0.7783 - val_lcm_accuracy_2k: 0.8774 - val_lcm_accuracy_3k: 0.9127 - val_lcm_accuracy_5k: 0.9505 - val_lcm_hamming_loss_k: 0.0315
Epoch 21/100
12/12 [==============================] - ETA: 0s - loss: 0.4525 - lcm_precision_1k: 0.8696 - lcm_precision_2k: 0.6885 - lcm_precision_3k: 0.5491 - lcm_precision_5k: 0.3733 - lcm_recall_1k: 0.5090 - lcm_recall_2k: 0.7329 - lcm_recall_3k: 0.8407 - lcm_recall_5k: 0.9210 - lcm_f1_1k: 0.6421 - lcm_f1_2k: 0.7099 - lcm_f1_3k: 0.6642 - lcm_f1_5k: 0.5312 - lcm_accuracy_1k: 0.8696 - lcm_accuracy_2k: 0.9455 - lcm_accuracy_3k: 0.9717 - lcm_accuracy_5k: 0.9873 - lcm_hamming_loss_k: 0.0276
Epoch 00021: val_loss did not improve from 0.56578
12/12 [==============================] - 1s 66ms/step - loss: 0.4525 - lcm_precision_1k: 0.8696 - lcm_precision_2k: 0.6885 - lcm_precision_3k: 0.5491 - lcm_precision_5k: 0.3733 - lcm_recall_1k: 0.5090 - lcm_recall_2k: 0.7329 - lcm_recall_3k: 0.8407 - lcm_recall_5k: 0.9210 - lcm_f1_1k: 0.6421 - lcm_f1_2k: 0.7099 - lcm_f1_3k: 0.6642 - lcm_f1_5k: 0.5312 - lcm_accuracy_1k: 0.8696 - lcm_accuracy_2k: 0.9455 - lcm_accuracy_3k: 0.9717 - lcm_accuracy_5k: 0.9873 - lcm_hamming_loss_k: 0.0276 - val_loss: 0.5661 - val_lcm_precision_1k: 0.7969 - val_lcm_precision_2k: 0.6242 - val_lcm_precision_3k: 0.4982 - val_lcm_precision_5k: 0.3473 - val_lcm_recall_1k: 0.4572 - val_lcm_recall_2k: 0.6668 - val_lcm_recall_3k: 0.7703 - val_lcm_recall_5k: 0.8634 - val_lcm_f1_1k: 0.5809 - val_lcm_f1_2k: 0.6445 - val_lcm_f1_3k: 0.6047 - val_lcm_f1_5k: 0.4951 - val_lcm_accuracy_1k: 0.7969 - val_lcm_accuracy_2k: 0.9010 - val_lcm_accuracy_3k: 0.9373 - val_lcm_accuracy_5k: 0.9657 - val_lcm_hamming_loss_k: 0.0307
Epoch 00021: early stopping
39/39 [==============================] - 1s 20ms/step - loss: 0.4930 - lcm_precision_1k: 0.8699 - lcm_precision_2k: 0.6828 - lcm_precision_3k: 0.5424 - lcm_precision_5k: 0.3715 - lcm_recall_1k: 0.4922 - lcm_recall_2k: 0.7110 - lcm_recall_3k: 0.8194 - lcm_recall_5k: 0.9027 - lcm_f1_1k: 0.6278 - lcm_f1_2k: 0.6957 - lcm_f1_3k: 0.6518 - lcm_f1_5k: 0.5257 - lcm_accuracy_1k: 0.8699 - lcm_accuracy_2k: 0.9360 - lcm_accuracy_3k: 0.9652 - lcm_accuracy_5k: 0.9812 - lcm_hamming_loss_k: 0.0284
Best model result:  [0.49299129843711853, 0.8699026107788086, 0.6827564239501953, 0.5424359440803528, 0.37145641446113586, 0.49218201637268066, 0.7110255360603333, 0.8194102048873901, 0.9027256369590759, 0.627765417098999, 0.6957476139068604, 0.6518357992172241, 0.5256658792495728, 0.8699026107788086, 0.9359768629074097, 0.9651870727539062, 0.9812203645706177, 0.028368953615427017]
2970
742
1238
Model: "model_6"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 text_input (InputLayer)        [(None, 120)]        0           []                               
                                                                                                  
 text_emb (Embedding)           (None, 120, 300)     1064400     ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_input (InputLayer)       [(None, 49)]         0           []                               
                                                                                                  
 pred_probs (Dense)             (None, 49)           50225       ['BiLSTM[0][0]']                 
                                                                                                  
==================================================================================================
Total params: 4,444,673
Trainable params: 3,380,273
Non-trainable params: 1,064,400
__________________________________________________________________________________________________
None
2 patience
Model: "model_7"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 49)]         0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 120)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 49, 300)      14700       ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 120, 300)     1064400     ['text_input[0][0]']             
                                                                                                  
 tf.__operators__.getitem_3 (Sl  (None, 49, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_lcm_emb (Dense)          (None, 49, 1024)     308224      ['tf.__operators__.getitem_3[0][0
                                                                 ]']                              
                                                                                                  
 dot_3 (Dot)                    (None, 49)           0           ['label_lcm_emb[0][0]',          
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 pred_probs (Dense)             (None, 49)           50225       ['BiLSTM[0][0]']                 
                                                                                                  
 label_sim_dict (Dense)         (None, 49)           2450        ['dot_3[0][0]']                  
                                                                                                  
 concatenate_3 (Concatenate)    (None, 98)           0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 4,770,047
Trainable params: 3,705,647
Non-trainable params: 1,064,400
__________________________________________________________________________________________________
None
Epoch 1/100
11/12 [==========================>...] - ETA: 0s - loss: 1.3653 - lcm_precision_1k: 0.2628 - lcm_precision_2k: 0.2170 - lcm_precision_3k: 0.1863 - lcm_precision_5k: 0.1582 - lcm_recall_1k: 0.1334 - lcm_recall_2k: 0.2209 - lcm_recall_3k: 0.2950 - lcm_recall_5k: 0.4123 - lcm_f1_1k: 0.1769 - lcm_f1_2k: 0.2188 - lcm_f1_3k: 0.2282 - lcm_f1_5k: 0.2285 - lcm_accuracy_1k: 0.2628 - lcm_accuracy_2k: 0.4286 - lcm_accuracy_3k: 0.5199 - lcm_accuracy_5k: 0.6474 - lcm_hamming_loss_k: 0.0522
Epoch 00001: val_loss improved from inf to 1.29757, saving model to logs/jupjxi-lbs-0604-114303/model/checkpoint_lbs.h5
12/12 [==============================] - 3s 100ms/step - loss: 1.3628 - lcm_precision_1k: 0.2636 - lcm_precision_2k: 0.2170 - lcm_precision_3k: 0.1858 - lcm_precision_5k: 0.1581 - lcm_recall_1k: 0.1329 - lcm_recall_2k: 0.2196 - lcm_recall_3k: 0.2938 - lcm_recall_5k: 0.4116 - lcm_f1_1k: 0.1767 - lcm_f1_2k: 0.2182 - lcm_f1_3k: 0.2275 - lcm_f1_5k: 0.2283 - lcm_accuracy_1k: 0.2636 - lcm_accuracy_2k: 0.4281 - lcm_accuracy_3k: 0.5193 - lcm_accuracy_5k: 0.6443 - lcm_hamming_loss_k: 0.0522 - val_loss: 1.2976 - val_lcm_precision_1k: 0.2568 - val_lcm_precision_2k: 0.2226 - val_lcm_precision_3k: 0.1861 - val_lcm_precision_5k: 0.1604 - val_lcm_recall_1k: 0.1254 - val_lcm_recall_2k: 0.2215 - val_lcm_recall_3k: 0.3033 - val_lcm_recall_5k: 0.4184 - val_lcm_f1_1k: 0.1684 - val_lcm_f1_2k: 0.2216 - val_lcm_f1_3k: 0.2307 - val_lcm_f1_5k: 0.2319 - val_lcm_accuracy_1k: 0.2568 - val_lcm_accuracy_2k: 0.4361 - val_lcm_accuracy_3k: 0.5308 - val_lcm_accuracy_5k: 0.6394 - val_lcm_hamming_loss_k: 0.0532
Epoch 2/100
11/12 [==========================>...] - ETA: 0s - loss: 1.2832 - lcm_precision_1k: 0.2852 - lcm_precision_2k: 0.2361 - lcm_precision_3k: 0.1954 - lcm_precision_5k: 0.1691 - lcm_recall_1k: 0.1436 - lcm_recall_2k: 0.2389 - lcm_recall_3k: 0.3221 - lcm_recall_5k: 0.4450 - lcm_f1_1k: 0.1909 - lcm_f1_2k: 0.2374 - lcm_f1_3k: 0.2432 - lcm_f1_5k: 0.2450 - lcm_accuracy_1k: 0.2852 - lcm_accuracy_2k: 0.4656 - lcm_accuracy_3k: 0.5628 - lcm_accuracy_5k: 0.6648 - lcm_hamming_loss_k: 0.0515
Epoch 00002: val_loss improved from 1.29757 to 1.26979, saving model to logs/jupjxi-lbs-0604-114303/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 90ms/step - loss: 1.2836 - lcm_precision_1k: 0.2830 - lcm_precision_2k: 0.2354 - lcm_precision_3k: 0.1936 - lcm_precision_5k: 0.1675 - lcm_recall_1k: 0.1424 - lcm_recall_2k: 0.2393 - lcm_recall_3k: 0.3207 - lcm_recall_5k: 0.4439 - lcm_f1_1k: 0.1893 - lcm_f1_2k: 0.2372 - lcm_f1_3k: 0.2413 - lcm_f1_5k: 0.2431 - lcm_accuracy_1k: 0.2830 - lcm_accuracy_2k: 0.4641 - lcm_accuracy_3k: 0.5587 - lcm_accuracy_5k: 0.6613 - lcm_hamming_loss_k: 0.0513 - val_loss: 1.2698 - val_lcm_precision_1k: 0.2568 - val_lcm_precision_2k: 0.2226 - val_lcm_precision_3k: 0.1861 - val_lcm_precision_5k: 0.1652 - val_lcm_recall_1k: 0.1254 - val_lcm_recall_2k: 0.2215 - val_lcm_recall_3k: 0.3033 - val_lcm_recall_5k: 0.4268 - val_lcm_f1_1k: 0.1684 - val_lcm_f1_2k: 0.2216 - val_lcm_f1_3k: 0.2307 - val_lcm_f1_5k: 0.2381 - val_lcm_accuracy_1k: 0.2568 - val_lcm_accuracy_2k: 0.4361 - val_lcm_accuracy_3k: 0.5308 - val_lcm_accuracy_5k: 0.6608 - val_lcm_hamming_loss_k: 0.0532
Epoch 3/100
12/12 [==============================] - ETA: 0s - loss: 1.2409 - lcm_precision_1k: 0.2846 - lcm_precision_2k: 0.2358 - lcm_precision_3k: 0.2063 - lcm_precision_5k: 0.1893 - lcm_recall_1k: 0.1424 - lcm_recall_2k: 0.2381 - lcm_recall_3k: 0.3306 - lcm_recall_5k: 0.4852 - lcm_f1_1k: 0.1897 - lcm_f1_2k: 0.2368 - lcm_f1_3k: 0.2538 - lcm_f1_5k: 0.2722 - lcm_accuracy_1k: 0.2846 - lcm_accuracy_2k: 0.4650 - lcm_accuracy_3k: 0.5676 - lcm_accuracy_5k: 0.7168 - lcm_hamming_loss_k: 0.0514
Epoch 00003: val_loss improved from 1.26979 to 1.19806, saving model to logs/jupjxi-lbs-0604-114303/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 87ms/step - loss: 1.2409 - lcm_precision_1k: 0.2846 - lcm_precision_2k: 0.2358 - lcm_precision_3k: 0.2063 - lcm_precision_5k: 0.1893 - lcm_recall_1k: 0.1424 - lcm_recall_2k: 0.2381 - lcm_recall_3k: 0.3306 - lcm_recall_5k: 0.4852 - lcm_f1_1k: 0.1897 - lcm_f1_2k: 0.2368 - lcm_f1_3k: 0.2538 - lcm_f1_5k: 0.2722 - lcm_accuracy_1k: 0.2846 - lcm_accuracy_2k: 0.4650 - lcm_accuracy_3k: 0.5676 - lcm_accuracy_5k: 0.7168 - lcm_hamming_loss_k: 0.0514 - val_loss: 1.1981 - val_lcm_precision_1k: 0.2581 - val_lcm_precision_2k: 0.2226 - val_lcm_precision_3k: 0.2304 - val_lcm_precision_5k: 0.2186 - val_lcm_recall_1k: 0.1258 - val_lcm_recall_2k: 0.2215 - val_lcm_recall_3k: 0.3573 - val_lcm_recall_5k: 0.5524 - val_lcm_f1_1k: 0.1690 - val_lcm_f1_2k: 0.2216 - val_lcm_f1_3k: 0.2795 - val_lcm_f1_5k: 0.3130 - val_lcm_accuracy_1k: 0.2581 - val_lcm_accuracy_2k: 0.4361 - val_lcm_accuracy_3k: 0.6066 - val_lcm_accuracy_5k: 0.7525 - val_lcm_hamming_loss_k: 0.0531
Epoch 4/100
11/12 [==========================>...] - ETA: 0s - loss: 1.1560 - lcm_precision_1k: 0.2837 - lcm_precision_2k: 0.2410 - lcm_precision_3k: 0.2375 - lcm_precision_5k: 0.2179 - lcm_recall_1k: 0.1435 - lcm_recall_2k: 0.2455 - lcm_recall_3k: 0.3872 - lcm_recall_5k: 0.5648 - lcm_f1_1k: 0.1905 - lcm_f1_2k: 0.2432 - lcm_f1_3k: 0.2943 - lcm_f1_5k: 0.3144 - lcm_accuracy_1k: 0.2837 - lcm_accuracy_2k: 0.4695 - lcm_accuracy_3k: 0.6310 - lcm_accuracy_5k: 0.7766 - lcm_hamming_loss_k: 0.0512
Epoch 00004: val_loss improved from 1.19806 to 1.11939, saving model to logs/jupjxi-lbs-0604-114303/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 98ms/step - loss: 1.1539 - lcm_precision_1k: 0.2850 - lcm_precision_2k: 0.2450 - lcm_precision_3k: 0.2375 - lcm_precision_5k: 0.2197 - lcm_recall_1k: 0.1433 - lcm_recall_2k: 0.2491 - lcm_recall_3k: 0.3862 - lcm_recall_5k: 0.5690 - lcm_f1_1k: 0.1906 - lcm_f1_2k: 0.2470 - lcm_f1_3k: 0.2941 - lcm_f1_5k: 0.3169 - lcm_accuracy_1k: 0.2850 - lcm_accuracy_2k: 0.4758 - lcm_accuracy_3k: 0.6326 - lcm_accuracy_5k: 0.7801 - lcm_hamming_loss_k: 0.0514 - val_loss: 1.1194 - val_lcm_precision_1k: 0.2568 - val_lcm_precision_2k: 0.2728 - val_lcm_precision_3k: 0.2622 - val_lcm_precision_5k: 0.2262 - val_lcm_recall_1k: 0.1254 - val_lcm_recall_2k: 0.2744 - val_lcm_recall_3k: 0.4160 - val_lcm_recall_5k: 0.5805 - val_lcm_f1_1k: 0.1684 - val_lcm_f1_2k: 0.2731 - val_lcm_f1_3k: 0.3216 - val_lcm_f1_5k: 0.3254 - val_lcm_accuracy_1k: 0.2568 - val_lcm_accuracy_2k: 0.4984 - val_lcm_accuracy_3k: 0.6441 - val_lcm_accuracy_5k: 0.7805 - val_lcm_hamming_loss_k: 0.0532
Epoch 5/100
11/12 [==========================>...] - ETA: 0s - loss: 1.0535 - lcm_precision_1k: 0.3058 - lcm_precision_2k: 0.3303 - lcm_precision_3k: 0.2951 - lcm_precision_5k: 0.2420 - lcm_recall_1k: 0.1584 - lcm_recall_2k: 0.3559 - lcm_recall_3k: 0.4768 - lcm_recall_5k: 0.6289 - lcm_f1_1k: 0.2086 - lcm_f1_2k: 0.3425 - lcm_f1_3k: 0.3644 - lcm_f1_5k: 0.3493 - lcm_accuracy_1k: 0.3058 - lcm_accuracy_2k: 0.5628 - lcm_accuracy_3k: 0.6982 - lcm_accuracy_5k: 0.8196 - lcm_hamming_loss_k: 0.0503
Epoch 00005: val_loss improved from 1.11939 to 1.04529, saving model to logs/jupjxi-lbs-0604-114303/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 84ms/step - loss: 1.0534 - lcm_precision_1k: 0.3003 - lcm_precision_2k: 0.3290 - lcm_precision_3k: 0.2965 - lcm_precision_5k: 0.2442 - lcm_recall_1k: 0.1559 - lcm_recall_2k: 0.3535 - lcm_recall_3k: 0.4765 - lcm_recall_5k: 0.6306 - lcm_f1_1k: 0.2052 - lcm_f1_2k: 0.3406 - lcm_f1_3k: 0.3654 - lcm_f1_5k: 0.3519 - lcm_accuracy_1k: 0.3003 - lcm_accuracy_2k: 0.5609 - lcm_accuracy_3k: 0.7000 - lcm_accuracy_5k: 0.8227 - lcm_hamming_loss_k: 0.0508 - val_loss: 1.0453 - val_lcm_precision_1k: 0.4142 - val_lcm_precision_2k: 0.3386 - val_lcm_precision_3k: 0.2912 - val_lcm_precision_5k: 0.2419 - val_lcm_recall_1k: 0.2302 - val_lcm_recall_2k: 0.3636 - val_lcm_recall_3k: 0.4520 - val_lcm_recall_5k: 0.6066 - val_lcm_f1_1k: 0.2959 - val_lcm_f1_2k: 0.3505 - val_lcm_f1_3k: 0.3541 - val_lcm_f1_5k: 0.3457 - val_lcm_accuracy_1k: 0.4142 - val_lcm_accuracy_2k: 0.5832 - val_lcm_accuracy_3k: 0.6658 - val_lcm_accuracy_5k: 0.7940 - val_lcm_hamming_loss_k: 0.0468
Epoch 6/100
12/12 [==============================] - ETA: 0s - loss: 0.9477 - lcm_precision_1k: 0.5024 - lcm_precision_2k: 0.4159 - lcm_precision_3k: 0.3531 - lcm_precision_5k: 0.2654 - lcm_recall_1k: 0.2836 - lcm_recall_2k: 0.4541 - lcm_recall_3k: 0.5636 - lcm_recall_5k: 0.6807 - lcm_f1_1k: 0.3624 - lcm_f1_2k: 0.4341 - lcm_f1_3k: 0.4341 - lcm_f1_5k: 0.3818 - lcm_accuracy_1k: 0.5024 - lcm_accuracy_2k: 0.6821 - lcm_accuracy_3k: 0.7693 - lcm_accuracy_5k: 0.8563 - lcm_hamming_loss_k: 0.0424
Epoch 00006: val_loss improved from 1.04529 to 0.89179, saving model to logs/jupjxi-lbs-0604-114303/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 91ms/step - loss: 0.9477 - lcm_precision_1k: 0.5024 - lcm_precision_2k: 0.4159 - lcm_precision_3k: 0.3531 - lcm_precision_5k: 0.2654 - lcm_recall_1k: 0.2836 - lcm_recall_2k: 0.4541 - lcm_recall_3k: 0.5636 - lcm_recall_5k: 0.6807 - lcm_f1_1k: 0.3624 - lcm_f1_2k: 0.4341 - lcm_f1_3k: 0.4341 - lcm_f1_5k: 0.3818 - lcm_accuracy_1k: 0.5024 - lcm_accuracy_2k: 0.6821 - lcm_accuracy_3k: 0.7693 - lcm_accuracy_5k: 0.8563 - lcm_hamming_loss_k: 0.0424 - val_loss: 0.8918 - val_lcm_precision_1k: 0.5822 - val_lcm_precision_2k: 0.4756 - val_lcm_precision_3k: 0.3773 - val_lcm_precision_5k: 0.2814 - val_lcm_recall_1k: 0.3189 - val_lcm_recall_2k: 0.4921 - val_lcm_recall_3k: 0.5754 - val_lcm_recall_5k: 0.6959 - val_lcm_f1_1k: 0.4117 - val_lcm_f1_2k: 0.4834 - val_lcm_f1_3k: 0.4554 - val_lcm_f1_5k: 0.4005 - val_lcm_accuracy_1k: 0.5822 - val_lcm_accuracy_2k: 0.7323 - val_lcm_accuracy_3k: 0.7951 - val_lcm_accuracy_5k: 0.8675 - val_lcm_hamming_loss_k: 0.0399
Epoch 7/100
12/12 [==============================] - ETA: 0s - loss: 0.8502 - lcm_precision_1k: 0.5939 - lcm_precision_2k: 0.4864 - lcm_precision_3k: 0.3915 - lcm_precision_5k: 0.2909 - lcm_recall_1k: 0.3411 - lcm_recall_2k: 0.5263 - lcm_recall_3k: 0.6180 - lcm_recall_5k: 0.7355 - lcm_f1_1k: 0.4332 - lcm_f1_2k: 0.5055 - lcm_f1_3k: 0.4793 - lcm_f1_5k: 0.4169 - lcm_accuracy_1k: 0.5939 - lcm_accuracy_2k: 0.7519 - lcm_accuracy_3k: 0.8179 - lcm_accuracy_5k: 0.8890 - lcm_hamming_loss_k: 0.0387
Epoch 00007: val_loss improved from 0.89179 to 0.83962, saving model to logs/jupjxi-lbs-0604-114303/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 86ms/step - loss: 0.8502 - lcm_precision_1k: 0.5939 - lcm_precision_2k: 0.4864 - lcm_precision_3k: 0.3915 - lcm_precision_5k: 0.2909 - lcm_recall_1k: 0.3411 - lcm_recall_2k: 0.5263 - lcm_recall_3k: 0.6180 - lcm_recall_5k: 0.7355 - lcm_f1_1k: 0.4332 - lcm_f1_2k: 0.5055 - lcm_f1_3k: 0.4793 - lcm_f1_5k: 0.4169 - lcm_accuracy_1k: 0.5939 - lcm_accuracy_2k: 0.7519 - lcm_accuracy_3k: 0.8179 - lcm_accuracy_5k: 0.8890 - lcm_hamming_loss_k: 0.0387 - val_loss: 0.8396 - val_lcm_precision_1k: 0.5808 - val_lcm_precision_2k: 0.4742 - val_lcm_precision_3k: 0.3888 - val_lcm_precision_5k: 0.2915 - val_lcm_recall_1k: 0.3330 - val_lcm_recall_2k: 0.5023 - val_lcm_recall_3k: 0.5938 - val_lcm_recall_5k: 0.7170 - val_lcm_f1_1k: 0.4230 - val_lcm_f1_2k: 0.4877 - val_lcm_f1_3k: 0.4697 - val_lcm_f1_5k: 0.4143 - val_lcm_accuracy_1k: 0.5808 - val_lcm_accuracy_2k: 0.7308 - val_lcm_accuracy_3k: 0.7915 - val_lcm_accuracy_5k: 0.8675 - val_lcm_hamming_loss_k: 0.0400
Epoch 8/100
11/12 [==========================>...] - ETA: 0s - loss: 0.7673 - lcm_precision_1k: 0.6616 - lcm_precision_2k: 0.5306 - lcm_precision_3k: 0.4190 - lcm_precision_5k: 0.3044 - lcm_recall_1k: 0.3814 - lcm_recall_2k: 0.5704 - lcm_recall_3k: 0.6563 - lcm_recall_5k: 0.7664 - lcm_f1_1k: 0.4836 - lcm_f1_2k: 0.5496 - lcm_f1_3k: 0.5114 - lcm_f1_5k: 0.4357 - lcm_accuracy_1k: 0.6616 - lcm_accuracy_2k: 0.7958 - lcm_accuracy_3k: 0.8469 - lcm_accuracy_5k: 0.9055 - lcm_hamming_loss_k: 0.0360
Epoch 00008: val_loss improved from 0.83962 to 0.78015, saving model to logs/jupjxi-lbs-0604-114303/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 93ms/step - loss: 0.7665 - lcm_precision_1k: 0.6584 - lcm_precision_2k: 0.5304 - lcm_precision_3k: 0.4184 - lcm_precision_5k: 0.3057 - lcm_recall_1k: 0.3769 - lcm_recall_2k: 0.5686 - lcm_recall_3k: 0.6549 - lcm_recall_5k: 0.7691 - lcm_f1_1k: 0.4791 - lcm_f1_2k: 0.5487 - lcm_f1_3k: 0.5105 - lcm_f1_5k: 0.4374 - lcm_accuracy_1k: 0.6584 - lcm_accuracy_2k: 0.7961 - lcm_accuracy_3k: 0.8483 - lcm_accuracy_5k: 0.9080 - lcm_hamming_loss_k: 0.0361 - val_loss: 0.7801 - val_lcm_precision_1k: 0.6322 - val_lcm_precision_2k: 0.5046 - val_lcm_precision_3k: 0.4130 - val_lcm_precision_5k: 0.3068 - val_lcm_recall_1k: 0.3548 - val_lcm_recall_2k: 0.5269 - val_lcm_recall_3k: 0.6304 - val_lcm_recall_5k: 0.7616 - val_lcm_f1_1k: 0.4540 - val_lcm_f1_2k: 0.5150 - val_lcm_f1_3k: 0.4986 - val_lcm_f1_5k: 0.4370 - val_lcm_accuracy_1k: 0.6322 - val_lcm_accuracy_2k: 0.7663 - val_lcm_accuracy_3k: 0.8193 - val_lcm_accuracy_5k: 0.8978 - val_lcm_hamming_loss_k: 0.0379
Epoch 9/100
12/12 [==============================] - ETA: 0s - loss: 0.7649 - lcm_precision_1k: 0.6660 - lcm_precision_2k: 0.5311 - lcm_precision_3k: 0.4223 - lcm_precision_5k: 0.3069 - lcm_recall_1k: 0.3868 - lcm_recall_2k: 0.5734 - lcm_recall_3k: 0.6611 - lcm_recall_5k: 0.7729 - lcm_f1_1k: 0.4892 - lcm_f1_2k: 0.5512 - lcm_f1_3k: 0.5152 - lcm_f1_5k: 0.4392 - lcm_accuracy_1k: 0.6660 - lcm_accuracy_2k: 0.8014 - lcm_accuracy_3k: 0.8514 - lcm_accuracy_5k: 0.9134 - lcm_hamming_loss_k: 0.0357
Epoch 00009: val_loss did not improve from 0.78015
12/12 [==============================] - 1s 68ms/step - loss: 0.7649 - lcm_precision_1k: 0.6660 - lcm_precision_2k: 0.5311 - lcm_precision_3k: 0.4223 - lcm_precision_5k: 0.3069 - lcm_recall_1k: 0.3868 - lcm_recall_2k: 0.5734 - lcm_recall_3k: 0.6611 - lcm_recall_5k: 0.7729 - lcm_f1_1k: 0.4892 - lcm_f1_2k: 0.5512 - lcm_f1_3k: 0.5152 - lcm_f1_5k: 0.4392 - lcm_accuracy_1k: 0.6660 - lcm_accuracy_2k: 0.8014 - lcm_accuracy_3k: 0.8514 - lcm_accuracy_5k: 0.9134 - lcm_hamming_loss_k: 0.0357 - val_loss: 0.8136 - val_lcm_precision_1k: 0.6192 - val_lcm_precision_2k: 0.4925 - val_lcm_precision_3k: 0.4053 - val_lcm_precision_5k: 0.3006 - val_lcm_recall_1k: 0.3461 - val_lcm_recall_2k: 0.5174 - val_lcm_recall_3k: 0.6168 - val_lcm_recall_5k: 0.7304 - val_lcm_f1_1k: 0.4437 - val_lcm_f1_2k: 0.5045 - val_lcm_f1_3k: 0.4888 - val_lcm_f1_5k: 0.4256 - val_lcm_accuracy_1k: 0.6192 - val_lcm_accuracy_2k: 0.7346 - val_lcm_accuracy_3k: 0.8153 - val_lcm_accuracy_5k: 0.8733 - val_lcm_hamming_loss_k: 0.0384
Epoch 10/100
12/12 [==============================] - ETA: 0s - loss: 0.7344 - lcm_precision_1k: 0.6901 - lcm_precision_2k: 0.5448 - lcm_precision_3k: 0.4360 - lcm_precision_5k: 0.3131 - lcm_recall_1k: 0.3998 - lcm_recall_2k: 0.5841 - lcm_recall_3k: 0.6786 - lcm_recall_5k: 0.7875 - lcm_f1_1k: 0.5062 - lcm_f1_2k: 0.5638 - lcm_f1_3k: 0.5308 - lcm_f1_5k: 0.4480 - lcm_accuracy_1k: 0.6901 - lcm_accuracy_2k: 0.8158 - lcm_accuracy_3k: 0.8661 - lcm_accuracy_5k: 0.9196 - lcm_hamming_loss_k: 0.0348
Epoch 00010: val_loss improved from 0.78015 to 0.74926, saving model to logs/jupjxi-lbs-0604-114303/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 88ms/step - loss: 0.7344 - lcm_precision_1k: 0.6901 - lcm_precision_2k: 0.5448 - lcm_precision_3k: 0.4360 - lcm_precision_5k: 0.3131 - lcm_recall_1k: 0.3998 - lcm_recall_2k: 0.5841 - lcm_recall_3k: 0.6786 - lcm_recall_5k: 0.7875 - lcm_f1_1k: 0.5062 - lcm_f1_2k: 0.5638 - lcm_f1_3k: 0.5308 - lcm_f1_5k: 0.4480 - lcm_accuracy_1k: 0.6901 - lcm_accuracy_2k: 0.8158 - lcm_accuracy_3k: 0.8661 - lcm_accuracy_5k: 0.9196 - lcm_hamming_loss_k: 0.0348 - val_loss: 0.7493 - val_lcm_precision_1k: 0.6719 - val_lcm_precision_2k: 0.5206 - val_lcm_precision_3k: 0.4327 - val_lcm_precision_5k: 0.3155 - val_lcm_recall_1k: 0.3810 - val_lcm_recall_2k: 0.5476 - val_lcm_recall_3k: 0.6573 - val_lcm_recall_5k: 0.7691 - val_lcm_f1_1k: 0.4860 - val_lcm_f1_2k: 0.5335 - val_lcm_f1_3k: 0.5215 - val_lcm_f1_5k: 0.4472 - val_lcm_accuracy_1k: 0.6719 - val_lcm_accuracy_2k: 0.7756 - val_lcm_accuracy_3k: 0.8413 - val_lcm_accuracy_5k: 0.9066 - val_lcm_hamming_loss_k: 0.0362
Epoch 11/100
12/12 [==============================] - ETA: 0s - loss: 0.6710 - lcm_precision_1k: 0.7275 - lcm_precision_2k: 0.5726 - lcm_precision_3k: 0.4623 - lcm_precision_5k: 0.3279 - lcm_recall_1k: 0.4197 - lcm_recall_2k: 0.6107 - lcm_recall_3k: 0.7172 - lcm_recall_5k: 0.8178 - lcm_f1_1k: 0.5321 - lcm_f1_2k: 0.5908 - lcm_f1_3k: 0.5620 - lcm_f1_5k: 0.4680 - lcm_accuracy_1k: 0.7275 - lcm_accuracy_2k: 0.8423 - lcm_accuracy_3k: 0.8975 - lcm_accuracy_5k: 0.9386 - lcm_hamming_loss_k: 0.0334
Epoch 00011: val_loss improved from 0.74926 to 0.69969, saving model to logs/jupjxi-lbs-0604-114303/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 87ms/step - loss: 0.6710 - lcm_precision_1k: 0.7275 - lcm_precision_2k: 0.5726 - lcm_precision_3k: 0.4623 - lcm_precision_5k: 0.3279 - lcm_recall_1k: 0.4197 - lcm_recall_2k: 0.6107 - lcm_recall_3k: 0.7172 - lcm_recall_5k: 0.8178 - lcm_f1_1k: 0.5321 - lcm_f1_2k: 0.5908 - lcm_f1_3k: 0.5620 - lcm_f1_5k: 0.4680 - lcm_accuracy_1k: 0.7275 - lcm_accuracy_2k: 0.8423 - lcm_accuracy_3k: 0.8975 - lcm_accuracy_5k: 0.9386 - lcm_hamming_loss_k: 0.0334 - val_loss: 0.6997 - val_lcm_precision_1k: 0.6922 - val_lcm_precision_2k: 0.5587 - val_lcm_precision_3k: 0.4607 - val_lcm_precision_5k: 0.3255 - val_lcm_recall_1k: 0.3871 - val_lcm_recall_2k: 0.5839 - val_lcm_recall_3k: 0.6944 - val_lcm_recall_5k: 0.7968 - val_lcm_f1_1k: 0.4961 - val_lcm_f1_2k: 0.5704 - val_lcm_f1_3k: 0.5535 - val_lcm_f1_5k: 0.4618 - val_lcm_accuracy_1k: 0.6922 - val_lcm_accuracy_2k: 0.8266 - val_lcm_accuracy_3k: 0.8703 - val_lcm_accuracy_5k: 0.9227 - val_lcm_hamming_loss_k: 0.0354
Epoch 12/100
12/12 [==============================] - ETA: 0s - loss: 0.6284 - lcm_precision_1k: 0.7585 - lcm_precision_2k: 0.5958 - lcm_precision_3k: 0.4778 - lcm_precision_5k: 0.3342 - lcm_recall_1k: 0.4407 - lcm_recall_2k: 0.6382 - lcm_recall_3k: 0.7424 - lcm_recall_5k: 0.8382 - lcm_f1_1k: 0.5574 - lcm_f1_2k: 0.6162 - lcm_f1_3k: 0.5813 - lcm_f1_5k: 0.4778 - lcm_accuracy_1k: 0.7585 - lcm_accuracy_2k: 0.8673 - lcm_accuracy_3k: 0.9144 - lcm_accuracy_5k: 0.9524 - lcm_hamming_loss_k: 0.0320
Epoch 00012: val_loss improved from 0.69969 to 0.68178, saving model to logs/jupjxi-lbs-0604-114303/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 90ms/step - loss: 0.6284 - lcm_precision_1k: 0.7585 - lcm_precision_2k: 0.5958 - lcm_precision_3k: 0.4778 - lcm_precision_5k: 0.3342 - lcm_recall_1k: 0.4407 - lcm_recall_2k: 0.6382 - lcm_recall_3k: 0.7424 - lcm_recall_5k: 0.8382 - lcm_f1_1k: 0.5574 - lcm_f1_2k: 0.6162 - lcm_f1_3k: 0.5813 - lcm_f1_5k: 0.4778 - lcm_accuracy_1k: 0.7585 - lcm_accuracy_2k: 0.8673 - lcm_accuracy_3k: 0.9144 - lcm_accuracy_5k: 0.9524 - lcm_hamming_loss_k: 0.0320 - val_loss: 0.6818 - val_lcm_precision_1k: 0.7110 - val_lcm_precision_2k: 0.5636 - val_lcm_precision_3k: 0.4584 - val_lcm_precision_5k: 0.3263 - val_lcm_recall_1k: 0.3959 - val_lcm_recall_2k: 0.5877 - val_lcm_recall_3k: 0.6929 - val_lcm_recall_5k: 0.7938 - val_lcm_f1_1k: 0.5079 - val_lcm_f1_2k: 0.5747 - val_lcm_f1_3k: 0.5512 - val_lcm_f1_5k: 0.4621 - val_lcm_accuracy_1k: 0.7110 - val_lcm_accuracy_2k: 0.8137 - val_lcm_accuracy_3k: 0.8585 - val_lcm_accuracy_5k: 0.9104 - val_lcm_hamming_loss_k: 0.0346
Epoch 13/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5943 - lcm_precision_1k: 0.7884 - lcm_precision_2k: 0.6113 - lcm_precision_3k: 0.4913 - lcm_precision_5k: 0.3420 - lcm_recall_1k: 0.4597 - lcm_recall_2k: 0.6564 - lcm_recall_3k: 0.7625 - lcm_recall_5k: 0.8559 - lcm_f1_1k: 0.5807 - lcm_f1_2k: 0.6330 - lcm_f1_3k: 0.5974 - lcm_f1_5k: 0.4887 - lcm_accuracy_1k: 0.7884 - lcm_accuracy_2k: 0.8896 - lcm_accuracy_3k: 0.9258 - lcm_accuracy_5k: 0.9588 - lcm_hamming_loss_k: 0.0307
Epoch 00013: val_loss improved from 0.68178 to 0.66960, saving model to logs/jupjxi-lbs-0604-114303/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 98ms/step - loss: 0.5951 - lcm_precision_1k: 0.7860 - lcm_precision_2k: 0.6123 - lcm_precision_3k: 0.4914 - lcm_precision_5k: 0.3434 - lcm_recall_1k: 0.4582 - lcm_recall_2k: 0.6558 - lcm_recall_3k: 0.7613 - lcm_recall_5k: 0.8579 - lcm_f1_1k: 0.5788 - lcm_f1_2k: 0.6332 - lcm_f1_3k: 0.5972 - lcm_f1_5k: 0.4904 - lcm_accuracy_1k: 0.7860 - lcm_accuracy_2k: 0.8896 - lcm_accuracy_3k: 0.9255 - lcm_accuracy_5k: 0.9601 - lcm_hamming_loss_k: 0.0309 - val_loss: 0.6696 - val_lcm_precision_1k: 0.7304 - val_lcm_precision_2k: 0.5754 - val_lcm_precision_3k: 0.4622 - val_lcm_precision_5k: 0.3323 - val_lcm_recall_1k: 0.4067 - val_lcm_recall_2k: 0.5921 - val_lcm_recall_3k: 0.6938 - val_lcm_recall_5k: 0.8038 - val_lcm_f1_1k: 0.5217 - val_lcm_f1_2k: 0.5829 - val_lcm_f1_3k: 0.5544 - val_lcm_f1_5k: 0.4699 - val_lcm_accuracy_1k: 0.7304 - val_lcm_accuracy_2k: 0.8126 - val_lcm_accuracy_3k: 0.8590 - val_lcm_accuracy_5k: 0.9118 - val_lcm_hamming_loss_k: 0.0339
Epoch 14/100
12/12 [==============================] - ETA: 0s - loss: 0.5795 - lcm_precision_1k: 0.7905 - lcm_precision_2k: 0.6223 - lcm_precision_3k: 0.4982 - lcm_precision_5k: 0.3484 - lcm_recall_1k: 0.4588 - lcm_recall_2k: 0.6624 - lcm_recall_3k: 0.7684 - lcm_recall_5k: 0.8685 - lcm_f1_1k: 0.5805 - lcm_f1_2k: 0.6416 - lcm_f1_3k: 0.6043 - lcm_f1_5k: 0.4973 - lcm_accuracy_1k: 0.7905 - lcm_accuracy_2k: 0.8847 - lcm_accuracy_3k: 0.9283 - lcm_accuracy_5k: 0.9649 - lcm_hamming_loss_k: 0.0307
Epoch 00014: val_loss improved from 0.66960 to 0.64124, saving model to logs/jupjxi-lbs-0604-114303/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 89ms/step - loss: 0.5795 - lcm_precision_1k: 0.7905 - lcm_precision_2k: 0.6223 - lcm_precision_3k: 0.4982 - lcm_precision_5k: 0.3484 - lcm_recall_1k: 0.4588 - lcm_recall_2k: 0.6624 - lcm_recall_3k: 0.7684 - lcm_recall_5k: 0.8685 - lcm_f1_1k: 0.5805 - lcm_f1_2k: 0.6416 - lcm_f1_3k: 0.6043 - lcm_f1_5k: 0.4973 - lcm_accuracy_1k: 0.7905 - lcm_accuracy_2k: 0.8847 - lcm_accuracy_3k: 0.9283 - lcm_accuracy_5k: 0.9649 - lcm_hamming_loss_k: 0.0307 - val_loss: 0.6412 - val_lcm_precision_1k: 0.7429 - val_lcm_precision_2k: 0.5917 - val_lcm_precision_3k: 0.4788 - val_lcm_precision_5k: 0.3394 - val_lcm_recall_1k: 0.4134 - val_lcm_recall_2k: 0.6090 - val_lcm_recall_3k: 0.7163 - val_lcm_recall_5k: 0.8235 - val_lcm_f1_1k: 0.5304 - val_lcm_f1_2k: 0.5996 - val_lcm_f1_3k: 0.5734 - val_lcm_f1_5k: 0.4803 - val_lcm_accuracy_1k: 0.7429 - val_lcm_accuracy_2k: 0.8321 - val_lcm_accuracy_3k: 0.8726 - val_lcm_accuracy_5k: 0.9280 - val_lcm_hamming_loss_k: 0.0333
Epoch 15/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5567 - lcm_precision_1k: 0.8093 - lcm_precision_2k: 0.6369 - lcm_precision_3k: 0.5082 - lcm_precision_5k: 0.3501 - lcm_recall_1k: 0.4680 - lcm_recall_2k: 0.6788 - lcm_recall_3k: 0.7848 - lcm_recall_5k: 0.8742 - lcm_f1_1k: 0.5929 - lcm_f1_2k: 0.6570 - lcm_f1_3k: 0.6168 - lcm_f1_5k: 0.4999 - lcm_accuracy_1k: 0.8093 - lcm_accuracy_2k: 0.9020 - lcm_accuracy_3k: 0.9407 - lcm_accuracy_5k: 0.9677 - lcm_hamming_loss_k: 0.0299 ETA: 0s - loss: 0.5701 - lcm_precision_1k: 0.8053 - lcm_precision_2k: 0.6292 - lcm_precision_3k: 0.5022 - lcm_precision_5k: 0.3456 - lcm_recall_1k: 0.4684 - lcm_recall_2k: 0.6765 - lcm_recall_3k: 0.7832 - lcm_recall_5k: 0.8715 - lcm_f1_1k: 0.5922 - lcm_f1_2k: 0.6519 - lcm_f1_3k: 0.6119 - lcm_f1_5k: 0.4949 - lcm_accuracy_1k: 0.8053 - lcm_accuracy_2k: 0.8971 - lcm_accuracy_3k: 0.9414 - lcm_accuracy_5k: 0.9649 - lcm_hamming_loss_k: 
Epoch 00015: val_loss improved from 0.64124 to 0.63086, saving model to logs/jupjxi-lbs-0604-114303/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 97ms/step - loss: 0.5561 - lcm_precision_1k: 0.8122 - lcm_precision_2k: 0.6363 - lcm_precision_3k: 0.5102 - lcm_precision_5k: 0.3511 - lcm_recall_1k: 0.4708 - lcm_recall_2k: 0.6785 - lcm_recall_3k: 0.7861 - lcm_recall_5k: 0.8744 - lcm_f1_1k: 0.5960 - lcm_f1_2k: 0.6566 - lcm_f1_3k: 0.6187 - lcm_f1_5k: 0.5010 - lcm_accuracy_1k: 0.8122 - lcm_accuracy_2k: 0.9026 - lcm_accuracy_3k: 0.9429 - lcm_accuracy_5k: 0.9682 - lcm_hamming_loss_k: 0.0298 - val_loss: 0.6309 - val_lcm_precision_1k: 0.7442 - val_lcm_precision_2k: 0.5974 - val_lcm_precision_3k: 0.4779 - val_lcm_precision_5k: 0.3402 - val_lcm_recall_1k: 0.4190 - val_lcm_recall_2k: 0.6188 - val_lcm_recall_3k: 0.7177 - val_lcm_recall_5k: 0.8287 - val_lcm_f1_1k: 0.5353 - val_lcm_f1_2k: 0.6074 - val_lcm_f1_3k: 0.5733 - val_lcm_f1_5k: 0.4819 - val_lcm_accuracy_1k: 0.7442 - val_lcm_accuracy_2k: 0.8280 - val_lcm_accuracy_3k: 0.8843 - val_lcm_accuracy_5k: 0.9304 - val_lcm_hamming_loss_k: 0.0333
Epoch 16/100
12/12 [==============================] - ETA: 0s - loss: 0.5356 - lcm_precision_1k: 0.8212 - lcm_precision_2k: 0.6452 - lcm_precision_3k: 0.5156 - lcm_precision_5k: 0.3551 - lcm_recall_1k: 0.4782 - lcm_recall_2k: 0.6883 - lcm_recall_3k: 0.7961 - lcm_recall_5k: 0.8872 - lcm_f1_1k: 0.6043 - lcm_f1_2k: 0.6660 - lcm_f1_3k: 0.6258 - lcm_f1_5k: 0.5071 - lcm_accuracy_1k: 0.8212 - lcm_accuracy_2k: 0.9131 - lcm_accuracy_3k: 0.9480 - lcm_accuracy_5k: 0.9796 - lcm_hamming_loss_k: 0.0293
Epoch 00016: val_loss improved from 0.63086 to 0.61031, saving model to logs/jupjxi-lbs-0604-114303/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 92ms/step - loss: 0.5356 - lcm_precision_1k: 0.8212 - lcm_precision_2k: 0.6452 - lcm_precision_3k: 0.5156 - lcm_precision_5k: 0.3551 - lcm_recall_1k: 0.4782 - lcm_recall_2k: 0.6883 - lcm_recall_3k: 0.7961 - lcm_recall_5k: 0.8872 - lcm_f1_1k: 0.6043 - lcm_f1_2k: 0.6660 - lcm_f1_3k: 0.6258 - lcm_f1_5k: 0.5071 - lcm_accuracy_1k: 0.8212 - lcm_accuracy_2k: 0.9131 - lcm_accuracy_3k: 0.9480 - lcm_accuracy_5k: 0.9796 - lcm_hamming_loss_k: 0.0293 - val_loss: 0.6103 - val_lcm_precision_1k: 0.7576 - val_lcm_precision_2k: 0.6002 - val_lcm_precision_3k: 0.4848 - val_lcm_precision_5k: 0.3459 - val_lcm_recall_1k: 0.4321 - val_lcm_recall_2k: 0.6267 - val_lcm_recall_3k: 0.7273 - val_lcm_recall_5k: 0.8407 - val_lcm_f1_1k: 0.5496 - val_lcm_f1_2k: 0.6125 - val_lcm_f1_3k: 0.5812 - val_lcm_f1_5k: 0.4897 - val_lcm_accuracy_1k: 0.7576 - val_lcm_accuracy_2k: 0.8471 - val_lcm_accuracy_3k: 0.8808 - val_lcm_accuracy_5k: 0.9362 - val_lcm_hamming_loss_k: 0.0327
Epoch 17/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5128 - lcm_precision_1k: 0.8388 - lcm_precision_2k: 0.6570 - lcm_precision_3k: 0.5250 - lcm_precision_5k: 0.3606 - lcm_recall_1k: 0.4860 - lcm_recall_2k: 0.6969 - lcm_recall_3k: 0.8076 - lcm_recall_5k: 0.8946 - lcm_f1_1k: 0.6153 - lcm_f1_2k: 0.6762 - lcm_f1_3k: 0.6362 - lcm_f1_5k: 0.5139 - lcm_accuracy_1k: 0.8388 - lcm_accuracy_2k: 0.9180 - lcm_accuracy_3k: 0.9556 - lcm_accuracy_5k: 0.9801 - lcm_hamming_loss_k: 0.0288
Epoch 00017: val_loss did not improve from 0.61031
12/12 [==============================] - 1s 62ms/step - loss: 0.5147 - lcm_precision_1k: 0.8333 - lcm_precision_2k: 0.6536 - lcm_precision_3k: 0.5232 - lcm_precision_5k: 0.3601 - lcm_recall_1k: 0.4849 - lcm_recall_2k: 0.6959 - lcm_recall_3k: 0.8078 - lcm_recall_5k: 0.8972 - lcm_f1_1k: 0.6129 - lcm_f1_2k: 0.6740 - lcm_f1_3k: 0.6350 - lcm_f1_5k: 0.5138 - lcm_accuracy_1k: 0.8333 - lcm_accuracy_2k: 0.9167 - lcm_accuracy_3k: 0.9539 - lcm_accuracy_5k: 0.9802 - lcm_hamming_loss_k: 0.0289 - val_loss: 0.6175 - val_lcm_precision_1k: 0.7577 - val_lcm_precision_2k: 0.5908 - val_lcm_precision_3k: 0.4785 - val_lcm_precision_5k: 0.3408 - val_lcm_recall_1k: 0.4315 - val_lcm_recall_2k: 0.6177 - val_lcm_recall_3k: 0.7241 - val_lcm_recall_5k: 0.8329 - val_lcm_f1_1k: 0.5490 - val_lcm_f1_2k: 0.6033 - val_lcm_f1_3k: 0.5757 - val_lcm_f1_5k: 0.4833 - val_lcm_accuracy_1k: 0.7577 - val_lcm_accuracy_2k: 0.8499 - val_lcm_accuracy_3k: 0.8859 - val_lcm_accuracy_5k: 0.9363 - val_lcm_hamming_loss_k: 0.0327
Epoch 18/100
12/12 [==============================] - ETA: 0s - loss: 0.5105 - lcm_precision_1k: 0.8406 - lcm_precision_2k: 0.6560 - lcm_precision_3k: 0.5226 - lcm_precision_5k: 0.3596 - lcm_recall_1k: 0.4878 - lcm_recall_2k: 0.6969 - lcm_recall_3k: 0.8032 - lcm_recall_5k: 0.8960 - lcm_f1_1k: 0.6172 - lcm_f1_2k: 0.6757 - lcm_f1_3k: 0.6331 - lcm_f1_5k: 0.5131 - lcm_accuracy_1k: 0.8406 - lcm_accuracy_2k: 0.9148 - lcm_accuracy_3k: 0.9481 - lcm_accuracy_5k: 0.9808 - lcm_hamming_loss_k: 0.0286
Epoch 00018: val_loss did not improve from 0.61031
12/12 [==============================] - 1s 63ms/step - loss: 0.5105 - lcm_precision_1k: 0.8406 - lcm_precision_2k: 0.6560 - lcm_precision_3k: 0.5226 - lcm_precision_5k: 0.3596 - lcm_recall_1k: 0.4878 - lcm_recall_2k: 0.6969 - lcm_recall_3k: 0.8032 - lcm_recall_5k: 0.8960 - lcm_f1_1k: 0.6172 - lcm_f1_2k: 0.6757 - lcm_f1_3k: 0.6331 - lcm_f1_5k: 0.5131 - lcm_accuracy_1k: 0.8406 - lcm_accuracy_2k: 0.9148 - lcm_accuracy_3k: 0.9481 - lcm_accuracy_5k: 0.9808 - lcm_hamming_loss_k: 0.0286 - val_loss: 0.6275 - val_lcm_precision_1k: 0.7240 - val_lcm_precision_2k: 0.5935 - val_lcm_precision_3k: 0.4824 - val_lcm_precision_5k: 0.3399 - val_lcm_recall_1k: 0.4089 - val_lcm_recall_2k: 0.6164 - val_lcm_recall_3k: 0.7250 - val_lcm_recall_5k: 0.8302 - val_lcm_f1_1k: 0.5221 - val_lcm_f1_2k: 0.6042 - val_lcm_f1_3k: 0.5787 - val_lcm_f1_5k: 0.4820 - val_lcm_accuracy_1k: 0.7240 - val_lcm_accuracy_2k: 0.8377 - val_lcm_accuracy_3k: 0.8724 - val_lcm_accuracy_5k: 0.9277 - val_lcm_hamming_loss_k: 0.0341
Epoch 00018: early stopping
39/39 [==============================] - 1s 21ms/step - loss: 0.5451 - lcm_precision_1k: 0.8335 - lcm_precision_2k: 0.6490 - lcm_precision_3k: 0.5155 - lcm_precision_5k: 0.3558 - lcm_recall_1k: 0.4704 - lcm_recall_2k: 0.6753 - lcm_recall_3k: 0.7805 - lcm_recall_5k: 0.8685 - lcm_f1_1k: 0.6003 - lcm_f1_2k: 0.6609 - lcm_f1_3k: 0.6199 - lcm_f1_5k: 0.5041 - lcm_accuracy_1k: 0.8335 - lcm_accuracy_2k: 0.9044 - lcm_accuracy_3k: 0.9387 - lcm_accuracy_5k: 0.9631 - lcm_hamming_loss_k: 0.0299
Best model result:  [0.5451341867446899, 0.8334846496582031, 0.6489666700363159, 0.5155153870582581, 0.3557794392108917, 0.47037437558174133, 0.6753000617027283, 0.7805308103561401, 0.8685154318809509, 0.6003402471542358, 0.6609346270561218, 0.6199430227279663, 0.5040566921234131, 0.8334846496582031, 0.9043513536453247, 0.9387434720993042, 0.9631487727165222, 0.029855556786060333]
2970
742
1238
Model: "model_8"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 text_input (InputLayer)        [(None, 120)]        0           []                               
                                                                                                  
 text_emb (Embedding)           (None, 120, 300)     1064400     ['text_input[0][0]']             
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_input (InputLayer)       [(None, 49)]         0           []                               
                                                                                                  
 pred_probs (Dense)             (None, 49)           50225       ['BiLSTM[0][0]']                 
                                                                                                  
==================================================================================================
Total params: 4,444,673
Trainable params: 3,380,273
Non-trainable params: 1,064,400
__________________________________________________________________________________________________
None
2 patience
Model: "model_9"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 label_input (InputLayer)       [(None, 49)]         0           []                               
                                                                                                  
 text_input (InputLayer)        [(None, 120)]        0           []                               
                                                                                                  
 label_emb (Embedding)          (None, 49, 300)      14700       ['label_input[0][0]']            
                                                                                                  
 text_emb (Embedding)           (None, 120, 300)     1064400     ['text_input[0][0]']             
                                                                                                  
 tf.__operators__.getitem_4 (Sl  (None, 49, 300)     0           ['label_emb[0][0]']              
 icingOpLambda)                                                                                   
                                                                                                  
 BiLSTM (Bidirectional)         (None, 1024)         3330048     ['text_emb[0][0]']               
                                                                                                  
 label_lcm_emb (Dense)          (None, 49, 1024)     308224      ['tf.__operators__.getitem_4[0][0
                                                                 ]']                              
                                                                                                  
 dot_4 (Dot)                    (None, 49)           0           ['label_lcm_emb[0][0]',          
                                                                  'BiLSTM[0][0]']                 
                                                                                                  
 pred_probs (Dense)             (None, 49)           50225       ['BiLSTM[0][0]']                 
                                                                                                  
 label_sim_dict (Dense)         (None, 49)           2450        ['dot_4[0][0]']                  
                                                                                                  
 concatenate_4 (Concatenate)    (None, 98)           0           ['pred_probs[0][0]',             
                                                                  'label_sim_dict[0][0]']         
                                                                                                  
==================================================================================================
Total params: 4,770,047
Trainable params: 3,705,647
Non-trainable params: 1,064,400
__________________________________________________________________________________________________
None
Epoch 1/100
11/12 [==========================>...] - ETA: 0s - loss: 1.3575 - lcm_precision_1k: 0.2702 - lcm_precision_2k: 0.2212 - lcm_precision_3k: 0.1966 - lcm_precision_5k: 0.1611 - lcm_recall_1k: 0.1324 - lcm_recall_2k: 0.2196 - lcm_recall_3k: 0.3070 - lcm_recall_5k: 0.4124 - lcm_f1_1k: 0.1776 - lcm_f1_2k: 0.2203 - lcm_f1_3k: 0.2394 - lcm_f1_5k: 0.2317 - lcm_accuracy_1k: 0.2702 - lcm_accuracy_2k: 0.4347 - lcm_accuracy_3k: 0.5479 - lcm_accuracy_5k: 0.6697 - lcm_hamming_loss_k: 0.0523
Epoch 00001: val_loss improved from inf to 1.30892, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 3s 104ms/step - loss: 1.3538 - lcm_precision_1k: 0.2672 - lcm_precision_2k: 0.2207 - lcm_precision_3k: 0.1974 - lcm_precision_5k: 0.1624 - lcm_recall_1k: 0.1304 - lcm_recall_2k: 0.2193 - lcm_recall_3k: 0.3084 - lcm_recall_5k: 0.4137 - lcm_f1_1k: 0.1752 - lcm_f1_2k: 0.2199 - lcm_f1_3k: 0.2404 - lcm_f1_5k: 0.2332 - lcm_accuracy_1k: 0.2672 - lcm_accuracy_2k: 0.4342 - lcm_accuracy_3k: 0.5488 - lcm_accuracy_5k: 0.6697 - lcm_hamming_loss_k: 0.0525 - val_loss: 1.3089 - val_lcm_precision_1k: 0.2419 - val_lcm_precision_2k: 0.2279 - val_lcm_precision_3k: 0.1805 - val_lcm_precision_5k: 0.1569 - val_lcm_recall_1k: 0.1310 - val_lcm_recall_2k: 0.2526 - val_lcm_recall_3k: 0.3092 - val_lcm_recall_5k: 0.4026 - val_lcm_f1_1k: 0.1691 - val_lcm_f1_2k: 0.2385 - val_lcm_f1_3k: 0.2276 - val_lcm_f1_5k: 0.2254 - val_lcm_accuracy_1k: 0.2419 - val_lcm_accuracy_2k: 0.4505 - val_lcm_accuracy_3k: 0.5190 - val_lcm_accuracy_5k: 0.6345 - val_lcm_hamming_loss_k: 0.0521
Epoch 2/100
11/12 [==========================>...] - ETA: 0s - loss: 1.2618 - lcm_precision_1k: 0.2898 - lcm_precision_2k: 0.2392 - lcm_precision_3k: 0.2078 - lcm_precision_5k: 0.1761 - lcm_recall_1k: 0.1423 - lcm_recall_2k: 0.2389 - lcm_recall_3k: 0.3325 - lcm_recall_5k: 0.4445 - lcm_f1_1k: 0.1909 - lcm_f1_2k: 0.2390 - lcm_f1_3k: 0.2557 - lcm_f1_5k: 0.2523 - lcm_accuracy_1k: 0.2898 - lcm_accuracy_2k: 0.4705 - lcm_accuracy_3k: 0.5842 - lcm_accuracy_5k: 0.6999 - lcm_hamming_loss_k: 0.0516
Epoch 00002: val_loss improved from 1.30892 to 1.23899, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 87ms/step - loss: 1.2630 - lcm_precision_1k: 0.2862 - lcm_precision_2k: 0.2384 - lcm_precision_3k: 0.2060 - lcm_precision_5k: 0.1760 - lcm_recall_1k: 0.1408 - lcm_recall_2k: 0.2384 - lcm_recall_3k: 0.3288 - lcm_recall_5k: 0.4436 - lcm_f1_1k: 0.1887 - lcm_f1_2k: 0.2384 - lcm_f1_3k: 0.2533 - lcm_f1_5k: 0.2519 - lcm_accuracy_1k: 0.2862 - lcm_accuracy_2k: 0.4692 - lcm_accuracy_3k: 0.5788 - lcm_accuracy_5k: 0.7017 - lcm_hamming_loss_k: 0.0517 - val_loss: 1.2390 - val_lcm_precision_1k: 0.2419 - val_lcm_precision_2k: 0.2138 - val_lcm_precision_3k: 0.1893 - val_lcm_precision_5k: 0.1807 - val_lcm_recall_1k: 0.1310 - val_lcm_recall_2k: 0.2279 - val_lcm_recall_3k: 0.3187 - val_lcm_recall_5k: 0.4774 - val_lcm_f1_1k: 0.1691 - val_lcm_f1_2k: 0.2192 - val_lcm_f1_3k: 0.2371 - val_lcm_f1_5k: 0.2619 - val_lcm_accuracy_1k: 0.2419 - val_lcm_accuracy_2k: 0.4223 - val_lcm_accuracy_3k: 0.5309 - val_lcm_accuracy_5k: 0.7048 - val_lcm_hamming_loss_k: 0.0521
Epoch 3/100
12/12 [==============================] - ETA: 0s - loss: 1.1889 - lcm_precision_1k: 0.2880 - lcm_precision_2k: 0.2383 - lcm_precision_3k: 0.2438 - lcm_precision_5k: 0.2119 - lcm_recall_1k: 0.1416 - lcm_recall_2k: 0.2373 - lcm_recall_3k: 0.3859 - lcm_recall_5k: 0.5405 - lcm_f1_1k: 0.1897 - lcm_f1_2k: 0.2378 - lcm_f1_3k: 0.2987 - lcm_f1_5k: 0.3044 - lcm_accuracy_1k: 0.2880 - lcm_accuracy_2k: 0.4687 - lcm_accuracy_3k: 0.6195 - lcm_accuracy_5k: 0.7609 - lcm_hamming_loss_k: 0.0517 ETA: 0s - loss: 1.2113 - lcm_precision_1k: 0.2963 - lcm_precision_2k: 0.2383 - lcm_precision_3k: 0.2375 - lcm_precision_5k: 0.2080 - lcm_recall_1k: 0.1442 - lcm_recall_2k: 0.2364 - lcm_recall_3k: 0.3704 - lcm_recall_5k: 0.5292 - lcm_f1_1k: 0.1938 - lcm_f1_2k: 0.2373 - lcm_f1_3k: 0.2894 - lcm_f1_5k: 0.2986 - lcm_accuracy_1k: 0.2963 - lcm_accuracy_2k: 0.4688 - lcm_accuracy_3k: 0.6021 - lcm_accuracy_5k: 0.7567 - lcm_hamming_loss_k: 
Epoch 00003: val_loss improved from 1.23899 to 1.16053, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 87ms/step - loss: 1.1889 - lcm_precision_1k: 0.2880 - lcm_precision_2k: 0.2383 - lcm_precision_3k: 0.2438 - lcm_precision_5k: 0.2119 - lcm_recall_1k: 0.1416 - lcm_recall_2k: 0.2373 - lcm_recall_3k: 0.3859 - lcm_recall_5k: 0.5405 - lcm_f1_1k: 0.1897 - lcm_f1_2k: 0.2378 - lcm_f1_3k: 0.2987 - lcm_f1_5k: 0.3044 - lcm_accuracy_1k: 0.2880 - lcm_accuracy_2k: 0.4687 - lcm_accuracy_3k: 0.6195 - lcm_accuracy_5k: 0.7609 - lcm_hamming_loss_k: 0.0517 - val_loss: 1.1605 - val_lcm_precision_1k: 0.2419 - val_lcm_precision_2k: 0.2138 - val_lcm_precision_3k: 0.2315 - val_lcm_precision_5k: 0.2044 - val_lcm_recall_1k: 0.1310 - val_lcm_recall_2k: 0.2279 - val_lcm_recall_3k: 0.3853 - val_lcm_recall_5k: 0.5293 - val_lcm_f1_1k: 0.1691 - val_lcm_f1_2k: 0.2192 - val_lcm_f1_3k: 0.2888 - val_lcm_f1_5k: 0.2945 - val_lcm_accuracy_1k: 0.2419 - val_lcm_accuracy_2k: 0.4223 - val_lcm_accuracy_3k: 0.6062 - val_lcm_accuracy_5k: 0.7288 - val_lcm_hamming_loss_k: 0.0521
Epoch 4/100
12/12 [==============================] - ETA: 0s - loss: 1.1079 - lcm_precision_1k: 0.2919 - lcm_precision_2k: 0.2593 - lcm_precision_3k: 0.2552 - lcm_precision_5k: 0.2284 - lcm_recall_1k: 0.1436 - lcm_recall_2k: 0.2635 - lcm_recall_3k: 0.4114 - lcm_recall_5k: 0.5805 - lcm_f1_1k: 0.1924 - lcm_f1_2k: 0.2613 - lcm_f1_3k: 0.3149 - lcm_f1_5k: 0.3278 - lcm_accuracy_1k: 0.2919 - lcm_accuracy_2k: 0.4939 - lcm_accuracy_3k: 0.6530 - lcm_accuracy_5k: 0.7910 - lcm_hamming_loss_k: 0.0515
Epoch 00004: val_loss improved from 1.16053 to 1.07900, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 90ms/step - loss: 1.1079 - lcm_precision_1k: 0.2919 - lcm_precision_2k: 0.2593 - lcm_precision_3k: 0.2552 - lcm_precision_5k: 0.2284 - lcm_recall_1k: 0.1436 - lcm_recall_2k: 0.2635 - lcm_recall_3k: 0.4114 - lcm_recall_5k: 0.5805 - lcm_f1_1k: 0.1924 - lcm_f1_2k: 0.2613 - lcm_f1_3k: 0.3149 - lcm_f1_5k: 0.3278 - lcm_accuracy_1k: 0.2919 - lcm_accuracy_2k: 0.4939 - lcm_accuracy_3k: 0.6530 - lcm_accuracy_5k: 0.7910 - lcm_hamming_loss_k: 0.0515 - val_loss: 1.0790 - val_lcm_precision_1k: 0.2458 - val_lcm_precision_2k: 0.2947 - val_lcm_precision_3k: 0.2689 - val_lcm_precision_5k: 0.2273 - val_lcm_recall_1k: 0.1336 - val_lcm_recall_2k: 0.3414 - val_lcm_recall_3k: 0.4435 - val_lcm_recall_5k: 0.5978 - val_lcm_f1_1k: 0.1722 - val_lcm_f1_2k: 0.3158 - val_lcm_f1_3k: 0.3343 - val_lcm_f1_5k: 0.3290 - val_lcm_accuracy_1k: 0.2458 - val_lcm_accuracy_2k: 0.5550 - val_lcm_accuracy_3k: 0.6541 - val_lcm_accuracy_5k: 0.7982 - val_lcm_hamming_loss_k: 0.0520
Epoch 5/100
11/12 [==========================>...] - ETA: 0s - loss: 1.0115 - lcm_precision_1k: 0.3523 - lcm_precision_2k: 0.3604 - lcm_precision_3k: 0.3145 - lcm_precision_5k: 0.2586 - lcm_recall_1k: 0.1886 - lcm_recall_2k: 0.3880 - lcm_recall_3k: 0.4930 - lcm_recall_5k: 0.6562 - lcm_f1_1k: 0.2455 - lcm_f1_2k: 0.3735 - lcm_f1_3k: 0.3839 - lcm_f1_5k: 0.3709 - lcm_accuracy_1k: 0.3523 - lcm_accuracy_2k: 0.6065 - lcm_accuracy_3k: 0.7280 - lcm_accuracy_5k: 0.8484 - lcm_hamming_loss_k: 0.0489
Epoch 00005: val_loss improved from 1.07900 to 0.95983, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 91ms/step - loss: 1.0099 - lcm_precision_1k: 0.3608 - lcm_precision_2k: 0.3634 - lcm_precision_3k: 0.3177 - lcm_precision_5k: 0.2597 - lcm_recall_1k: 0.1929 - lcm_recall_2k: 0.3890 - lcm_recall_3k: 0.4963 - lcm_recall_5k: 0.6575 - lcm_f1_1k: 0.2512 - lcm_f1_2k: 0.3756 - lcm_f1_3k: 0.3873 - lcm_f1_5k: 0.3722 - lcm_accuracy_1k: 0.3608 - lcm_accuracy_2k: 0.6112 - lcm_accuracy_3k: 0.7296 - lcm_accuracy_5k: 0.8491 - lcm_hamming_loss_k: 0.0487 - val_loss: 0.9598 - val_lcm_precision_1k: 0.4614 - val_lcm_precision_2k: 0.4001 - val_lcm_precision_3k: 0.3375 - val_lcm_precision_5k: 0.2616 - val_lcm_recall_1k: 0.2789 - val_lcm_recall_2k: 0.4538 - val_lcm_recall_3k: 0.5483 - val_lcm_recall_5k: 0.6826 - val_lcm_f1_1k: 0.3470 - val_lcm_f1_2k: 0.4247 - val_lcm_f1_3k: 0.4173 - val_lcm_f1_5k: 0.3780 - val_lcm_accuracy_1k: 0.4614 - val_lcm_accuracy_2k: 0.6707 - val_lcm_accuracy_3k: 0.7427 - val_lcm_accuracy_5k: 0.8552 - val_lcm_hamming_loss_k: 0.0432
Epoch 6/100
12/12 [==============================] - ETA: 0s - loss: 0.8967 - lcm_precision_1k: 0.5466 - lcm_precision_2k: 0.4544 - lcm_precision_3k: 0.3786 - lcm_precision_5k: 0.2851 - lcm_recall_1k: 0.3036 - lcm_recall_2k: 0.4819 - lcm_recall_3k: 0.5858 - lcm_recall_5k: 0.7116 - lcm_f1_1k: 0.3902 - lcm_f1_2k: 0.4676 - lcm_f1_3k: 0.4599 - lcm_f1_5k: 0.4071 - lcm_accuracy_1k: 0.5466 - lcm_accuracy_2k: 0.7238 - lcm_accuracy_3k: 0.8005 - lcm_accuracy_5k: 0.8745 - lcm_hamming_loss_k: 0.0410
Epoch 00006: val_loss improved from 0.95983 to 0.88237, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 94ms/step - loss: 0.8967 - lcm_precision_1k: 0.5466 - lcm_precision_2k: 0.4544 - lcm_precision_3k: 0.3786 - lcm_precision_5k: 0.2851 - lcm_recall_1k: 0.3036 - lcm_recall_2k: 0.4819 - lcm_recall_3k: 0.5858 - lcm_recall_5k: 0.7116 - lcm_f1_1k: 0.3902 - lcm_f1_2k: 0.4676 - lcm_f1_3k: 0.4599 - lcm_f1_5k: 0.4071 - lcm_accuracy_1k: 0.5466 - lcm_accuracy_2k: 0.7238 - lcm_accuracy_3k: 0.8005 - lcm_accuracy_5k: 0.8745 - lcm_hamming_loss_k: 0.0410 - val_loss: 0.8824 - val_lcm_precision_1k: 0.5263 - val_lcm_precision_2k: 0.4300 - val_lcm_precision_3k: 0.3623 - val_lcm_precision_5k: 0.2742 - val_lcm_recall_1k: 0.3177 - val_lcm_recall_2k: 0.4822 - val_lcm_recall_3k: 0.5802 - val_lcm_recall_5k: 0.7076 - val_lcm_f1_1k: 0.3956 - val_lcm_f1_2k: 0.4542 - val_lcm_f1_3k: 0.4457 - val_lcm_f1_5k: 0.3949 - val_lcm_accuracy_1k: 0.5263 - val_lcm_accuracy_2k: 0.6874 - val_lcm_accuracy_3k: 0.7744 - val_lcm_accuracy_5k: 0.8679 - val_lcm_hamming_loss_k: 0.0405
Epoch 7/100
11/12 [==========================>...] - ETA: 0s - loss: 0.8269 - lcm_precision_1k: 0.5881 - lcm_precision_2k: 0.4922 - lcm_precision_3k: 0.4096 - lcm_precision_5k: 0.3015 - lcm_recall_1k: 0.3350 - lcm_recall_2k: 0.5271 - lcm_recall_3k: 0.6367 - lcm_recall_5k: 0.7522 - lcm_f1_1k: 0.4268 - lcm_f1_2k: 0.5089 - lcm_f1_3k: 0.4984 - lcm_f1_5k: 0.4304 - lcm_accuracy_1k: 0.5881 - lcm_accuracy_2k: 0.7724 - lcm_accuracy_3k: 0.8420 - lcm_accuracy_5k: 0.8995 - lcm_hamming_loss_k: 0.0392
Epoch 00007: val_loss improved from 0.88237 to 0.79991, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 96ms/step - loss: 0.8267 - lcm_precision_1k: 0.5926 - lcm_precision_2k: 0.4958 - lcm_precision_3k: 0.4113 - lcm_precision_5k: 0.3037 - lcm_recall_1k: 0.3343 - lcm_recall_2k: 0.5262 - lcm_recall_3k: 0.6344 - lcm_recall_5k: 0.7509 - lcm_f1_1k: 0.4273 - lcm_f1_2k: 0.5103 - lcm_f1_3k: 0.4989 - lcm_f1_5k: 0.4323 - lcm_accuracy_1k: 0.5926 - lcm_accuracy_2k: 0.7746 - lcm_accuracy_3k: 0.8432 - lcm_accuracy_5k: 0.8998 - lcm_hamming_loss_k: 0.0393 - val_loss: 0.7999 - val_lcm_precision_1k: 0.6128 - val_lcm_precision_2k: 0.4854 - val_lcm_precision_3k: 0.3967 - val_lcm_precision_5k: 0.2913 - val_lcm_recall_1k: 0.3740 - val_lcm_recall_2k: 0.5441 - val_lcm_recall_3k: 0.6403 - val_lcm_recall_5k: 0.7525 - val_lcm_f1_1k: 0.4635 - val_lcm_f1_2k: 0.5125 - val_lcm_f1_3k: 0.4893 - val_lcm_f1_5k: 0.4196 - val_lcm_accuracy_1k: 0.6128 - val_lcm_accuracy_2k: 0.7637 - val_lcm_accuracy_3k: 0.8304 - val_lcm_accuracy_5k: 0.8985 - val_lcm_hamming_loss_k: 0.0370
Epoch 8/100
12/12 [==============================] - ETA: 0s - loss: 0.7470 - lcm_precision_1k: 0.6661 - lcm_precision_2k: 0.5361 - lcm_precision_3k: 0.4370 - lcm_precision_5k: 0.3164 - lcm_recall_1k: 0.3741 - lcm_recall_2k: 0.5634 - lcm_recall_3k: 0.6706 - lcm_recall_5k: 0.7830 - lcm_f1_1k: 0.4791 - lcm_f1_2k: 0.5493 - lcm_f1_3k: 0.5291 - lcm_f1_5k: 0.4506 - lcm_accuracy_1k: 0.6661 - lcm_accuracy_2k: 0.8015 - lcm_accuracy_3k: 0.8623 - lcm_accuracy_5k: 0.9139 - lcm_hamming_loss_k: 0.0362
Epoch 00008: val_loss improved from 0.79991 to 0.75930, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 94ms/step - loss: 0.7470 - lcm_precision_1k: 0.6661 - lcm_precision_2k: 0.5361 - lcm_precision_3k: 0.4370 - lcm_precision_5k: 0.3164 - lcm_recall_1k: 0.3741 - lcm_recall_2k: 0.5634 - lcm_recall_3k: 0.6706 - lcm_recall_5k: 0.7830 - lcm_f1_1k: 0.4791 - lcm_f1_2k: 0.5493 - lcm_f1_3k: 0.5291 - lcm_f1_5k: 0.4506 - lcm_accuracy_1k: 0.6661 - lcm_accuracy_2k: 0.8015 - lcm_accuracy_3k: 0.8623 - lcm_accuracy_5k: 0.9139 - lcm_hamming_loss_k: 0.0362 - val_loss: 0.7593 - val_lcm_precision_1k: 0.6622 - val_lcm_precision_2k: 0.5070 - val_lcm_precision_3k: 0.4088 - val_lcm_precision_5k: 0.3000 - val_lcm_recall_1k: 0.4057 - val_lcm_recall_2k: 0.5662 - val_lcm_recall_3k: 0.6542 - val_lcm_recall_5k: 0.7660 - val_lcm_f1_1k: 0.5026 - val_lcm_f1_2k: 0.5343 - val_lcm_f1_3k: 0.5026 - val_lcm_f1_5k: 0.4307 - val_lcm_accuracy_1k: 0.6622 - val_lcm_accuracy_2k: 0.7853 - val_lcm_accuracy_3k: 0.8405 - val_lcm_accuracy_5k: 0.9031 - val_lcm_hamming_loss_k: 0.0350
Epoch 9/100
11/12 [==========================>...] - ETA: 0s - loss: 0.7755 - lcm_precision_1k: 0.6371 - lcm_precision_2k: 0.5178 - lcm_precision_3k: 0.4214 - lcm_precision_5k: 0.3103 - lcm_recall_1k: 0.3568 - lcm_recall_2k: 0.5499 - lcm_recall_3k: 0.6522 - lcm_recall_5k: 0.7715 - lcm_f1_1k: 0.4572 - lcm_f1_2k: 0.5331 - lcm_f1_3k: 0.5118 - lcm_f1_5k: 0.4425 - lcm_accuracy_1k: 0.6371 - lcm_accuracy_2k: 0.7795 - lcm_accuracy_3k: 0.8477 - lcm_accuracy_5k: 0.9116 - lcm_hamming_loss_k: 0.0373
Epoch 00009: val_loss did not improve from 0.75930
12/12 [==============================] - 1s 67ms/step - loss: 0.7777 - lcm_precision_1k: 0.6397 - lcm_precision_2k: 0.5198 - lcm_precision_3k: 0.4206 - lcm_precision_5k: 0.3094 - lcm_recall_1k: 0.3570 - lcm_recall_2k: 0.5495 - lcm_recall_3k: 0.6488 - lcm_recall_5k: 0.7680 - lcm_f1_1k: 0.4581 - lcm_f1_2k: 0.5340 - lcm_f1_3k: 0.5102 - lcm_f1_5k: 0.4410 - lcm_accuracy_1k: 0.6397 - lcm_accuracy_2k: 0.7800 - lcm_accuracy_3k: 0.8463 - lcm_accuracy_5k: 0.9108 - lcm_hamming_loss_k: 0.0373 - val_loss: 0.7725 - val_lcm_precision_1k: 0.6502 - val_lcm_precision_2k: 0.5103 - val_lcm_precision_3k: 0.4137 - val_lcm_precision_5k: 0.2983 - val_lcm_recall_1k: 0.3944 - val_lcm_recall_2k: 0.5738 - val_lcm_recall_3k: 0.6718 - val_lcm_recall_5k: 0.7712 - val_lcm_f1_1k: 0.4900 - val_lcm_f1_2k: 0.5393 - val_lcm_f1_3k: 0.5115 - val_lcm_f1_5k: 0.4297 - val_lcm_accuracy_1k: 0.6502 - val_lcm_accuracy_2k: 0.7867 - val_lcm_accuracy_3k: 0.8535 - val_lcm_accuracy_5k: 0.9099 - val_lcm_hamming_loss_k: 0.0355
Epoch 10/100
11/12 [==========================>...] - ETA: 0s - loss: 0.7107 - lcm_precision_1k: 0.7053 - lcm_precision_2k: 0.5675 - lcm_precision_3k: 0.4567 - lcm_precision_5k: 0.3247 - lcm_recall_1k: 0.3950 - lcm_recall_2k: 0.5946 - lcm_recall_3k: 0.6965 - lcm_recall_5k: 0.8029 - lcm_f1_1k: 0.5064 - lcm_f1_2k: 0.5807 - lcm_f1_3k: 0.5516 - lcm_f1_5k: 0.4624 - lcm_accuracy_1k: 0.7053 - lcm_accuracy_2k: 0.8231 - lcm_accuracy_3k: 0.8729 - lcm_accuracy_5k: 0.9304 - lcm_hamming_loss_k: 0.0347
Epoch 00010: val_loss improved from 0.75930 to 0.69850, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 94ms/step - loss: 0.7120 - lcm_precision_1k: 0.7028 - lcm_precision_2k: 0.5632 - lcm_precision_3k: 0.4541 - lcm_precision_5k: 0.3233 - lcm_recall_1k: 0.3933 - lcm_recall_2k: 0.5902 - lcm_recall_3k: 0.6953 - lcm_recall_5k: 0.8016 - lcm_f1_1k: 0.5043 - lcm_f1_2k: 0.5764 - lcm_f1_3k: 0.5494 - lcm_f1_5k: 0.4607 - lcm_accuracy_1k: 0.7028 - lcm_accuracy_2k: 0.8184 - lcm_accuracy_3k: 0.8743 - lcm_accuracy_5k: 0.9303 - lcm_hamming_loss_k: 0.0346 - val_loss: 0.6985 - val_lcm_precision_1k: 0.6797 - val_lcm_precision_2k: 0.5423 - val_lcm_precision_3k: 0.4408 - val_lcm_precision_5k: 0.3137 - val_lcm_recall_1k: 0.4082 - val_lcm_recall_2k: 0.5974 - val_lcm_recall_3k: 0.7017 - val_lcm_recall_5k: 0.8061 - val_lcm_f1_1k: 0.5092 - val_lcm_f1_2k: 0.5675 - val_lcm_f1_3k: 0.5407 - val_lcm_f1_5k: 0.4512 - val_lcm_accuracy_1k: 0.6797 - val_lcm_accuracy_2k: 0.8131 - val_lcm_accuracy_3k: 0.8750 - val_lcm_accuracy_5k: 0.9277 - val_lcm_hamming_loss_k: 0.0343
Epoch 11/100
12/12 [==============================] - ETA: 0s - loss: 0.6547 - lcm_precision_1k: 0.7280 - lcm_precision_2k: 0.5890 - lcm_precision_3k: 0.4738 - lcm_precision_5k: 0.3351 - lcm_recall_1k: 0.4144 - lcm_recall_2k: 0.6186 - lcm_recall_3k: 0.7238 - lcm_recall_5k: 0.8289 - lcm_f1_1k: 0.5281 - lcm_f1_2k: 0.6034 - lcm_f1_3k: 0.5727 - lcm_f1_5k: 0.4773 - lcm_accuracy_1k: 0.7280 - lcm_accuracy_2k: 0.8472 - lcm_accuracy_3k: 0.8965 - lcm_accuracy_5k: 0.9455 - lcm_hamming_loss_k: 0.0337 ETA: 0s - loss: 0.6528 - lcm_precision_1k: 0.7315 - lcm_precision_2k: 0.5918 - lcm_precision_3k: 0.4857 - lcm_precision_5k: 0.3387 - lcm_recall_1k: 0.4132 - lcm_recall_2k: 0.6198 - lcm_recall_3k: 0.7357 - lcm_recall_5k: 0.8320 - lcm_f1_1k: 0.5280 - lcm_f1_2k: 0.6054 - lcm_f1_3k: 0.5850 - lcm_f1_5k: 0.4814 - lcm_accuracy_1k: 0.7315 - lcm_accuracy_2k: 0.8574 - lcm_accuracy_3k: 0.9102 - lcm_accuracy_5k: 0.9512 - lcm_hamming_loss
Epoch 00011: val_loss improved from 0.69850 to 0.66941, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 88ms/step - loss: 0.6547 - lcm_precision_1k: 0.7280 - lcm_precision_2k: 0.5890 - lcm_precision_3k: 0.4738 - lcm_precision_5k: 0.3351 - lcm_recall_1k: 0.4144 - lcm_recall_2k: 0.6186 - lcm_recall_3k: 0.7238 - lcm_recall_5k: 0.8289 - lcm_f1_1k: 0.5281 - lcm_f1_2k: 0.6034 - lcm_f1_3k: 0.5727 - lcm_f1_5k: 0.4773 - lcm_accuracy_1k: 0.7280 - lcm_accuracy_2k: 0.8472 - lcm_accuracy_3k: 0.8965 - lcm_accuracy_5k: 0.9455 - lcm_hamming_loss_k: 0.0337 - val_loss: 0.6694 - val_lcm_precision_1k: 0.7082 - val_lcm_precision_2k: 0.5517 - val_lcm_precision_3k: 0.4454 - val_lcm_precision_5k: 0.3172 - val_lcm_recall_1k: 0.4381 - val_lcm_recall_2k: 0.6144 - val_lcm_recall_3k: 0.7104 - val_lcm_recall_5k: 0.8138 - val_lcm_f1_1k: 0.5410 - val_lcm_f1_2k: 0.5807 - val_lcm_f1_3k: 0.5469 - val_lcm_f1_5k: 0.4560 - val_lcm_accuracy_1k: 0.7082 - val_lcm_accuracy_2k: 0.8355 - val_lcm_accuracy_3k: 0.8846 - val_lcm_accuracy_5k: 0.9359 - val_lcm_hamming_loss_k: 0.0331
Epoch 12/100
12/12 [==============================] - ETA: 0s - loss: 0.6205 - lcm_precision_1k: 0.7567 - lcm_precision_2k: 0.6043 - lcm_precision_3k: 0.4838 - lcm_precision_5k: 0.3413 - lcm_recall_1k: 0.4284 - lcm_recall_2k: 0.6354 - lcm_recall_3k: 0.7393 - lcm_recall_5k: 0.8431 - lcm_f1_1k: 0.5469 - lcm_f1_2k: 0.6193 - lcm_f1_3k: 0.5848 - lcm_f1_5k: 0.4858 - lcm_accuracy_1k: 0.7567 - lcm_accuracy_2k: 0.8680 - lcm_accuracy_3k: 0.9101 - lcm_accuracy_5k: 0.9524 - lcm_hamming_loss_k: 0.0325 ETA: 0s - loss: 0.6263 - lcm_precision_1k: 0.7528 - lcm_precision_2k: 0.6032 - lcm_precision_3k: 0.4818 - lcm_precision_5k: 0.3387 - lcm_recall_1k: 0.4229 - lcm_recall_2k: 0.6301 - lcm_recall_3k: 0.7330 - lcm_recall_5k: 0.8360 - lcm_f1_1k: 0.5415 - lcm_f1_2k: 0.6162 - lcm_f1_3k: 0.5813 - lcm_f1_5k: 0.4821 - lcm_accuracy_1k: 0.7528 - lcm_accuracy_2k: 0.8633 - lcm_accuracy_3k: 0.9024 - lcm_accuracy_5k: 0.9459 - lcm_hamming_loss_k: 
Epoch 00012: val_loss improved from 0.66941 to 0.66588, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 90ms/step - loss: 0.6205 - lcm_precision_1k: 0.7567 - lcm_precision_2k: 0.6043 - lcm_precision_3k: 0.4838 - lcm_precision_5k: 0.3413 - lcm_recall_1k: 0.4284 - lcm_recall_2k: 0.6354 - lcm_recall_3k: 0.7393 - lcm_recall_5k: 0.8431 - lcm_f1_1k: 0.5469 - lcm_f1_2k: 0.6193 - lcm_f1_3k: 0.5848 - lcm_f1_5k: 0.4858 - lcm_accuracy_1k: 0.7567 - lcm_accuracy_2k: 0.8680 - lcm_accuracy_3k: 0.9101 - lcm_accuracy_5k: 0.9524 - lcm_hamming_loss_k: 0.0325 - val_loss: 0.6659 - val_lcm_precision_1k: 0.6905 - val_lcm_precision_2k: 0.5528 - val_lcm_precision_3k: 0.4511 - val_lcm_precision_5k: 0.3223 - val_lcm_recall_1k: 0.4156 - val_lcm_recall_2k: 0.6110 - val_lcm_recall_3k: 0.7231 - val_lcm_recall_5k: 0.8269 - val_lcm_f1_1k: 0.5183 - val_lcm_f1_2k: 0.5795 - val_lcm_f1_3k: 0.5549 - val_lcm_f1_5k: 0.4634 - val_lcm_accuracy_1k: 0.6905 - val_lcm_accuracy_2k: 0.8284 - val_lcm_accuracy_3k: 0.9063 - val_lcm_accuracy_5k: 0.9470 - val_lcm_hamming_loss_k: 0.0338
Epoch 13/100
12/12 [==============================] - ETA: 0s - loss: 0.5994 - lcm_precision_1k: 0.7714 - lcm_precision_2k: 0.6153 - lcm_precision_3k: 0.4954 - lcm_precision_5k: 0.3467 - lcm_recall_1k: 0.4392 - lcm_recall_2k: 0.6442 - lcm_recall_3k: 0.7514 - lcm_recall_5k: 0.8537 - lcm_f1_1k: 0.5597 - lcm_f1_2k: 0.6294 - lcm_f1_3k: 0.5971 - lcm_f1_5k: 0.4930 - lcm_accuracy_1k: 0.7714 - lcm_accuracy_2k: 0.8707 - lcm_accuracy_3k: 0.9152 - lcm_accuracy_5k: 0.9560 - lcm_hamming_loss_k: 0.0318
Epoch 00013: val_loss improved from 0.66588 to 0.63039, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 85ms/step - loss: 0.5994 - lcm_precision_1k: 0.7714 - lcm_precision_2k: 0.6153 - lcm_precision_3k: 0.4954 - lcm_precision_5k: 0.3467 - lcm_recall_1k: 0.4392 - lcm_recall_2k: 0.6442 - lcm_recall_3k: 0.7514 - lcm_recall_5k: 0.8537 - lcm_f1_1k: 0.5597 - lcm_f1_2k: 0.6294 - lcm_f1_3k: 0.5971 - lcm_f1_5k: 0.4930 - lcm_accuracy_1k: 0.7714 - lcm_accuracy_2k: 0.8707 - lcm_accuracy_3k: 0.9152 - lcm_accuracy_5k: 0.9560 - lcm_hamming_loss_k: 0.0318 - val_loss: 0.6304 - val_lcm_precision_1k: 0.7266 - val_lcm_precision_2k: 0.5668 - val_lcm_precision_3k: 0.4549 - val_lcm_precision_5k: 0.3274 - val_lcm_recall_1k: 0.4305 - val_lcm_recall_2k: 0.6149 - val_lcm_recall_3k: 0.7238 - val_lcm_recall_5k: 0.8366 - val_lcm_f1_1k: 0.5397 - val_lcm_f1_2k: 0.5888 - val_lcm_f1_3k: 0.5579 - val_lcm_f1_5k: 0.4702 - val_lcm_accuracy_1k: 0.7266 - val_lcm_accuracy_2k: 0.8329 - val_lcm_accuracy_3k: 0.8898 - val_lcm_accuracy_5k: 0.9527 - val_lcm_hamming_loss_k: 0.0324
Epoch 14/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5788 - lcm_precision_1k: 0.7919 - lcm_precision_2k: 0.6325 - lcm_precision_3k: 0.5072 - lcm_precision_5k: 0.3526 - lcm_recall_1k: 0.4443 - lcm_recall_2k: 0.6568 - lcm_recall_3k: 0.7680 - lcm_recall_5k: 0.8672 - lcm_f1_1k: 0.5692 - lcm_f1_2k: 0.6443 - lcm_f1_3k: 0.6109 - lcm_f1_5k: 0.5013 - lcm_accuracy_1k: 0.7919 - lcm_accuracy_2k: 0.8871 - lcm_accuracy_3k: 0.9286 - lcm_accuracy_5k: 0.9659 - lcm_hamming_loss_k: 0.0312
Epoch 00014: val_loss improved from 0.63039 to 0.59897, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 91ms/step - loss: 0.5774 - lcm_precision_1k: 0.7925 - lcm_precision_2k: 0.6298 - lcm_precision_3k: 0.5046 - lcm_precision_5k: 0.3504 - lcm_recall_1k: 0.4489 - lcm_recall_2k: 0.6582 - lcm_recall_3k: 0.7682 - lcm_recall_5k: 0.8663 - lcm_f1_1k: 0.5729 - lcm_f1_2k: 0.6436 - lcm_f1_3k: 0.6091 - lcm_f1_5k: 0.4989 - lcm_accuracy_1k: 0.7925 - lcm_accuracy_2k: 0.8840 - lcm_accuracy_3k: 0.9265 - lcm_accuracy_5k: 0.9650 - lcm_hamming_loss_k: 0.0309 - val_loss: 0.5990 - val_lcm_precision_1k: 0.7682 - val_lcm_precision_2k: 0.5946 - val_lcm_precision_3k: 0.4736 - val_lcm_precision_5k: 0.3307 - val_lcm_recall_1k: 0.4626 - val_lcm_recall_2k: 0.6543 - val_lcm_recall_3k: 0.7503 - val_lcm_recall_5k: 0.8423 - val_lcm_f1_1k: 0.5769 - val_lcm_f1_2k: 0.6223 - val_lcm_f1_3k: 0.5799 - val_lcm_f1_5k: 0.4745 - val_lcm_accuracy_1k: 0.7682 - val_lcm_accuracy_2k: 0.8759 - val_lcm_accuracy_3k: 0.9175 - val_lcm_accuracy_5k: 0.9473 - val_lcm_hamming_loss_k: 0.0307
Epoch 15/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5507 - lcm_precision_1k: 0.8160 - lcm_precision_2k: 0.6436 - lcm_precision_3k: 0.5121 - lcm_precision_5k: 0.3553 - lcm_recall_1k: 0.4658 - lcm_recall_2k: 0.6791 - lcm_recall_3k: 0.7820 - lcm_recall_5k: 0.8792 - lcm_f1_1k: 0.5929 - lcm_f1_2k: 0.6608 - lcm_f1_3k: 0.6188 - lcm_f1_5k: 0.5060 - lcm_accuracy_1k: 0.8160 - lcm_accuracy_2k: 0.9066 - lcm_accuracy_3k: 0.9386 - lcm_accuracy_5k: 0.9709 - lcm_hamming_loss_k: 0.0299
Epoch 00015: val_loss improved from 0.59897 to 0.58949, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 89ms/step - loss: 0.5488 - lcm_precision_1k: 0.8146 - lcm_precision_2k: 0.6452 - lcm_precision_3k: 0.5152 - lcm_precision_5k: 0.3570 - lcm_recall_1k: 0.4641 - lcm_recall_2k: 0.6782 - lcm_recall_3k: 0.7840 - lcm_recall_5k: 0.8794 - lcm_f1_1k: 0.5912 - lcm_f1_2k: 0.6611 - lcm_f1_3k: 0.6217 - lcm_f1_5k: 0.5078 - lcm_accuracy_1k: 0.8146 - lcm_accuracy_2k: 0.9052 - lcm_accuracy_3k: 0.9394 - lcm_accuracy_5k: 0.9722 - lcm_hamming_loss_k: 0.0302 - val_loss: 0.5895 - val_lcm_precision_1k: 0.7699 - val_lcm_precision_2k: 0.5847 - val_lcm_precision_3k: 0.4726 - val_lcm_precision_5k: 0.3332 - val_lcm_recall_1k: 0.4684 - val_lcm_recall_2k: 0.6437 - val_lcm_recall_3k: 0.7480 - val_lcm_recall_5k: 0.8487 - val_lcm_f1_1k: 0.5817 - val_lcm_f1_2k: 0.6118 - val_lcm_f1_3k: 0.5785 - val_lcm_f1_5k: 0.4780 - val_lcm_accuracy_1k: 0.7699 - val_lcm_accuracy_2k: 0.8742 - val_lcm_accuracy_3k: 0.9128 - val_lcm_accuracy_5k: 0.9519 - val_lcm_hamming_loss_k: 0.0306
Epoch 16/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5341 - lcm_precision_1k: 0.8168 - lcm_precision_2k: 0.6468 - lcm_precision_3k: 0.5194 - lcm_precision_5k: 0.3587 - lcm_recall_1k: 0.4661 - lcm_recall_2k: 0.6802 - lcm_recall_3k: 0.7932 - lcm_recall_5k: 0.8868 - lcm_f1_1k: 0.5933 - lcm_f1_2k: 0.6629 - lcm_f1_3k: 0.6275 - lcm_f1_5k: 0.5107 - lcm_accuracy_1k: 0.8168 - lcm_accuracy_2k: 0.9023 - lcm_accuracy_3k: 0.9453 - lcm_accuracy_5k: 0.9762 - lcm_hamming_loss_k: 0.0299
Epoch 00016: val_loss improved from 0.58949 to 0.57922, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 89ms/step - loss: 0.5329 - lcm_precision_1k: 0.8196 - lcm_precision_2k: 0.6506 - lcm_precision_3k: 0.5219 - lcm_precision_5k: 0.3607 - lcm_recall_1k: 0.4670 - lcm_recall_2k: 0.6820 - lcm_recall_3k: 0.7937 - lcm_recall_5k: 0.8873 - lcm_f1_1k: 0.5947 - lcm_f1_2k: 0.6657 - lcm_f1_3k: 0.6295 - lcm_f1_5k: 0.5127 - lcm_accuracy_1k: 0.8196 - lcm_accuracy_2k: 0.9051 - lcm_accuracy_3k: 0.9455 - lcm_accuracy_5k: 0.9771 - lcm_hamming_loss_k: 0.0300 - val_loss: 0.5792 - val_lcm_precision_1k: 0.7650 - val_lcm_precision_2k: 0.5995 - val_lcm_precision_3k: 0.4834 - val_lcm_precision_5k: 0.3420 - val_lcm_recall_1k: 0.4540 - val_lcm_recall_2k: 0.6524 - val_lcm_recall_3k: 0.7662 - val_lcm_recall_5k: 0.8753 - val_lcm_f1_1k: 0.5687 - val_lcm_f1_2k: 0.6238 - val_lcm_f1_3k: 0.5921 - val_lcm_f1_5k: 0.4914 - val_lcm_accuracy_1k: 0.7650 - val_lcm_accuracy_2k: 0.8713 - val_lcm_accuracy_3k: 0.9289 - val_lcm_accuracy_5k: 0.9674 - val_lcm_hamming_loss_k: 0.0308
Epoch 17/100
11/12 [==========================>...] - ETA: 0s - loss: 0.5131 - lcm_precision_1k: 0.8406 - lcm_precision_2k: 0.6676 - lcm_precision_3k: 0.5300 - lcm_precision_5k: 0.3629 - lcm_recall_1k: 0.4785 - lcm_recall_2k: 0.6989 - lcm_recall_3k: 0.8061 - lcm_recall_5k: 0.8942 - lcm_f1_1k: 0.6097 - lcm_f1_2k: 0.6828 - lcm_f1_3k: 0.6394 - lcm_f1_5k: 0.5163 - lcm_accuracy_1k: 0.8406 - lcm_accuracy_2k: 0.9176 - lcm_accuracy_3k: 0.9538 - lcm_accuracy_5k: 0.9816 - lcm_hamming_loss_k: 0.0291
Epoch 00017: val_loss improved from 0.57922 to 0.56510, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 96ms/step - loss: 0.5122 - lcm_precision_1k: 0.8392 - lcm_precision_2k: 0.6672 - lcm_precision_3k: 0.5307 - lcm_precision_5k: 0.3631 - lcm_recall_1k: 0.4776 - lcm_recall_2k: 0.6995 - lcm_recall_3k: 0.8088 - lcm_recall_5k: 0.8968 - lcm_f1_1k: 0.6086 - lcm_f1_2k: 0.6828 - lcm_f1_3k: 0.6408 - lcm_f1_5k: 0.5169 - lcm_accuracy_1k: 0.8392 - lcm_accuracy_2k: 0.9180 - lcm_accuracy_3k: 0.9539 - lcm_accuracy_5k: 0.9820 - lcm_hamming_loss_k: 0.0290 - val_loss: 0.5651 - val_lcm_precision_1k: 0.7886 - val_lcm_precision_2k: 0.6074 - val_lcm_precision_3k: 0.4868 - val_lcm_precision_5k: 0.3411 - val_lcm_recall_1k: 0.4702 - val_lcm_recall_2k: 0.6642 - val_lcm_recall_3k: 0.7750 - val_lcm_recall_5k: 0.8722 - val_lcm_f1_1k: 0.5883 - val_lcm_f1_2k: 0.6334 - val_lcm_f1_3k: 0.5972 - val_lcm_f1_5k: 0.4900 - val_lcm_accuracy_1k: 0.7886 - val_lcm_accuracy_2k: 0.8778 - val_lcm_accuracy_3k: 0.9295 - val_lcm_accuracy_5k: 0.9658 - val_lcm_hamming_loss_k: 0.0298
Epoch 18/100
11/12 [==========================>...] - ETA: 0s - loss: 0.4902 - lcm_precision_1k: 0.8487 - lcm_precision_2k: 0.6761 - lcm_precision_3k: 0.5366 - lcm_precision_5k: 0.3690 - lcm_recall_1k: 0.4877 - lcm_recall_2k: 0.7112 - lcm_recall_3k: 0.8184 - lcm_recall_5k: 0.9065 - lcm_f1_1k: 0.6193 - lcm_f1_2k: 0.6931 - lcm_f1_3k: 0.6481 - lcm_f1_5k: 0.5244 - lcm_accuracy_1k: 0.8487 - lcm_accuracy_2k: 0.9279 - lcm_accuracy_3k: 0.9595 - lcm_accuracy_5k: 0.9812 - lcm_hamming_loss_k: 0.0288
Epoch 00018: val_loss improved from 0.56510 to 0.55019, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 94ms/step - loss: 0.4887 - lcm_precision_1k: 0.8516 - lcm_precision_2k: 0.6777 - lcm_precision_3k: 0.5364 - lcm_precision_5k: 0.3689 - lcm_recall_1k: 0.4893 - lcm_recall_2k: 0.7130 - lcm_recall_3k: 0.8193 - lcm_recall_5k: 0.9076 - lcm_f1_1k: 0.6214 - lcm_f1_2k: 0.6947 - lcm_f1_3k: 0.6482 - lcm_f1_5k: 0.5245 - lcm_accuracy_1k: 0.8516 - lcm_accuracy_2k: 0.9274 - lcm_accuracy_3k: 0.9596 - lcm_accuracy_5k: 0.9822 - lcm_hamming_loss_k: 0.0286 - val_loss: 0.5502 - val_lcm_precision_1k: 0.8167 - val_lcm_precision_2k: 0.6153 - val_lcm_precision_3k: 0.4916 - val_lcm_precision_5k: 0.3421 - val_lcm_recall_1k: 0.4889 - val_lcm_recall_2k: 0.6757 - val_lcm_recall_3k: 0.7833 - val_lcm_recall_5k: 0.8707 - val_lcm_f1_1k: 0.6106 - val_lcm_f1_2k: 0.6430 - val_lcm_f1_3k: 0.6034 - val_lcm_f1_5k: 0.4907 - val_lcm_accuracy_1k: 0.8167 - val_lcm_accuracy_2k: 0.8933 - val_lcm_accuracy_3k: 0.9354 - val_lcm_accuracy_5k: 0.9602 - val_lcm_hamming_loss_k: 0.0287
Epoch 19/100
12/12 [==============================] - ETA: 0s - loss: 0.4724 - lcm_precision_1k: 0.8629 - lcm_precision_2k: 0.6853 - lcm_precision_3k: 0.5418 - lcm_precision_5k: 0.3702 - lcm_recall_1k: 0.4979 - lcm_recall_2k: 0.7234 - lcm_recall_3k: 0.8275 - lcm_recall_5k: 0.9111 - lcm_f1_1k: 0.6313 - lcm_f1_2k: 0.7037 - lcm_f1_3k: 0.6547 - lcm_f1_5k: 0.5264 - lcm_accuracy_1k: 0.8629 - lcm_accuracy_2k: 0.9375 - lcm_accuracy_3k: 0.9642 - lcm_accuracy_5k: 0.9835 - lcm_hamming_loss_k: 0.0281
Epoch 00019: val_loss improved from 0.55019 to 0.54737, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 93ms/step - loss: 0.4724 - lcm_precision_1k: 0.8629 - lcm_precision_2k: 0.6853 - lcm_precision_3k: 0.5418 - lcm_precision_5k: 0.3702 - lcm_recall_1k: 0.4979 - lcm_recall_2k: 0.7234 - lcm_recall_3k: 0.8275 - lcm_recall_5k: 0.9111 - lcm_f1_1k: 0.6313 - lcm_f1_2k: 0.7037 - lcm_f1_3k: 0.6547 - lcm_f1_5k: 0.5264 - lcm_accuracy_1k: 0.8629 - lcm_accuracy_2k: 0.9375 - lcm_accuracy_3k: 0.9642 - lcm_accuracy_5k: 0.9835 - lcm_hamming_loss_k: 0.0281 - val_loss: 0.5474 - val_lcm_precision_1k: 0.8047 - val_lcm_precision_2k: 0.6225 - val_lcm_precision_3k: 0.4987 - val_lcm_precision_5k: 0.3428 - val_lcm_recall_1k: 0.4858 - val_lcm_recall_2k: 0.6811 - val_lcm_recall_3k: 0.7872 - val_lcm_recall_5k: 0.8757 - val_lcm_f1_1k: 0.6051 - val_lcm_f1_2k: 0.6495 - val_lcm_f1_3k: 0.6098 - val_lcm_f1_5k: 0.4922 - val_lcm_accuracy_1k: 0.8047 - val_lcm_accuracy_2k: 0.8916 - val_lcm_accuracy_3k: 0.9345 - val_lcm_accuracy_5k: 0.9631 - val_lcm_hamming_loss_k: 0.0292
Epoch 20/100
11/12 [==========================>...] - ETA: 0s - loss: 0.4612 - lcm_precision_1k: 0.8747 - lcm_precision_2k: 0.6944 - lcm_precision_3k: 0.5452 - lcm_precision_5k: 0.3727 - lcm_recall_1k: 0.5021 - lcm_recall_2k: 0.7310 - lcm_recall_3k: 0.8305 - lcm_recall_5k: 0.9151 - lcm_f1_1k: 0.6379 - lcm_f1_2k: 0.7122 - lcm_f1_3k: 0.6583 - lcm_f1_5k: 0.5296 - lcm_accuracy_1k: 0.8747 - lcm_accuracy_2k: 0.9474 - lcm_accuracy_3k: 0.9705 - lcm_accuracy_5k: 0.9869 - lcm_hamming_loss_k: 0.0277
Epoch 00020: val_loss improved from 0.54737 to 0.54234, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 93ms/step - loss: 0.4599 - lcm_precision_1k: 0.8743 - lcm_precision_2k: 0.6942 - lcm_precision_3k: 0.5463 - lcm_precision_5k: 0.3732 - lcm_recall_1k: 0.5030 - lcm_recall_2k: 0.7313 - lcm_recall_3k: 0.8317 - lcm_recall_5k: 0.9168 - lcm_f1_1k: 0.6386 - lcm_f1_2k: 0.7122 - lcm_f1_3k: 0.6594 - lcm_f1_5k: 0.5304 - lcm_accuracy_1k: 0.8743 - lcm_accuracy_2k: 0.9470 - lcm_accuracy_3k: 0.9708 - lcm_accuracy_5k: 0.9880 - lcm_hamming_loss_k: 0.0277 - val_loss: 0.5423 - val_lcm_precision_1k: 0.7977 - val_lcm_precision_2k: 0.6195 - val_lcm_precision_3k: 0.4943 - val_lcm_precision_5k: 0.3455 - val_lcm_recall_1k: 0.4844 - val_lcm_recall_2k: 0.6811 - val_lcm_recall_3k: 0.7822 - val_lcm_recall_5k: 0.8785 - val_lcm_f1_1k: 0.6019 - val_lcm_f1_2k: 0.6477 - val_lcm_f1_3k: 0.6050 - val_lcm_f1_5k: 0.4955 - val_lcm_accuracy_1k: 0.7977 - val_lcm_accuracy_2k: 0.8936 - val_lcm_accuracy_3k: 0.9332 - val_lcm_accuracy_5k: 0.9673 - val_lcm_hamming_loss_k: 0.0294
Epoch 21/100
12/12 [==============================] - ETA: 0s - loss: 0.4456 - lcm_precision_1k: 0.8748 - lcm_precision_2k: 0.7001 - lcm_precision_3k: 0.5549 - lcm_precision_5k: 0.3748 - lcm_recall_1k: 0.5055 - lcm_recall_2k: 0.7392 - lcm_recall_3k: 0.8451 - lcm_recall_5k: 0.9205 - lcm_f1_1k: 0.6406 - lcm_f1_2k: 0.7190 - lcm_f1_3k: 0.6698 - lcm_f1_5k: 0.5327 - lcm_accuracy_1k: 0.8748 - lcm_accuracy_2k: 0.9487 - lcm_accuracy_3k: 0.9734 - lcm_accuracy_5k: 0.9861 - lcm_hamming_loss_k: 0.0277
Epoch 00021: val_loss improved from 0.54234 to 0.53801, saving model to logs/kppqpn-lbs-0604-114325/model/checkpoint_lbs.h5
12/12 [==============================] - 1s 94ms/step - loss: 0.4456 - lcm_precision_1k: 0.8748 - lcm_precision_2k: 0.7001 - lcm_precision_3k: 0.5549 - lcm_precision_5k: 0.3748 - lcm_recall_1k: 0.5055 - lcm_recall_2k: 0.7392 - lcm_recall_3k: 0.8451 - lcm_recall_5k: 0.9205 - lcm_f1_1k: 0.6406 - lcm_f1_2k: 0.7190 - lcm_f1_3k: 0.6698 - lcm_f1_5k: 0.5327 - lcm_accuracy_1k: 0.8748 - lcm_accuracy_2k: 0.9487 - lcm_accuracy_3k: 0.9734 - lcm_accuracy_5k: 0.9861 - lcm_hamming_loss_k: 0.0277 - val_loss: 0.5380 - val_lcm_precision_1k: 0.8123 - val_lcm_precision_2k: 0.6272 - val_lcm_precision_3k: 0.4987 - val_lcm_precision_5k: 0.3464 - val_lcm_recall_1k: 0.4847 - val_lcm_recall_2k: 0.6849 - val_lcm_recall_3k: 0.7906 - val_lcm_recall_5k: 0.8769 - val_lcm_f1_1k: 0.6061 - val_lcm_f1_2k: 0.6536 - val_lcm_f1_3k: 0.6108 - val_lcm_f1_5k: 0.4961 - val_lcm_accuracy_1k: 0.8123 - val_lcm_accuracy_2k: 0.8920 - val_lcm_accuracy_3k: 0.9427 - val_lcm_accuracy_5k: 0.9642 - val_lcm_hamming_loss_k: 0.0289
Epoch 22/100
11/12 [==========================>...] - ETA: 0s - loss: 0.4291 - lcm_precision_1k: 0.8952 - lcm_precision_2k: 0.7118 - lcm_precision_3k: 0.5614 - lcm_precision_5k: 0.3791 - lcm_recall_1k: 0.5173 - lcm_recall_2k: 0.7485 - lcm_recall_3k: 0.8533 - lcm_recall_5k: 0.9314 - lcm_f1_1k: 0.6556 - lcm_f1_2k: 0.7296 - lcm_f1_3k: 0.6772 - lcm_f1_5k: 0.5388 - lcm_accuracy_1k: 0.8952 - lcm_accuracy_2k: 0.9528 - lcm_accuracy_3k: 0.9744 - lcm_accuracy_5k: 0.9904 - lcm_hamming_loss_k: 0.0267
Epoch 00022: val_loss did not improve from 0.53801
12/12 [==============================] - 1s 64ms/step - loss: 0.4293 - lcm_precision_1k: 0.8980 - lcm_precision_2k: 0.7128 - lcm_precision_3k: 0.5612 - lcm_precision_5k: 0.3786 - lcm_recall_1k: 0.5195 - lcm_recall_2k: 0.7498 - lcm_recall_3k: 0.8527 - lcm_recall_5k: 0.9294 - lcm_f1_1k: 0.6582 - lcm_f1_2k: 0.7308 - lcm_f1_3k: 0.6768 - lcm_f1_5k: 0.5379 - lcm_accuracy_1k: 0.8980 - lcm_accuracy_2k: 0.9551 - lcm_accuracy_3k: 0.9755 - lcm_accuracy_5k: 0.9907 - lcm_hamming_loss_k: 0.0268 - val_loss: 0.5399 - val_lcm_precision_1k: 0.7974 - val_lcm_precision_2k: 0.6261 - val_lcm_precision_3k: 0.4990 - val_lcm_precision_5k: 0.3441 - val_lcm_recall_1k: 0.4778 - val_lcm_recall_2k: 0.6830 - val_lcm_recall_3k: 0.7920 - val_lcm_recall_5k: 0.8788 - val_lcm_f1_1k: 0.5964 - val_lcm_f1_2k: 0.6522 - val_lcm_f1_3k: 0.6115 - val_lcm_f1_5k: 0.4940 - val_lcm_accuracy_1k: 0.7974 - val_lcm_accuracy_2k: 0.8953 - val_lcm_accuracy_3k: 0.9453 - val_lcm_accuracy_5k: 0.9692 - val_lcm_hamming_loss_k: 0.0295
Epoch 23/100
11/12 [==========================>...] - ETA: 0s - loss: 0.4186 - lcm_precision_1k: 0.8920 - lcm_precision_2k: 0.7111 - lcm_precision_3k: 0.5620 - lcm_precision_5k: 0.3802 - lcm_recall_1k: 0.5176 - lcm_recall_2k: 0.7520 - lcm_recall_3k: 0.8579 - lcm_recall_5k: 0.9335 - lcm_f1_1k: 0.6549 - lcm_f1_2k: 0.7309 - lcm_f1_3k: 0.6790 - lcm_f1_5k: 0.5402 - lcm_accuracy_1k: 0.8920 - lcm_accuracy_2k: 0.9549 - lcm_accuracy_3k: 0.9801 - lcm_accuracy_5k: 0.9901 - lcm_hamming_loss_k: 0.0269
Epoch 00023: val_loss did not improve from 0.53801
12/12 [==============================] - 1s 59ms/step - loss: 0.4181 - lcm_precision_1k: 0.8924 - lcm_precision_2k: 0.7130 - lcm_precision_3k: 0.5642 - lcm_precision_5k: 0.3816 - lcm_recall_1k: 0.5159 - lcm_recall_2k: 0.7517 - lcm_recall_3k: 0.8581 - lcm_recall_5k: 0.9334 - lcm_f1_1k: 0.6537 - lcm_f1_2k: 0.7317 - lcm_f1_3k: 0.6807 - lcm_f1_5k: 0.5417 - lcm_accuracy_1k: 0.8924 - lcm_accuracy_2k: 0.9549 - lcm_accuracy_3k: 0.9802 - lcm_accuracy_5k: 0.9898 - lcm_hamming_loss_k: 0.0270 - val_loss: 0.5418 - val_lcm_precision_1k: 0.7905 - val_lcm_precision_2k: 0.6266 - val_lcm_precision_3k: 0.5031 - val_lcm_precision_5k: 0.3444 - val_lcm_recall_1k: 0.4698 - val_lcm_recall_2k: 0.6830 - val_lcm_recall_3k: 0.7929 - val_lcm_recall_5k: 0.8745 - val_lcm_f1_1k: 0.5886 - val_lcm_f1_2k: 0.6525 - val_lcm_f1_3k: 0.6148 - val_lcm_f1_5k: 0.4937 - val_lcm_accuracy_1k: 0.7905 - val_lcm_accuracy_2k: 0.8925 - val_lcm_accuracy_3k: 0.9408 - val_lcm_accuracy_5k: 0.9668 - val_lcm_hamming_loss_k: 0.0297
Epoch 00023: early stopping
39/39 [==============================] - 1s 20ms/step - loss: 0.4812 - lcm_precision_1k: 0.8831 - lcm_precision_2k: 0.6987 - lcm_precision_3k: 0.5462 - lcm_precision_5k: 0.3739 - lcm_recall_1k: 0.4983 - lcm_recall_2k: 0.7230 - lcm_recall_3k: 0.8241 - lcm_recall_5k: 0.9090 - lcm_f1_1k: 0.6361 - lcm_f1_2k: 0.7097 - lcm_f1_3k: 0.6560 - lcm_f1_5k: 0.5292 - lcm_accuracy_1k: 0.8831 - lcm_accuracy_2k: 0.9436 - lcm_accuracy_3k: 0.9700 - lcm_accuracy_5k: 0.9804 - lcm_hamming_loss_k: 0.0278
Best model result:  [0.4812168478965759, 0.8830744624137878, 0.698748767375946, 0.5461538434028625, 0.37393075227737427, 0.49827688932418823, 0.723010241985321, 0.8241102695465088, 0.9090486168861389, 0.6361492872238159, 0.709681510925293, 0.6559820175170898, 0.5292193293571472, 0.8830744624137878, 0.9435511827468872, 0.9699998497962952, 0.980417788028717, 0.02783080004155636]
fold_result:  [[0.41830337047576904, 0.8951692581176758, 0.7152538299560547, 0.5653231143951416, 0.3805307447910309, 0.5162205100059509, 0.7495743632316589, 0.8528359532356262, 0.9243797063827515, 0.6537653803825378, 0.7309410572052002, 0.6789171099662781, 0.5384482741355896, 0.8951692581176758, 0.9648255705833435, 0.9788126945495605, 0.9884229898452759, 0.027337245643138885], [0.45892876386642456, 0.8618846535682678, 0.6977666616439819, 0.5535179376602173, 0.3769744336605072, 0.4929641783237457, 0.7306179404258728, 0.8354102969169617, 0.9161770343780518, 0.62613445520401, 0.7127858400344849, 0.6648779511451721, 0.5334470868110657, 0.8618846535682678, 0.9467639327049255, 0.9732100367546082, 0.9879922270774841, 0.028696002438664436], [0.49299129843711853, 0.8699026107788086, 0.6827564239501953, 0.5424359440803528, 0.37145641446113586, 0.49218201637268066, 0.7110255360603333, 0.8194102048873901, 0.9027256369590759, 0.627765417098999, 0.6957476139068604, 0.6518357992172241, 0.5256658792495728, 0.8699026107788086, 0.9359768629074097, 0.9651870727539062, 0.9812203645706177, 0.028368953615427017], [0.5451341867446899, 0.8334846496582031, 0.6489666700363159, 0.5155153870582581, 0.3557794392108917, 0.47037437558174133, 0.6753000617027283, 0.7805308103561401, 0.8685154318809509, 0.6003402471542358, 0.6609346270561218, 0.6199430227279663, 0.5040566921234131, 0.8334846496582031, 0.9043513536453247, 0.9387434720993042, 0.9631487727165222, 0.029855556786060333], [0.4812168478965759, 0.8830744624137878, 0.698748767375946, 0.5461538434028625, 0.37393075227737427, 0.49827688932418823, 0.723010241985321, 0.8241102695465088, 0.9090486168861389, 0.6361492872238159, 0.709681510925293, 0.6559820175170898, 0.5292193293571472, 0.8830744624137878, 0.9435511827468872, 0.9699998497962952, 0.980417788028717, 0.02783080004155636]]
average_result:  [0.4793148934841156, 0.8687031269073486, 0.6886984705924988, 0.5445892453193665, 0.37173435688018797, 0.4940035939216614, 0.7179056286811829, 0.8224595069885254, 0.9041692852973938, 0.6288309574127198, 0.7020181298255921, 0.6543111801147461, 0.5261674523353577, 0.8687031269073486, 0.9390937805175781, 0.9651906251907348, 0.9802404284477234, 0.028417711704969408]
2024-06-04 11:43:53,245 : INFO : =======End=======
