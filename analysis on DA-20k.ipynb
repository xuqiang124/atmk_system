{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    for DataSet DA-20k\n",
    "    LHABS:   'tbpcqi-labs-0604-122216'\n",
    "    LBS:    'dgfzzb-lbs-0604-124454'\n",
    "    LHAB:    'ynukky-lab-0604-133426'\n",
    "    Basic:  'gkrqzx-b-0608-122552'\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and get the attention layer\n",
    "'''\n",
    "LHABS\tlogs/DA-20k/cut/LHABS/tbpcqi-labs-0604-122216/model/checkpoint_labs.h5\n",
    "LHAB    logs/DA-20k/cut/LHAB/iwprfa-lab-0604-133738/model/checkpoint_lab.h5\n",
    "LBS    logs/DA-20k/cut/LBS/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5\n",
    "'''\n",
    "%cd MathByte\n",
    "from models.evaluation_metrics import precision_1k,precision_2k, precision_3k, precision_5k, recall_1k, recall_2k,recall_3k, recall_5k, F1_1k,F1_2k, F1_3k, F1_5k, lcm_metrics\n",
    "import models.lstm\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Flatten, Dropout, Concatenate, Lambda, Multiply, Reshape, Dot, Bidirectional\n",
    "import keras.backend as K\n",
    "import utils\n",
    "\n",
    "\n",
    "logdir = \"logs/DA-20k/cut/LBS/dgfzzb-lbs-0604-124454/model/checkpoint_lbs.h5\"\n",
    "use_att = \"_labs\" in logdir or \"_lab\" in logdir\n",
    "use_lcm = \"_labs\" in logdir or \"_lbs\" in logdir\n",
    "if use_att:\n",
    "    layer_name_0 = \"0_attention_layer_att_weight\"\n",
    "    layer_name_1 = \"1_attention_layer_att_weight\" # att_context\n",
    "loss, metrics = lcm_metrics(427, 4)\n",
    "\n",
    "saved_model = load_model(logdir, custom_objects={\n",
    "    \"K\": K,\n",
    "    \"precision_1k\": precision_1k,\n",
    "    \"precision_2k\": precision_2k,\n",
    "    \"precision_3k\": precision_3k,\n",
    "    \"precision_5k\": precision_5k,\n",
    "    \"recall_1k\": recall_1k,\n",
    "    \"recall_2k\": recall_2k,\n",
    "    \"recall_3k\": recall_3k,\n",
    "    \"recall_5k\": recall_5k,\n",
    "    \"F1_1k\": F1_1k,\n",
    "    \"F1_2k\": F1_2k,\n",
    "    \"F1_3k\": F1_3k,\n",
    "    \"F1_5k\": F1_5k,\n",
    "    \"lcm_loss\": loss,\n",
    "    \"lcm_precision_1k\": metrics[0],\n",
    "    \"lcm_precision_2k\": metrics[1],\n",
    "    \"lcm_precision_3k\": metrics[2],\n",
    "    \"lcm_precision_5k\": metrics[3],\n",
    "    \"lcm_recall_1k\": metrics[4],\n",
    "    \"lcm_recall_2k\": metrics[5],\n",
    "    \"lcm_recall_3k\": metrics[6],\n",
    "    \"lcm_recall_5k\": metrics[7],\n",
    "    \"lcm_f1_1k\": metrics[8],\n",
    "    \"lcm_f1_2k\": metrics[9],\n",
    "    \"lcm_f1_3k\": metrics[10],\n",
    "    \"lcm_f1_5k\": metrics[11],\n",
    "    \"lcm_accuracy_1k\": metrics[12],\n",
    "    \"lcm_accuracy_2k\": metrics[13],\n",
    "    \"lcm_accuracy_3k\": metrics[14],\n",
    "    \"lcm_accuracy_5k\": metrics[15],\n",
    "    \"lcm_hamming_loss_k\": metrics[16]\n",
    "},compile = False)\n",
    "# saved_model.summary()\n",
    "print(saved_model.summary())\n",
    "if use_att:\n",
    "    model = Model(inputs=saved_model.input,outputs=[saved_model.output, saved_model.get_layer(layer_name_0).output, saved_model.get_layer(layer_name_1).output])\n",
    "else:\n",
    "    model = Model(inputs=saved_model.input,outputs=[[saved_model.output]])\n",
    "print(use_lcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> 427 82595\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "import h5py\n",
    "import numpy as np\n",
    "f_data = h5py.File('../file_data/DA-20k/math_data_cut.h5', 'r')\n",
    "import pickle\n",
    "cache_file_pickle = \"../file_data/DA-20k/vocab_label.pkl\"\n",
    "word2index, label2index = None, None\n",
    "with open(cache_file_pickle, 'rb') as data_f_pickle:\n",
    "    word2index, label2index = pickle.load(data_f_pickle)\n",
    "index2word = {}\n",
    "index2label = {}\n",
    "for key in word2index:\n",
    "  index2word[word2index[key]] = key\n",
    "for key in label2index:\n",
    "  index2label[label2index[key]] = key\n",
    "print(index2word[0], len(label2index), len(index2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n",
      "107\n",
      "[[  59    3  965 ...    0    0    0]\n",
      " [  96    3   32 ...    0    0    0]\n",
      " [ 105    3   32 ...    0    0    0]\n",
      " ...\n",
      " [ 126    3   78 ...    0    0    0]\n",
      " [ 130    3    4 ...    0    0    0]\n",
      " [ 133    3 4341 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# use the TestSet to test the model\n",
    "test_X = f_data['X'][()][16893:17000] # id 50779 index 5457  # id 45936 index 641  # id 62271 index 16893\n",
    "test_Y = f_data['y'][()][16893:17000]\n",
    "L_test = np.array([np.array(range(442))\n",
    "                          for i in range(len(test_X))])\n",
    "print(len(test_X))\n",
    "print(len(test_Y))\n",
    "print(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the weights of the model\n",
    "outputs = model.predict([test_X, L_test],batch_size = 512)\n",
    "model_outputs = outputs[0]\n",
    "if use_att:\n",
    "  attention_outputs_0 = outputs[1]\n",
    "  attention_outputs_1 = outputs[2]\n",
    "if use_lcm:\n",
    "  # lcm model\n",
    "  model_outputs = model_outputs[:, :427]\n",
    "def sigmoid(z):\n",
    "  return 1/(1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "which_one = 0\n",
    "# before the prediction i supposed you tokenized text\n",
    "tokenized_text = [index2word[item] for item in test_X[which_one]]\n",
    "# if you are using batches the outputs will be in batches\n",
    "# get exact attentions of chars\n",
    "level_1_attention = []\n",
    "labels = []\n",
    "for i, val in enumerate(test_Y[which_one]):\n",
    "  if val==1:\n",
    "    labels.append(index2label[i])\n",
    "    if use_att:\n",
    "      level_1_attention.append(attention_outputs_1[which_one][i])\n",
    "\n",
    "pred_labels = []\n",
    "rank_mat = np.argsort(model_outputs[which_one])\n",
    "backup = np.copy(model_outputs[which_one])\n",
    "# for m in range(len(labels)):\n",
    "for m in range(3):\n",
    "  y_pred = np.copy(backup)\n",
    "  y_pred[rank_mat[:-(m + 1)]] = 0\n",
    "  y_pred = np.ceil(y_pred)\n",
    "for i, val in enumerate(y_pred):\n",
    "  if val==1:\n",
    "    pred_labels.append(index2label[i])\n",
    "print(','.join(tokenized_text))\n",
    "print(\"True knowledge concepts:\", labels)\n",
    "print(\"Pred knowledge concepts:\", pred_labels)\n",
    "\n",
    "level_1_attention_output = np.mean(np.array(level_1_attention),axis=0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 get the distribution of label-semantic attention\n",
    "class CharVal(object):\n",
    "    def __init__(self, char, val):\n",
    "        self.char = char\n",
    "        self.val = val\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.char\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#%02x%02x%02x' % rgb\n",
    "def color_charvals(s):\n",
    "    r = 255-int(s.val*255) # 100\n",
    "    if r > 120:\n",
    "      r = 255\n",
    "    color = rgb_to_hex((255, r, r))\n",
    "    return 'background-color: %s' % color\n",
    "\n",
    "if use_att:\n",
    "    # you need to match each char and attention\n",
    "    char_vals = [CharVal(c, v) for c, v in zip(tokenized_text, level_1_attention_output)]\n",
    "    import pandas as pd\n",
    "    char_df = pd.DataFrame(char_vals).transpose()\n",
    "    # apply coloring values\n",
    "    char_df = char_df.style.applymap(color_charvals)\n",
    "char_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Analysis of multi-label smoothing combining textual features\n",
    "if use_lcm:\n",
    "  outs = outputs[0] # output\n",
    "  label_sim_dist = outs[:, 427:] # lcm simulated labels\n",
    "  pred_probs = outs[:, :427] # lcm predicted labels\n",
    "  simulated_y_true = K.softmax(label_sim_dist+4*test_Y)\n",
    "\n",
    "  which_simulated_y = simulated_y_true[which_one] # simulated labels\n",
    "  ground_y = test_Y[which_one] # ground truth\n",
    "  pred = K.softmax(pred_probs[which_one]) # predicted labels\n",
    "\n",
    "  import matplotlib.pyplot as plt\n",
    "  x_data = [i for i in range(427)]\n",
    "  # draw the simulated label distribution\n",
    "  plt.plot(x_data,which_simulated_y,color='blue')\n",
    "  for i in range(len(x_data)):\n",
    "    if(ground_y[i]==1):\n",
    "      plt.vlines(i, 0, 0.2, colors = \"orange\", linestyles = \"dashed\")\n",
    "  plt.show()\n",
    "  # draw the predicted label distribution\n",
    "  plt.plot(x_data,pred_probs[which_one],color='blue')\n",
    "  for i in range(len(x_data)):\n",
    "    if(ground_y[i]==1):\n",
    "      plt.vlines(i, 0, 1, colors = \"orange\", linestyles = \"dashed\")\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atmk11111",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
